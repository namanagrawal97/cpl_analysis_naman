{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import glob\n",
    "import getpass\n",
    "import importlib\n",
    "import functions\n",
    "import spectrogram_plotting_functions\n",
    "importlib.reload(functions)\n",
    "importlib.reload(spectrogram_plotting_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "files = glob.glob(base+'\\\\all_data_mat\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard_dict={'98':'b','119':'w','120':'nc','49':'1','48':'0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230616_dk6_BW_context_day2.mat']\n",
    "event_data_df=[]\n",
    "con_data_df=[]\n",
    "shuffled_event_data_df=[]\n",
    "events_codes_all = {}\n",
    "random_baseline_data=[]\n",
    "baseline_lfp_all=[]\n",
    "\n",
    "for file_num,file in enumerate(files):\n",
    "    #if 'dk1' in file:\n",
    "        \n",
    "        print(file)\n",
    "        base_name = os.path.basename(file)\n",
    "        base_name, _ = os.path.splitext(base_name)\n",
    "\n",
    "        date, rat_id, task = functions.exp_params(base_name)\n",
    "        print(date, rat_id, task)\n",
    "        if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "            task = 'nocontext'\n",
    "        print(date, rat_id, task)\n",
    "\n",
    "        f = h5py.File(file, 'r')\n",
    "        channels = list(f.keys())\n",
    "        print(channels)\n",
    "\n",
    "\n",
    "\n",
    "        if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "            print(\"No AON or vHp channels in this file\")\n",
    "            continue\n",
    "\n",
    "        events,reference_electrode=functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "        global_start_time, global_end_time=functions.find_global_start_end_times(f,channels)\n",
    "        \n",
    "        ## Reference electrode finding and padding\n",
    "        reference_time = np.array(reference_electrode['times']).flatten()\n",
    "        reference_value = np.array(reference_electrode['values']).flatten()\n",
    "        padd_ref_data,padded_ref_time=functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "        events_codes = np.array(events['codes'][0])\n",
    "        events_times = np.array(events['times'][0])\n",
    "        events_codes_all[base_name] = events_codes\n",
    "        epochs = functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "        #epochs = functions.generate_specific_num_of_epochs_with_first_event(events_codes, events_times,5)\n",
    "        aon_lfp_channels=[x for x in channels if 'AON' in x ]\n",
    "        vHp_lfp_channels=[x for x in channels if 'vHp' in x ]\n",
    "        all_channels=np.concatenate((aon_lfp_channels,vHp_lfp_channels))\n",
    "        print(all_channels)\n",
    "        \n",
    "        mne_baseline_data=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before=np.zeros((len(epochs),len(all_channels),4000))\n",
    "        mne_epoch_door_after=np.zeros((len(epochs),len(all_channels),4000))\n",
    "        mne_epoch_dig_before=np.zeros((len(epochs),len(all_channels),4000))\n",
    "        mne_epoch_dig_after=np.zeros((len(epochs),len(all_channels),4000))\n",
    "        \n",
    "        first_event = events_times[0]\n",
    "        \n",
    "        for channel_num,channeli in enumerate(all_channels):\n",
    "            if \"AON\" in channeli or \"vHp\" in channeli:\n",
    "                channel_id = channeli\n",
    "                data_all = f[channeli]\n",
    "                raw_data = np.array(data_all['values']).flatten()\n",
    "                raw_time = np.array(data_all['times']).flatten()\n",
    "                sampling_rate = int(1 / data_all['interval'][0][0])\n",
    "                print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "                \n",
    "                padded_data,padded_time=functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "                subtracted_data = padded_data - padd_ref_data\n",
    "                raw_data=subtracted_data\n",
    "                \n",
    "                notch_filtered_data = functions.iir_notch(raw_data, sampling_rate, 60)\n",
    "                \n",
    "                data_before, time, baseline_mean, baseline_std=functions.baseline_data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "                normalized_data=functions.zscore_event_data(notch_filtered_data, baseline_mean, baseline_std)\n",
    "\n",
    "                #baseline_row=[rat_id,task,channel_id,[data_before]]\n",
    "                #baseline_lfp_all.append(baseline_row)\n",
    "                #normalized_data, time, data_before = functions.data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "                baseline_data_truncated= data_before[-4000:]\n",
    "                \n",
    "                mne_baseline_data[0,channel_num,:]=list(baseline_data_truncated)\n",
    "                \n",
    "                total = normalized_data\n",
    "\n",
    "                \n",
    "                for i, epochi in enumerate(epochs):\n",
    "                    door_timestamp = epochi[0][0]\n",
    "                    trial_type = epochi[0][1]\n",
    "                    dig_type = epochi[1, 1]\n",
    "                    print(dig_type)\n",
    "                    dig_timestamp = epochi[1, 0]\n",
    "                    print(door_timestamp, trial_type, dig_timestamp, dig_type)\n",
    "                    data_complete_trial = functions.extract_complete_trial_data(total, time, door_timestamp, dig_timestamp, sampling_rate)\n",
    "                    #Here we will extract and store the events data\n",
    "                    data_door_before,data_door_after=functions.extract_door_data(total, time, door_timestamp, sampling_rate)    \n",
    "                    data_dig_before, data_dig_after=functions.extract_dig_data(total,time, dig_timestamp, sampling_rate)\n",
    "                    event_data_list=[data_door_before,data_door_after,data_dig_before,data_dig_after]\n",
    "                    [functions.zscore_event_data(event_data, baseline_mean ,baseline_std) for event_data in event_data_list]\n",
    "                    mne_epoch_door_before[i,channel_num,:]=list(event_data_list[0])\n",
    "                    mne_epoch_door_after[i,channel_num,:]=list(event_data_list[1])\n",
    "                    mne_epoch_dig_before[i,channel_num,:]=list(event_data_list[2])\n",
    "                    mne_epoch_dig_after[i,channel_num,:]=list(event_data_list[3])\n",
    "        if len(all_channels)>0:\n",
    "            fs=2000\n",
    "            freqs = np.arange(1,100)\n",
    "            n_cycles = freqs/2\n",
    "            info = mne.create_info(ch_names=list(all_channels), sfreq=fs, ch_types='eeg')\n",
    "            mne_baseline = mne.EpochsArray(mne_baseline_data, info)\n",
    "            mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "            mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "            mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "            mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "            row_list=[file_num,rat_id,task,mne_baseline,mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after]\n",
    "            con_data_df.append(row_list)\n",
    "\n",
    "        # fs=2000\n",
    "        # freqs = np.arange(1,100)\n",
    "        # n_cycles = freqs/2\n",
    "        # info = mne.create_info(ch_names=list(all_channels), sfreq=fs, ch_types='eeg')\n",
    "        # mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "        # mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "        # mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "        # mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "        # row_list=[rat_id,task,mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after]\n",
    "        # con_data_df.append(row_list)\n",
    "#baseline_lfp_all = pd.DataFrame(baseline_lfp_all, columns=['rat', 'experiment', 'channel', 'data'])\n",
    "con_data_df=pd.DataFrame(con_data_df, columns=['experiment','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df=pd.DataFrame(con_data_df, columns=['rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'])\n",
    "\n",
    "BWcontext_data=con_data_df[(con_data_df['task']=='BWnocontext') & (con_data_df['rat_id']!='dk3')]\n",
    "print(BWcontext_data.shape)\n",
    "fig,axs=plt.subplots(3,4, sharex=True, sharey=True, figsize=(20,10))\n",
    "axs=axs.flatten()\n",
    "fig.suptitle('BW Context Post Door AON-vHp Granger Causality')\n",
    "for trial in range(BWcontext_data.shape[0]):\n",
    "    trial_epoch=BWcontext_data['mne_epoch_door_after'].iloc[trial]\n",
    "    print(\"trial_epoch\")\n",
    "    trial_id =f\"{BWcontext_data['rat_id'].iloc[trial]} {BWcontext_data['task'].iloc[trial]}\"\n",
    "    print(trial_id)\n",
    "    aon_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(trial_epoch.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "    print(aon_signals)\n",
    "    vhp_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(trial_epoch.info[\"chs\"])\n",
    "        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "    print(vhp_signals)\n",
    "\n",
    "    indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "    indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "    gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "        trial_epoch,\n",
    "        method=[\"gc\"],\n",
    "        indices=indices_aon_vhp,\n",
    "        fmin=2.5,\n",
    "        fmax=100,\n",
    "        rank=None,\n",
    "        gc_n_lags=20,\n",
    "    )\n",
    "    freqs = gc_ab.freqs\n",
    "\n",
    "    gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "        trial_epoch,\n",
    "        method=[\"gc\"],\n",
    "        indices=indices_vhp_aon,\n",
    "        fmin=2.5,\n",
    "        fmax=100,\n",
    "        rank=None,\n",
    "        gc_n_lags=20,\n",
    "    )\n",
    "    freqs = gc_ba.freqs\n",
    "\n",
    "    net_gc = gc_ab.get_data() - gc_ba.get_data()  # [A => B] - [B => A]\n",
    "    ax=axs[trial]\n",
    "    ax.plot((freqs[0], freqs[-1]), (0, 0), linewidth=2, linestyle=\"--\", color=\"k\")\n",
    "    ax.plot(freqs, net_gc[0], linewidth=2)\n",
    "    ax.set_title(f\"{BWcontext_data['rat_id'].iloc[trial]} \", fontsize=8)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\BWnocontext_post_door_aon_vhp_gc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SpectralConnectivity | freq : [2.500000, 100.000000], , nave : 20, nodes, n_estimated : 4, 1, ~136 kB>\n",
      "(1, 196)\n"
     ]
    }
   ],
   "source": [
    "print(gc_ab)\n",
    "print(gc_ab.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df=pd.DataFrame(con_data_df, columns=['rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'])\n",
    "con_data_df_clean=con_data_df[con_data_df['rat_id']!='dk3']\n",
    "\n",
    "\n",
    "events_dict={'mne_epoch_door_before':'door before','mne_epoch_door_after':'door after','mne_epoch_dig_before':'dig before','mne_epoch_dig_after':'dig after'}\n",
    "\n",
    "def calculate_net_gc(mne_data):\n",
    "        aon_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(aon_signals)\n",
    "        vhp_signals=[\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "            if \"vHp\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(vhp_signals)\n",
    "\n",
    "        indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "        indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "\n",
    "        gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "        mne_data,\n",
    "        method=[\"gc\"],\n",
    "        indices=indices_aon_vhp,\n",
    "        fmin=2.5,\n",
    "        fmax=100,\n",
    "        rank=None,\n",
    "        gc_n_lags=20,\n",
    "        )\n",
    "        freqs = gc_ab.freqs\n",
    "\n",
    "        gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "            mne_data,\n",
    "            method=[\"gc\"],\n",
    "            indices=indices_vhp_aon,\n",
    "            fmin=2.5,\n",
    "            fmax=100,\n",
    "            rank=None,\n",
    "            gc_n_lags=20,\n",
    "        )\n",
    "        freqs = gc_ba.freqs\n",
    "\n",
    "        net_gc = gc_ab.get_data() - gc_ba.get_data()\n",
    "        return net_gc[0], freqs\n",
    "\n",
    "gc_data_df=pd.DataFrame()\n",
    "gc_data_df['rat_id']=con_data_df_clean['rat_id']\n",
    "gc_data_df['task']=con_data_df_clean['task']\n",
    "gc_data_df['door_before']=con_data_df_clean['mne_epoch_door_before'].apply(lambda x: calculate_net_gc(x)[0])\n",
    "gc_data_df['door_after']=con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_net_gc(x)[0])\n",
    "gc_data_df['dig_before']=con_data_df_clean['mne_epoch_dig_before'].apply(lambda x: calculate_net_gc(x)[0])\n",
    "gc_data_df['dig_after']=con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_net_gc(x)[0])\n",
    "\n",
    "gc_data_df['freqs']=con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_net_gc(x)[1])\n",
    "\n",
    "gc_data_df=pd.DataFrame(gc_data_df, columns=['rat_id','task','door_before','door_after','dig_before','dig_after', 'freqs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "gc_data_df_bwcontext=gc_data_df[gc_data_df['task']=='BWcontext']\n",
    "gc_data_df_bwnocontext=gc_data_df[gc_data_df['task']=='BWnocontext']\n",
    "\n",
    "fig,axs=plt.subplots(2,2, sharex=True, sharey=True, figsize=(20,10))\n",
    "axs=axs.flatten()\n",
    "fig.suptitle('BW Context vs  BW No Context AON-vHp Granger Causality')\n",
    "events_dict={'door_before': 'Door Before','door_after': 'Door After','dig_before': 'Dig Before','dig_after': 'Dig After'}\n",
    "for i,event in enumerate(events_dict.keys()):\n",
    "    ax=axs[i]\n",
    "    bwcontext_mean=np.mean(gc_data_df_bwcontext[event], axis=0)\n",
    "    bwnocontext_mean=np.mean(gc_data_df_bwnocontext[event], axis=0)\n",
    "    bwcontext_sem=scipy.stats.sem(gc_data_df_bwcontext[event], axis=0)\n",
    "    bwnocontext_sem=scipy.stats.sem(gc_data_df_bwnocontext[event], axis=0)\n",
    "\n",
    "    ax.plot((freqs[0], freqs[-1]), (0, 0), linewidth=2, linestyle=\"--\", color=\"k\")\n",
    "    ax.axvspan(4,8, alpha=0.2, color='red', label='Theta Range')\n",
    "    ax.axvspan(12,20, alpha=0.2, color='green', label='Beta Range')\n",
    "    ax.axvspan(30,80, alpha=0.2, color='grey', label='Gamma Range')\n",
    "    ax.plot(freqs, bwcontext_mean, linewidth=2, label='BWcontext mean')\n",
    "    ax.fill_between(freqs, bwcontext_mean - bwcontext_sem, bwcontext_mean + bwcontext_sem, alpha=0.2, label='BWcontext SEM')\n",
    "    ax.plot(freqs, gc_data_df_bwnocontext[event].mean(), linewidth=2, label='BW no context mean')\n",
    "    ax.fill_between(freqs, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, alpha=0.2, label='BW no context SEM')    \n",
    "    ax.set_title(f\"{events_dict[event]}\", fontsize=8)\n",
    "    ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\GC_BWcontext_vs_BWnocontext_AON_vHp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Boxplots for GC measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#%matplotlib qt\n",
    "bands_dict={'total':[2.5,100],'theta': [4,8],'beta':[12,20],'gamma':[30,80]}\n",
    "\n",
    "def calculate_gc_per_band(gc_array,freqs_array, bands_dict):\n",
    "    freqs_array = np.array(freqs_array)  # Convert freqs_array to numpy array\n",
    "    gc_bands_dict={}\n",
    "    for band in bands_dict.keys():\n",
    "        band_indices=np.where((freqs_array>=bands_dict[band][0]) & (freqs_array<=bands_dict[band][1]))\n",
    "        gc_band=gc_array[band_indices]\n",
    "\n",
    "        gc_bands_dict[band]=(np.sum(gc_band)*0.5)/len(gc_band)\n",
    "\n",
    "    return gc_bands_dict\n",
    "\n",
    "test_gc=gc_data_df_bwcontext['door_before'].iloc[0]\n",
    "test_freqs=gc_data_df_bwcontext['freqs'].iloc[0]\n",
    "test_gc_band=calculate_gc_per_band(test_gc,test_freqs, bands_dict)\n",
    "\n",
    "gc_cols = ['door_before', 'door_after', 'dig_before', 'dig_after']\n",
    "gc_data_df_bands = []\n",
    "\n",
    "for index, row in gc_data_df.iterrows():\n",
    "    rat_id = row['rat_id']\n",
    "    task = row['task']\n",
    "    freqs = row['freqs']\n",
    "    for gc_col in gc_cols:\n",
    "        gc_values = calculate_gc_per_band(row[gc_col], freqs, bands_dict)\n",
    "        for band, gc_value in gc_values.items():\n",
    "            gc_data_df_bands.append({\n",
    "                'rat_id': rat_id,\n",
    "                'task': task,\n",
    "                'event': gc_col,\n",
    "                'band': band,\n",
    "                'gcvalue': gc_value\n",
    "            })\n",
    "\n",
    "gc_data_df_bands = pd.DataFrame(gc_data_df_bands)\n",
    "gc_data_df_bands=gc_data_df_bands[gc_data_df_bands['task']!='nocontext']\n",
    "print(gc_data_df_bands)\n",
    "\n",
    "fig, axs=plt.subplots(2,2, sharex=False, sharey=True, figsize=(20,10))\n",
    "axs=axs.flatten()\n",
    "fig.suptitle('Average Net AON -> vHp granger causality per band')\n",
    "for i, event in enumerate(gc_cols):\n",
    "    print(i, event)\n",
    "    ax=axs[i]\n",
    "    gc_event=gc_data_df_bands[gc_data_df_bands['event']==event]\n",
    "    ax.axhline(0, color='black', lw=1)\n",
    "    sns.boxplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,showfliers=False, ax=ax)\n",
    "    sns.stripplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax)\n",
    "    ax.set_title(f\"{event}\", fontsize=10)\n",
    "    ax.set_xlabel('')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\GC_net_AoN_vHp.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
