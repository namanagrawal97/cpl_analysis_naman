{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import functions\n",
    "\n",
    "importlib.reload(functions)\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('compiled_data_power.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk1_nocontext_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk3_nocontext_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk5_nocontext_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk6_nocontext_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230531_dk1_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230531_dk3_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230531_dk5_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230531_dk6_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230609_dk1_BW_nocontext_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230609_dk3_BW_nocontext_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230610_dk1_BW_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230610_dk3_BW_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230615_dk5_BW_context_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230615_dk6_BW_context_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230616_dk5_BW_context_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230616_dk6_BW_context_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230623_dk1_BW_context_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230626_dk1_BW_context_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230626_dk5_BW_nocontext_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230626_dk6_BW_nocontext_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230627_dk1_BW_context_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230627_dk5_BW_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230628_dk6_BW_nocontext_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230718_dk1_nocontext_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230718_dk5_nocontext_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230718_dk6_nocontext_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230719_dk1_nocontext_os2_day2_part1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230719_dk1_nocontext_os2_day2_part2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230719_dk5_nocontext_os2_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230719_dk6_nocontext_os2_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230807_dk3_BW_context_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230808_dk3_BW_context_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230808_dk5_BW_nocontext_day1_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230808_dk6_BW_nocontext_day1_os2[discard]_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230810_dk5_BW_nocontext_day2_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230817_dk1_BW_context_os2_day1_pt1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230817_dk1_BW_context_os2_day1_pt2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230818_dk1_BW_context_os2_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230818_dk3_BW_context_os2_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230821_dk3_BW_context_os2_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230821_dk5_BW_context_day1_os2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230822_dk1_BW_nocontext_os2_day1_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230823_dk1_BW_nocontext_os2_day2_compiled_data.pkl'\n",
      " 'c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230823_dk5_BW_context_day2_os2_compiled_data.pkl']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "experiment_list=np.unique(data['file'])\n",
    "print(experiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_number 0\n",
      "0\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "channel_number 1\n",
      "1\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "channel_number 2\n",
      "2\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "channel_number 3\n",
      "3\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "channel_number 4\n",
      "4\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "channel_number 5\n",
      "5\n",
      "['no_context']\n",
      "7\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "conditions=['white','black','no_context']\n",
    "experiment_list=['c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk1_nocontext_compiled_data.pkl']\n",
    "for experimenti  in experiment_list:\n",
    "    base_name = os.path.basename(experimenti).replace('.pkl', '')\n",
    "    power_df=pd.DataFrame()\n",
    "    small_data= data[data['file']==experimenti]\n",
    "    channels=np.unique(small_data['channel_id'])\n",
    "    \n",
    "    for channel_num,channel_id in enumerate(channels):\n",
    "        print('channel_number',channel_num)\n",
    "        channel_data=small_data[small_data['channel_id']==channel_id]\n",
    "        print(channel_num)\n",
    "        true_conditions=[]\n",
    "        for i in conditions:\n",
    "            condition= i+'_trials_before'\n",
    "            if len(channel_data[condition][channel_num])>1:\n",
    "                true_conditions.append(i)\n",
    "        print(true_conditions)\n",
    "        for conditioni in true_conditions:\n",
    "            correct_trials=len(channel_data['correct_in_' + conditioni + '_after'][channel_num])\n",
    "            print(correct_trials)\n",
    "            incorrect_trials=len(channel_data['incorrect_in_' + conditioni + '_after'][channel_num])\n",
    "            total_trials =  correct_trials+incorrect_trials\n",
    "            print(incorrect_trials)\n",
    "            #print(conditioni)\n",
    "            for correcti in range(len(channel_data['correct_in_' + conditioni + '_after'][channel_num])-1):\n",
    "                    print(correcti)\n",
    "                # Create a dictionary for the row\n",
    "                    row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'context': conditioni,\n",
    "                    'bin_id': correcti,\n",
    "                    'correct?': 1,\n",
    "                    'total_power_pre_door': channel_data[conditioni + '_trials_before'][channel_num][correcti],\n",
    "                    'total_power_post_door': channel_data[conditioni + '_trials_after'][channel_num][correcti],\n",
    "                    'total_power_pre_odor': channel_data['correct_in_' + conditioni + '_after'],\n",
    "                    'total_power_pre_odor': channel_data['correct_in_' + conditioni + '_before'],\n",
    "\n",
    "                    'beta_power_pre_door': channel_data[conditioni + '_trials_before_beta'][channel_num][correcti],\n",
    "                    'beta_power_post_door': channel_data[conditioni + '_trials_after_beta'][channel_num][correcti],\n",
    "                    'beta_power_pre_odor': channel_data['correct_in_' + conditioni + '_before_beta'],\n",
    "                    'beta_power_post_odor': channel_data['correct_in_' + conditioni + '_after_beta'],\n",
    "\n",
    "                    'gamma_power_pre_door': channel_data[conditioni + '_trials_before_gamma'][channel_num][correcti],\n",
    "                    'gamma_power_post_door': channel_data[conditioni + '_trials_after_gamma'][channel_num][correcti],\n",
    "                    'gamma_power_pre_odor': channel_data['correct_in_' + conditioni + '_before_gamma'],\n",
    "                    'gamma_power_post_odor': channel_data['correct_in_' + conditioni + '_after_gamma'],\n",
    "\n",
    "                    'theta_power_pre_door': channel_data[conditioni + '_trials_before_theta'][channel_num][correcti],\n",
    "                    'theta_power_post_door': channel_data[conditioni + '_trials_after_theta'][channel_num][correcti],\n",
    "                    'theta_power_pre_odor': channel_data['correct_in_' + conditioni + '_before_theta'],\n",
    "                    'theta_power_post_odor': channel_data['correct_in_' + conditioni + '_after_theta']\n",
    "                }\n",
    "\n",
    "            for incorrecti in range(len(channel_data['incorrect_in_' + conditioni + '_after'][channel_num])-1):\n",
    "                    print(incorrecti)\n",
    "                    # Create a dictionary for the row\n",
    "                    row = {\n",
    "                        'experiment': base_name,\n",
    "                        'channel_id': channel_id,\n",
    "                        'context': conditioni,\n",
    "                        'bin_id': incorrecti + correcti,\n",
    "                        'correct?': 0,\n",
    "                        'total_power_pre_door': channel_data[conditioni + '_trials_before'][channel_num][incorrecti],\n",
    "                        'total_power_post_door': channel_data[conditioni + '_trials_after'][channel_num][incorrecti],\n",
    "                        'total_power_pre_odor': channel_data['incorrect_in_' + conditioni + '_after'],\n",
    "                        'total_power_pre_odor': channel_data['incorrect_in_' + conditioni + '_before'],\n",
    "\n",
    "                        'beta_power_pre_door': channel_data[conditioni + '_trials_before_beta'][channel_num][incorrecti],\n",
    "                        'beta_power_post_door': channel_data[conditioni + '_trials_after_beta'][channel_num][incorrecti],\n",
    "                        'beta_power_pre_odor': channel_data['incorrect_in_' + conditioni + '_before_beta'],\n",
    "                        'beta_power_post_odor': channel_data['incorrect_in_' + conditioni + '_after_beta'],\n",
    "\n",
    "                        'gamma_power_pre_door': channel_data[conditioni + '_trials_before_gamma'][channel_num][incorrecti],\n",
    "                        'gamma_power_post_door': channel_data[conditioni + '_trials_after_gamma'][channel_num][incorrecti],\n",
    "                        'gamma_power_pre_odor': channel_data['incorrect_in_' + conditioni + '_before_gamma'],\n",
    "                        'gamma_power_post_odor': channel_data['incorrect_in_' + conditioni + '_after_gamma'],\n",
    "\n",
    "                        'theta_power_pre_door': channel_data[conditioni + '_trials_before_theta'][channel_num][incorrecti],\n",
    "                        'theta_power_post_door': channel_data[conditioni + '_trials_after_theta'][channel_num][incorrecti],\n",
    "                        'theta_power_pre_odor': channel_data['incorrect_in_' + conditioni + '_before_theta'],\n",
    "                        'theta_power_post_odor': channel_data['incorrect_in_' + conditioni + '_after_theta']\n",
    "                    }\n",
    "    power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    #     if len(channel_data['black_trials'])>1:\n",
    "    #         print('number of black trials',len(channel_data['black_trials']))\n",
    "    #         for i in range(len(channel_data['black_trials'][channel_num])):\n",
    "    #             #print(i)\n",
    "    #             bin_id='dooropen_black_after_bin'+str(i)\n",
    "    #             total_power=channel_data['black_trials'][i]\n",
    "    #             beta_power=channel_data['black_trials_beta'][i]\n",
    "    #             gamma_power=channel_data['black_trials_gamma'][i]\n",
    "    #             theta_power=channel_data['black_trials_theta'][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #             #print(f\"Appended row: {row}\")\n",
    "    #     elif len(channel_data['white_trials'])>1:\n",
    "    #         print('number of white trials',len(channel_data['white_trials']))\n",
    "    #         for i in range(len(channel_data['white_trials'][channel_num])):\n",
    "    #             #print(i)\n",
    "    #             bin_id='dooropen_after_bin'+str(i)\n",
    "    #             total_power=channel_data['white_trials'][i]\n",
    "    #             beta_power=channel_data['white_trials_beta'][i]\n",
    "    #             gamma_power=channel_data['white_trials_gamma'][i]\n",
    "    #             theta_power=channel_data['white_trials_theta'][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #             #print(f\"Appended row: {row}\")\n",
    "    #     elif len(channel_data['no_context_trials'][channel_num])>1:\n",
    "    #         print('number of no context trials',len(channel_data['no_context_trials']))\n",
    "    #         for i in range(len(channel_data['no_context_trials'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='dooropen_no_context_after_bin'+str(i)\n",
    "    #             total_power=channel_data['no_context_trials'][channel_num][i]\n",
    "    #             beta_power=channel_data['no_context_trials_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['no_context_trials_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['no_context_trials_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #             #print(f\"Appended row: {row}\")\n",
    "\n",
    "    #     if  len(channel_data['correct_in_black_after'][channel_num])>1:\n",
    "    #         print('correct digs in black after',len(channel_data['correct_in_black_after']))\n",
    "    #         for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_black_after_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_black_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_black_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_black_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_black_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['correct_in_white_before'][channel_num])>1:\n",
    "    #         print('correct digs in white before',len(channel_data['correct_in_white_before']))\n",
    "    #         for i in range(len(channel_data['correct_in_black_before'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_white_before_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_white_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_white_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_white_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_white_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['correct_in_no_context_before'][channel_num])>1:\n",
    "    #         print('correct digs in no_context before',len(channel_data['correct_in_no_context_before']))\n",
    "    #         for i in range(len(channel_data['correct_in_no_context_before'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_no_context_before_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_no_context_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_no_context_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_no_context_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_no_context_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "    #     if  len(channel_data['correct_in_black_after'][channel_num])>1:\n",
    "    #         print('correct digs in black after',len(channel_data['correct_in_black_after']))\n",
    "    #         for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_black_after_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_black_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_black_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_black_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_black_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['correct_in_white_after'][channel_num])>1:\n",
    "    #         print('correct digs in white after',len(channel_data['correct_in_white_after']))\n",
    "    #         for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_white_after_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_white_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_white_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_white_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_white_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['correct_in_no_context_after'][channel_num])>1:\n",
    "    #         print('correct digs in no_context after',len(channel_data['correct_in_no_context_after']))\n",
    "    #         for i in range(len(channel_data['correct_in_no_context_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='correctdig_no_context_after_bin'+str(i)\n",
    "    #             total_power=channel_data['correct_in_no_context_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['correct_in_no_context_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['correct_in_no_context_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['correct_in_no_context_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "    #     if  len(channel_data['incorrect_in_black_before'][channel_num])>1:\n",
    "    #         print('incorrect digs in black before',len(channel_data['incorrect_in_black_before']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_black_before'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_black_before_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_black_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_black_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_black_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_black_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['incorrect_in_white_before'][channel_num])>1:\n",
    "    #         print('incorrect digs in white before',len(channel_data['incorrect_in_white_before']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_black_before'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_white_before_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_white_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_white_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_white_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_white_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['incorrect_in_no_context_before'][channel_num])>1:\n",
    "    #         print('incorrect digs in no_context before',len(channel_data['incorrect_in_no_context_before']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_no_context_before'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_no_context_before_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_no_context_before'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_no_context_before_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_no_context_before_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_no_context_before_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    #     if  len(channel_data['incorrect_in_black_after'][channel_num])>1:\n",
    "    #         print('incorrect digs in black after',len(channel_data['incorrect_in_black_after']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_black_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_black_after_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_black_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_black_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_black_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_black_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['incorrect_in_white_after'][channel_num])>1:\n",
    "    #         print('incorrect digs in white after',len(channel_data['incorrect_in_white_after']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_black_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_white_after_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_white_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_white_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_white_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_white_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    #     elif  len(channel_data['incorrect_in_no_context_after'][channel_num])>1:\n",
    "    #         print('incorrect digs in no_context after',len(channel_data['incorrect_in_no_context_after']))\n",
    "    #         for i in range(len(channel_data['incorrect_in_no_context_after'][channel_num])):\n",
    "    #             print('trial',i)\n",
    "    #             bin_id='incorrectdig_no_context_after_bin'+str(i)\n",
    "    #             total_power=channel_data['incorrect_in_no_context_after'][channel_num][i]\n",
    "    #             beta_power=channel_data['incorrect_in_no_context_after_beta'][channel_num][i]\n",
    "    #             gamma_power=channel_data['incorrect_in_no_context_after_gamma'][channel_num][i]\n",
    "    #             theta_power=channel_data['incorrect_in_no_context_after_theta'][channel_num][i]\n",
    "\n",
    "    #             # Create a dictionary for the row\n",
    "    #             row = {\n",
    "    #                 'experiment': base_name,\n",
    "    #                 'channel_id': channel_id,\n",
    "    #                 'bin_id': bin_id,\n",
    "    #                 'total_power': total_power,\n",
    "    #                 'beta_power': beta_power,\n",
    "    #                 'gamma_power': gamma_power,\n",
    "    #                 'theta_power': theta_power\n",
    "    #             }\n",
    "                \n",
    "    #             # Append the row to the DataFrame\n",
    "    #             power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    # power_df.to_csv('{}.csv'.format(base_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchannel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconditioni\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_trials_before\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "channel_data[conditioni+'_trials_before'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions=['white','black','no_context']\n",
    "true_conditions=[]\n",
    "for i in conditions:\n",
    "    condition= i+'_trials_before'\n",
    "    \n",
    "    if len(channel_data[condition][0])>1:\n",
    "        true_conditions.append(i)\n",
    "\n",
    "print(true_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "experiment_list=['c:\\\\Users\\\\sinha\\\\Documents\\\\GitHub\\\\lfp\\\\cpl_analysis\\\\20230529_dk1_nocontext_compiled_data.pkl']\n",
    "for experimenti  in experiment_list:\n",
    "    base_name = os.path.basename(experimenti).replace('.pkl', '')\n",
    "    power_df=pd.DataFrame()\n",
    "    small_data= data[data['file']==experimenti]\n",
    "    channels=np.unique(small_data['channel_id'])\n",
    "    for channel_num,channel_id in enumerate(channels):\n",
    "        print('channel_number',channel_num)\n",
    "        channel_data=small_data[small_data['channel_id']==channel_id]\n",
    "        \n",
    "        if len(channel_data['black_trials'])>1:\n",
    "            print('number of black trials',len(channel_data['black_trials']))\n",
    "            for i in range(len(channel_data['black_trials'][channel_num])):\n",
    "                #print(i)\n",
    "                bin_id='dooropen_black_after_bin'+str(i)\n",
    "                total_power=channel_data['black_trials'][i]\n",
    "                beta_power=channel_data['black_trials_beta'][i]\n",
    "                gamma_power=channel_data['black_trials_gamma'][i]\n",
    "                theta_power=channel_data['black_trials_theta'][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "                #print(f\"Appended row: {row}\")\n",
    "        elif len(channel_data['white_trials'])>1:\n",
    "            print('number of white trials',len(channel_data['white_trials']))\n",
    "            for i in range(len(channel_data['white_trials'][channel_num])):\n",
    "                #print(i)\n",
    "                bin_id='dooropen_after_bin'+str(i)\n",
    "                total_power=channel_data['white_trials'][i]\n",
    "                beta_power=channel_data['white_trials_beta'][i]\n",
    "                gamma_power=channel_data['white_trials_gamma'][i]\n",
    "                theta_power=channel_data['white_trials_theta'][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "                #print(f\"Appended row: {row}\")\n",
    "        elif len(channel_data['no_context_trials'][channel_num])>1:\n",
    "            print('number of no context trials',len(channel_data['no_context_trials']))\n",
    "            for i in range(len(channel_data['no_context_trials'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='dooropen_no_context_after_bin'+str(i)\n",
    "                total_power=channel_data['no_context_trials'][channel_num][i]\n",
    "                beta_power=channel_data['no_context_trials_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['no_context_trials_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['no_context_trials_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "                #print(f\"Appended row: {row}\")\n",
    "\n",
    "        if  len(channel_data['correct_in_black_after'][channel_num])>1:\n",
    "            print('correct digs in black after',len(channel_data['correct_in_black_after']))\n",
    "            for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_black_after_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_black_before'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_black_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_black_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_black_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['correct_in_white_before'][channel_num])>1:\n",
    "            print('correct digs in white before',len(channel_data['correct_in_white_before']))\n",
    "            for i in range(len(channel_data['correct_in_black_before'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_white_before_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_white_before'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_white_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_white_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_white_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['correct_in_no_context_before'][channel_num])>1:\n",
    "            print('correct digs in no_context before',len(channel_data['correct_in_no_context_before']))\n",
    "            for i in range(len(channel_data['correct_in_no_context_before'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_no_context_before_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_no_context_before'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_no_context_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_no_context_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_no_context_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "        if  len(channel_data['correct_in_black_after'][channel_num])>1:\n",
    "            print('correct digs in black after',len(channel_data['correct_in_black_after']))\n",
    "            for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_black_after_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_black_after'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_black_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_black_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_black_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['correct_in_white_after'][channel_num])>1:\n",
    "            print('correct digs in white after',len(channel_data['correct_in_white_after']))\n",
    "            for i in range(len(channel_data['correct_in_black_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_white_after_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_white_after'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_white_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_white_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_white_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['correct_in_no_context_after'][channel_num])>1:\n",
    "            print('correct digs in no_context after',len(channel_data['correct_in_no_context_after']))\n",
    "            for i in range(len(channel_data['correct_in_no_context_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='correctdig_no_context_after_bin'+str(i)\n",
    "                total_power=channel_data['correct_in_no_context_after'][channel_num][i]\n",
    "                beta_power=channel_data['correct_in_no_context_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['correct_in_no_context_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['correct_in_no_context_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "        if  len(channel_data['incorrect_in_black_before'][channel_num])>1:\n",
    "            print('incorrect digs in black before',len(channel_data['incorrect_in_black_before']))\n",
    "            for i in range(len(channel_data['incorrect_in_black_before'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_black_before_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_black_before'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_black_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_black_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_black_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['incorrect_in_white_before'][channel_num])>1:\n",
    "            print('incorrect digs in white before',len(channel_data['incorrect_in_white_before']))\n",
    "            for i in range(len(channel_data['incorrect_in_black_before'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_white_before_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_white_before'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_white_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_white_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_white_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['incorrect_in_no_context_before'][channel_num])>1:\n",
    "            print('incorrect digs in no_context before',len(channel_data['incorrect_in_no_context_before']))\n",
    "            for i in range(len(channel_data['incorrect_in_no_context_before'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_no_context_before_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_no_context_before'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_no_context_before_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_no_context_before_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_no_context_before_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        if  len(channel_data['incorrect_in_black_after'][channel_num])>1:\n",
    "            print('incorrect digs in black after',len(channel_data['incorrect_in_black_after']))\n",
    "            for i in range(len(channel_data['incorrect_in_black_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_black_after_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_black_after'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_black_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_black_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_black_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['incorrect_in_white_after'][channel_num])>1:\n",
    "            print('incorrect digs in white after',len(channel_data['incorrect_in_white_after']))\n",
    "            for i in range(len(channel_data['incorrect_in_black_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_white_after_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_white_after'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_white_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_white_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_white_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "        elif  len(channel_data['incorrect_in_no_context_after'][channel_num])>1:\n",
    "            print('incorrect digs in no_context after',len(channel_data['incorrect_in_no_context_after']))\n",
    "            for i in range(len(channel_data['incorrect_in_no_context_after'][channel_num])):\n",
    "                print('trial',i)\n",
    "                bin_id='incorrectdig_no_context_after_bin'+str(i)\n",
    "                total_power=channel_data['incorrect_in_no_context_after'][channel_num][i]\n",
    "                beta_power=channel_data['incorrect_in_no_context_after_beta'][channel_num][i]\n",
    "                gamma_power=channel_data['incorrect_in_no_context_after_gamma'][channel_num][i]\n",
    "                theta_power=channel_data['incorrect_in_no_context_after_theta'][channel_num][i]\n",
    "\n",
    "                # Create a dictionary for the row\n",
    "                row = {\n",
    "                    'experiment': base_name,\n",
    "                    'channel_id': channel_id,\n",
    "                    'bin_id': bin_id,\n",
    "                    'total_power': total_power,\n",
    "                    'beta_power': beta_power,\n",
    "                    'gamma_power': gamma_power,\n",
    "                    'theta_power': theta_power\n",
    "                }\n",
    "                \n",
    "                # Append the row to the DataFrame\n",
    "                power_df = pd.concat([power_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    power_df.to_csv('{}.csv'.format(base_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(channel_data['no_context_trials'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.03134588 0.12951029 0.01954163 0.06390976 0.02208174 0.10315011\n",
    " 0.023102   0.21312694 0.03903342 0.02263169]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
