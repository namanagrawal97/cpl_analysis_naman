{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca97c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import getpass\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc2b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 'Keyboard' found in both files.\n",
      "Key 'LFP1_AON' found in both files.\n",
      "Key 'LFP1_vHp' found in both files.\n",
      "Key 'LFP2_AON' found in both files.\n",
      "Key 'LFP2_vHp' found in both files.\n",
      "Key 'LFP3_AON' found in both files.\n",
      "Key 'LFP4_AON' found in both files.\n",
      "Key 'Ref' found in both files.\n",
      "Key 'Respirat' found in both files.\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n",
      "<class 'h5py._hl.group.Group'>\n"
     ]
    }
   ],
   "source": [
    "file1 = \"D:\\\\Dropbox\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt1.mat\"\n",
    "file2 = \"D:\\\\Dropbox\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt2.mat\"\n",
    "\n",
    "file1_data = h5py.File(file1, 'r')\n",
    "file2_data = h5py.File(file2, 'r')\n",
    "\n",
    "\n",
    "file1_data.keys()\n",
    "file2_data.keys()\n",
    "\n",
    "for key in file1_data.keys():\n",
    "    if key in file2_data.keys():\n",
    "        print(f\"Key '{key}' found in both files.\")\n",
    "    else:\n",
    "        print(f\"Key '{key}' not found in file2.\")\n",
    "\n",
    "for key in file2_data.keys():\n",
    "    data_1 = file1_data[key]\n",
    "    data_2 = file2_data[key]\n",
    "    # Now you can work with data_1 and data_2\n",
    "    print(type(data_1))\n",
    "    print(type(data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8239410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def copy_attrs(src, dst):\n",
    "    for k, v in src.attrs.items():\n",
    "        if k not in dst.attrs:\n",
    "            dst.attrs[k] = v\n",
    "        else:\n",
    "            # If conflict, keep both with suffixes (only if values differ)\n",
    "            try:\n",
    "                # Use np.array_equal if both are arrays, else use ==\n",
    "                if isinstance(dst.attrs[k], np.ndarray) or isinstance(v, np.ndarray):\n",
    "                    same = np.array_equal(dst.attrs[k], v)\n",
    "                else:\n",
    "                    same = (dst.attrs[k] == v)\n",
    "            except Exception:\n",
    "                same = False\n",
    "            if not same:\n",
    "                dst.attrs[f\"{k}_file2\"] = v  # assuming src is from file2 when called second\n",
    "\n",
    "def merge_groups(g1: h5py.Group, g2: h5py.Group, gout: h5py.Group, concat_axis=0):\n",
    "    keys1 = set(g1.keys())\n",
    "    keys2 = set(g2.keys())\n",
    "    all_keys = keys1 | keys2\n",
    "\n",
    "    for name in all_keys:\n",
    "        in1 = name in g1\n",
    "        in2 = name in g2\n",
    "\n",
    "        if in1 and in2:\n",
    "            o1 = g1[name]\n",
    "            o2 = g2[name]\n",
    "\n",
    "            if isinstance(o1, h5py.Group) and isinstance(o2, h5py.Group):\n",
    "                sub = gout.create_group(name)\n",
    "                copy_attrs(o1, sub)\n",
    "                copy_attrs(o2, sub)\n",
    "                merge_groups(o1, o2, sub, concat_axis=concat_axis)\n",
    "\n",
    "            elif isinstance(o1, h5py.Dataset) and isinstance(o2, h5py.Dataset):\n",
    "                # Can we concatenate?\n",
    "                compatible = (\n",
    "                    o1.dtype == o2.dtype and\n",
    "                    o1.ndim == o2.ndim and\n",
    "                    all((i == concat_axis) or (o1.shape[i] == o2.shape[i]) for i in range(o1.ndim))\n",
    "                )\n",
    "                if compatible:\n",
    "                    d1 = o1[...]\n",
    "                    d2 = o2[...]\n",
    "                    merged = np.concatenate([d1, d2], axis=concat_axis)\n",
    "                    dset = gout.create_dataset(\n",
    "                        name,\n",
    "                        data=merged,\n",
    "                        compression=o1.compression or o2.compression,\n",
    "                        chunks=o1.chunks or o2.chunks\n",
    "                    )\n",
    "                    copy_attrs(o1, dset)\n",
    "                    copy_attrs(o2, dset)\n",
    "                else:\n",
    "                    # Conflict: keep both versions\n",
    "                    gout.copy(o1, f\"{name}_file1\")\n",
    "                    gout.copy(o2, f\"{name}_file2\")\n",
    "            else:\n",
    "                # One is group, one is dataset: keep both\n",
    "                if isinstance(o1, h5py.Group):\n",
    "                    gout.copy(o1, f\"{name}_file1_group\")\n",
    "                else:\n",
    "                    gout.copy(o1, f\"{name}_file1_dataset\")\n",
    "                if isinstance(o2, h5py.Group):\n",
    "                    gout.copy(o2, f\"{name}_file2_group\")\n",
    "                else:\n",
    "                    gout.copy(o2, f\"{name}_file2_dataset\")\n",
    "\n",
    "        elif in1:\n",
    "            gout.copy(g1[name], name)\n",
    "        else:\n",
    "            gout.copy(g2[name], name)\n",
    "\n",
    "def merge_files(file1, file2, out_file, concat_axis=0):\n",
    "    with h5py.File(file1, \"r\") as f1, h5py.File(file2, \"r\") as f2, h5py.File(out_file, \"w\") as fout:\n",
    "        copy_attrs(f1, fout)\n",
    "        copy_attrs(f2, fout)\n",
    "        merge_groups(f1, f2, fout, concat_axis=concat_axis)\n",
    "        f1.close()\n",
    "        f2.close()\n",
    "        fout.close()\n",
    "# Example usage (concatenate datasets along axis 0)\n",
    "file1 = r\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt1.mat\"\n",
    "file2 = r\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt2.mat\"\n",
    "outf  = r\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_merged.mat\"\n",
    "\n",
    "merge_files(file1, file2, outf, concat_axis=0)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0efef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n",
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n",
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n",
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n",
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n",
      "<HDF5 dataset \"values\": shape (1, 777936), type \"<f8\">\n",
      "<HDF5 dataset \"values\": shape (1, 3021431), type \"<f8\">\n",
      "<KeysViewHDF5 ['comment', 'interval', 'length', 'offset', 'scale', 'start', 'times_file1', 'times_file2', 'title', 'units', 'values_file1', 'values_file2']>\n"
     ]
    }
   ],
   "source": [
    "file1=f\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt1.mat\"\n",
    "file2=f\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_pt2.mat\"\n",
    "outf  = f\"D:\\\\Dropbox\\\\CPLab\\\\all_data_mat_250825\\\\20230817_dk1_BW_context_os2_day1_merged.mat\"\n",
    "file1_data= h5py.File(file1, 'r')\n",
    "file2_data= h5py.File(file2, 'r')\n",
    "outf_data= h5py.File(outf, 'r')\n",
    "channel_names = ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp']\n",
    "\n",
    "for channeli in channel_names:\n",
    "    file1_channel = file1_data[channeli]\n",
    "    file2_channel = file2_data[channeli]\n",
    "    outf_channel = outf_data[channeli]\n",
    "\n",
    "    print(file1_channel['values'])\n",
    "    print(file2_channel['values'])\n",
    "    #print(outf_channel['values'])\n",
    "    print(outf_channel.keys())\n",
    "file1_data.close()\n",
    "file2_data.close()\n",
    "outf_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dfeb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V20230719_dk1_nocontext_os2_day2_Ch1\n",
      "(1, 2276770)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch2\n",
      "(1, 2276770)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch29\n",
      "(1, 1139)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch3\n",
      "(1, 2276770)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch31\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch4\n",
      "(1, 2276770)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch5\n",
      "(1, 2276769)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch6\n",
      "(1, 2276769)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "V20230719_dk1_nocontext_os2_day2_Ch8\n",
      "(1, 2276769)\n",
      "None\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dk1_merged = f\"D:\\\\Dropbox\\\\CPLab\\\\dk1_parts\\\\20230719_dk1_nocontext_os2_day2.mat\"\n",
    "\n",
    "dk1_data= h5py.File(dk1_merged, 'r')\n",
    "channels= dk1_data.keys()\n",
    "\n",
    "for channeli in channels:\n",
    "    channel_data = dk1_data[channeli]\n",
    "    file1_channel = file1_data[channeli] if channeli in file1_data else None\n",
    "    file2_channel = file2_data[channeli] if channeli in file2_data else None\n",
    "    print(channeli)\n",
    "    #print(channel_data.keys())\n",
    "    if 'values' in channel_data:\n",
    "        print(channel_data['values'].shape)\n",
    "        print(file1_channel['values'].shape if file1_channel is not None else None)\n",
    "        print(file2_channel['values'].shape if file2_channel is not None else None)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
