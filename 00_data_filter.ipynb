{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import getpass\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current user\n",
    "user = getpass.getuser()\n",
    "print(\"Hello\", user)\n",
    "\n",
    "# Define base directory paths\n",
    "base = 'C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "print('base = ', base)\n",
    "\n",
    "# Define paths for saving filtered files and results\n",
    "files_savepath = base + '\\\\all_data_filtered_mat\\\\'\n",
    "print('filtered files will be stored at', files_savepath)\n",
    "\n",
    "savepath = base + '\\\\results\\\\'\n",
    "print('plots and stuff will be at', savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Load and clean filter data from an Excel file\"\"\"\n",
    "\n",
    "filter_data = pd.read_excel(\"C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab\\\\filecheck.xlsx\".format(user)) #Loading up the data that contains the manual annotation from Christiane\n",
    "filter_data = filter_data.dropna(axis=1, how='all') #Removes the columns where all the values are NA\n",
    "filter_data = filter_data.dropna(axis=0, how='all') # Removes the rows where all the values are NA\n",
    "filter_data = filter_data.drop(filter_data.columns[-1], axis=1) #Drop the last column that just contains comments\n",
    "filter_data.reset_index(drop=True, inplace=True) # Reset the index becuase of the dropped rows\n",
    "filter_data.columns = ['file', 'LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'date'] #Manually set the column names\n",
    "\n",
    "\"Extract file names without extensions from filter data\"\n",
    "\n",
    "filter_data_files = list(filter_data['file']) #take the 'file' column from the dataframe\n",
    "filter_base_names_without_ext = [os.path.splitext(os.path.basename(file))[0] for file in filter_data_files] #extract the file names, removes the paths from the filenames and stores it as a list\n",
    "print(filter_base_names_without_ext)\n",
    "\n",
    "# Update filter data with base names without extensions\n",
    "filter_data['file'] = filter_base_names_without_ext\n",
    "\n",
    "# Extract annotations from filter data\n",
    "filter_data_annotations = filter_data.iloc[:, 1:6] #Extracting annotations \"no\" and \"ok\"\n",
    "filter_data_annotations = np.array(filter_data_annotations) #saving it as an array\n",
    "print(np.unique(filter_data_annotations)) #printing out the uniques annotations to make sure that annotations are \"no\" and \"ok\" only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find all .mat files in the specified directory\n",
    "files = glob.glob(r'C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\*.mat'.format(user))\n",
    "print(files)\n",
    "\n",
    "# Print the number of files and the shape of the filter data\n",
    "print(len(files))\n",
    "print(filter_data.shape)\n",
    "\n",
    "# Extract base names without extensions from the list of files\n",
    "files_list = []\n",
    "for file in files:\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name_without_ext = os.path.splitext(base_name)[0]\n",
    "    files_list.append(base_name_without_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find uncommon elements between the list of files and filter data\n",
    "set1 = set(files_list)\n",
    "set2 = set(filter_data['file'])\n",
    "uncommon_elements = set1.symmetric_difference(set2)\n",
    "uncommon_elements_list = list(uncommon_elements)\n",
    "print(uncommon_elements_list)\n",
    "\n",
    "# These two files don't exist and are a typo in the filecheck.xlsx file\n",
    "# ['20230609_dk1_BW_nocontext_day2', '20230822_dk1_BW_nocontext_os2_day2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we will drop the data file columns that are \"NO\" in the manual annotation file(filecheck.xlsx)\"\"\"\n",
    "\n",
    "# Define channel names\n",
    "channel_names = ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp']\n",
    "\n",
    "# Initialize a list to store files that are not found\n",
    "not_here_list = []\n",
    "\n",
    "# Iterate over each file and delete specified columns if necessary\n",
    "for file in files: #Loading the data files\n",
    "    f = h5py.File(file, 'r+') #reading the file with the option of writing to it by using \"r+\" \n",
    "    try:\n",
    "        base_name = os.path.basename(file)\n",
    "        base_name_without_ext = os.path.splitext(base_name)[0]\n",
    "        if base_name_without_ext in filter_base_names_without_ext: #checking if the data file exists in filecheck.xlsx \n",
    "            print(base_name_without_ext, 'yes')\n",
    "            row = filter_data.loc[filter_data['file'] == base_name_without_ext] #locates the row of the file in filecheck.xlsx\n",
    "            for column in row.columns: #Iterating through the manual annotations\n",
    "                value = row[column].values[0]\n",
    "                if value == 'no' or value == 'NO': #If the annotation of a channel is \"NO\"\n",
    "                    print(f\"Column '{column}' has value 'no'\")\n",
    "                    if column in f.keys():\n",
    "                        del f[column] # Deletes that channel in the data file\n",
    "                        print(f\"Deleted key '{column}' from file '{file}'\")\n",
    "                elif value == 'ok' or value == 'OK': # If the annotation of a channel is  \"OK\"\n",
    "                    print(f\"Column '{column}' has value 'ok'\") #Do nothing\n",
    "        else:\n",
    "            print(base_name_without_ext, 'this file not here') #if the data file does not exist in filecheck.xlsx\n",
    "            not_here_list.append(base_name_without_ext) \n",
    "    finally:\n",
    "        f.close() #Close the data file. This saves the manipulations we have made in the above code.\n",
    "\n",
    "print(not_here_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the channels in each file\n",
    "for file in files:\n",
    "    f = h5py.File(file, 'r')\n",
    "    channels = f.keys()\n",
    "    print(file, channels)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================== End of Main Code =============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code is to check for Keyboard annotations in data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to convert decimal numbers to Unicode characters\n",
    "def decimal_to_unicode(decimal_list):\n",
    "    \"\"\"\n",
    "    Convert a list of decimal numbers to their corresponding Unicode characters.\n",
    "    \n",
    "    Parameters:\n",
    "    decimal_list (list): List of decimal numbers.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of Unicode characters.\n",
    "    \"\"\"\n",
    "    return [chr(decimal) for decimal in decimal_list]\n",
    "\n",
    "# Example usage of decimal_to_unicode function\n",
    "decimal_list = [65, 66, 67, 8364]  # A, B, C, â‚¬\n",
    "unicode_characters = decimal_to_unicode(decimal_list)\n",
    "print(unicode_characters)\n",
    "\n",
    "# Define a function to combine strings with an optional separator\n",
    "def combine_strings(string_list, separator=''):\n",
    "    \"\"\"\n",
    "    Combine strings in a list into a single string with an optional separator.\n",
    "    \n",
    "    Parameters:\n",
    "    string_list (list): List of strings to combine.\n",
    "    separator (str): Separator to use between strings. Default is an empty string.\n",
    "    \n",
    "    Returns:\n",
    "    str: Combined string.\n",
    "    \"\"\"\n",
    "    return separator.join(string_list)\n",
    "\n",
    "# Example usage of combine_strings function\n",
    "string_list = ['Hello', 'world', 'this', 'is', 'a', 'test']\n",
    "combined_string = combine_strings(string_list, ' ')\n",
    "print(combined_string)\n",
    "\n",
    "# Initialize lists to store codes and comments from all files\n",
    "codes_all = []\n",
    "comments_all = []\n",
    "\n",
    "# Iterate over each file and extract codes and comments\n",
    "for file in files:\n",
    "    f = h5py.File(file, 'r')\n",
    "    channels = list(f.keys())\n",
    "\n",
    "    # Check for the presence of specific channels and extract events\n",
    "    if 'Keyboard' in channels:\n",
    "        events = f['Keyboard']\n",
    "    elif 'keyboard' in channels:\n",
    "        events = f['keyboard']\n",
    "    elif 'memory' in channels:\n",
    "        events = f['memory']\n",
    "    elif 'Memory' in channels:\n",
    "        events = f['Memory']\n",
    "\n",
    "    # Print the title of the events\n",
    "    print(events['title'][:, 0])\n",
    "    print(combine_strings(decimal_to_unicode(events['title'][:, 0]), ''))\n",
    "\n",
    "    # Append codes and comments to the respective lists\n",
    "    codes_all.append(np.array(events['codes'][0]))\n",
    "    comments_all.append(np.array(events['comment']))\n",
    "\n",
    "    # Convert comments to Unicode and combine them into a single string\n",
    "    please = decimal_to_unicode(events['comment'][:, 0])\n",
    "    combined_string = combine_strings(please, ' ')\n",
    "    print(combined_string)\n",
    "\n",
    "# Concatenate all codes and comments\n",
    "codes_all = np.concatenate(codes_all)\n",
    "comments_all = np.concatenate(comments_all)\n",
    "\n",
    "# Print unique codes and comments\n",
    "codes_all_unique = np.unique(codes_all)\n",
    "comments_all_unique = np.unique(comments_all)\n",
    "print(codes_all_unique)\n",
    "print(comments_all_unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
