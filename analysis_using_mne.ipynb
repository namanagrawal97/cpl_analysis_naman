{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b9d38b",
   "metadata": {},
   "source": [
    "## Loading packages and savepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import getpass\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import functions\n",
    "import lfp_pre_processing_functions\n",
    "import power_functions\n",
    "import coherence_functions\n",
    "import spectrogram_plotting_functions\n",
    "import plotting_styles\n",
    "import scipy.stats\n",
    "import mne_connectivity\n",
    "importlib.reload(functions) #loads our custom made functions.py file\n",
    "importlib.reload(spectrogram_plotting_functions)\n",
    "importlib.reload(plotting_styles)\n",
    "\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mne-qt-browser\n",
    "%matplotlib qt\n",
    "import mne\n",
    "print(mne.get_config())  # same as mne.get_config(key=None)\n",
    "mne.set_config('MNE_BROWSER_BACKEND', 'qt')  # set the backend to matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the current user\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "if user == 'CPLab':\n",
    "    base='D:\\\\Dropbox\\\\CPLab'\n",
    "else:\n",
    "    base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "#Set the basepath, savepath and load the data files\n",
    "files = glob.glob(base+'\\\\all_data_mat_250825\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(\"Base path:\", base)\n",
    "print(\"Save path:\", savepath)\n",
    "print(files)\n",
    "\n",
    "\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 1\n",
    "fs = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f222371",
   "metadata": {},
   "source": [
    "## Making MNE Epochs Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c01163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import sys\n",
    "importlib.reload(lfp_pre_processing_functions)\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230616_dk6_BW_context_day2.mat']\n",
    "event_data_df=[]\n",
    "con_data_df=[]\n",
    "\n",
    "con_data_df_shuffled=[]\n",
    "shuffled_event_data_df=[]\n",
    "events_codes_all = {}\n",
    "random_baseline_data=[]\n",
    "baseline_lfp_all=[]\n",
    "\n",
    "files_short=[files[10]] ### TEST CHANGE THIS \n",
    "\n",
    "\n",
    "for file_num,file in enumerate(files):\n",
    "    #if 'dk1' in file:\n",
    "        \n",
    "        #print(file)\n",
    "        base_name = os.path.basename(file)\n",
    "        base_name, _ = os.path.splitext(base_name)\n",
    "\n",
    "        date, rat_id, task = lfp_pre_processing_functions.exp_params(base_name)\n",
    "        print(date, rat_id, task)\n",
    "        if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "            task = 'nocontext'\n",
    "        if task =='nocontext':\n",
    "            continue\n",
    "        # if rat_id=='dk1': #REMOVING DK1 TEMPORARLILY . PLEASE CHANGE LATER\n",
    "        #     continue\n",
    "        f = h5py.File(file, 'r')\n",
    "        channels = list(f.keys())\n",
    "        #print(channels)\n",
    "         \n",
    "        if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "            print(\"No AON or vHp channels in this file\")\n",
    "            continue\n",
    "\n",
    "        events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "        global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "        \n",
    "        ## Reference electrode finding and padding\n",
    "        reference_time = np.array(reference_electrode['times']).flatten()\n",
    "        reference_value = np.array(reference_electrode['values']).flatten()\n",
    "        padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "        events_codes = np.array(events['codes'][0])\n",
    "        events_times = np.array(events['times'][0])\n",
    "        events_codes_all[base_name] = events_codes\n",
    "        epochs = lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "        #epochs = functions.generate_specific_num_of_epochs_with_first_event(events_codes, events_times,5)\n",
    "        aon_lfp_channels=[x for x in channels if 'AON' in x ]\n",
    "        vHp_lfp_channels=[x for x in channels if 'vHp' in x ]\n",
    "        ref_lfp_channels=[x for x in channels if \"Ref\" in x or 'REF' in x or 'ref' in x]\n",
    "        all_channels=np.concatenate((aon_lfp_channels,vHp_lfp_channels, ref_lfp_channels))\n",
    "        #print(all_channels)\n",
    "        \n",
    "        mne_baseline_data=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        mne_epoch_around_dig=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        \n",
    "        mne_baseline_data_shuffled=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "        mne_epoch_around_dig_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "\n",
    "        print(f'File {rat_id} {task} {date} has {len(epochs)} epochs and {len(all_channels)} channels')\n",
    "\n",
    "\n",
    "        first_event = events_times[0]\n",
    "        \n",
    "        for channel_num,channeli in enumerate(all_channels):\n",
    "            if \"AON\" in channeli or \"vHp\" in channeli or \"Ref\" in channeli:\n",
    "                channel_id = channeli\n",
    "                data_all = f[channeli]\n",
    "                raw_data = np.array(data_all['values']).flatten()\n",
    "                raw_time = np.array(data_all['times']).flatten()\n",
    "                sampling_rate = int(1 / data_all['interval'][0][0])\n",
    "                #print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "                \n",
    "                padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "\n",
    "                # padded_data = padded_data/8000 #Accounting for the 8000Amplifier\n",
    "                # padd_ref_data = padd_ref_data/8000\n",
    "                if \"Ref\" in channeli:\n",
    "                    subtracted_data = padded_data\n",
    "                else:                \n",
    "                    subtracted_data = padded_data - padd_ref_data # Subtracting reference channel\n",
    "\n",
    "                notch_data = lfp_pre_processing_functions.iir_notch(subtracted_data, sampling_rate, 60) ###CHANGE notch_data to notch_filtered_data\n",
    "\n",
    "                #print(notch_data.nbytes)\n",
    "                #notch_data_detrended = scipy.signal.detrend(notch_data)\n",
    "                #notch_filtered_data=lfp_pre_processing_functions.sosbandpass(notch_data_detrended, fs=2000, start_freq=1,end_freq=100, order=8) ###CHANGE THIS FOR NOT BANDBASS FILTERTING\n",
    "                #print(notch_filtered_data.nbytes)\n",
    "                \n",
    "                data_before, time, baseline_mean, baseline_std=lfp_pre_processing_functions.baseline_data_normalization(notch_data, raw_time, first_event, sampling_rate)\n",
    "                first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "\n",
    "                mne_baseline_data[0,channel_num,:]=list(data_before)\n",
    "                mne_baseline_data_shuffled[0,channel_num,:]=list(np.random.permutation(data_before))\n",
    "                total = notch_data\n",
    "\n",
    "                epoch_metadata =[]\n",
    "\n",
    "                for i, epochi in enumerate(epochs):\n",
    "                    door_timestamp = epochi[0][0]\n",
    "                    trial_type = epochi[0][1]\n",
    "                    dig_type = epochi[1, 1]\n",
    "                    #print(dig_type)\n",
    "                    dig_timestamp = epochi[1, 0]\n",
    "                    #print(door_timestamp, trial_type, dig_timestamp, dig_type)\n",
    "\n",
    "                                        # Calculate the time difference\n",
    "                    time_diff = dig_timestamp - door_timestamp\n",
    "                    \n",
    "                    # Store metadata for this epoch\n",
    "                    epoch_metadata.append({\n",
    "                        'epoch_id': i,\n",
    "                        'door_timestamp': door_timestamp,\n",
    "                        'dig_timestamp': dig_timestamp,\n",
    "                        'time_diff': time_diff,\n",
    "                        'trial_type': trial_type,\n",
    "                        'dig_type': dig_type\n",
    "                    })\n",
    "\n",
    "\n",
    "                    data_trial_before, data_trial_after=lfp_pre_processing_functions.extract_event_data(notch_data,time,door_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_dig_before, data_dig_after=lfp_pre_processing_functions.extract_event_data(notch_data,time,dig_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_around_door=np.concatenate((data_trial_before, data_trial_after))\n",
    "                    data_around_dig=np.concatenate((data_dig_before, data_dig_after))\n",
    "\n",
    "                    epoch_data = [data_trial_before, data_trial_after, data_dig_before, data_dig_after, data_around_door, data_around_dig]\n",
    "                    event_data_list = [lfp_pre_processing_functions.zscore_event_data(x, baseline_std) for x in epoch_data]\n",
    "\n",
    "                    #event_data_list = [x for x in epoch_data]\n",
    "\n",
    "                    mne_epoch_door_before[i,channel_num,:]=list(event_data_list[0][-int(time_window*fs):])\n",
    "                    mne_epoch_door_after[i,channel_num,:]=list(event_data_list[1][:int(time_window*fs)])\n",
    "                    mne_epoch_dig_before[i,channel_num,:]=list(event_data_list[2][-int(time_window*fs):])\n",
    "                    mne_epoch_dig_after[i,channel_num,:]=list(event_data_list[3][:int(time_window*fs)])\n",
    "                    mid_point = int(len(event_data_list[4]) / 2)\n",
    "                    mne_epoch_around_door[i,channel_num,:]=list(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "                    mne_epoch_around_dig[i,channel_num,:]=list(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "\n",
    "                    mne_epoch_door_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[0][-int(time_window*fs):]))\n",
    "                    mne_epoch_door_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[1][:int(time_window*fs)]))\n",
    "                    mne_epoch_dig_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[2][-int(time_window*fs):]))\n",
    "                    mne_epoch_dig_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[3][:int(time_window*fs)]))\n",
    "                    mne_epoch_around_door_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "                    mne_epoch_around_dig_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "\n",
    "        if len(all_channels)>0:\n",
    "            fs=2000\n",
    "            freqs = np.arange(1,100)\n",
    "            n_cycles = freqs/3\n",
    "            \n",
    "            info = mne.create_info(ch_names=list(all_channels), sfreq=fs, ch_types='eeg')\n",
    "            \n",
    "            metadata_df = pd.DataFrame(epoch_metadata)\n",
    "\n",
    "            mne_baseline = mne.EpochsArray(mne_baseline_data, info)\n",
    "            mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info,metadata=metadata_df)\n",
    "            mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info,metadata=metadata_df)\n",
    "            mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info,metadata=metadata_df)\n",
    "            mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info,metadata=metadata_df)\n",
    "            mne_epoch_around_door = mne.EpochsArray(mne_epoch_around_door, info,metadata=metadata_df)\n",
    "            mne_epoch_around_dig = mne.EpochsArray(mne_epoch_around_dig, info,metadata=metadata_df)\n",
    "            \n",
    "            events_list = [mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after,mne_epoch_around_door,mne_epoch_around_dig]\n",
    "            \n",
    "            row_list=[file_num,date,rat_id,task,mne_baseline,mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after,mne_epoch_around_door,mne_epoch_around_dig]\n",
    "            \n",
    "            mne_baseline_shuffled = mne.EpochsArray(mne_baseline_data_shuffled, info)\n",
    "            mne_epoch_door_before_shuffled = mne.EpochsArray(mne_epoch_door_before_shuffled, info)\n",
    "            mne_epoch_door_after_shuffled = mne.EpochsArray(mne_epoch_door_after_shuffled, info)\n",
    "            mne_epoch_dig_before_shuffled = mne.EpochsArray(mne_epoch_dig_before_shuffled, info)\n",
    "            mne_epoch_dig_after_shuffled = mne.EpochsArray(mne_epoch_dig_after_shuffled, info)\n",
    "            mne_epoch_around_door_shuffled = mne.EpochsArray(mne_epoch_around_door_shuffled, info)\n",
    "            mne_epoch_around_dig_shuffled = mne.EpochsArray(mne_epoch_around_dig_shuffled, info)\n",
    "            row_list_shuffled=[file_num,date,rat_id,task,mne_baseline_shuffled,mne_epoch_door_before_shuffled,mne_epoch_door_after_shuffled,mne_epoch_dig_before_shuffled,mne_epoch_dig_after_shuffled,mne_epoch_around_door_shuffled,mne_epoch_around_dig_shuffled]\n",
    "            shuffled_event_data_df.append(row_list_shuffled)\n",
    "\n",
    "            con_data_df.append(row_list)\n",
    "            con_data_df_shuffled.append(row_list_shuffled)\n",
    "\n",
    "\n",
    "con_data_df=pd.DataFrame(con_data_df, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df.to_pickle(savepath+f'raw_mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "con_data_df_shuffled=pd.DataFrame(con_data_df_shuffled, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df_shuffled.to_pickle(savepath+f'raw_mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef2feb",
   "metadata": {},
   "source": [
    "## Bad Epoch Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c530c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df = pd.read_pickle(savepath+f'raw_mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch = con_data_df.iloc[0]['mne_epoch_dig_before']\n",
    "aon_indices = [i for i, ch in enumerate(test_epoch.ch_names) if 'AON' in ch]\n",
    "vHp_indices = [i for i, ch in enumerate(test_epoch.ch_names) if 'vHp' in ch]\n",
    "test_epoch.plot(scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_epochs_with_metadata(epochs, metadata_cols=['time_diff']):\n",
    "    \"\"\"\n",
    "    Interactive epoch viewer that displays metadata for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epochs : mne.EpochsArray\n",
    "        The epochs object to visualize\n",
    "    metadata_cols : list\n",
    "        List of metadata column names to display\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    bad_epochs = plot_epochs_with_metadata(mne_epoch_door_before, ['time_diff', 'trial_type'])\n",
    "    # Click through epochs, press 'b' to mark as bad, arrow keys to navigate\n",
    "    # Close window when done\n",
    "    \"\"\"\n",
    "    \n",
    "    n_epochs = len(epochs)\n",
    "    current_idx = [0]  # Use list to allow modification in nested function\n",
    "    bad_epochs = set()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), \n",
    "                            gridspec_kw={'height_ratios': [4, 1]})\n",
    "    \n",
    "    def update_plot():\n",
    "        idx = current_idx[0]\n",
    "        \n",
    "        # Clear previous plots\n",
    "        axes[0].clear()\n",
    "        axes[1].clear()\n",
    "        \n",
    "        # Plot epoch data\n",
    "        epoch_data = epochs[idx].get_data()[0]  # shape: (n_channels, n_times)\n",
    "        times = epochs.times\n",
    "        \n",
    "        for ch_idx, ch_data in enumerate(epoch_data):\n",
    "            axes[0].plot(times, ch_data + ch_idx * 5, label=epochs.ch_names[ch_idx])\n",
    "        \n",
    "        axes[0].set_xlabel('Time (s)')\n",
    "        axes[0].set_ylabel('Channels (offset)')\n",
    "        axes[0].legend(loc='upper right', fontsize=8)\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Create title with metadata\n",
    "        title = f\"Epoch {idx}/{n_epochs-1}\"\n",
    "        if epochs.metadata is not None:\n",
    "            for col in metadata_cols:\n",
    "                if col in epochs.metadata.columns:\n",
    "                    val = epochs.metadata.iloc[idx][col]\n",
    "                    title += f\" | {col}: {val:.4f}\" if isinstance(val, (int, float)) else f\" | {col}: {val}\"\n",
    "        \n",
    "        # Add bad epoch indicator\n",
    "        if idx in bad_epochs:\n",
    "            title += \" | *** MARKED BAD ***\"\n",
    "            axes[0].set_facecolor('#ffcccc')\n",
    "        else:\n",
    "            axes[0].set_facecolor('white')\n",
    "            \n",
    "        axes[0].set_title(title, fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Show metadata table in bottom subplot\n",
    "        axes[1].axis('off')\n",
    "        if epochs.metadata is not None:\n",
    "            metadata_text = \"Metadata:\\n\"\n",
    "            for col in epochs.metadata.columns:\n",
    "                val = epochs.metadata.iloc[idx][col]\n",
    "                metadata_text += f\"{col}: {val}\\n\"\n",
    "            axes[1].text(0.1, 0.5, metadata_text, fontsize=10, verticalalignment='center',\n",
    "                        family='monospace')\n",
    "        \n",
    "        # Add instructions\n",
    "        instructions = \"Navigation: ← → arrows | Mark bad: 'b' | Quit: 'q' or close window\"\n",
    "        axes[1].text(0.1, 0.05, instructions, fontsize=9, style='italic')\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    def on_key(event):\n",
    "        if event.key == 'right':\n",
    "            current_idx[0] = min(current_idx[0] + 1, n_epochs - 1)\n",
    "            update_plot()\n",
    "        elif event.key == 'left':\n",
    "            current_idx[0] = max(current_idx[0] - 1, 0)\n",
    "            update_plot()\n",
    "        elif event.key == 'b':\n",
    "            idx = current_idx[0]\n",
    "            if idx in bad_epochs:\n",
    "                bad_epochs.remove(idx)\n",
    "                print(f\"Epoch {idx} unmarked as bad (Total bad: {len(bad_epochs)})\")\n",
    "            else:\n",
    "                bad_epochs.add(idx)\n",
    "                print(f\"Epoch {idx} marked as bad (Total bad: {len(bad_epochs)})\")\n",
    "            update_plot()\n",
    "        elif event.key == 'q':\n",
    "            plt.close(fig)\n",
    "    \n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "    \n",
    "    # Initial plot\n",
    "    update_plot()\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)  # Ensure blocking behavior\n",
    "    \n",
    "    # Return list of bad epochs (after window closes)\n",
    "    bad_list = sorted(list(bad_epochs))\n",
    "    print(f\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Total bad epochs marked: {len(bad_list)}\")\n",
    "    print(f\"Bad epoch indices: {bad_list}\")\n",
    "    \n",
    "    return bad_list\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# bad_epochs = plot_epochs_with_metadata(mne_epoch_door_before, ['time_diff', 'trial_type', 'dig_type'])\n",
    "# \n",
    "# # Then mark them in your epochs object:\n",
    "# if len(bad_epochs) > 0:\n",
    "#     mne_epoch_door_before.drop(bad_epochs, reason='manual_review')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def plot_epochs_grid_with_metadata(epochs, metadata_cols=['time_diff'], n_cols=4):\n",
    "    \"\"\"\n",
    "    Interactive epoch grid viewer that displays all epochs and metadata.\n",
    "    Click on epochs to mark as bad.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epochs : mne.EpochsArray\n",
    "        The epochs object to visualize\n",
    "    metadata_cols : list\n",
    "        List of metadata column names to display\n",
    "    n_cols : int\n",
    "        Number of columns in the grid\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    bad_epochs = plot_epochs_grid_with_metadata(mne_epoch_door_before, ['time_diff', 'trial_type'], n_cols=5)\n",
    "    # Click on epochs to toggle bad/good\n",
    "    # Press 'q' to finish and close\n",
    "    \"\"\"\n",
    "    \n",
    "    n_epochs = len(epochs)\n",
    "    n_rows = int(np.ceil(n_epochs / n_cols))\n",
    "    bad_epochs = set()\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows))\n",
    "    fig.suptitle('Click on epochs to mark as BAD (red border). Press \"q\" when done.', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Flatten axes for easier indexing\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "    \n",
    "    # Store rectangles for each subplot\n",
    "    rectangles = {}\n",
    "    \n",
    "    def plot_epoch(idx, ax):\n",
    "        \"\"\"Plot a single epoch in the given axis\"\"\"\n",
    "        ax.clear()\n",
    "        \n",
    "        if idx >= n_epochs:\n",
    "            ax.axis('off')\n",
    "            return\n",
    "        \n",
    "        # Get epoch data\n",
    "        epoch_data = epochs[idx].get_data()[0]  # shape: (n_channels, n_times)\n",
    "        times = epochs.times\n",
    "        \n",
    "        # Plot each channel with offset\n",
    "        for ch_idx, ch_data in enumerate(epoch_data):\n",
    "            ax.plot(times, ch_data + ch_idx * 5, linewidth=0.8, alpha=0.7)\n",
    "        \n",
    "        # Create title with metadata\n",
    "        title = f\"Epoch {idx}\"\n",
    "        if epochs.metadata is not None:\n",
    "            for col in metadata_cols:\n",
    "                if col in epochs.metadata.columns:\n",
    "                    val = epochs.metadata.iloc[idx][col]\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        title += f\"\\n{col}: {val:.3f}\"\n",
    "                    else:\n",
    "                        title += f\"\\n{col}: {val}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=9, fontweight='bold')\n",
    "        ax.set_xlabel('Time (s)', fontsize=8)\n",
    "        ax.tick_params(labelsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add red border if marked as bad\n",
    "        if idx in bad_epochs:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(4)\n",
    "            ax.set_facecolor('#ffcccc')\n",
    "        else:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('black')\n",
    "                spine.set_linewidth(1)\n",
    "            ax.set_facecolor('white')\n",
    "    \n",
    "    def update_all_plots():\n",
    "        \"\"\"Redraw all epoch plots\"\"\"\n",
    "        for idx, ax in enumerate(axes):\n",
    "            plot_epoch(idx, ax)\n",
    "        fig.canvas.draw_idle()\n",
    "    \n",
    "    def on_click(event):\n",
    "        \"\"\"Handle mouse click events\"\"\"\n",
    "        if event.inaxes is None:\n",
    "            return\n",
    "        \n",
    "        # Find which subplot was clicked\n",
    "        for idx, ax in enumerate(axes):\n",
    "            if ax == event.inaxes and idx < n_epochs:\n",
    "                # Toggle bad epoch status\n",
    "                if idx in bad_epochs:\n",
    "                    bad_epochs.remove(idx)\n",
    "                    print(f\"Epoch {idx} unmarked as bad (Total bad: {len(bad_epochs)})\")\n",
    "                else:\n",
    "                    bad_epochs.add(idx)\n",
    "                    print(f\"Epoch {idx} marked as bad (Total bad: {len(bad_epochs)})\")\n",
    "                \n",
    "                # Redraw just this subplot\n",
    "                plot_epoch(idx, ax)\n",
    "                fig.canvas.draw_idle()\n",
    "                break\n",
    "    \n",
    "    def on_key(event):\n",
    "        \"\"\"Handle keyboard events\"\"\"\n",
    "        if event.key == 'q':\n",
    "            plt.close(fig)\n",
    "        elif event.key == 'r':\n",
    "            # Reset all bad epochs\n",
    "            bad_epochs.clear()\n",
    "            print(\"All bad epoch markings cleared\")\n",
    "            update_all_plots()\n",
    "    \n",
    "    # Connect event handlers\n",
    "    fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "    \n",
    "    # Initial plot of all epochs\n",
    "    update_all_plots()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)\n",
    "    \n",
    "    # Return list of bad epochs (after window closes)\n",
    "    bad_list = sorted(list(bad_epochs))\n",
    "    print(f\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Total bad epochs marked: {len(bad_list)}\")\n",
    "    print(f\"Bad epoch indices: {bad_list}\")\n",
    "    \n",
    "    return bad_list\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# bad_epochs = plot_epochs_grid_with_metadata(\n",
    "#     mne_epoch_door_before, \n",
    "#     metadata_cols=['time_diff', 'trial_type', 'dig_type'],\n",
    "#     n_cols=5\n",
    "# )\n",
    "# \n",
    "# # Then mark them in your epochs object:\n",
    "# if len(bad_epochs) > 0:\n",
    "#     mne_epoch_door_before.drop(bad_epochs, reason='manual_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "bad_epochs = plot_epochs_grid_with_metadata(test_epoch, ['time_diff', 'trial_type', 'dig_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c46fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Then mark them in your epochs object:\n",
    "if len(bad_epochs) > 0:\n",
    "    test_epoch.drop(bad_epochs, reason='manual_review')\n",
    "print(test_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_manual.loc['mne_epoch_dig_before_manual'] = bad_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1694c",
   "metadata": {},
   "source": [
    "### Dig Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_manual = con_data_df.copy()\n",
    "\n",
    "print(con_data_df_manual.shape[0])\n",
    "# Create the column FIRST with empty lists\n",
    "all_bad_epochs = []\n",
    "for row in range(con_data_df_manual.shape[0]):\n",
    "    epoch1 = con_data_df_manual.iloc[row]['mne_epoch_dig_before']\n",
    "    bad_epochs = plot_epochs_with_metadata(epoch1, ['time_diff', 'trial_type', 'dig_type'])\n",
    "    all_bad_epochs.append(bad_epochs)\n",
    "\n",
    "con_data_df_manual['bad_epochs_dig_before'] = all_bad_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5c7bd",
   "metadata": {},
   "source": [
    "### Dig After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0613973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(con_data_df_manual.shape[0])\n",
    "# Create the column FIRST with empty lists\n",
    "all_bad_epochs = []\n",
    "for row in range(con_data_df_manual.shape[0]):\n",
    "    epoch1 = con_data_df_manual.iloc[row]['mne_epoch_dig_after']\n",
    "    bad_epochs = plot_epochs_with_metadata(epoch1, ['time_diff', 'trial_type', 'dig_type'])\n",
    "    all_bad_epochs.append(bad_epochs)\n",
    "\n",
    "con_data_df_manual['bad_epochs_dig_after'] = all_bad_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04552a",
   "metadata": {},
   "source": [
    "### Door Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(con_data_df_manual.shape[0])\n",
    "# Create the column FIRST with empty lists\n",
    "all_bad_epochs = []\n",
    "for row in range(con_data_df_manual.shape[0]):\n",
    "    epoch1 = con_data_df_manual.iloc[row]['mne_epoch_door_before']\n",
    "    bad_epochs = plot_epochs_with_metadata(epoch1, ['time_diff', 'trial_type', 'dig_type'])\n",
    "    all_bad_epochs.append(bad_epochs)\n",
    "\n",
    "con_data_df_manual['bad_epochs_door_before'] = all_bad_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_manual.to_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_231125.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_marked = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_231125.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "door_before_dropped_total = 0\n",
    "dig_before_dropped_total = 0\n",
    "dig_after_dropped_total = 0\n",
    "\n",
    "for row in range(con_data_df_marked.shape[0]):\n",
    "    door_before = con_data_df_marked.iloc[row]['mne_epoch_door_before']\n",
    "    dig_before = con_data_df_marked.iloc[row]['mne_epoch_dig_before']    \n",
    "    dig_after = con_data_df_marked.iloc[row]['mne_epoch_dig_after']\n",
    "    \n",
    "    door_before_bad_epochs = con_data_df_marked.iloc[row]['bad_epochs_door_before']\n",
    "    dig_before_bad_epochs = con_data_df_marked.iloc[row]['bad_epochs_dig_before']    \n",
    "    dig_after_bad_epochs = con_data_df_marked.iloc[row]['bad_epochs_dig_after']\n",
    "    \n",
    "    door_before.drop(door_before_bad_epochs)\n",
    "    dig_before.drop(dig_before_bad_epochs)\n",
    "    dig_after.drop(dig_after_bad_epochs)\n",
    "    \n",
    "    door_before_dropped_total = door_before_dropped_total + len(door_before_bad_epochs)\n",
    "    dig_before_dropped_total = dig_before_dropped_total + len(dig_before_bad_epochs)\n",
    "    dig_after_dropped_total = dig_after_dropped_total + len(dig_after_bad_epochs)\n",
    "\n",
    "print(\"Total Door Before Epochs Dropped - \", door_before_dropped_total, \"Out of\", 20*27)\n",
    "print(\"Total Dig Before Epochs Dropped - \", dig_before_dropped_total, \"Out of\", 20*27)\n",
    "print(\"Total Dig After Epochs Dropped - \", dig_after_dropped_total, \"Out of\", 20*27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7e09c",
   "metadata": {},
   "source": [
    "## Coherence average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_pkl(time_window, fs, tanh_norm, filepath):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(filepath)\n",
    "\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        print(event_epoch.events.shape[0])\n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            \n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "                        \n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        ########TRYING HIGHPASS FILTERING FOR ARTIFACT REMOVAL################\n",
    "                        # epoch_highpass = event_epoch.copy().filter(l_freq = 1, h_freq=None, filter_length = \"0.7s\" )\n",
    "                        # con = mne_connectivity.spectral_connectivity_epochs(epoch_highpass, method='coh', sfreq=int(fs),\n",
    "                        #                                     mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                        #                                     cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'marked_coherence_spectrogram_before_after_door_dig_truncated_{}{}_231125.pkl'.format(int(time_window*fs), suffix))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "\n",
    "###############\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='_normalized'\n",
    "else:\n",
    "    suffix ='_non-normalized'\n",
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'marked_coherence_spectrogram_before_after_door_dig_truncated_{}{}_231125.pkl'.format(int(time_window*fs), suffix))\n",
    "event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "times=np.arange(0, time_window, 1/fs)\n",
    "fig, axs=plt.subplots(2,3, figsize=(15,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Before Door','Before Dig','After Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('Time (s)')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[0,i].set_title(event_names[i])\n",
    "\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)')\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[1,i].set_title(event_names[i])\n",
    "    axs[0,0].text(-0.3, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.3, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence (A.U.)', fontsize=12)\n",
    "fig.savefig(savepath+f'marked_coherence_spectrogram_before_after_door_dig_{int(time_window*fs/2)}ms{suffix}_231125.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05828db2",
   "metadata": {},
   "source": [
    "## Coherence Per Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_perexperiment_pkl(time_window, fs, tanh_norm):\n",
    "\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "\n",
    "\n",
    "    con_data_df_clean=con_data_df_marked\n",
    "\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "\n",
    "    test_list = [con_data_df_clean.iloc[0]]\n",
    "    mean_con_data=pd.DataFrame()\n",
    "    def epoch_coherogram(epoch, fmin=1, fmax=100, fs=2000):\n",
    "            print(epoch.events.shape)\n",
    "        # if epoch.events.shape[0] < 5:\n",
    "        #     print(\"Not enough events in the epoch\")\n",
    "        #     return None\n",
    "        # else:\n",
    "            freqs = np.arange(fmin, fmax)\n",
    "            n_cycles = freqs / 3\n",
    "            con = mne_connectivity.spectral_connectivity_epochs(epoch, method='coh', sfreq=int(fs),\n",
    "                                                                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "            coh = con.get_data(output='dense')\n",
    "            indices = con.names\n",
    "            aon_vHp_con = []\n",
    "            for i in range(coh.shape[0]):\n",
    "                for j in range(coh.shape[1]):\n",
    "                    if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                        coherence= coh[i,j,:,:]\n",
    "                        if tanh_norm:\n",
    "                            coherence=np.arctanh(coherence)\n",
    "                        aon_vHp_con.append(coherence)\n",
    "            \n",
    "            mean_con = np.mean(aon_vHp_con, axis=0)\n",
    "            return mean_con\n",
    "    mean_con_data['mne_epoch_door_before'] = con_data_df_clean['mne_epoch_door_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_before'] = con_data_df_clean['mne_epoch_dig_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_after'] = con_data_df_clean['mne_epoch_dig_after'].apply(epoch_coherogram)\n",
    "\n",
    "    mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "    mean_con_data['date'] = con_data_df_clean['date']\n",
    "    mean_con_data['task'] = con_data_df_clean['task']\n",
    "    mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "    mean_con_data.dropna(inplace=True)\n",
    "    mean_con_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    mean_con_data.to_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}_231125.pkl')\n",
    "\n",
    "coherogram_perexperiment_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11045761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "#################\n",
    "\n",
    "event_of_interest = 'mne_epoch_door_before'\n",
    "\n",
    "def plot_coherogram_perexperiment(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    mean_con_data=pd.read_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}_231125.pkl')\n",
    "    vmin = mean_con_data[event_of_interest].apply(np.min).min()\n",
    "    vmax = mean_con_data[event_of_interest].apply(np.max).max()\n",
    "\n",
    "    BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "    BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "    rat_ids, rat_nums = np.unique(BWcontext_data['rat_id'], return_counts=True)\n",
    "    print(rat_ids, rat_nums)\n",
    "    rat_nums_max = rat_nums.max()\n",
    "    print(rat_nums_max)\n",
    "    import matplotlib.pyplot as plt\n",
    "    writer = pd.ExcelWriter(savepath + 'marked_coherogram_perexperiment_{}_{}_231125.xlsx'.format(int(time_window*fs),suffix))\n",
    "\n",
    "    for group_name, group_df in task_data_dict.items():\n",
    "        print(f\"Plotting group: {group_name}\")\n",
    "        group_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "        rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "        rat_nums_max = rat_nums.max()\n",
    "\n",
    "        num_of_rows = 4 # Each row should be a rats\n",
    "        num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "        fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "        dk1_count = 0\n",
    "        dk3_count = 0\n",
    "        dk5_count = 0\n",
    "        dk6_count = 0\n",
    "        for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "            rat_id = row['rat_id']\n",
    "            data = np.array(row[event_of_interest])\n",
    "            if rat_id == 'dk1':\n",
    "                ax=axs[0, dk1_count]\n",
    "                dk1_count += 1\n",
    "            elif rat_id == 'dk3':\n",
    "                ax=axs[1, dk3_count]\n",
    "                dk3_count += 1\n",
    "            elif rat_id == 'dk5':\n",
    "                ax=axs[2, dk5_count]\n",
    "                dk5_count += 1\n",
    "            elif rat_id == 'dk6':\n",
    "                ax=axs[3, dk6_count]\n",
    "                dk6_count += 1\n",
    "            im = ax.imshow(data, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=0, vmax=1)\n",
    "            ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "\n",
    "            ##### Writing to excel\n",
    "\n",
    "            freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, data.shape[0])]\n",
    "            freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "            print(len(freqs))\n",
    "            time_points = [f'{np.round(t, 3)}s' for t in np.linspace(0, time_window, data.shape[1])]\n",
    "\n",
    "            df_towrite = pd.DataFrame(data)\n",
    "            df_towrite.loc[-1] = time_points  # Add time points as the first row\n",
    "            df_towrite.index = df_towrite.index + 1  # Shift index\n",
    "            df_towrite = df_towrite.sort_index()\n",
    "            df_towrite.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "            df_towrite.to_excel(writer, sheet_name=f'{group_dict[group_name]}_{rat_id}_{row[\"date\"]}', index=False)\n",
    "\n",
    "        for j in range(i + 1, len(axs)):\n",
    "            fig.delaxes(axs[j])\n",
    "        fig.suptitle(f\"{group_dict[group_name]} Coherence {suffix} {event_of_interest}\", fontsize=16)\n",
    "        fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02, label=f'Coherence {suffix}')\n",
    "        fig.savefig(savepath + f'{group_name}_coherogram_per_experiment_{event_of_interest}_{int(time_window*fs)}_231125.png', dpi=300, bbox_inches='tight')\n",
    "        #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "    writer.close()\n",
    "plot_coherogram_perexperiment(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383e89c",
   "metadata": {},
   "source": [
    "## Calculating Power and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49135539",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix ='_normalized'\n",
    "\n",
    "mne_epochs = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_181125.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_power_tfr(epoch):\n",
    "    fmin=1\n",
    "    fmax=100\n",
    "    fs=2000\n",
    "    freqs = np.arange(fmin,fmax)\n",
    "    n_cycles = freqs/3\n",
    "\n",
    "    power = epoch.compute_tfr(\n",
    "        method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False,\n",
    "    )\n",
    "\n",
    "    return power\n",
    "results = []\n",
    "for row in mne_epochs.itertuples(index=False):\n",
    "    experiment, rat_id, task, date = row.experiment, row.rat_id, row.task, row.date\n",
    "    door_before,door_after = row.mne_epoch_door_before, row.mne_epoch_door_after\n",
    "    dig_before,dig_after = row.mne_epoch_dig_before, row.mne_epoch_dig_after\n",
    "    around_door, around_dig = row.mne_epoch_around_door, row.mne_epoch_around_dig\n",
    "\n",
    "    power_door_before = get_power_tfr(door_before)\n",
    "    power_dig_before = get_power_tfr(dig_before)\n",
    "    power_dig_after = get_power_tfr(dig_after)\n",
    "\n",
    "    #net_power = power_dig_before - power_door_before\n",
    "    channel_names = door_before.ch_names\n",
    "    new_row = [experiment, rat_id, task, date,power_door_before,power_dig_before,power_dig_after, channel_names]\n",
    "    results.append(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ea58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results, columns=['experiment', 'rat_id', 'task','date', 'power_pre_door','power_pre_dig','power_post_dig', 'channel_names'])\n",
    "results_df.to_pickle(savepath + 'marked_power_tfr_epochs_mrlt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(savepath+'marked_power_tfr_epochs_mrlt.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_averaged_power(epoch, area):\n",
    "    print(epoch.ch_names)\n",
    "    area_channels = [channel for channel in epoch.ch_names if area in channel]\n",
    "    #print(area_channels)\n",
    "\n",
    "    if len(area_channels)==0:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    else:\n",
    "        area_epoch = epoch.copy()\n",
    "        area_epoch.pick(area_channels)\n",
    "        averaged_epoch_power = area_epoch.average(dim='epochs')\n",
    "        print(f\"Data shape before mean: {averaged_epoch_power.shape}\")  # DEBUG\n",
    "        mean_ch_power = np.mean(averaged_epoch_power.get_data(), axis = 0)\n",
    "        print(f\"Data shape after mean: {mean_ch_power.shape}\")  # DEBUG\n",
    "        return mean_ch_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371030dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_averaged_epoch_power = make_averaged_power(test_power_epoch, \"vHp\")\n",
    "# print(test_averaged_epoch_power.shape)\n",
    "\n",
    "for area in [\"AON\", \"vHp\"]:\n",
    "    area_df = pd.DataFrame()\n",
    "    fig, axs = plt.subplots(2,3, figsize= (15,10))\n",
    "    fig.suptitle(f'Average {area} Power')\n",
    "    for rowi, task in enumerate([\"BWcontext\", \"BWnocontext\"]):\n",
    "        task_data=results_df[results_df['task']==task]\n",
    "        print(f\"\\nTask: {task}, Area: {area}, Rows in task_data: {len(task_data)}\")\n",
    "        for coli, event in enumerate(['power_pre_door', 'power_pre_dig','power_post_dig']):\n",
    "            print(coli,event, task, area)\n",
    "            event_arrays = task_data[event].apply(lambda x: make_averaged_power(x, area))\n",
    "            \n",
    "            valid_arrays = [arr for arr in event_arrays.values if arr is not None]\n",
    "            \n",
    "            print(f\"Valid arrays found: {len(valid_arrays)}\")\n",
    "            \n",
    "            if len(valid_arrays) > 0:\n",
    "                averaged_array = np.mean(np.stack(valid_arrays), axis=0)\n",
    "                print(f\"Averaged array shape: {averaged_array.shape}\")\n",
    "                \n",
    "                ax = axs[rowi, coli]\n",
    "                im = ax.imshow(X= averaged_array, cmap = 'viridis', aspect='auto', origin='lower')\n",
    "                                # Add titles and labels\n",
    "                ax.set_title(f'{event.replace(\"_\", \" \").title()}')\n",
    "                ax.set_xlabel('Time (samples)')\n",
    "                ax.set_ylabel('Frequency (Hz)')\n",
    "                ax.set_xticks(list(np.arange(0,int(time_window*fs)+200,200)))\n",
    "                ax.set_xticklabels(list(np.round(np.arange(0,time_window +0.1,0.1), decimals = 1)))\n",
    "                # Add colorbar\n",
    "                plt.colorbar(im, ax=ax, label='Power (mV^2/Hz)')\n",
    "                \n",
    "                # Add row labels\n",
    "                if coli == 0:\n",
    "                    ax.set_ylabel(f'{task}\\nFrequency (Hz)', fontweight='bold')\n",
    "                # Add your plotting code here\n",
    "            else:\n",
    "                print(f\"WARNING: No valid data for {area}, {task}, {event}\")\n",
    "                ax = axs[rowi, coli]\n",
    "                ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'marked_power_spectrogram_{area}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb84e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_con_data = pd.read_pickle(savepath+'marked_power_tfr_epochs_mrlt.pkl')\n",
    "BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "rat_ids, rat_nums = np.unique(BWcontext_data['rat_id'], return_counts=True)\n",
    "print(rat_ids, rat_nums)\n",
    "rat_nums_max = rat_nums.max()\n",
    "print(rat_nums_max)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "event_of_interest = 'power_pre_dig'\n",
    "area_of_interest = \"AON\"\n",
    "\n",
    "for event_of_interest in ['power_pre_door', 'power_pre_dig', 'power_post_dig']:\n",
    "    for area_of_interest in [\"AON\", \"vHp\"]:\n",
    "\n",
    "        for group_name, group_df in task_data_dict.items():\n",
    "            print(f\"Plotting group: {group_name}\")\n",
    "            group_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "            rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "            rat_nums_max = rat_nums.max()\n",
    "\n",
    "            num_of_rows = 4 # Each row should be a rats\n",
    "            num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "            fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "            dk1_count = 0\n",
    "            dk3_count = 0\n",
    "            dk5_count = 0\n",
    "            dk6_count = 0\n",
    "            for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "                rat_id = row['rat_id']\n",
    "                data = row[event_of_interest]\n",
    "                \n",
    "                power_data = make_averaged_power(data, area_of_interest)\n",
    "                \n",
    "                if rat_id == 'dk1':\n",
    "                    ax=axs[0, dk1_count]\n",
    "                    dk1_count += 1\n",
    "                elif rat_id == 'dk3':\n",
    "                    ax=axs[1, dk3_count]\n",
    "                    dk3_count += 1\n",
    "                elif rat_id == 'dk5':\n",
    "                    ax=axs[2, dk5_count]\n",
    "                    dk5_count += 1\n",
    "                elif rat_id == 'dk6':\n",
    "                    ax=axs[3, dk6_count]\n",
    "                    dk6_count += 1\n",
    "                im = ax.imshow(power_data, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "                ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "            for j in range(i + 1, len(axs)):\n",
    "                fig.delaxes(axs[j])\n",
    "            fig.suptitle(f\"{group_dict[group_name]} {area_of_interest} {event_of_interest}\", fontsize=16)\n",
    "            fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02, label=f'Power (mV^2/Hz)')\n",
    "            fig.savefig(savepath + f'powerspec_per_experiment_{group_name}_{event_of_interest}_{area_of_interest}_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "            #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79220fdc",
   "metadata": {},
   "source": [
    "## Individual Experiment Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9a6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59961db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ind_exp_coherence(epoch):\n",
    "    \n",
    "    #print(row,event, event_epoch) \n",
    "    event_epoch=epoch\n",
    "    print(event_epoch.events.shape[0])\n",
    "    if event_epoch.events.shape[0] <5:\n",
    "        print(f\"Skipping {event} due to insufficient events\")\n",
    "        raise TypeError\n",
    "    fmin=1\n",
    "    fmax=100\n",
    "    fs=2000\n",
    "    freqs = np.arange(fmin,fmax)\n",
    "    n_cycles = freqs/3\n",
    "    \n",
    "    con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                        mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                        cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "    \n",
    "    ########TRYING HIGHPASS FILTERING FOR ARTIFACT REMOVAL################\n",
    "    # epoch_highpass = event_epoch.copy().filter(l_freq = 1, h_freq=None, filter_length = \"0.7s\" )\n",
    "    # con = mne_connectivity.spectral_connectivity_epochs(epoch_highpass, method='coh', sfreq=int(fs),\n",
    "    #                                     mode='cwt_morlet', cwt_freqs=freqs,\n",
    "    #                                     cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coh = con.get_data(output='dense')\n",
    "    indices = con.names\n",
    "    \n",
    "    aon_vHp_con =[]\n",
    "    for i in range(coh.shape[0]):\n",
    "        for j in range(coh.shape[1]):\n",
    "            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                coherence= coh[i,j,:,:]\n",
    "                coherence=np.arctanh(coherence)\n",
    "                aon_vHp_con.append(coherence)\n",
    "    return np.mean(aon_vHp_con, axis=0)\n",
    "\n",
    "def ind_exp_power(epoch, area):\n",
    "    fmin=1\n",
    "    fmax=100\n",
    "    fs=2000\n",
    "    freqs = np.arange(fmin,fmax)\n",
    "    n_cycles = freqs/3\n",
    "\n",
    "    power = epoch.compute_tfr(\n",
    "        method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False,\n",
    "    )\n",
    "    print(epoch.ch_names)\n",
    "    area_channels = [channel for channel in epoch.ch_names if area in channel]\n",
    "    area_epoch = power.copy()\n",
    "    area_epoch.pick(area_channels)\n",
    "    averaged_epoch_power = area_epoch.average(dim='epochs')\n",
    "    averaged_channel_power = np.mean(area_epoch.get_data(), axis =1)\n",
    "    num_of_epochs = area_epoch.get_data().shape[0] \n",
    "    print(f\"Data shape before mean: {averaged_epoch_power.shape}\")  # DEBUG\n",
    "    mean_ch_power = np.mean(averaged_epoch_power.get_data(), axis = 0)\n",
    "    print(f\"Data shape after mean: {mean_ch_power.shape}\")  # DEBUG\n",
    "    return num_of_epochs,averaged_channel_power, mean_ch_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141c62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df = pd.read_pickle(savepath+f'raw_mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aabd185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rat =\"dk1\"\n",
    "task = \"BWcontext\"\n",
    "date = \"20230818\"\n",
    "\n",
    "experiment_data = con_data_df[(con_data_df.date==date) & (con_data_df.rat_id==rat) & (con_data_df.task==task)]\n",
    "event_of_interest = \"mne_epoch_door_before\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8224b8a",
   "metadata": {},
   "source": [
    "### Initial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ed68a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1653193634.py:32: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (4, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "Channels: ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "test_epoch = experiment_data.at[experiment_data.index[0],event_of_interest]\n",
    "\n",
    "coherence = ind_exp_coherence(test_epoch)\n",
    "\n",
    "num_of_epochs,aon_power, avg_aon_power = ind_exp_power(test_epoch, \"AON\")\n",
    "#print(aon_power)\n",
    "\n",
    "num_of_epochs,vhp_power, avg_vhp_power = ind_exp_power(test_epoch, \"vHp\")\n",
    "#print(vhp_power)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "fig.suptitle(f'{rat} {task} {date} {event_of_interest}')\n",
    "axs=axs.flatten()\n",
    "\n",
    "im0 = axs[0].imshow(coherence, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[0].set_title(\"Coherence\")\n",
    "plt.colorbar(im0, ax=axs[0])\n",
    "\n",
    "im1 = axs[1].imshow(avg_aon_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[1].set_title(\"AON Power\")\n",
    "plt.colorbar(im1, ax=axs[1])\n",
    "\n",
    "im2 = axs[2].imshow(avg_vhp_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[2].set_title(\"vHp Power\")\n",
    "plt.colorbar(im2, ax=axs[2])\n",
    "\n",
    "fig2, axs2 = plt.subplots(nrows=2, ncols = num_of_epochs, figsize = (20,5))\n",
    "fig2.suptitle(f'{rat} {task} {date} {event_of_interest}')\n",
    "for rowi,power in enumerate([aon_power, vhp_power]):\n",
    "    # vmin = power.apply(np.min).min()\n",
    "    # vmax = power.apply(np.max).max()\n",
    "    for coli in range(power.shape[0]):\n",
    "        ax = axs2[rowi, coli]\n",
    "        im = ax.imshow(power[coli, :, :], extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')#, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f'{coli}')\n",
    "        if coli == 0 :\n",
    "            if rowi==0:\n",
    "                ax.text(-0.3, 0.5,\"AON Power\", transform=ax.transAxes, fontsize=10, verticalalignment='center', rotation=90)\n",
    "            else:\n",
    "                ax.text(-0.3, 0.5,\"vHp Power\", transform=ax.transAxes, fontsize=10, verticalalignment='center', rotation=90)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1d4b3",
   "metadata": {},
   "source": [
    "### Annotation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "02835ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x201d274f3a0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3 epochs: 0, 4, 9\n",
      "The following epochs were marked as bad and are dropped:\n",
      "[2, 6, 15]\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "test_epoch.plot(scalings=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7ee57",
   "metadata": {},
   "source": [
    "### Revised plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4f60acfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1653193634.py:32: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (4, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "Channels: ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "coherence = ind_exp_coherence(test_epoch)\n",
    "\n",
    "num_of_epochs,aon_power, avg_aon_power = ind_exp_power(test_epoch, \"AON\")\n",
    "#print(aon_power)\n",
    "\n",
    "num_of_epochs,vhp_power, avg_vhp_power = ind_exp_power(test_epoch, \"vHp\")\n",
    "#print(vhp_power)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "fig.suptitle(f'{rat} {task} {date} {event_of_interest}')\n",
    "axs=axs.flatten()\n",
    "\n",
    "im0 = axs[0].imshow(coherence, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[0].set_title(\"Coherence\")\n",
    "plt.colorbar(im0, ax=axs[0])\n",
    "\n",
    "im1 = axs[1].imshow(avg_aon_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[1].set_title(\"AON Power\")\n",
    "plt.colorbar(im1, ax=axs[1])\n",
    "\n",
    "im2 = axs[2].imshow(avg_vhp_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "axs[2].set_title(\"vHp Power\")\n",
    "plt.colorbar(im2, ax=axs[2])\n",
    "\n",
    "fig2, axs2 = plt.subplots(nrows=2, ncols = num_of_epochs, figsize = (20,5))\n",
    "fig2.suptitle(f'{rat} {task} {date} {event_of_interest}')\n",
    "for rowi,power in enumerate([aon_power, vhp_power]):\n",
    "    # vmin = power.apply(np.min).min()\n",
    "    # vmax = power.apply(np.max).max()\n",
    "    for coli in range(power.shape[0]):\n",
    "        ax = axs2[rowi, coli]\n",
    "        im = ax.imshow(power[coli, :, :], extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')#, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f'{coli}')\n",
    "        if coli == 0 :\n",
    "            if rowi==0:\n",
    "                ax.text(-0.3, 0.5,\"AON Power\", transform=ax.transAxes, fontsize=10, verticalalignment='center', rotation=90)\n",
    "            else:\n",
    "                ax.text(-0.3, 0.5,\"vHp Power\", transform=ax.transAxes, fontsize=10, verticalalignment='center', rotation=90)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4f79c",
   "metadata": {},
   "source": [
    "## Annotation Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0d4134a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df.to_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0b57505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 18 events (all good), 0 – 1 s (baseline off), ~1.4 MB, data loaded,\n",
      " '1': 18>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 14 events (all good), 0 – 1 s (baseline off), ~884 kB, data loaded,\n",
      " '1': 14>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 17 events (all good), 0 – 1 s (baseline off), ~1.3 MB, data loaded,\n",
      " '1': 17>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 12 events (all good), 0 – 1 s (baseline off), ~1.1 MB, data loaded,\n",
      " '1': 12>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 13 events (all good), 0 – 1 s (baseline off), ~1.4 MB, data loaded,\n",
      " '1': 13>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 13 events (all good), 0 – 1 s (baseline off), ~1.2 MB, data loaded,\n",
      " '1': 13>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 5 events (all good), 0 – 1 s (baseline off), ~480 kB, data loaded,\n",
      " '1': 5>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 18 events (all good), 0 – 1 s (baseline off), ~2.2 MB, data loaded,\n",
      " '1': 18>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "c:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne_connectivity\\spectral\\epochs_bivariate.py:81: RuntimeWarning: invalid value encountered in divide\n",
      "  self.con_scores[con_idx] = np.abs(csd_mean) / np.sqrt(psd_xx * psd_yy)\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 6 events (all good), 0 – 1 s (baseline off), ~668 kB, data loaded,\n",
      " '1': 6>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 19 events (all good), 0 – 1 s (baseline off), ~2.0 MB, data loaded,\n",
      " '1': 19>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 14 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 14>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 19 events (all good), 0 – 1 s (baseline off), ~2.0 MB, data loaded,\n",
      " '1': 19>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 17 events (all good), 0 – 1 s (baseline off), ~1.8 MB, data loaded,\n",
      " '1': 17>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.2 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.8 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~2.1 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.8 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~1.8 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: There were no Annotations stored in <EpochsArray | 20 events (all good), 0 – 1 s (baseline off), ~2.5 MB, data loaded,\n",
      " '1': 20>, so metadata was not modified.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1827852203.py:47: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     all_con_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_con_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m event_list)\n\u001b[0;32m     76\u001b[0m     all_con_data_df\u001b[38;5;241m.\u001b[39mto_pickle(savepath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarked_coherence_spectrogram_before_after_door_dig_truncated_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_251125.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mint\u001b[39m(time_window\u001b[38;5;241m*\u001b[39mfs), suffix))\n\u001b[1;32m---> 78\u001b[0m \u001b[43mcoherogram_pkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtanh_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtanh_norm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[120], line 47\u001b[0m, in \u001b[0;36mcoherogram_pkl\u001b[1;34m(time_window, fs, tanh_norm)\u001b[0m\n\u001b[0;32m     44\u001b[0m freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(fmin,fmax)\n\u001b[0;32m     45\u001b[0m n_cycles \u001b[38;5;241m=\u001b[39m freqs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 47\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43mmne_connectivity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspectral_connectivity_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcwt_morlet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwt_freqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcwt_n_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cycles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m########TRYING HIGHPASS FILTERING FOR ARTIFACT REMOVAL################\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# epoch_highpass = event_epoch.copy().filter(l_freq = 1, h_freq=None, filter_length = \"0.7s\" )\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# con = mne_connectivity.spectral_connectivity_epochs(epoch_highpass, method='coh', sfreq=int(fs),\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#                                     mode='cwt_morlet', cwt_freqs=freqs,\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#                                     cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m coh \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mget_data(output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<decorator-gen-302>:10\u001b[0m, in \u001b[0;36mspectral_connectivity_epochs\u001b[1;34m(data, names, method, indices, sfreq, mode, fmin, fmax, fskip, faverage, tmin, tmax, mt_bandwidth, mt_adaptive, mt_low_bias, cwt_freqs, cwt_n_cycles, gc_n_lags, rank, block_size, n_jobs, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne_connectivity\\spectral\\epochs.py:1168\u001b[0m, in \u001b[0;36mspectral_connectivity_epochs\u001b[1;34m(data, names, method, indices, sfreq, mode, fmin, fmax, fskip, faverage, tmin, tmax, mt_bandwidth, mt_adaptive, mt_low_bias, cwt_freqs, cwt_n_cycles, gc_n_lags, rank, block_size, n_jobs, verbose)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    computing cross-spectral density for epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1165\u001b[0m             \u001b[38;5;241m%\u001b[39m (epoch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1166\u001b[0m         )\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;66;03m# con methods and psd are updated inplace\u001b[39;00m\n\u001b[1;32m-> 1168\u001b[0m         _epoch_spectral_connectivity(data\u001b[38;5;241m=\u001b[39mthis_epoch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_params)\n\u001b[0;32m   1169\u001b[0m         epoch_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;66;03m# process epochs in parallel\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne_connectivity\\spectral\\epochs.py:485\u001b[0m, in \u001b[0;36m_epoch_spectral_connectivity\u001b[1;34m(data, sig_idx, tmin_idx, tmax_idx, sfreq, method, mode, window_fun, eigvals, wavelets, freq_mask, mt_adaptive, idx_map, n_cons, block_size, psd, accumulate_psd, con_method_types, con_methods, n_signals, n_signals_use, n_times, gc_n_lags, accumulate_inplace)\u001b[0m\n\u001b[0;32m    483\u001b[0m con_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m-\u001b[39m n_extra)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# this codes can be very slow\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m csd \u001b[38;5;241m=\u001b[39m x_t[idx_map[\u001b[38;5;241m0\u001b[39m][con_idx]] \u001b[38;5;241m*\u001b[39m \u001b[43mx_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcon_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m con_methods:\n\u001b[0;32m    488\u001b[0m     method\u001b[38;5;241m.\u001b[39maccumulate(con_idx, csd)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_pkl(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        print(event_epoch.events.shape[0])\n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            \n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "                        \n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        ########TRYING HIGHPASS FILTERING FOR ARTIFACT REMOVAL################\n",
    "                        # epoch_highpass = event_epoch.copy().filter(l_freq = 1, h_freq=None, filter_length = \"0.7s\" )\n",
    "                        # con = mne_connectivity.spectral_connectivity_epochs(epoch_highpass, method='coh', sfreq=int(fs),\n",
    "                        #                                     mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                        #                                     cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'marked_coherence_spectrogram_before_after_door_dig_truncated_{}{}_251125.pkl'.format(int(time_window*fs), suffix))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf37a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "\n",
    "###############\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='_normalized'\n",
    "else:\n",
    "    suffix ='_non-normalized'\n",
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'marked_coherence_spectrogram_before_after_door_dig_truncated_{}{}_251125.pkl'.format(int(time_window*fs), suffix))\n",
    "event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "times=np.arange(0, time_window, 1/fs)\n",
    "fig, axs=plt.subplots(2,3, figsize=(15,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Before Door','Before Dig','After Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('Time (s)')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[0,i].set_title(event_names[i])\n",
    "\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)')\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[1,i].set_title(event_names[i])\n",
    "    axs[0,0].text(-0.3, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.3, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence (A.U.)', fontsize=12)\n",
    "fig.savefig(savepath+f'marked_coherence_spectrogram_before_after_door_dig_{int(time_window*fs/2)}ms{suffix}_231125.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c467277",
   "metadata": {},
   "source": [
    "## Everything Together from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5445a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def ind_exp_coherence(epoch):\n",
    "    \"\"\"\n",
    "    Calculate coherence between AON and vHp channels for given epochs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epoch : mne.EpochsArray\n",
    "        Epoch data containing AON and vHp channels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    coherence : np.ndarray\n",
    "        Mean coherence across AON-vHp channel pairs (freqs x time)\n",
    "    \"\"\"\n",
    "    event_epoch = epoch\n",
    "    print(f\"Number of epochs: {event_epoch.events.shape[0]}\")\n",
    "    \n",
    "    if event_epoch.events.shape[0] < 5:\n",
    "        print(f\"Skipping due to insufficient events (< 5)\")\n",
    "        raise TypeError(\"Insufficient events for coherence calculation\")\n",
    "    \n",
    "    fmin = 1\n",
    "    fmax = 100\n",
    "    fs = 2000\n",
    "    freqs = np.arange(fmin, fmax)\n",
    "    n_cycles = freqs / 3\n",
    "    \n",
    "    con = mne_connectivity.spectral_connectivity_epochs(\n",
    "        event_epoch, method='coh', sfreq=int(fs),\n",
    "        mode='cwt_morlet', cwt_freqs=freqs,\n",
    "        cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False\n",
    "    )\n",
    "    \n",
    "    coh = con.get_data(output='dense')\n",
    "    indices = con.names\n",
    "    \n",
    "    aon_vHp_con = []\n",
    "    for i in range(coh.shape[0]):\n",
    "        for j in range(coh.shape[1]):\n",
    "            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                coherence = coh[i, j, :, :]\n",
    "                coherence = np.arctanh(coherence)\n",
    "                aon_vHp_con.append(coherence)\n",
    "    \n",
    "    return np.mean(aon_vHp_con, axis=0)\n",
    "\n",
    "\n",
    "def ind_exp_power(epoch, area):\n",
    "    \"\"\"\n",
    "    Calculate power for a specific brain area across epochs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epoch : mne.EpochsArray\n",
    "        Epoch data\n",
    "    area : str\n",
    "        Brain area identifier (e.g., 'AON' or 'vHp')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    num_of_epochs : int\n",
    "        Number of epochs\n",
    "    averaged_channel_power : np.ndarray\n",
    "        Power for each epoch, averaged across channels (epochs x freqs x time)\n",
    "    mean_ch_power : np.ndarray\n",
    "        Power averaged across both epochs and channels (freqs x time)\n",
    "    \"\"\"\n",
    "    fmin = 1\n",
    "    fmax = 100\n",
    "    fs = 2000\n",
    "    freqs = np.arange(fmin, fmax)\n",
    "    n_cycles = freqs / 3\n",
    "    \n",
    "    power = epoch.compute_tfr(\n",
    "        method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"Channels: {epoch.ch_names}\")\n",
    "    area_channels = [channel for channel in epoch.ch_names if area in channel]\n",
    "    area_epoch = power.copy()\n",
    "    area_epoch.pick(area_channels)\n",
    "    \n",
    "    averaged_epoch_power = area_epoch.average(dim='epochs')\n",
    "    averaged_channel_power = np.mean(area_epoch.get_data(), axis=1)\n",
    "    num_of_epochs = area_epoch.get_data().shape[0]\n",
    "    \n",
    "    print(f\"Data shape before mean: {averaged_epoch_power.shape}\")\n",
    "    mean_ch_power = np.mean(averaged_epoch_power.get_data(), axis=0)\n",
    "    print(f\"Data shape after mean: {mean_ch_power.shape}\")\n",
    "    \n",
    "    return num_of_epochs, averaged_channel_power, mean_ch_power\n",
    "\n",
    "\n",
    "def plot_epochs_grid_with_metadata(epochs, metadata_cols=['time_diff'], n_cols=4, pre_marked_bad=None, position=None, power_figs=None):\n",
    "    \"\"\"\n",
    "    Interactive epoch grid viewer that displays all epochs and metadata.\n",
    "    Click on epochs to mark as bad.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epochs : mne.EpochsArray\n",
    "        The epochs object to visualize\n",
    "    metadata_cols : list\n",
    "        List of metadata column names to display\n",
    "    n_cols : int\n",
    "        Number of columns in the grid\n",
    "    pre_marked_bad : list, optional\n",
    "        List of epoch indices that are already marked as bad\n",
    "    position : tuple, optional\n",
    "        (x, y) position in pixels for the figure window\n",
    "    power_figs : tuple, optional\n",
    "        (fig1, fig2) power/coherence figures to close when this window closes\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    bad_epochs = plot_epochs_grid_with_metadata(mne_epoch_door_before, ['time_diff', 'trial_type'], n_cols=5)\n",
    "    # Click on epochs to toggle bad/good\n",
    "    # Press 'q' to finish and close\n",
    "    \"\"\"\n",
    "    \n",
    "    n_epochs = len(epochs)\n",
    "    n_rows = int(np.ceil(n_epochs / n_cols))\n",
    "    \n",
    "    # Initialize with pre-marked bad epochs if provided\n",
    "    if pre_marked_bad is None:\n",
    "        bad_epochs = set()\n",
    "    else:\n",
    "        bad_epochs = set(pre_marked_bad)\n",
    "        print(f\"Starting with {len(bad_epochs)} pre-marked bad epochs: {sorted(list(bad_epochs))}\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows))\n",
    "    \n",
    "    # Position the window if specified\n",
    "    if position is not None:\n",
    "        mngr = fig.canvas.manager\n",
    "        try:\n",
    "            mngr.window.setGeometry(position[0], position[1], 400*n_cols, 300*n_rows)\n",
    "        except:\n",
    "            try:\n",
    "                mngr.window.wm_geometry(f\"+{position[0]}+{position[1]}\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    fig.suptitle('Click on epochs to mark as BAD (red border). Press \"q\" when done.', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Flatten axes for easier indexing\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten() if n_rows > 1 or n_cols > 1 else [axes]\n",
    "    \n",
    "    # Store rectangles for each subplot\n",
    "    rectangles = {}\n",
    "    \n",
    "    def plot_epoch(idx, ax):\n",
    "        \"\"\"Plot a single epoch in the given axis\"\"\"\n",
    "        ax.clear()\n",
    "        \n",
    "        if idx >= n_epochs:\n",
    "            ax.axis('off')\n",
    "            return\n",
    "        \n",
    "        # Get epoch data\n",
    "        epoch_data = epochs[idx].get_data()[0]  # shape: (n_channels, n_times)\n",
    "        times = epochs.times\n",
    "        \n",
    "        # Plot each channel with offset\n",
    "        for ch_idx, ch_data in enumerate(epoch_data):\n",
    "            ax.plot(times, ch_data + ch_idx * 5, linewidth=0.8, alpha=0.7)\n",
    "        \n",
    "        # Create title with metadata\n",
    "        title = f\"Epoch {idx}\"\n",
    "        if epochs.metadata is not None:\n",
    "            for col in metadata_cols:\n",
    "                if col in epochs.metadata.columns:\n",
    "                    val = epochs.metadata.iloc[idx][col]\n",
    "                    if isinstance(val, (int, float)):\n",
    "                        title += f\"\\n{col}: {val:.3f}\"\n",
    "                    else:\n",
    "                        title += f\"\\n{col}: {val}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=9, fontweight='bold')\n",
    "        ax.set_xlabel('Time (s)', fontsize=8)\n",
    "        ax.tick_params(labelsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add red border if marked as bad\n",
    "        if idx in bad_epochs:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(4)\n",
    "            ax.set_facecolor('#ffcccc')\n",
    "        else:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('black')\n",
    "                spine.set_linewidth(1)\n",
    "            ax.set_facecolor('white')\n",
    "    \n",
    "    def update_all_plots():\n",
    "        \"\"\"Redraw all epoch plots\"\"\"\n",
    "        for idx, ax in enumerate(axes):\n",
    "            plot_epoch(idx, ax)\n",
    "        fig.canvas.draw_idle()\n",
    "    \n",
    "    def on_click(event):\n",
    "        \"\"\"Handle mouse click events\"\"\"\n",
    "        if event.inaxes is None:\n",
    "            return\n",
    "        \n",
    "        # Find which subplot was clicked\n",
    "        for idx, ax in enumerate(axes):\n",
    "            if ax == event.inaxes and idx < n_epochs:\n",
    "                # Toggle bad epoch status\n",
    "                if idx in bad_epochs:\n",
    "                    bad_epochs.remove(idx)\n",
    "                    print(f\"Epoch {idx} unmarked as bad (Total bad: {len(bad_epochs)})\")\n",
    "                else:\n",
    "                    bad_epochs.add(idx)\n",
    "                    print(f\"Epoch {idx} marked as bad (Total bad: {len(bad_epochs)})\")\n",
    "                \n",
    "                # Redraw just this subplot\n",
    "                plot_epoch(idx, ax)\n",
    "                fig.canvas.draw_idle()\n",
    "                break\n",
    "    \n",
    "    def on_key(event):\n",
    "        \"\"\"Handle keyboard events\"\"\"\n",
    "        if event.key == 'q':\n",
    "            # Close power/coherence figures if provided\n",
    "            if power_figs is not None:\n",
    "                try:\n",
    "                    plt.close(power_figs[0])\n",
    "                    plt.close(power_figs[1])\n",
    "                    print(\"Closed power/coherence plots\")\n",
    "                except:\n",
    "                    pass\n",
    "            plt.close(fig)\n",
    "        elif event.key == 'r':\n",
    "            # Reset all bad epochs\n",
    "            bad_epochs.clear()\n",
    "            print(\"All bad epoch markings cleared\")\n",
    "            update_all_plots()\n",
    "    \n",
    "    # Connect event handlers\n",
    "    fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "    \n",
    "    # Initial plot of all epochs\n",
    "    update_all_plots()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)\n",
    "    \n",
    "    # Return list of bad epochs (after window closes)\n",
    "    bad_list = sorted(list(bad_epochs))\n",
    "    print(f\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Total bad epochs marked: {len(bad_list)}\")\n",
    "    print(f\"Bad epoch indices: {bad_list}\")\n",
    "    \n",
    "    return bad_list\n",
    "\n",
    "\n",
    "def plot_coherence_and_power(epochs, rat='', task='', date='', event_name='', time_window=1.0, \n",
    "                            ind_exp_coherence=None, ind_exp_power=None, block=False, position=None):\n",
    "    \"\"\"\n",
    "    Plot coherence and power for all epochs to help identify bad epochs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epochs : mne.EpochsArray\n",
    "        The epochs object to analyze\n",
    "    rat : str\n",
    "        Rat ID for plot title\n",
    "    task : str\n",
    "        Task name for plot title\n",
    "    date : str\n",
    "        Date for plot title\n",
    "    event_name : str\n",
    "        Event name for plot title\n",
    "    time_window : float\n",
    "        Time window for extent in plots\n",
    "    ind_exp_coherence : function\n",
    "        Function to calculate coherence (must be provided)\n",
    "    ind_exp_power : function\n",
    "        Function to calculate power (must be provided)\n",
    "    block : bool\n",
    "        If True, blocks execution until plots are closed\n",
    "    position : tuple, optional\n",
    "        (x, y) position in pixels for the figure window\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig, fig2 : matplotlib figures\n",
    "        The two figure objects (for non-blocking mode)\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    plot_coherence_and_power(\n",
    "        test_epoch, \n",
    "        rat='dk6', \n",
    "        task='context', \n",
    "        date='20230616',\n",
    "        event_name='dig_before',\n",
    "        time_window=1.0,\n",
    "        ind_exp_coherence=ind_exp_coherence,\n",
    "        ind_exp_power=ind_exp_power,\n",
    "        block=False,  # Don't block, keep plots open\n",
    "        position=(100, 100)  # Position on screen\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    if ind_exp_coherence is None or ind_exp_power is None:\n",
    "        raise ValueError(\"Must provide ind_exp_coherence and ind_exp_power functions\")\n",
    "    \n",
    "    # Calculate coherence and power\n",
    "    coherence = ind_exp_coherence(epochs)\n",
    "    num_of_epochs, aon_power, avg_aon_power = ind_exp_power(epochs, \"AON\")\n",
    "    num_of_epochs, vhp_power, avg_vhp_power = ind_exp_power(epochs, \"vHp\")\n",
    "    \n",
    "    # Figure 1: Average coherence and power\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    if position is not None:\n",
    "        mngr = fig.canvas.manager\n",
    "        # Try to position the window (method depends on backend)\n",
    "        try:\n",
    "            mngr.window.setGeometry(position[0], position[1], 1500, 500)\n",
    "        except:\n",
    "            try:\n",
    "                mngr.window.wm_geometry(f\"+{position[0]}+{position[1]}\")\n",
    "            except:\n",
    "                pass  # If positioning fails, just use default\n",
    "    \n",
    "    fig.suptitle(f'{rat} {task} {date} {event_name}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax0 = fig.add_subplot(1, 3, 1)\n",
    "    im0 = ax0.imshow(coherence, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "    ax0.set_title(\"Coherence\")\n",
    "    ax0.set_xlabel(\"Time (s)\")\n",
    "    ax0.set_ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(im0, ax=ax0)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 3, 2)\n",
    "    im1 = ax1.imshow(avg_aon_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "    ax1.set_title(\"AON Power\")\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 3, 3)\n",
    "    im2 = ax2.imshow(avg_vhp_power, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "    ax2.set_title(\"vHp Power\")\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.set_ylabel(\"Frequency (Hz)\")\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Figure 2: Individual epoch power\n",
    "    fig2 = plt.figure(figsize=(20, 5))\n",
    "    if position is not None:\n",
    "        mngr2 = fig2.canvas.manager\n",
    "        # Position below first figure (offset by height)\n",
    "        try:\n",
    "            mngr2.window.setGeometry(position[0], position[1] + 550, 2000, 500)\n",
    "        except:\n",
    "            try:\n",
    "                mngr2.window.wm_geometry(f\"+{position[0]}+{position[1] + 550}\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    fig2.suptitle(f'{rat} {task} {date} {event_name} - Individual Epochs', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for rowi, power in enumerate([aon_power, vhp_power]):\n",
    "        for coli in range(power.shape[0]):\n",
    "            ax = fig2.add_subplot(2, num_of_epochs, rowi * num_of_epochs + coli + 1)\n",
    "            im = ax.imshow(power[coli, :, :], extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "            ax.set_title(f'Epoch {coli}', fontsize=9)\n",
    "            \n",
    "            if coli == 0:\n",
    "                if rowi == 0:\n",
    "                    ax.text(-0.3, 0.5, \"AON Power\", transform=ax.transAxes, fontsize=10, \n",
    "                           verticalalignment='center', rotation=90)\n",
    "                else:\n",
    "                    ax.text(-0.3, 0.5, \"vHp Power\", transform=ax.transAxes, fontsize=10, \n",
    "                           verticalalignment='center', rotation=90)\n",
    "            \n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if block:\n",
    "        plt.show(block=True)\n",
    "    else:\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.1)  # Brief pause to render plots\n",
    "    \n",
    "    return fig, fig2\n",
    "\n",
    "\n",
    "def annotate_and_clean_epochs_dataframe(df, event_columns=None, metadata_cols=['time_diff', 'trial_type', 'dig_type'], \n",
    "                                       n_cols=5, savepath=None, show_power_coherence=False, \n",
    "                                       time_window=1.0, ind_exp_coherence=None, ind_exp_power=None):\n",
    "    \"\"\"\n",
    "    Annotate bad epochs for all event types in a dataframe and create cleaned versions.\n",
    "    Optionally display coherence and power plots before annotation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing epoch data columns\n",
    "    event_columns : list, optional\n",
    "        List of column names containing epoch data to annotate.\n",
    "        If None, uses default event columns.\n",
    "    metadata_cols : list\n",
    "        Metadata columns to display during annotation\n",
    "    n_cols : int\n",
    "        Number of columns in the grid display\n",
    "    savepath : str, optional\n",
    "        Path to save the annotated dataframe. If None, doesn't save.\n",
    "    show_power_coherence : bool\n",
    "        If True, show coherence and power plots before epoch annotation\n",
    "    time_window : float\n",
    "        Time window for power/coherence plots\n",
    "    ind_exp_coherence : function\n",
    "        Function to calculate coherence (required if show_power_coherence=True)\n",
    "    ind_exp_power : function\n",
    "        Function to calculate power (required if show_power_coherence=True)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_annotated : pd.DataFrame\n",
    "        Dataframe with added columns:\n",
    "        - bad_epochs_{event}: list of bad epoch indices\n",
    "        - dropped_epochs_{event}: clean epoch data with bad epochs removed\n",
    "    \n",
    "    Usage:\n",
    "    ------\n",
    "    # Without power/coherence plots:\n",
    "    con_data_df_annotated = annotate_and_clean_epochs_dataframe(\n",
    "        con_data_df,\n",
    "        event_columns=['mne_epoch_door_before', 'mne_epoch_dig_before'],\n",
    "        metadata_cols=['time_diff', 'trial_type', 'dig_type'],\n",
    "        n_cols=5,\n",
    "        savepath=savepath\n",
    "    )\n",
    "    \n",
    "    # With power/coherence plots:\n",
    "    con_data_df_annotated = annotate_and_clean_epochs_dataframe(\n",
    "        con_data_df,\n",
    "        event_columns=['mne_epoch_door_before'],\n",
    "        show_power_coherence=True,\n",
    "        time_window=1.0,\n",
    "        ind_exp_coherence=ind_exp_coherence,\n",
    "        ind_exp_power=ind_exp_power,\n",
    "        savepath='path/to/save/'\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default event columns if not specified\n",
    "    if event_columns is None:\n",
    "        event_columns = ['mne_epoch_door_before', 'mne_epoch_door_after', \n",
    "                        'mne_epoch_dig_before', 'mne_epoch_dig_after',\n",
    "                        'mne_epoch_around_door', 'mne_epoch_around_dig']\n",
    "    \n",
    "    # Check if power/coherence functions are provided when needed\n",
    "    if show_power_coherence and (ind_exp_coherence is None or ind_exp_power is None):\n",
    "        raise ValueError(\"Must provide ind_exp_coherence and ind_exp_power functions when show_power_coherence=True\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_annotated = df.copy()\n",
    "    \n",
    "    # Step 1: For each event type, collect bad epochs for all rows\n",
    "    for event_col in event_columns:\n",
    "        print(f\"\\n{'#'*70}\")\n",
    "        print(f\"# Processing event type: {event_col}\")\n",
    "        print(f\"{'#'*70}\\n\")\n",
    "        \n",
    "        # Collect bad epochs for this event type across all rows\n",
    "        all_bad_epochs_for_event = []\n",
    "        \n",
    "        for row in range(df_annotated.shape[0]):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Row {row}/{df_annotated.shape[0]-1}\")\n",
    "            \n",
    "            rat = df_annotated.iloc[row]['rat_id']\n",
    "            task = df_annotated.iloc[row]['task']\n",
    "            date = df_annotated.iloc[row]['date']\n",
    "            \n",
    "            print(f\"Rat: {rat}, Task: {task}, Date: {date}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Get the event data\n",
    "            event_data = df_annotated.iloc[row][event_col]\n",
    "            \n",
    "            # Optionally show power and coherence plots first\n",
    "            if show_power_coherence:\n",
    "                print(\"\\nDisplaying coherence and power plots...\")\n",
    "                fig1, fig2 = plot_coherence_and_power(\n",
    "                    event_data,\n",
    "                    rat=rat,\n",
    "                    task=task,\n",
    "                    date=date,\n",
    "                    event_name=event_col.replace('mne_epoch_', ''),\n",
    "                    time_window=time_window,\n",
    "                    ind_exp_coherence=ind_exp_coherence,\n",
    "                    ind_exp_power=ind_exp_power,\n",
    "                    block=False  # Don't block - keep plots open\n",
    "                )\n",
    "            \n",
    "            # Annotate bad epochs with iterative refinement\n",
    "            print(\"\\nNow annotate bad epochs in the grid viewer...\")\n",
    "            if show_power_coherence:\n",
    "                print(\"(Power/coherence plots will stay open for reference)\")\n",
    "            \n",
    "            # Iterative annotation loop\n",
    "            iteration = 1\n",
    "            all_marked_bad = []\n",
    "            \n",
    "            while True:\n",
    "                print(f\"\\n--- Annotation Iteration {iteration} ---\")\n",
    "                if iteration > 1:\n",
    "                    print(f\"Previously marked bad epochs: {all_marked_bad}\")\n",
    "                    # Show original power/coherence plots again for reference\n",
    "                    print(\"Displaying ORIGINAL coherence and power plots for reference...\")\n",
    "                    fig1, fig2 = plot_coherence_and_power(\n",
    "                        event_data,\n",
    "                        rat=rat,\n",
    "                        task=task,\n",
    "                        date=f\"{date} (ORIGINAL - Iteration {iteration})\",\n",
    "                        event_name=event_col.replace('mne_epoch_', ''),\n",
    "                        time_window=time_window,\n",
    "                        ind_exp_coherence=ind_exp_coherence,\n",
    "                        ind_exp_power=ind_exp_power,\n",
    "                        block=False,  # Don't block\n",
    "                        position=(0, 0)  # Position on left monitor\n",
    "                    )\n",
    "                else:\n",
    "                    # First iteration - position on left monitor\n",
    "                    if show_power_coherence:\n",
    "                        fig1, fig2 = plot_coherence_and_power(\n",
    "                            event_data,\n",
    "                            rat=rat,\n",
    "                            task=task,\n",
    "                            date=date,\n",
    "                            event_name=event_col.replace('mne_epoch_', ''),\n",
    "                            time_window=time_window,\n",
    "                            ind_exp_coherence=ind_exp_coherence,\n",
    "                            ind_exp_power=ind_exp_power,\n",
    "                            block=False,\n",
    "                            position=(0, 0)  # Left monitor\n",
    "                        )\n",
    "                \n",
    "                # Show grid viewer on right monitor, passing power figures to close with it\n",
    "                bad_epochs = plot_epochs_grid_with_metadata(\n",
    "                    event_data, \n",
    "                    metadata_cols=metadata_cols,\n",
    "                    n_cols=n_cols,\n",
    "                    pre_marked_bad=all_marked_bad,  # Pass previously marked epochs\n",
    "                    position=(1920, 0) if show_power_coherence else None,  # Right monitor (adjust 1920 to your left monitor width)\n",
    "                    power_figs=(fig1, fig2) if show_power_coherence else None  # Pass figures to close\n",
    "                )\n",
    "                \n",
    "                # Update the list of all bad epochs\n",
    "                all_marked_bad = bad_epochs\n",
    "                \n",
    "                # Note: Power/coherence plots are now automatically closed when grid viewer closes\n",
    "                \n",
    "                # Show cleaned data if epochs were dropped\n",
    "                if show_power_coherence and len(all_marked_bad) > 0:\n",
    "                    print(f\"\\n{len(all_marked_bad)} bad epochs marked: {all_marked_bad}\")\n",
    "                    print(f\"Original number of epochs: {len(event_data)}\")\n",
    "                    \n",
    "                    # Create clean version\n",
    "                    event_data_copy = event_data.copy()\n",
    "                    print(f\"After copy: {len(event_data_copy)} epochs\")\n",
    "                    \n",
    "                    event_data_copy.drop(all_marked_bad, reason='manual_review')\n",
    "                    print(f\"After marking bad: {len(event_data_copy)} total, selection: {event_data_copy.selection}\")\n",
    "                    print(f\"Drop log: {event_data_copy.drop_log}\")\n",
    "                    \n",
    "                    event_data_clean = event_data_copy.drop_bad()\n",
    "                    print(f\"After drop_bad: {type(event_data_clean)}, value: {event_data_clean}\")\n",
    "                    \n",
    "                    # Check if drop_bad returned None or the object itself\n",
    "                    if event_data_clean is None:\n",
    "                        # drop_bad modifies in place and returns None\n",
    "                        event_data_clean = event_data_copy\n",
    "                        print(f\"drop_bad returned None, using event_data_copy: {len(event_data_clean)} epochs\")\n",
    "                    \n",
    "                    # Check if any epochs remain\n",
    "                    if len(event_data_clean) == 0:\n",
    "                        print(\"WARNING: All epochs were marked as bad! No data remains.\")\n",
    "                        response = input(\"Do you want to go back and mark fewer epochs? (y/n): \").strip().lower()\n",
    "                        if response == 'y':\n",
    "                            iteration += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Keeping all epochs marked as bad (empty dataset).\")\n",
    "                            break\n",
    "                    \n",
    "                    print(f\"Clean data has {len(event_data_clean)} epochs\")\n",
    "                    \n",
    "                    # Check if enough epochs remain for coherence calculation\n",
    "                    if len(event_data_clean) < 5:\n",
    "                        print(f\"WARNING: Only {len(event_data_clean)} epochs remain (need at least 5 for coherence).\")\n",
    "                        response = input(\"Do you want to go back and mark fewer epochs? (y/n): \").strip().lower()\n",
    "                        if response == 'y':\n",
    "                            iteration += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Proceeding with limited epochs (coherence calculation may fail).\")\n",
    "                    \n",
    "                    # Show power/coherence for cleaned data\n",
    "                    print(\"Displaying CLEANED coherence and power plots...\")\n",
    "                    print(\"Close the plots to continue, or answer 'y' to refine (mark more bad epochs)\")\n",
    "                    \n",
    "                    try:\n",
    "                        fig1_clean, fig2_clean = plot_coherence_and_power(\n",
    "                            event_data_clean,\n",
    "                            rat=rat,\n",
    "                            task=task,\n",
    "                            date=f\"{date} (CLEANED - Iteration {iteration})\",\n",
    "                            event_name=event_col.replace('mne_epoch_', ''),\n",
    "                            time_window=time_window,\n",
    "                            ind_exp_coherence=ind_exp_coherence,\n",
    "                            ind_exp_power=ind_exp_power,\n",
    "                            block=True  # Block to review cleaned data\n",
    "                        )\n",
    "                    except (TypeError, AttributeError, ValueError) as e:\n",
    "                        print(f\"WARNING: Could not generate cleaned plots. Error: {e}\")\n",
    "                        print(f\"Error type: {type(e)}\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "                        print(\"This may happen if too few epochs remain or data is invalid.\")\n",
    "                        response = input(\"Do you want to go back and mark fewer epochs? (y/n): \").strip().lower()\n",
    "                        if response == 'y':\n",
    "                            iteration += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            print(\"Proceeding with current epoch selection.\")\n",
    "                            break\n",
    "                    \n",
    "                    # Ask if user wants to refine further\n",
    "                    response = input(\"\\nDo you want to mark MORE bad epochs? (y/n): \").strip().lower()\n",
    "                    if response == 'y':\n",
    "                        iteration += 1\n",
    "                        continue  # Go back to annotation\n",
    "                    else:\n",
    "                        print(\"Finalizing annotations...\")\n",
    "                        break\n",
    "                else:\n",
    "                    # No bad epochs marked or show_power_coherence is False\n",
    "                    if show_power_coherence and len(all_marked_bad) == 0:\n",
    "                        print(\"\\nNo bad epochs marked - data is already clean!\")\n",
    "                    break\n",
    "            \n",
    "            # Store the final list of bad epochs\n",
    "            all_bad_epochs_for_event.append(all_marked_bad)\n",
    "        \n",
    "        # Step 2: Add column \"bad_epochs_{event}\"\n",
    "        bad_col_name = f'bad_epochs_{event_col.replace(\"mne_epoch_\", \"\")}'\n",
    "        df_annotated[bad_col_name] = all_bad_epochs_for_event\n",
    "        \n",
    "        # Step 3: Create \"dropped_epochs_{event}\" column\n",
    "        # This is a copy of the event with bad epochs dropped\n",
    "        dropped_epochs_list = []\n",
    "        \n",
    "        for row in range(df_annotated.shape[0]):\n",
    "            # Get original event data\n",
    "            event_data = df_annotated.iloc[row][event_col]\n",
    "            \n",
    "            # Make a copy to avoid modifying the original\n",
    "            event_data_copy = event_data.copy()\n",
    "            \n",
    "            # Get bad epochs for this row\n",
    "            bad_epochs = all_bad_epochs_for_event[row]\n",
    "            \n",
    "            # Drop bad epochs if any exist\n",
    "            if len(bad_epochs) > 0:\n",
    "                event_data_copy.drop(bad_epochs, reason='manual_review')\n",
    "                # Create clean version with bad epochs actually removed\n",
    "                event_data_clean = event_data_copy.drop_bad()\n",
    "            else:\n",
    "                event_data_clean = event_data_copy\n",
    "            \n",
    "            dropped_epochs_list.append(event_data_clean)\n",
    "        \n",
    "        # Add the dropped_epochs column\n",
    "        dropped_col_name = f'dropped_epochs_{event_col.replace(\"mne_epoch_\", \"\")}'\n",
    "        df_annotated[dropped_col_name] = dropped_epochs_list\n",
    "        \n",
    "        print(f\"\\n✓ Completed {event_col}\")\n",
    "        print(f\"  - Added column: {bad_col_name}\")\n",
    "        print(f\"  - Added column: {dropped_col_name}\")\n",
    "    \n",
    "    # Step 4: Save the final dataframe if savepath provided\n",
    "    if savepath is not None:\n",
    "        save_file = savepath + 'con_data_df_manual_annotated.pkl'\n",
    "        df_annotated.to_pickle(save_file)\n",
    "        print(f\"\\n✓ Saved annotated dataframe to: {save_file}\")\n",
    "    \n",
    "    # Step 5: Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for row in range(df_annotated.shape[0]):\n",
    "        print(f\"\\nRow {row} - {df_annotated.iloc[row]['rat_id']} - {df_annotated.iloc[row]['task']}\")\n",
    "        for event_col in event_columns:\n",
    "            bad_col_name = f'bad_epochs_{event_col.replace(\"mne_epoch_\", \"\")}'\n",
    "            dropped_col_name = f'dropped_epochs_{event_col.replace(\"mne_epoch_\", \"\")}'\n",
    "            \n",
    "            n_total = len(df_annotated.iloc[row][event_col])\n",
    "            n_bad = len(df_annotated.iloc[row][bad_col_name])\n",
    "            n_clean = len(df_annotated.iloc[row][dropped_col_name])\n",
    "            \n",
    "            print(f\"  {event_col}: {n_total} total → {n_bad} bad → {n_clean} clean\")\n",
    "    \n",
    "    return df_annotated\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib qt  # Or %matplotlib tk - allows multiple windows\n",
    "#\n",
    "# con_data_df_annotated = annotate_and_clean_epochs_dataframe(\n",
    "#     con_data_df,\n",
    "#     event_columns=['mne_epoch_door_before', 'mne_epoch_dig_before'],\n",
    "#     metadata_cols=['time_diff', 'trial_type', 'dig_type'],\n",
    "#     n_cols=5,\n",
    "#     show_power_coherence=True,\n",
    "#     time_window=1.0,\n",
    "#     ind_exp_coherence=ind_exp_coherence,\n",
    "#     ind_exp_power=ind_exp_power,\n",
    "#     savepath=savepath\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4838723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experiment      date rat_id         task  \\\n",
      "0           8  20230609    dk1  BWnocontext   \n",
      "\n",
      "                                        mne_baseline  \\\n",
      "0  <EpochsArray | 1 events (all good), 0 – 2 s (b...   \n",
      "\n",
      "                               mne_epoch_door_before  \\\n",
      "0  <EpochsArray | 20 events (all good), 0 – 1 s (...   \n",
      "\n",
      "                                mne_epoch_door_after  \\\n",
      "0  <EpochsArray | 20 events (all good), 0 – 1 s (...   \n",
      "\n",
      "                                mne_epoch_dig_before  \\\n",
      "0  <EpochsArray | 20 events (all good), 0 – 1 s (...   \n",
      "\n",
      "                                 mne_epoch_dig_after  \\\n",
      "0  <EpochsArray | 20 events (all good), 0 – 1 s (...   \n",
      "\n",
      "                               mne_epoch_around_door  \\\n",
      "0  <EpochsArray | 20 events (all good), 0 – 2 s (...   \n",
      "\n",
      "                                mne_epoch_around_dig  \n",
      "0  <EpochsArray | 20 events (all good), 0 – 2 s (...  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "\n",
    "# Load your data\n",
    "con_data_df = pd.read_pickle(savepath + f'raw_mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "con_data_df_small = con_data_df.iloc[0:1,:]\n",
    "print(con_data_df_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83794c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# Processing event type: mne_epoch_door_before\n",
      "######################################################################\n",
      "\n",
      "\n",
      "============================================================\n",
      "Row 0/0\n",
      "Rat: dk1, Task: BWnocontext, Date: 20230609\n",
      "============================================================\n",
      "\n",
      "Displaying coherence and power plots...\n",
      "Number of epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1653193634.py:32: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: ['LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "Channels: ['LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "\n",
      "Now annotate bad epochs in the grid viewer...\n",
      "(Power/coherence plots will stay open for reference)\n",
      "\n",
      "--- Annotation Iteration 1 ---\n",
      "Number of epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1653193634.py:32: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: ['LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "Channels: ['LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp', 'Ref']\n",
      "Data shape before mean: (2, 99, 2000)\n",
      "Data shape after mean: (99, 2000)\n",
      "Starting with 0 pre-marked bad epochs: []\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "Total bad epochs marked: 0\n",
      "Bad epoch indices: []\n",
      "\n",
      "No bad epochs marked - data is already clean!\n",
      "\n",
      "✓ Completed mne_epoch_door_before\n",
      "  - Added column: bad_epochs_door_before\n",
      "  - Added column: dropped_epochs_door_before\n",
      "\n",
      "######################################################################\n",
      "# Processing event type: mne_epoch_dig_before\n",
      "######################################################################\n",
      "\n",
      "\n",
      "============================================================\n",
      "Row 0/0\n",
      "Rat: dk1, Task: BWnocontext, Date: 20230609\n",
      "============================================================\n",
      "\n",
      "Displaying coherence and power plots...\n",
      "Number of epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_3212\\1653193634.py:32: RuntimeWarning: fmin=1.000 Hz corresponds to 1.000 < 5 cycles based on the epoch length 1.000 sec, need at least 5.000 sec epochs or fmin=5.000. Spectrum estimate will be unreliable.\n",
      "  con = mne_connectivity.spectral_connectivity_epochs(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the complete annotation workflow\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m con_data_df_annotated \u001b[38;5;241m=\u001b[39m \u001b[43mannotate_and_clean_epochs_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcon_data_df_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmne_epoch_door_before\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmne_epoch_dig_before\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmne_epoch_dig_after\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_diff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrial_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdig_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_power_coherence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mind_exp_coherence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_exp_coherence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Your function\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mind_exp_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_exp_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Your function\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavepath\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 504\u001b[0m, in \u001b[0;36mannotate_and_clean_epochs_dataframe\u001b[1;34m(df, event_columns, metadata_cols, n_cols, savepath, show_power_coherence, time_window, ind_exp_coherence, ind_exp_power)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_power_coherence:\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDisplaying coherence and power plots...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 504\u001b[0m     fig1, fig2 \u001b[38;5;241m=\u001b[39m \u001b[43mplot_coherence_and_power\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_col\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmne_epoch_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mind_exp_coherence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_exp_coherence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mind_exp_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind_exp_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't block - keep plots open\u001b[39;49;00m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;66;03m# Annotate bad epochs with iterative refinement\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNow annotate bad epochs in the grid viewer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 322\u001b[0m, in \u001b[0;36mplot_coherence_and_power\u001b[1;34m(epochs, rat, task, date, event_name, time_window, ind_exp_coherence, ind_exp_power, block, position)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Calculate coherence and power\u001b[39;00m\n\u001b[0;32m    321\u001b[0m coherence \u001b[38;5;241m=\u001b[39m ind_exp_coherence(epochs)\n\u001b[1;32m--> 322\u001b[0m num_of_epochs, aon_power, avg_aon_power \u001b[38;5;241m=\u001b[39m \u001b[43mind_exp_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m num_of_epochs, vhp_power, avg_vhp_power \u001b[38;5;241m=\u001b[39m ind_exp_power(epochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvHp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Figure 1: Average coherence and power\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 78\u001b[0m, in \u001b[0;36mind_exp_power\u001b[1;34m(epoch, area)\u001b[0m\n\u001b[0;32m     75\u001b[0m freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(fmin, fmax)\n\u001b[0;32m     76\u001b[0m n_cycles \u001b[38;5;241m=\u001b[39m freqs \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 78\u001b[0m power \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_tfr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmorlet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cycles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_itc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChannels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m.\u001b[39mch_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m area_channels \u001b[38;5;241m=\u001b[39m [channel \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m epoch\u001b[38;5;241m.\u001b[39mch_names \u001b[38;5;28;01mif\u001b[39;00m area \u001b[38;5;129;01min\u001b[39;00m channel]\n",
      "File \u001b[1;32m<decorator-gen-225>:12\u001b[0m, in \u001b[0;36mcompute_tfr\u001b[1;34m(self, method, freqs, tmin, tmax, picks, proj, output, average, return_itc, decim, n_jobs, verbose, **method_kw)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\epochs.py:2675\u001b[0m, in \u001b[0;36mBaseEpochs.compute_tfr\u001b[1;34m(self, method, freqs, tmin, tmax, picks, proj, output, average, return_itc, decim, n_jobs, verbose, **method_kw)\u001b[0m\n\u001b[0;32m   2673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2674\u001b[0m \u001b[38;5;66;03m# now handle average=False\u001b[39;00m\n\u001b[1;32m-> 2675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m EpochsTFR(\n\u001b[0;32m   2676\u001b[0m     inst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2677\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   2678\u001b[0m     freqs\u001b[38;5;241m=\u001b[39mfreqs,\n\u001b[0;32m   2679\u001b[0m     tmin\u001b[38;5;241m=\u001b[39mtmin,\n\u001b[0;32m   2680\u001b[0m     tmax\u001b[38;5;241m=\u001b[39mtmax,\n\u001b[0;32m   2681\u001b[0m     picks\u001b[38;5;241m=\u001b[39mpicks,\n\u001b[0;32m   2682\u001b[0m     proj\u001b[38;5;241m=\u001b[39mproj,\n\u001b[0;32m   2683\u001b[0m     decim\u001b[38;5;241m=\u001b[39mdecim,\n\u001b[0;32m   2684\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m   2685\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2686\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kw,\n\u001b[0;32m   2687\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:3152\u001b[0m, in \u001b[0;36mEpochsTFR.__init__\u001b[1;34m(self, info, data, times, freqs, inst, method, comment, tmin, tmax, picks, proj, decim, events, event_id, selection, drop_log, metadata, n_jobs, verbose, **method_kw)\u001b[0m\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;66;03m# end TODO ↑↑↑↑↑↑\u001b[39;00m\n\u001b[0;32m   3147\u001b[0m \n\u001b[0;32m   3148\u001b[0m \u001b[38;5;66;03m# dict is allowed for __setstate__ compatibility\u001b[39;00m\n\u001b[0;32m   3149\u001b[0m _validate_type(\n\u001b[0;32m   3150\u001b[0m     inst, (BaseEpochs, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject passed to EpochsTFR constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3151\u001b[0m )\n\u001b[1;32m-> 3152\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   3153\u001b[0m     inst,\n\u001b[0;32m   3154\u001b[0m     method,\n\u001b[0;32m   3155\u001b[0m     freqs,\n\u001b[0;32m   3156\u001b[0m     tmin\u001b[38;5;241m=\u001b[39mtmin,\n\u001b[0;32m   3157\u001b[0m     tmax\u001b[38;5;241m=\u001b[39mtmax,\n\u001b[0;32m   3158\u001b[0m     picks\u001b[38;5;241m=\u001b[39mpicks,\n\u001b[0;32m   3159\u001b[0m     proj\u001b[38;5;241m=\u001b[39mproj,\n\u001b[0;32m   3160\u001b[0m     decim\u001b[38;5;241m=\u001b[39mdecim,\n\u001b[0;32m   3161\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m   3162\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3163\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kw,\n\u001b[0;32m   3164\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:1246\u001b[0m, in \u001b[0;36mBaseTFR.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decim \u001b[38;5;241m=\u001b[39m _ensure_slice(decim)\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_times \u001b[38;5;241m=\u001b[39m inst\u001b[38;5;241m.\u001b[39mtimes[time_mask]\n\u001b[1;32m-> 1246\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_tfr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_epoch_attributes()\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;66;03m# \"apply\" decim to the rest of the object (data is decimated in _compute_tfr)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:1507\u001b[0m, in \u001b[0;36mBaseTFR._compute_tfr\u001b[1;34m(self, data, n_jobs, verbose)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_tfr\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, n_jobs, verbose):\n\u001b[1;32m-> 1507\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tfr_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;66;03m# assign ._data and maybe ._itc\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;66;03m# tfr_array_stockwell always returns ITC (sometimes it's None)\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstockwell\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m<decorator-gen-162>:12\u001b[0m, in \u001b[0;36mtfr_array_morlet\u001b[1;34m(data, sfreq, freqs, n_cycles, zero_mean, use_fft, decim, output, n_jobs, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:1001\u001b[0m, in \u001b[0;36mtfr_array_morlet\u001b[1;34m(data, sfreq, freqs, n_cycles, zero_mean, use_fft, decim, output, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtfr_array_morlet\u001b[39m(\n\u001b[0;32m    919\u001b[0m     data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    929\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    930\u001b[0m ):\n\u001b[0;32m    931\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Time-Frequency Representation (TFR) using Morlet wavelets.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \n\u001b[0;32m    933\u001b[0m \u001b[38;5;124;03m    Same computation as `~mne.time_frequency.tfr_morlet`, but operates on\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03m    .. footbibliography::\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_tfr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43msfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmorlet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cycles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_bandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:573\u001b[0m, in \u001b[0;36m_compute_tfr\u001b[1;34m(epoch_data, freqs, sfreq, method, n_cycles, zero_mean, time_bandwidth, use_fft, decim, output, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    570\u001b[0m parallel, my_cwt, n_jobs \u001b[38;5;241m=\u001b[39m parallel_func(_time_frequency_loop, n_jobs)\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# Parallelization is applied across channels.\u001b[39;00m\n\u001b[1;32m--> 573\u001b[0m tfrs \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_cwt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# FIXME: to avoid overheads we should use np.array_split()\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel_idx, tfr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tfrs):\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\parallel.py:127\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[1;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_verbose\u001b[39m(\u001b[38;5;241m*\u001b[39margs, verbose\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m use_log_level(verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sinha\\anaconda3\\envs\\lfp\\lib\\site-packages\\mne\\time_frequency\\tfr.py:723\u001b[0m, in \u001b[0;36m_time_frequency_loop\u001b[1;34m(X, Ws, output, use_fft, mode, decim, method)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx, tfr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(coefs):\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;66;03m# Transform complex values\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_power\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 723\u001b[0m         tfr \u001b[38;5;241m=\u001b[39m (tfr \u001b[38;5;241m*\u001b[39m \u001b[43mtfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mreal  \u001b[38;5;66;03m# power\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    725\u001b[0m         tfr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mangle(tfr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the complete annotation workflow\n",
    "con_data_df_annotated = annotate_and_clean_epochs_dataframe(\n",
    "    df=con_data_df_small,\n",
    "    event_columns=['mne_epoch_door_before', 'mne_epoch_dig_before', 'mne_epoch_dig_after'],\n",
    "    metadata_cols=['time_diff', 'trial_type', 'dig_type'],\n",
    "    n_cols=5,\n",
    "    show_power_coherence=True,\n",
    "    time_window=1.0,\n",
    "    ind_exp_coherence=ind_exp_coherence,  # Your function\n",
    "    ind_exp_power=ind_exp_power,          # Your function\n",
    "    savepath=savepath\n",
    ")\n",
    "\n",
    "# The result will have new columns:\n",
    "# - bad_epochs_door_before: list of bad epoch indices\n",
    "# - dropped_epochs_door_before: clean epochs with bad ones removed\n",
    "# - bad_epochs_dig_before: list of bad epoch indices  \n",
    "# - dropped_epochs_dig_before: clean epochs with bad ones removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7198447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen width: 1920\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "root = tk.Tk()\n",
    "print(f\"Screen width: {root.winfo_screenwidth()}\")\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd74a32",
   "metadata": {},
   "source": [
    "## End of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig = test_epoch.compute_psd(fmin=1, fmax=100, method='multitaper').plot(average=True, amplitude=False, picks=\"data\")\n",
    "test_epoch.plot_image(combine=\"mean\", picks=aon_indices)\n",
    "test_epoch.plot_image(combine=\"mean\", picks=vHp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7176730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02171d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_all_channels_data = mne.io.RawArray(all_channels_data, info)\n",
    "mne_all_channels_data.plot(scalings='auto', show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f183ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs.plot(n_epochs=10, events=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs[\"1\"].plot_image(combine=\"mean\", colorbar=True, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_epochs[\"1\"].plot_tfr(fmin=4, fmax=100, method='multitaper', show=True, picks=data_channels, spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79794ad",
   "metadata": {},
   "source": [
    "## Plotting TFR of raw data (complete experiment) to check for noise in each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ef5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr= mne_all_channels_data.compute_tfr(method='morlet', freqs=np.arange(1, 100), n_cycles=np.arange(1, 100)/3,picks=data_channels, decim=1, n_jobs=1, verbose=True)\n",
    "print(tfr.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf313826",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr.plot([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TFR for each channel\n",
    "n_channels = all_ch_data_tfr.shape[1]\n",
    "n_freqs = all_ch_data_tfr.shape[2]\n",
    "n_times = all_ch_data_tfr.shape[3]\n",
    "\n",
    "fig, axes = plt.subplots(n_channels, 1, figsize=(12, 3 * n_channels), sharex=True)\n",
    "if n_channels == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ch in range(n_channels):\n",
    "    ax = axes[ch]\n",
    "    im = ax.imshow(\n",
    "        all_ch_data_tfr[0, ch], \n",
    "        aspect='auto', \n",
    "        origin='lower',\n",
    "        extent=[times[0], times[-1], freqs[0], freqs[-1]],\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    ax.set_title(f\"TFR - {all_channels[ch]}\")\n",
    "    ax.set_ylabel(\"Frequency (Hz)\")\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', label='Power')\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
