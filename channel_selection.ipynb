{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c613306",
   "metadata": {},
   "source": [
    "# 1 Importing packages and the functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e426405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import getpass\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import functions\n",
    "import lfp_pre_processing_functions\n",
    "import power_functions\n",
    "import coherence_functions\n",
    "import spectrogram_plotting_functions\n",
    "import plotting_styles\n",
    "import scipy.stats\n",
    "import mne_connectivity\n",
    "importlib.reload(functions) #loads our custom made functions.py file\n",
    "importlib.reload(spectrogram_plotting_functions)\n",
    "importlib.reload(plotting_styles)\n",
    "\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a447a0",
   "metadata": {},
   "source": [
    "# 2 - Loading the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db88638",
   "metadata": {},
   "source": [
    "This code fetches the current 'user' by using getpass. Then it sets the basepath, loads the files and specifies the savepath. Note that the basepath, files and savepath need to be changed depending on where you have kept the files and where you want the results to be stored. In this case, I have set it up to be in a particular folder in my Dropbox account, which is stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f840d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the current user\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "\n",
    "if user == 'CPLab':\n",
    "    base='D:\\\\Dropbox\\\\CPLab'\n",
    "else:\n",
    "    base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "#Set the basepath, savepath and load the data files\n",
    "files = glob.glob(base+'\\\\all_data_mat_unfiltered\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(\"Base path:\", base)\n",
    "print(\"Save path:\", savepath)\n",
    "print(files)\n",
    "\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfaf6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard_dict={'98':'b','119':'w','120':'nc','49':'1','48':'0'} #specifying the map of keyboard annotations to their meanings.\n",
    "all_bands={'total':[1,100],'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "importlib.reload(lfp_pre_processing_functions) #Reloading the lfp_pre_processing_functions module to ensure we have the latest version\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat', f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230626_dk6_BW_nocontext_day1.mat'] #This is just for testing purposes\n",
    "\n",
    "#Initializing a few empty things to store data\n",
    "events_codes_all = {}\n",
    "compiled_data_all_epochs = []\n",
    "compiled_data_list=[]\n",
    "compiled_shuffled_data_list = []\n",
    "baseline_lfp_all = []\n",
    "normalization_comparison_all = []\n",
    "baseline_dict = {}\n",
    "for file in files: #Looping through data files\n",
    "    \n",
    "    ## Get the date, mouse_id and task from the file name\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name, _ = os.path.splitext(base_name)\n",
    "    date, mouse_id, task=lfp_pre_processing_functions.exp_params(base_name) #Using a custom made function [see functions.py]\n",
    "    print(date, mouse_id, task)\n",
    "    if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "        task = 'nocontext'\n",
    "    if task =='nocontext':\n",
    "        continue\n",
    "    f=h5py.File(file, 'r')  ## Open the data file\n",
    "    channels = list(f.keys()) ## Extract channels list from the data file\n",
    "    print(base_name, channels)\n",
    "    if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "        continue\n",
    "    events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    events_codes=np.array(events['codes'][0]) #saving the keyboard annotations of the events (door open, door close etc.)\n",
    "    events_times=np.array(events['times'][0]) #saving when the events happened\n",
    "    events_codes_all[base_name] = events_codes #saving the codes in a dictionary to be analyzed later for events other than the ones in our keyboard_dict map\n",
    "    \n",
    "    #Generating epochs from events (epochs are basically start of a trial and end of a trial)\n",
    "    epochs=lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "\n",
    "    # task Start time\n",
    "    first_event=events_times[0]\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "    global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "    \n",
    "    ## Reference electrode finding and padding\n",
    "    reference_time = np.array(reference_electrode['times']).flatten()\n",
    "    reference_value = np.array(reference_electrode['values']).flatten()\n",
    "    padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "    for channeli in channels:\n",
    "        if \"AON\" in channeli or  \"vHp\" in channeli :\n",
    "            \n",
    "            channel_id=channeli\n",
    "            # Extracting raw data and time\n",
    "            data_all=f[channeli]\n",
    "            raw_data=np.array(data_all['values']).flatten()\n",
    "            raw_time = np.array(data_all['times']).flatten()\n",
    "            sampling_rate = 2000\n",
    "            print(channel_id)\n",
    "            print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "            \n",
    "            padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "            ref_subtracted_data = padded_data - padd_ref_data # Subtracting the reference electrode data from the raw data\n",
    "            \n",
    "            #notch_filtered_data = lfp_pre_processing_functions.iir_notch(raw_data, sampling_rate, 60)\n",
    "            \n",
    "            def extract_baseline_data(data,time,first_event,sampling_rate):\n",
    "                if first_event>2.0:\n",
    "                    baseline_data=data[np.where(time>first_event)[0][0]-2*sampling_rate:np.where(time>first_event)[0][0]]\n",
    "                else:\n",
    "                    baseline_data=data[0:np.where(time>first_event)[0][0]]\n",
    "                baseline_mean=np.mean(baseline_data)\n",
    "                baseline_std=np.std(baseline_data)\n",
    "                \n",
    "                #baseline_data_norm=(baseline_data-baseline_mean)/baseline_std\n",
    "                print('normalizing data')\n",
    "                return baseline_data,time, baseline_mean, baseline_std\n",
    "            \n",
    "            # Extracting baseline data\n",
    "            data_before, time, baseline_mean, baseline_std=extract_baseline_data(ref_subtracted_data, raw_time, first_event, sampling_rate)\n",
    "            first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "            baseline_row=[base_name, mouse_id,task,channel_id,np.array(data_before)]\n",
    "            baseline_lfp_all.append(baseline_row)\n",
    "            baseline_dict[base_name] = baseline_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_lfp_all_df=pd.DataFrame(baseline_lfp_all, columns=['base_name', 'mouse_id', 'task', 'channel_id', 'data_before'])\n",
    "baseline_lfp_all_df['welch'] = baseline_lfp_all_df['data_before'].apply(lambda x: power_functions.apply_welch_transform(x))\n",
    "baseline_lfp_all_df['line_power'] = baseline_lfp_all_df['welch'].apply(lambda x: power_functions.get_band_power(x, 58, 62))\n",
    "baseline_lfp_all_df['total_power'] = baseline_lfp_all_df['welch'].apply(lambda x: power_functions.get_band_power(x, 1, 100))\n",
    "baseline_lfp_all_df['line_power_ratio'] = baseline_lfp_all_df['line_power'] / baseline_lfp_all_df['total_power']\n",
    "baseline_lfp_all_df = baseline_lfp_all_df.sort_values(by=['mouse_id','task'])\n",
    "baseline_lfp_final = baseline_lfp_all_df[['base_name', 'mouse_id', 'task', 'channel_id', 'line_power_ratio']]\n",
    "#baseline_lfp_final=baseline_lfp_final.sort_values(by=['line_power_ratio'], ascending=False)\n",
    "baseline_lfp_final = baseline_lfp_final.reset_index(drop=True)\n",
    "baseline_lfp_final.to_csv(os.path.join(savepath, 'baseline_channel_selection_melted.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list= ['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp']\n",
    "base_names = baseline_lfp_all_df['base_name'].unique()\n",
    "print(base_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108a742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f15f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for base_namei in base_names[0]:\n",
    "    fig, axs = plt.subplots(6, 1, figsize=(10, 6), sharex=True, sharey=True)\n",
    "    fig.suptitle(base_namei)\n",
    "    baseline_lfp_all_df_base = baseline_lfp_all_df[baseline_lfp_all_df['base_name'] == base_namei]\n",
    "    for axi,channel_id in enumerate(channel_list):\n",
    "        channel_data = baseline_lfp_all_df_base[baseline_lfp_all_df_base['channel_id'] == channel_id]\n",
    "        if channel_data.empty:\n",
    "            continue\n",
    "        welch_data = channel_data['welch'].values[0]\n",
    "        frequency = np.linspace(0, 1000, len(welch_data))\n",
    "        ax= axs[axi]\n",
    "        ax.plot(frequency, welch_data, label=channel_id)\n",
    "        ax.set_title(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_lfp_all_df = baseline_lfp_all_df.sort_values(by=['mouse_id', 'task', 'base_name'])\n",
    "final_table = baseline_lfp_all_df.pivot(index=['base_name'], columns='channel_id', values='line_power_ratio')\n",
    "final_table = final_table.reindex(\n",
    "    baseline_lfp_all_df.drop_duplicates('base_name').sort_values(['mouse_id', 'task', 'base_name'])['base_name']\n",
    ")\n",
    "final_table = final_table[['LFP1_AON', 'LFP2_AON', 'LFP3_AON', 'LFP4_AON', 'LFP1_vHp', 'LFP2_vHp']]\n",
    "final_table_melted = final_table.reset_index().melt(id_vars='base_name', var_name='channel_id', value_name='line_power_ratio')\n",
    "final_table.to_csv(os.path.join(savepath, 'baseline_channel_selection.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc1966",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cca11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check=pd.read_excel(os.path.join(savepath, 'filecheck_8325.xlsx'))\n",
    "manual_check=manual_check[['base_name', 'LFP1AON', 'LFP2AON', 'LFP3AON', 'LFP4AON', 'LFP1vHC', 'LFP2vHC']]\n",
    "manual_check = manual_check.rename(columns={\n",
    "    'LFP1AON': 'LFP1_AON', \n",
    "    'LFP2AON': 'LFP2_AON', \n",
    "    'LFP3AON': 'LFP3_AON', \n",
    "    'LFP4AON': 'LFP4_AON', \n",
    "    'LFP1vHC': 'LFP1_vHp', \n",
    "    'LFP2vHC': 'LFP2_vHp'\n",
    "})\n",
    "manual_check = manual_check.set_index('base_name')\n",
    "manual_check.to_csv(os.path.join(savepath, 'manual_check_channel_selection.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a1e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4af1f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66cec672",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aca9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624b3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
