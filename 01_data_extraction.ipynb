{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import functions\n",
    "import spectrogram_plotting_functions\n",
    "import scipy.stats\n",
    "importlib.reload(functions)\n",
    "importlib.reload(spectrogram_plotting_functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "import glob\n",
    "base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "files = glob.glob(base+'\\\\all_data_mat_filtered\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyboard_dict={'98':'b','119':'w','120':'nc','49':'1','48':'0'}\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat'] #This is just for testing purposes\n",
    "events_codes_all = {}\n",
    "compiled_data_all_epochs = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    # Initialize an empty DataFrame to store the results for all epochs\n",
    "    ## Get the date, mouse_id and task from the file name\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name, _ = os.path.splitext(base_name)\n",
    "\n",
    "    date, mouse_id, task=functions.exp_params(base_name)\n",
    "    print(date, mouse_id, task)\n",
    "    ## Open the file\n",
    "    f=h5py.File(file, 'r')\n",
    "    channels = list(f.keys())\n",
    "    print(channels)\n",
    "\n",
    "    if 'Keyboard' in channels:\n",
    "        events = f['Keyboard']\n",
    "    elif 'keyboard' in channels:\n",
    "        events = f['keyboard']\n",
    "    elif 'memory' in channels:\n",
    "        events = f['memory']\n",
    "    elif 'Memory' in channels:\n",
    "        events = f['Memory']\n",
    "\n",
    "    events_codes=np.array(events['codes'][0])\n",
    "    events_times=np.array(events['times'][0])\n",
    "    events_codes_all[base_name] = events_codes\n",
    "    #Generating epochs from events (epochs are basically start of a trial and end of a trial)\n",
    "    epochs=functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "\n",
    "    # Experiment Start time\n",
    "    first_event=events_times[0]\n",
    "\n",
    "    for channeli in channels:\n",
    "        if \"AON\" in channeli or  \"vHp\" in channeli :\n",
    "            \n",
    "            channel_id=channeli\n",
    "            # Extracting raw data and time\n",
    "            data_all=f[channeli]\n",
    "            raw_data=np.array(data_all['values']).flatten()\n",
    "            raw_time = np.array(data_all['times']).flatten()\n",
    "            sampling_rate = int(1/data_all['interval'][0][0])\n",
    "            print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "            # Normalizing the data by subtracting the mean and std of data 30sec before the first event\n",
    "            normalized_data,time,data_before=functions.data_normalization(raw_data,raw_time,first_event, sampling_rate)\n",
    "\n",
    "            # Applying a notch filter\n",
    "            notch_filtered_data=functions.iir_notch(normalized_data, sampling_rate,60)\n",
    "            total=notch_filtered_data\n",
    "            # Extracting the bands\n",
    "            beta=functions.beta_band(notch_filtered_data, sampling_rate)\n",
    "            gamma=functions.gamma_band(notch_filtered_data, sampling_rate)\n",
    "            theta=functions.theta_band(notch_filtered_data, sampling_rate)\n",
    "\n",
    "            all_bands=[total,beta, gamma, theta]\n",
    "\n",
    "            for i,epochi in enumerate(epochs):\n",
    "                compiled_data = pd.DataFrame()\n",
    "\n",
    "                door_timestamp = epochi[0][0]\n",
    "                trial_type = epochi[0][1]\n",
    "                dig_type = epochi[1, 1]\n",
    "                print(dig_type)\n",
    "                dig_timestamp = epochi[1, 0]\n",
    "                print(door_timestamp,trial_type,dig_timestamp,dig_type)\n",
    "                for bandi in all_bands:\n",
    "                    data_complete_trial=functions.extract_complete_trial_data(bandi,time,door_timestamp,dig_timestamp,sampling_rate)\n",
    "                        # Create a DataFrame for the current bandi\n",
    "                    bandi_data = pd.DataFrame({\n",
    "                        'data_complete_trial': [data_complete_trial]\n",
    "\n",
    "                    })\n",
    "                    \n",
    "                    # Concatenate the current bandi DataFrame with the compiled_data DataFrame along axis=1\n",
    "                    compiled_data = pd.concat([compiled_data, bandi_data], axis=1)\n",
    "                compiled_data.columns = ['total_complete_trial',\n",
    "                            'beta_complete_trial',\n",
    "                            'gamma_complete_trial',\n",
    "                            'theta_complete_trial']\n",
    "                compiled_data.insert(0, 'rat', mouse_id)\n",
    "                compiled_data.insert(1, 'date', date)\n",
    "                compiled_data.insert(2, 'experiment', task)\n",
    "                compiled_data.insert(3, 'channel', channel_id)\n",
    "                compiled_data.insert(4, 'trial', i)\n",
    "                compiled_data.insert(5, 'timestamps', [[door_timestamp, dig_timestamp]])\n",
    "\n",
    "                compiled_data.insert(6, 'side', keyboard_dict[str(int(trial_type))])\n",
    "                compiled_data.insert(7, 'correct?', keyboard_dict[str(int(dig_type))])\n",
    "                compiled_data.insert(8, 'first 30 seconds power', functions.calculate_power_1D(data_before))\n",
    "                compiled_data.insert(9, 'time', [time])\n",
    "                \n",
    "                compiled_data_all_epochs = pd.concat([compiled_data_all_epochs, compiled_data], axis=0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "keyboard_dict = {'98': 'b', '119': 'w', '120': 'nc', '49': '1', '48': '0'}\n",
    "# files = [f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat'] # This is just for testing purposes\n",
    "events_codes_all = {}\n",
    "compiled_data_all_epochs = []\n",
    "\n",
    "def process_file(file):\n",
    "    compiled_data_list = []\n",
    "    \n",
    "    # Get the date, mouse_id and task from the file name\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name, _ = os.path.splitext(base_name)\n",
    "    date, mouse_id, task = functions.exp_params(base_name)\n",
    "    print(date, mouse_id, task)\n",
    "    \n",
    "    # Open the file\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        channels = list(f.keys())\n",
    "        print(channels)\n",
    "\n",
    "        if 'Keyboard' in channels:\n",
    "            events = f['Keyboard']\n",
    "        elif 'keyboard' in channels:\n",
    "            events = f['keyboard']\n",
    "        elif 'memory' in channels:\n",
    "            events = f['memory']\n",
    "        elif 'Memory' in channels:\n",
    "            events = f['Memory']\n",
    "\n",
    "        events_codes = np.array(events['codes'][0])\n",
    "        events_times = np.array(events['times'][0])\n",
    "        events_codes_all[base_name] = events_codes\n",
    "        \n",
    "        # Generating epochs from events (epochs are basically start of a trial and end of a trial)\n",
    "        epochs = functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "        \n",
    "        # Experiment Start time\n",
    "        first_event = events_times[0]\n",
    "\n",
    "        for channeli in channels:\n",
    "            if \"AON\" in channeli or \"vHp\" in channeli:\n",
    "                channel_id = channeli\n",
    "                # Extracting raw data and time\n",
    "                data_all = f[channeli]\n",
    "                raw_data = np.array(data_all['values']).flatten()\n",
    "                raw_time = np.array(data_all['times']).flatten()\n",
    "                sampling_rate = int(1 / data_all['interval'][0][0])\n",
    "                print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "                \n",
    "                # Normalizing the data by subtracting the mean and std of data 30sec before the first event\n",
    "                normalized_data, time, data_before = functions.data_normalization(raw_data, raw_time, first_event, sampling_rate)\n",
    "                \n",
    "                # Applying a notch filter\n",
    "                notch_filtered_data = functions.iir_notch(normalized_data, sampling_rate, 60)\n",
    "                total = notch_filtered_data\n",
    "                \n",
    "                # Extracting the bands\n",
    "                beta = functions.beta_band(notch_filtered_data, sampling_rate)\n",
    "                gamma = functions.gamma_band(notch_filtered_data, sampling_rate)\n",
    "                theta = functions.theta_band(notch_filtered_data, sampling_rate)\n",
    "                \n",
    "                all_bands = [total, beta, gamma, theta]\n",
    "\n",
    "                for i, epochi in enumerate(epochs):\n",
    "                    door_timestamp = epochi[0][0]\n",
    "                    trial_type = epochi[0][1]\n",
    "                    dig_type = epochi[1, 1]\n",
    "                    dig_timestamp = epochi[1, 0]\n",
    "                    print(dig_type)\n",
    "                    print(door_timestamp, trial_type, dig_timestamp, dig_type)\n",
    "                    \n",
    "                    band_data_dict = {}\n",
    "                    for bandi, band_name in zip(all_bands, ['total', 'beta', 'gamma', 'theta']):\n",
    "                        data_complete_trial = functions.extract_complete_trial_data(bandi, time, door_timestamp, dig_timestamp, sampling_rate)\n",
    "                        band_data_dict[f'{band_name}_complete_trial'] = [data_complete_trial]\n",
    "                    \n",
    "                    compiled_data = pd.DataFrame(band_data_dict)\n",
    "                    compiled_data.insert(0, 'rat', mouse_id)\n",
    "                    compiled_data.insert(1, 'date', date)\n",
    "                    compiled_data.insert(2, 'experiment', task)\n",
    "                    compiled_data.insert(3, 'channel', channel_id)\n",
    "                    compiled_data.insert(4, 'trial', i)\n",
    "\n",
    "                    # Assuming 'door_timestamp' and 'dig_timestamp' are lists or arrays of timestamps\n",
    "                    door_timestamp_array = np.array(door_timestamp, dtype=float)\n",
    "                    dig_timestamp_array = np.array(dig_timestamp, dtype=float)\n",
    "\n",
    "                    formatted_door_timestamp = np.round(door_timestamp_array, 2)\n",
    "                    formatted_dig_timestamp = np.round(dig_timestamp_array, 2)\n",
    "                    compiled_data.insert(5, 'timestamps', [[formatted_door_timestamp.tolist(), formatted_dig_timestamp.tolist()]])\n",
    "                    #compiled_data.insert(5, 'timestamps', [[door_timestamp, dig_timestamp]])\n",
    "                    compiled_data.insert(6, 'side', keyboard_dict[str(int(trial_type))])\n",
    "                    compiled_data.insert(7, 'correct?', keyboard_dict[str(int(dig_type))])\n",
    "                    compiled_data.insert(8, 'first 30 seconds power', functions.calculate_power_1D(data_before))\n",
    "                    # Assuming 'time' is a list or array of time values\n",
    "                    time_array = np.array(time, dtype=float)\n",
    "                    formatted_time = np.round(time_array, 8)\n",
    "\n",
    "                    # Insert the formatted 'time' values into the DataFrame\n",
    "                    compiled_data.insert(9, 'time', [formatted_time])\n",
    "                    #compiled_data.insert(9, 'time', [time])\n",
    "\n",
    "                    compiled_data_list.append(compiled_data)\n",
    "    \n",
    "    return compiled_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat'] #This is just for testing purposes\n",
    "\n",
    "# Process files sequentially\n",
    "for file in files:\n",
    "    compiled_data_list = process_file(file)\n",
    "    compiled_data_all_epochs.extend(compiled_data_list)\n",
    "# Flatten the list of lists\n",
    "\n",
    "compiled_data_all_epochs = pd.concat(compiled_data_all_epochs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rat      date experiment   channel  trial        timestamps side correct?  \\\n",
      "0  dk1  20230529  nocontext  LFP1_AON      0   [181.2, 182.71]   nc        1   \n",
      "1  dk1  20230529  nocontext  LFP1_AON      1  [237.77, 239.46]   nc        0   \n",
      "2  dk1  20230529  nocontext  LFP1_AON      2  [279.55, 280.29]   nc        1   \n",
      "3  dk1  20230529  nocontext  LFP1_AON      3  [348.95, 349.84]   nc        0   \n",
      "4  dk1  20230529  nocontext  LFP1_AON      4  [466.79, 468.26]   nc        1   \n",
      "\n",
      "   first 30 seconds power                                               time  \\\n",
      "0                0.112047  [5e-05, 0.00055, 0.00105, 0.00155, 0.00205, 0....   \n",
      "1                0.112047  [5e-05, 0.00055, 0.00105, 0.00155, 0.00205, 0....   \n",
      "2                0.112047  [5e-05, 0.00055, 0.00105, 0.00155, 0.00205, 0....   \n",
      "3                0.112047  [5e-05, 0.00055, 0.00105, 0.00155, 0.00205, 0....   \n",
      "4                0.112047  [5e-05, 0.00055, 0.00105, 0.00155, 0.00205, 0....   \n",
      "\n",
      "                                total_complete_trial  \\\n",
      "0  [-0.06871715099940695, -0.06482672533582118, -...   \n",
      "1  [1.2097677699033267, 1.173291913112573, 1.1416...   \n",
      "2  [0.3852873437321285, 0.3998796954368451, 0.421...   \n",
      "3  [-0.45362404143742396, -0.463820994596029, -0....   \n",
      "4  [5.282795088447373, 5.3223280659800905, 5.3477...   \n",
      "\n",
      "                                 beta_complete_trial  \\\n",
      "0  [0.19617630019389784, 0.19929560830014362, 0.2...   \n",
      "1  [0.23953368925511104, 0.22869061361606466, 0.2...   \n",
      "2  [0.06502411977179, 0.07070561715414135, 0.0763...   \n",
      "3  [0.06640194546326272, 0.07185665249307942, 0.0...   \n",
      "4  [0.4538844558680637, 0.4491059411618742, 0.443...   \n",
      "\n",
      "                                gamma_complete_trial  \\\n",
      "0  [-0.08201506438887157, -0.08164368038279424, -...   \n",
      "1  [-0.013599297808412106, -0.02211908112731152, ...   \n",
      "2  [-0.17935277764526197, -0.184875234729039, -0....   \n",
      "3  [-0.02924077627514098, -0.02898542720914465, -...   \n",
      "4  [-0.09384372122588013, -0.1058661046532619, -0...   \n",
      "\n",
      "                                theta_complete_trial  \n",
      "0  [0.19411207593298077, 0.19376517398227855, 0.1...  \n",
      "1  [0.8192187747828921, 0.8103598675204986, 0.801...  \n",
      "2  [0.13754708075886446, 0.12993636448827575, 0.1...  \n",
      "3  [-0.012058737328485912, -0.01802630396606558, ...  \n",
      "4  [0.17254148406215875, 0.20883290573104227, 0.2...  \n"
     ]
    }
   ],
   "source": [
    "print(compiled_data_all_epochs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(compiled_data_all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m large_int_columns\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Check for large integers\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m large_int_columns \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_large_integers_in_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiled_data_all_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns with large integers:\u001b[39m\u001b[38;5;124m\"\u001b[39m, large_int_columns)\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mcheck_large_integers_in_arrays\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)))\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# Check each array element for large integers\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_int64\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     10\u001b[0m             large_int_columns\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m large_int_columns\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\series.py:4908\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mcheck_large_integers_in_arrays.<locals>.<lambda>\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)))\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# Check each array element for large integers\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m arr: \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_int64\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     10\u001b[0m             large_int_columns\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m large_int_columns\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)))\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# Check each array element for large integers\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m arr: \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m max_int64 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m arr))\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     10\u001b[0m             large_int_columns\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m large_int_columns\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to check for large integers in a DataFrame with array elements\n",
    "def check_large_integers_in_arrays(df):\n",
    "    large_int_columns = []\n",
    "    max_int64 = np.iinfo(np.int64).max\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].apply(lambda x: isinstance(x, (list, np.ndarray))).all():\n",
    "            # Check each array element for large integers\n",
    "            if df[col].apply(lambda arr: any(isinstance(i, int) and i > max_int64 for i in arr)).any():\n",
    "                large_int_columns.append(col)\n",
    "    \n",
    "    return large_int_columns\n",
    "\n",
    "# Check for large integers\n",
    "large_int_columns = check_large_integers_in_arrays(compiled_data_all_epochs)\n",
    "print(\"Columns with large integers:\", large_int_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert large integers to float64\n",
    "compiled_data_all_epochs = compiled_data_all_epochs.applymap(\n",
    "    lambda x: np.float64(x) if isinstance(x, int) and x > np.iinfo(np.int64).max else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Local\\Temp\\ipykernel_65568\\1597684416.py:3: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['rat', 'date', 'experiment', 'channel', 'timestamps', 'side',\n",
      "       'correct?', 'time', 'total_complete_trial', 'beta_complete_trial',\n",
      "       'gamma_complete_trial', 'theta_complete_trial'],\n",
      "      dtype='object')]\n",
      "\n",
      "  compiled_data_all_epochs.to_hdf(os.path.join(savepath,filename), key='df', mode='w', complevel=9, complib='blosc')\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the DataFrame with compression and chunking\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompiled_data_all_rats_all_epoch.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcompiled_data_all_epochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msavepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblosc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\core\\generic.py:2852\u001b[0m, in \u001b[0;36mNDFrame.to_hdf\u001b[1;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pytables\n\u001b[0;32m   2850\u001b[0m \u001b[38;5;66;03m# Argument 3 to \"to_hdf\" has incompatible type \"NDFrame\"; expected\u001b[39;00m\n\u001b[0;32m   2851\u001b[0m \u001b[38;5;66;03m# \"Union[DataFrame, Series]\" [arg-type]\u001b[39;00m\n\u001b[1;32m-> 2852\u001b[0m \u001b[43mpytables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2860\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2866\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:311\u001b[0m, in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m HDFStore(\n\u001b[0;32m    309\u001b[0m         path_or_buf, mode\u001b[38;5;241m=\u001b[39mmode, complevel\u001b[38;5;241m=\u001b[39mcomplevel, complib\u001b[38;5;241m=\u001b[39mcomplib\n\u001b[0;32m    310\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[1;32m--> 311\u001b[0m         \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     f(path_or_buf)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:293\u001b[0m, in \u001b[0;36mto_hdf.<locals>.<lambda>\u001b[1;34m(store)\u001b[0m\n\u001b[0;32m    279\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m store: store\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    280\u001b[0m         key,\n\u001b[0;32m    281\u001b[0m         value,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# NB: dropna is not passed to `put`\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m store: \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m path_or_buf \u001b[38;5;241m=\u001b[39m stringify_path(path_or_buf)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:1160\u001b[0m, in \u001b[0;36mHDFStore.put\u001b[1;34m(self, key, value, format, index, append, complib, complevel, min_itemsize, nan_rep, data_columns, encoding, errors, track_times, dropna)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.hdf.default_format\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_format(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_to_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:1858\u001b[0m, in \u001b[0;36mHDFStore._write_to_group\u001b[1;34m(self, key, value, format, axes, index, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, encoding, errors, track_times)\u001b[0m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression not supported on Fixed format stores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# write the object\u001b[39;00m\n\u001b[1;32m-> 1858\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfletcher32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfletcher32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpectedrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpectedrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, Table) \u001b[38;5;129;01mand\u001b[39;00m index:\n\u001b[0;32m   1875\u001b[0m     s\u001b[38;5;241m.\u001b[39mcreate_index(columns\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:3333\u001b[0m, in \u001b[0;36mBlockManagerFixed.write\u001b[1;34m(self, obj, **kwargs)\u001b[0m\n\u001b[0;32m   3330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m   3331\u001b[0m     \u001b[38;5;66;03m# I have no idea why, but writing values before items fixed #2299\u001b[39;00m\n\u001b[0;32m   3332\u001b[0m     blk_items \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mitems\u001b[38;5;241m.\u001b[39mtake(blk\u001b[38;5;241m.\u001b[39mmgr_locs)\n\u001b[1;32m-> 3333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblock\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblk_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_index(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_items\u001b[39m\u001b[38;5;124m\"\u001b[39m, blk_items)\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\pandas\\io\\pytables.py:3172\u001b[0m, in \u001b[0;36mGenericFixed.write_array\u001b[1;34m(self, key, obj, items)\u001b[0m\n\u001b[0;32m   3169\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(ws, PerformanceWarning, stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level())\n\u001b[0;32m   3171\u001b[0m     vlarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle\u001b[38;5;241m.\u001b[39mcreate_vlarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, key, _tables()\u001b[38;5;241m.\u001b[39mObjectAtom())\n\u001b[1;32m-> 3172\u001b[0m     \u001b[43mvlarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(value\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   3175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle\u001b[38;5;241m.\u001b[39mcreate_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, key, value\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\tables\\vlarray.py:528\u001b[0m, in \u001b[0;36mVLArray.append\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m    525\u001b[0m     nobjects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    526\u001b[0m     nparr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnparr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Thomas\\anaconda3\\envs\\lfp\\lib\\site-packages\\tables\\hdf5extension.pyx:2092\u001b[0m, in \u001b[0;36mtables.hdf5extension.VLArray._append\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame with compression and chunking\n",
    "filename = 'compiled_data_all_rats_all_epoch.h5'\n",
    "compiled_data_all_epochs.to_hdf(os.path.join(savepath,filename), key='df', mode='w', complevel=9, complib='blosc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "\n",
    "# Free up memory\n",
    "del compiled_data_all_epochs, compiled_data_list, events_codes_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.maxsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.06871715099940695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming compiled_data_all_epochs is a pandas DataFrame\n",
    "in_memory_size = sys.getsizeof(compiled_data_all_epochs)\n",
    "print(f\"In-memory size: {in_memory_size / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Rough estimate of compressed size (assuming a compression ratio of 2:1)\n",
    "compression_ratio = 9\n",
    "estimated_compressed_size = in_memory_size / compression_ratio\n",
    "print(f\"Estimated compressed size: {estimated_compressed_size / (1024 ** 3):.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
