{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Importing packages and the functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import getpass\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import functions\n",
    "import lfp_pre_processing_functions\n",
    "import power_functions\n",
    "import coherence_functions\n",
    "import spectrogram_plotting_functions\n",
    "import plotting_styles\n",
    "import scipy.stats\n",
    "import mne_connectivity\n",
    "import mne\n",
    "importlib.reload(functions) #loads our custom made functions.py file\n",
    "importlib.reload(spectrogram_plotting_functions)\n",
    "importlib.reload(plotting_styles)\n",
    "\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Loading the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fetches the current 'user' by using getpass. Then it sets the basepath, loads the files and specifies the savepath. Note that the basepath, files and savepath need to be changed depending on where you have kept the files and where you want the results to be stored. In this case, I have set it up to be in a particular folder in my Dropbox account, which is stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the current user\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "if user == 'CPLab':\n",
    "    base='D:\\\\Dropbox\\\\CPLab'\n",
    "else:\n",
    "    base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "#Set the basepath, savepath and load the data files\n",
    "files = glob.glob(base+'\\\\all_data_mat_250825\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(\"Base path:\", base)\n",
    "print(\"Save path:\", savepath)\n",
    "print(files)\n",
    "\n",
    "\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyboard_dict={'98':'b','119':'w','120':'nc','49':'1','48':'0'} #specifying the map of keyboard annotations to their meanings.\n",
    "all_bands={'total':[1,100],'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "importlib.reload(lfp_pre_processing_functions) #Reloading the lfp_pre_processing_functions module to ensure we have the latest version\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat', f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230626_dk6_BW_nocontext_day1.mat'] #This is just for testing purposes\n",
    "time_window=1\n",
    "fs=2000\n",
    "#Initializing a few empty things to store data\n",
    "events_codes_all = {}\n",
    "compiled_data_all_epochs = []\n",
    "compiled_data_list=[]\n",
    "compiled_shuffled_data_list = []\n",
    "baseline_lfp_all = []\n",
    "normalization_comparison_all = []\n",
    "for file in files: #Looping through data files\n",
    "    \n",
    "    ## Get the date, mouse_id and task from the file name\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name, _ = os.path.splitext(base_name)\n",
    "    date, mouse_id, task=lfp_pre_processing_functions.exp_params(base_name) #Using a custom made function [see functions.py]\n",
    "    print(date, mouse_id, task)\n",
    "    if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "        task = 'nocontext'\n",
    "    if task =='nocontext':\n",
    "        continue\n",
    "    f=h5py.File(file, 'r')  ## Open the data file\n",
    "    channels = list(f.keys()) ## Extract channels list from the data file\n",
    "    print(channels)\n",
    "    if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "        continue\n",
    "    events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    events_codes=np.array(events['codes'][0]) #saving the keyboard annotations of the events (door open, door close etc.)\n",
    "    events_times=np.array(events['times'][0]) #saving when the events happened\n",
    "    events_codes_all[base_name] = events_codes #saving the codes in a dictionary to be analyzed later for events other than the ones in our keyboard_dict map\n",
    "    \n",
    "    #Generating epochs from events (epochs are basically start of a trial and end of a trial)\n",
    "    epochs=lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "\n",
    "    # task Start time\n",
    "    first_event=events_times[0]\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "    global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "    \n",
    "    ## Reference electrode finding and padding\n",
    "    reference_time = np.array(reference_electrode['times']).flatten()\n",
    "    reference_value = np.array(reference_electrode['values']).flatten()\n",
    "    padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "\n",
    "    for channeli in channels:\n",
    "        if \"AON\" in channeli or  \"vHp\" in channeli :\n",
    "            \n",
    "            channel_id=channeli\n",
    "            # Extracting raw data and time\n",
    "            data_all=f[channeli]\n",
    "            raw_data=np.array(data_all['values']).flatten()\n",
    "            raw_time = np.array(data_all['times']).flatten()\n",
    "            sampling_rate = 2000\n",
    "            print(channel_id)\n",
    "            print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "            \n",
    "            padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "            subtracted_data = padded_data - padd_ref_data\n",
    "            raw_data=subtracted_data\n",
    "            notch_filtered_data = lfp_pre_processing_functions.iir_notch(raw_data, sampling_rate, 60)\n",
    "            \n",
    "            data_before, time, baseline_mean, baseline_std=lfp_pre_processing_functions.baseline_data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "            first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "\n",
    "            baseline_row=[mouse_id,task,channel_id,np.array(data_before)]\n",
    "            baseline_lfp_all.append(baseline_row)\n",
    "            normalized_data=notch_filtered_data\n",
    "\n",
    "            #Saving non-normalized data and normalized data for plotting\n",
    "            normalization_row=[mouse_id,task,channel_id,[notch_filtered_data[first_event_index:first_event_index+30*sampling_rate]],np.mean(data_before),np.std(data_before),[normalized_data[first_event_index:first_event_index+30*sampling_rate]]]\n",
    "            normalization_comparison_all.append(normalization_row)\n",
    "\n",
    "\n",
    "            for i,epochi in enumerate(epochs):\n",
    "                \n",
    "                compiled_data = pd.DataFrame() # Initializing a dataframe to store the data of a single epoch\n",
    "                compiled_shuffled_data = pd.DataFrame() # Initializing a dataframe to store the shuffled data of a single epoch\n",
    "                door_timestamp = epochi[0][0]\n",
    "                trial_type = epochi[0][1]\n",
    "                dig_type = epochi[1, 1]\n",
    "                dig_timestamp = epochi[1, 0]\n",
    "                print(door_timestamp,trial_type,dig_timestamp,dig_type)\n",
    "                \n",
    "                \n",
    "                data_complete_trial=lfp_pre_processing_functions.extract_complete_trial_data(notch_filtered_data,time,door_timestamp,dig_timestamp,sampling_rate,time_window)\n",
    "                data_trial_before, data_trial_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,door_timestamp,sampling_rate,time_window)\n",
    "                data_dig_before, data_dig_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,dig_timestamp,sampling_rate,time_window)\n",
    "                data_door_around=np.append(data_trial_before, data_trial_after)\n",
    "                data_dig_around=np.append(data_dig_before, data_dig_after)\n",
    "                epoch_data = [data_complete_trial, data_trial_before, data_trial_after, data_dig_before, data_dig_after, data_door_around, data_dig_around]\n",
    "                epoch_data = [lfp_pre_processing_functions.zscore_event_data(x, baseline_std) for x in epoch_data]\n",
    "                shuffled_epoch_data = [np.random.permutation(x) for x in epoch_data]  # Shuffle the epoch data\n",
    "                compiled_data = dict(rat=mouse_id, date=date, task=task, channel=channel_id, trial=i, timestamps=[door_timestamp, dig_timestamp],\n",
    "                                     side=keyboard_dict.get(str(int(trial_type)), ''), correct=keyboard_dict.get(str(int(dig_type)), ''), time=time,\n",
    "                                     **dict(zip(['complete_trial', 'pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig'], epoch_data)))\n",
    "                compiled_shuffled_data = dict(rat=mouse_id, date=date, task=task, channel=channel_id, trial=i, timestamps=[door_timestamp, dig_timestamp],\n",
    "                                     side=keyboard_dict.get(str(int(trial_type)), ''), correct=keyboard_dict.get(str(int(dig_type)), ''), time=time,\n",
    "                                     **dict(zip(['complete_trial', 'pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig'], shuffled_epoch_data)))\n",
    "                compiled_data_list.append(compiled_data)\n",
    "                compiled_shuffled_data_list.append(compiled_shuffled_data)\n",
    "def combine_and_save_data(data_list, name):\n",
    "    compiled_data_all_epochs = []\n",
    "    compiled_data_all_epochs.extend(data_list)\n",
    "    compiled_data_all_epochs = pd.DataFrame(compiled_data_all_epochs)\n",
    "    compiled_data_all_epochs= compiled_data_all_epochs[compiled_data_all_epochs['task']!='nocontext']\n",
    "    compiled_data_all_epochs.to_pickle(savepath+'{}.pkl'.format(name))\n",
    "\n",
    "combine_and_save_data(compiled_data_list, f'compiled_data_all_epochs_truncated_{int(time_window*fs)}')\n",
    "combine_and_save_data(compiled_shuffled_data_list, f'compiled_shuffled_data_all_epochs_truncated_{int(time_window*fs)}')\n",
    "\n",
    "baseline_lfp_all = pd.DataFrame(baseline_lfp_all, columns=['rat', 'task', 'channel', 'data'])\n",
    "baseline_lfp_all.to_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "normalization_comparison_all = pd.DataFrame(normalization_comparison_all, columns=['rat', 'task', 'channel', 'non_normalized_data', 'baseline_mean', 'baseline_std', 'normalized_data'])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Waveform Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Rat 1-100Hz around door and digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "waveform_data_all = compiled_data_all_epochs.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data_all['channel'] = waveform_data_all['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "event_dictionary = {'around_door':'Before and After door open', 'around_dig': 'Before and After Digging'}\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "rat_list=['dk5']\n",
    "for rat in rat_list:\n",
    "    writer=pd.ExcelWriter(os.path.join(savepath, f'{rat}_waveform_data.xlsx'), engine='xlsxwriter')\n",
    "    \n",
    "    waveform_data = waveform_data_all[waveform_data_all['rat'] == rat]\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "    fig.suptitle(f'{rat} LFP (1-100Hz)', fontsize=20)\n",
    "    \n",
    "    subfigs = fig.subfigures(2, 1)\n",
    "    subfigs=subfigs.flatten()\n",
    "    for subfig in subfigs:\n",
    "        subfig.patch.set_edgecolor('black')\n",
    "        subfig.patch.set_linewidth(2)\n",
    "\n",
    "    areas=['AON','vHp']\n",
    "    for outerind, area in enumerate(areas):\n",
    "        subfig=subfigs[outerind]\n",
    "        axs = subfig.subplots(1, 2)\n",
    "        subfig.suptitle(f'{area}', fontsize=16)\n",
    "        waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "        waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "\n",
    "        for innerind, col in enumerate(['around_door', 'around_dig']):\n",
    "            data = np.array(waveform_data_area[col].tolist())  # Ensure data is a numpy array\n",
    "            ax = axs[innerind]  # Correct indexing for axs\n",
    "            ax.set_title(f'{event_dictionary[col]}', fontsize=16)            \n",
    "            sheet_dict={}\n",
    "            for task in (['BWcontext', 'BWnocontext']):\n",
    "                task_data = data[waveform_data_area['task'] == task]\n",
    "                \n",
    "                if len(task_data) > 0:\n",
    "                    task_data = np.array([functions.freq_band(row, all_bands_dict['total'][0], all_bands_dict['total'][1], 2000) for row in task_data])\n",
    "                    data_mean = np.mean(task_data, axis=0)\n",
    "                    data_sem = scipy.stats.sem(task_data, axis=0)\n",
    "                    time_axis = np.linspace(-0.7, 0.7, len(data_mean))\n",
    "                    ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                    ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "                    sheet_dict[f'{task}_mean'] = data_mean\n",
    "                    sheet_dict[f'{task}_sem'] = data_sem\n",
    "            sheet_dict['time'] = time_axis\n",
    "            sheet_df=pd.DataFrame(sheet_dict)\n",
    "            sheet_df.to_excel(writer, sheet_name=f'{area}_{col}', index=False)\n",
    "            ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "            ax.set_xlabel('Time (s)', fontsize=14)\n",
    "            ax.set_ylabel('Amplitude (uV)', fontsize=14)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "            #ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    #writer.close()\n",
    "    #fig.savefig(os.path.join(savepath,f' LFP_total_waveform_{rat}'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All rats alls bands around door and digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "rat_list=list(np.unique(compiled_data_all_epochs['rat']))\n",
    "window = [-2, 2]  # Set the window for the waveform\n",
    "\n",
    "#band = 'total'  # Insert the band of interest\n",
    "tasks = ['BWcontext', 'BWnocontext']\n",
    "areas=['AON','vHp']\n",
    "compiled_data_all_epochs['around_door'] = compiled_data_all_epochs['pre_door'].apply(lambda x: x.tolist()) + compiled_data_all_epochs['post_door'].apply(lambda x: x.tolist())\n",
    "compiled_data_all_epochs['around_dig'] = compiled_data_all_epochs['pre_dig'].apply(lambda x: x.tolist()) + compiled_data_all_epochs['post_dig'].apply(lambda x: x.tolist())\n",
    "print(np.array(compiled_data_all_epochs['around_door'][0]).shape, np.array(compiled_data_all_epochs['around_dig'][0]).shape)\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "\n",
    "for rati in rat_list:\n",
    "    rat_dict = {}\n",
    "    rat_data = compiled_data_all_epochs[compiled_data_all_epochs['rat'] == rati]\n",
    "    rat_data['channel']=rat_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    rat_data = rat_data.reset_index(drop=True)\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(10, 10))    \n",
    "    subfigs = fig.subfigures(2, 1)\n",
    "    subfigs=subfigs.flatten()\n",
    "    subfigs[1].set_facecolor('0.85')\n",
    "    fig.suptitle(f'{rati}')\n",
    "    \n",
    "    for outerind, area in enumerate(areas):\n",
    "        subfig=subfigs[outerind]\n",
    "        axs = subfig.subplots(4, 2)\n",
    "        \n",
    "        rat_data_area = rat_data[rat_data['channel'] == area]\n",
    "        rat_data_area = rat_data_area.reset_index(drop=True)   \n",
    "    \n",
    "        for i, band in enumerate(all_bands_dict.keys()):\n",
    "            rat_data_band=rat_data_area.__deepcopy__()\n",
    "            for col in (['around_door', 'around_dig']):\n",
    "                rat_data_band[col] = rat_data_area[col].apply(lambda x: functions.freq_band(x, all_bands_dict[band][0], all_bands_dict[band][1], 2000))\n",
    "\n",
    "            rat_data_band_grouped = rat_data_band.groupby(['task', 'channel'])\n",
    "            for (task, channel), group in rat_data_band_grouped:\n",
    "                group=group.reset_index(drop=True)\n",
    "                print(group.shape)\n",
    "                #group['around_dig']=np.concatenate([group['pre_dig'], group['post_dig']], axis=1)\n",
    "                for j, col in enumerate(['around_door', 'around_dig']):\n",
    "                    data = np.array(group[col])\n",
    "                    data_mean = np.mean(data, axis=0)\n",
    "                    data_sem = scipy.stats.sem(data, axis=0)\n",
    "                    time_axis = np.linspace(-0.7, 0.7, len(data_mean))\n",
    "                    ax = axs[i, j]\n",
    "                    ax.set_title(f'{band} {channel} {col}')\n",
    "                    ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                    ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "                    ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "    #fig.savefig(os.path.join(savepath,f' LFP_waveform{rati}'), dpi=300)\n",
    "    plt.show()\n",
    "    #plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged across rats single band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = compiled_data_all_epochs.copy()\n",
    "waveform_data['channel'] = waveform_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "event_dictionary = {'around_door':'Before and After door open', 'around_dig': 'Before and After Digging'}\n",
    "fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "fig.suptitle(f'raw LFP averaged across rats', fontsize=20)\n",
    "\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "subfigs=subfigs.flatten()\n",
    "for subfig in subfigs:\n",
    "    subfig.patch.set_edgecolor('black')\n",
    "    subfig.patch.set_linewidth(0.5)\n",
    "areas=['AON','vHp']\n",
    "for outerind, area in enumerate(areas):\n",
    "    subfig=subfigs[outerind]\n",
    "    axs = subfig.subplots(1, 2)\n",
    "    subfig.suptitle(f'{area}', fontsize= 16) \n",
    "    waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "    waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "\n",
    "    for innerind, col in enumerate(['around_door', 'around_dig']):\n",
    "        data = np.array(waveform_data_area[col].tolist())  # Ensure data is a numpy array\n",
    "        ax = axs[innerind]  # Correct indexing for axs\n",
    "        ax.set_title(f'{event_dictionary[col]}', fontsize=14)\n",
    "        for task in (['BWcontext', 'BWnocontext']):\n",
    "            task_data = data[waveform_data_area['task'] == task]\n",
    "            if len(task_data) > 0:\n",
    "            \n",
    "                data_mean = np.mean(task_data, axis=0)\n",
    "                data_sem = scipy.stats.sem(task_data, axis=0)\n",
    "                time_axis = np.linspace(-2, 2, len(data_mean))\n",
    "                \n",
    "                ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "        ax.set_xlabel('Time (s)', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude (uV)', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "#fig.savefig(os.path.join(savepath,f' LFP_raw_waveform_averaged'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged across rats all bands (To be Deleted later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = compiled_data_all_epochs.copy()\n",
    "waveform_data['channel'] = waveform_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "waveform_data = waveform_data.reset_index(drop=True)\n",
    "fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "subfigs=subfigs.flatten()\n",
    "subfigs[1].set_facecolor('0.85')\n",
    "fig.suptitle(f'Waveform')\n",
    "\n",
    "for i, band in enumerate(all_bands_dict.keys()):\n",
    "    print(band)\n",
    "\n",
    "waveform_data_grouped = waveform_data.groupby(['task', 'channel'])\n",
    "for outerind, area in enumerate(areas):\n",
    "    subfig=subfigs[outerind]\n",
    "    axs = subfig.subplots(4, 2)\n",
    "    waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "    waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "    \n",
    "    for i, band in enumerate(all_bands_dict.keys()):\n",
    "        for col in (['around_door', 'around_dig']):\n",
    "            waveform_data_area[col+'_'+band] = waveform_data_area[col].apply(lambda x: functions.freq_band(x, all_bands_dict[band][0], all_bands_dict[band][1], 2000))\n",
    "\n",
    "        data = waveform_data_area[[f'around_door_{band}', f'around_dig_{band}']]\n",
    "        data_mean = data.groupby(waveform_data_area['task']).mean() \n",
    "        data_sem = data.groupby(waveform_data_area['task']).sem()\n",
    "        time_axis = np.linspace(-2, 2, len(data_mean.columns))\n",
    "        for j, task in enumerate(tasks):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_title(f'{band} {task}')\n",
    "            ax.plot(time_axis, data_mean.loc[task], color=plotting_styles.colors[task])\n",
    "            ax.fill_between(time_axis, data_mean.loc[task] - data_sem.loc[task], data_mean.loc[task] + data_sem.loc[task], alpha=0.2, color=plotting_styles.colors[task])\n",
    "            ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Power Spectra Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Baseline Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting_styles\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "importlib.reload(plotting_styles)\n",
    "importlib.reload(power_functions)\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "df['channel']=df['channel'].apply(lambda x:'AON' if 'AON' in x else 'vHp')\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "mean_dict={}\n",
    "for channel, data in channel_experiment_group:\n",
    "    print(channel)\n",
    "    data_array=np.vstack(data['data'].to_numpy())\n",
    "    print(data_array.shape)\n",
    "    data_array_welch = np.array([power_functions.apply_welch_transform(row) for row in data_array]) # Applying Welch's method to each row of data_array\n",
    "    print(data_array_welch.shape)\n",
    "    freqs = np.linspace(0,1000,num=int(data_array_welch.shape[1]))  # Assuming the frequency range is 0-1000 Hz\n",
    "    print(freqs.shape)\n",
    "\n",
    "    data_array_welch_mean = np.mean(data_array_welch, axis=0)\n",
    "    data_array_welch_std = np.std(data_array_welch, axis=0)\n",
    "    print(data_array_welch_mean.shape, data_array_welch_std.shape)\n",
    "    mean_dict[channel[0] + '_' + channel[1] + '_mean'] = data_array_welch_mean\n",
    "    mean_dict[channel[0] + '_' + channel[1] + '_std'] = data_array_welch_std\n",
    "    \n",
    "    ax.plot(freqs,data_array_welch_mean, linestyle=linestyle[channel[1]], color=colors[channel[0]], label=f'{channel[0]} {channel[1]}')\n",
    "    ax.fill_between(freqs,data_array_welch_mean-data_array_welch_std,data_array_welch_mean+data_array_welch_std, alpha=0.1, color=colors[channel[0]])\n",
    "    #ax.set_yscale('log')\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.legend(loc='upper right', fontsize=20)\n",
    "    ax.set_title('Baseline Power Spectral Density', fontsize=20)\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "    ax.set_ylabel('Power (V^2/Hz)', fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "#    ax.set_yscale('log')\n",
    "mean_dict['frequency']=freqs\n",
    "mean_df=pd.DataFrame(mean_dict)\n",
    "#mean_df.to_csv(savepath+'baseline_power_truncated.csv')\n",
    "#plt.savefig(savepath+'baseline_power_truncated.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# Calculate multitaper PSD for each group and plot\n",
    "fig_mt, ax_mt = plt.subplots(figsize=(15, 10))\n",
    "mt_mean_dict = {}\n",
    "for channel, data in channel_experiment_group:\n",
    "    data_array = np.vstack(data['data'].to_numpy())\n",
    "    # Multitaper PSD: average across trials\n",
    "    psds = []\n",
    "    for row in data_array:\n",
    "        psd, freqs_mt = psd_array_multitaper(row, sfreq=2000,bandwidth=2, fmin=0, fmax=100, adaptive=True, normalization='full', verbose=0)\n",
    "        psds.append(psd)\n",
    "    psds = np.array(psds)\n",
    "    psd_mean = psds.mean(axis=0)\n",
    "    psd_std = psds.std(axis=0)\n",
    "    mt_mean_dict[channel[0] + '_' + channel[1] + '_mean'] = psd_mean\n",
    "    mt_mean_dict[channel[0] + '_' + channel[1] + '_std'] = psd_std\n",
    "    ax_mt.plot(freqs_mt, psd_mean, linestyle=linestyle[channel[1]], color=colors[channel[0]], label=f'{channel[0]}_{channel[1]}')\n",
    "    ax_mt.fill_between(freqs_mt, psd_mean-psd_std, psd_mean+psd_std, alpha=0.1, color=colors[channel[0]])\n",
    "ax_mt.set_xlim(0, 100)\n",
    "handles, labels = ax_mt.get_legend_handles_labels()\n",
    "ax_mt.legend(handles, [channel_dict[l] for l in labels], loc='upper right', fontsize=20)\n",
    "ax_mt.set_title('Baseline Power Spectral Density (Multitaper)', fontsize=20)\n",
    "ax_mt.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "ax_mt.set_ylabel('Power (V^2/Hz)', fontsize=20)\n",
    "ax_mt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "mt_mean_dict['frequency'] = freqs_mt\n",
    "mt_mean_df = pd.DataFrame(mt_mean_dict)\n",
    "mt_mean_df.to_csv(savepath+'baseline_psd_multitaper.csv')\n",
    "plt.savefig(savepath+'baseline_psd_multitaper.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close(fig_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Prepare data for ANOVA: for each frequency, compare power between tasks\n",
    "# We'll do this for both AON and vHp channels\n",
    "\n",
    "results = {'frequency': [], 'AON_F': [], 'AON_p': [], 'vHp_F': [], 'vHp_p': []}\n",
    "tasks = ['BWcontext', 'BWnocontext']\n",
    "def make_welch_data_dfs(data, task, channel):\n",
    "    data_task_channel = data[(data['task'] == task) & (data['channel'] == channel)]\n",
    "    data_array = np.vstack(data_task_channel['data'].to_numpy())\n",
    "    data_array_welch = np.array([power_functions.apply_welch_transform(row) for row in data_array])  # Applying Welch's method to each row of data_array\n",
    "    return data_array_welch\n",
    "\n",
    "aon_context_vals= make_welch_data_dfs(df, 'BWcontext', 'AON')\n",
    "aon_nocontext_vals= make_welch_data_dfs(df, 'BWnocontext', 'AON')\n",
    "vHp_context_vals= make_welch_data_dfs(df, 'BWcontext', 'vHp')\n",
    "vHp_nocontext_vals= make_welch_data_dfs(df, 'BWnocontext', 'vHp')\n",
    "for freq in range(aon_context_vals.shape[1]):\n",
    "    aon_f, aon_p = f_oneway(aon_context_vals[:, freq], aon_nocontext_vals[:, freq])\n",
    "    vHp_f, vHp_p = f_oneway(vHp_context_vals[:, freq], vHp_nocontext_vals[:, freq])\n",
    "    \n",
    "    results['frequency'].append(freq)\n",
    "    results['AON_F'].append(aon_f)\n",
    "    results['AON_p'].append(aon_p)\n",
    "    results['vHp_F'].append(vHp_f)\n",
    "    results['vHp_p'].append(vHp_p)\n",
    "    # Convert results to DataFrame and filter for frequency 1 to 100\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[(results_df['frequency'] >= 1) & (results_df['frequency'] <= 100)]\n",
    "results_df.to_csv(savepath + 'anova_psd_per_frequency_1_100.csv', index=False)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For each frequency, extract power for each task and channel\n",
    "for i, freq in enumerate(mean_df['frequency']):\n",
    "    # For ANOVA, we need the raw values, not the means, so we go back to the original data\n",
    "    # Get all AON/vHp power values at this frequency for each task\n",
    "    aon_mask = (data['channel'] == 'AON')\n",
    "    vhp_mask = (data['channel'] == 'vHp')\n",
    "    context_mask = (data['task'] == 'BWcontext')\n",
    "    nocontext_mask = (data['task'] == 'BWnocontext')\n",
    "\n",
    "    aon_context_vals = data_array_welch[aon_mask & context_mask, i]\n",
    "    aon_nocontext_vals = data_array_welch[aon_mask & nocontext_mask, i]\n",
    "    vhp_context_vals = data_array_welch[vhp_mask & context_mask, i]\n",
    "    vhp_nocontext_vals = data_array_welch[vhp_mask & nocontext_mask, i]\n",
    "\n",
    "    # ANOVA for AON\n",
    "    if len(aon_context_vals) > 1 and len(aon_nocontext_vals) > 1:\n",
    "        F_aon, p_aon = f_oneway(aon_context_vals, aon_nocontext_vals)\n",
    "    else:\n",
    "        F_aon, p_aon = float('nan'), float('nan')\n",
    "\n",
    "    # ANOVA for vHp\n",
    "    if len(vhp_context_vals) > 1 and len(vhp_nocontext_vals) > 1:\n",
    "        F_vhp, p_vhp = f_oneway(vhp_context_vals, vhp_nocontext_vals)\n",
    "    else:\n",
    "        F_vhp, p_vhp = float('nan'), float('nan')\n",
    "\n",
    "    results['frequency'].append(freq)\n",
    "    results['AON_F'].append(F_aon)\n",
    "    results['AON_p'].append(p_aon)\n",
    "    results['vHp_F'].append(F_vhp)\n",
    "    results['vHp_p'].append(p_vhp)\n",
    "\n",
    "anova_df = pd.DataFrame(results)\n",
    "anova_df.to_csv(savepath + 'anova_psd_per_frequency.csv', index=False)\n",
    "print(anova_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselinePower Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl') #Loading the baseline LFP data\n",
    "df= baseline_lfp_all.__deepcopy__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "importlib.reload(plotting_styles)\n",
    "importlib.reload(power_functions)\n",
    "linestyles = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors\n",
    "brain_areas = ['AON','vHp']\n",
    "\n",
    "\n",
    "number_per_segment = 2000\n",
    "tukey_window = scipy.signal.get_window(('tukey', 0.2), number_per_segment)    \n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "df['data']=df['data'].apply(lambda x:power_functions.apply_welch_transform(x))\n",
    "\n",
    "for band_name, band_values in all_bands_dict.items():\n",
    "    df[band_name+'_power']=df['data'].apply(lambda x:power_functions.get_band_power(x, band_values[0], band_values[1]))\n",
    "\n",
    "writer=pd.ExcelWriter(savepath+'baseline_power_per_band_welch.xlsx')\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 10), sharey=True)\n",
    "axs=axs.flatten()\n",
    "for i, area in enumerate(brain_areas):\n",
    "    data = df[df['channel'].str.contains(area)]\n",
    "    data_melted = data.melt(id_vars=['rat','task','channel'], value_vars=['total_power','beta_power','gamma_power','theta_power'], var_name='band', value_name='power')\n",
    "    sns.barplot(\n",
    "        data=data_melted, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, ax=axs[i])\n",
    "    sns.stripplot(data=data_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, dodge=True, alpha=0.5, jitter=0.2, ax=axs[i], linewidth=1, legend=False )\n",
    "#    axs[i].set_yscale('log')\n",
    "    axs[i].set_title(f'Baseline {area} Power per Band', fontsize=20)\n",
    "    axs[i].set_xlabel('Band', fontsize=20)\n",
    "    axs[i].set_ylabel('Power V^2', fontsize=20)\n",
    "    axs[i].legend(loc='upper right', fontsize=15)\n",
    "    axs[i].set_xticks(([0,1,2,3]),list(all_bands_dict.keys()))\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=15)\n",
    "    data_melted.to_excel(writer, sheet_name=area)\n",
    "writer.close()\n",
    "plt.savefig(savepath+'baseline_power_per_band_welch.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl') #Loading the baseline LFP data\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "\n",
    "# Calculate multitaper PSD and band power for each row\n",
    "df['data_mt'] = df['data'].apply(lambda x: psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=100, adaptive=True,bandwidth=2, normalization='full', verbose=0, max_iter=500)[0])\n",
    "\n",
    "for band_name, band_values in all_bands_dict.items():\n",
    "    # df[band_name + '_power_mt'] = df['data_mt'].apply(lambda x: psd_array_multitaper(x, sfreq=2000, fmin=band_values[0], fmax=band_values[1], adaptive=True,bandwidth=2, normalization='full', verbose=0, max_iter=500,faverage=True)[0])\n",
    "\n",
    "    df[band_name + '_power_mt'] = df['data_mt'].apply(lambda x: power_functions.get_band_power(x, band_values[0], band_values[1]))\n",
    "    epsilon = 1e-12\n",
    "    #df[band_name + '_power_mt'] = df[band_name + '_power_mt'].apply(lambda x: 10*np.log10(x + epsilon))     # Log-normalize multitaper band power, handling log(0) by adding a small epsilon\n",
    "\n",
    "    # Plot multitaper band power\n",
    "writer_mt = pd.ExcelWriter(savepath + 'baseline_power_per_band_multitaper.xlsx')\n",
    "\n",
    "fig_mt, axs_mt = plt.subplots(1, 2, figsize=(15, 10), sharey=True)\n",
    "axs_mt = axs_mt.flatten()\n",
    "for i, area in enumerate(brain_areas):\n",
    "    data_mt = df[df['channel'].str.contains(area)]\n",
    "    data_melted_mt = data_mt.melt(\n",
    "        id_vars=['rat', 'task', 'channel'],\n",
    "        value_vars=['total_power_mt', 'beta_power_mt', 'gamma_power_mt', 'theta_power_mt'],\n",
    "        var_name='band', value_name='power'\n",
    "    )\n",
    "    # Plot log-normalized multitaper band power\n",
    "    sns.barplot(\n",
    "        data=data_melted_mt, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, ax=axs_mt[i]\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=data_melted_mt, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, dodge=True, alpha=1, jitter=0.2,\n",
    "        ax=axs_mt[i], linewidth=1, legend=False\n",
    "    )\n",
    "    axs_mt[i].set_title(f'Baseline {area} Power per band', fontsize=20)\n",
    "    axs_mt[i].set_xlabel('Band', fontsize=20)\n",
    "    axs_mt[i].set_ylabel('Power (V^2)', fontsize=20)\n",
    "    handles, labels = axs_mt[i].get_legend_handles_labels()\n",
    "    axs_mt[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "    #axs_mt[i].legend(loc='upper right', fontsize=15)\n",
    "    axs_mt[i].set_xticks([0, 1, 2, 3], list(all_bands_dict.keys()))\n",
    "    axs_mt[i].tick_params(axis='both', which='major', labelsize=15)\n",
    "    data_melted_mt.to_excel(writer_mt, sheet_name=area)\n",
    "writer_mt.close()\n",
    "plt.savefig(savepath + 'baseline_power_per_band_multitaper.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Power Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "df['channel']=df['channel'].apply(lambda x:'AON' if 'AON' in x else 'vHp')\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "\n",
    "\"\"\"\n",
    "Doing a test run\n",
    "\n",
    "test_array = df['data'].iloc[0]\n",
    "print(test_array.shape)\n",
    "\n",
    "test_array_new = test_array.reshape((1,1,-1))\n",
    "print(test_array_new.shape)\n",
    "\n",
    "fmin = 1\n",
    "fmax = 100\n",
    "freqs = np.arange(fmin, fmax)\n",
    "n_cycles = freqs / 3.  # different number of cycles per frequency\n",
    "fs =2000\n",
    "\n",
    "tfr_array = tfr_array_morlet(test_array_new, sfreq=fs, freqs=freqs, n_cycles=n_cycles, n_jobs=-1, output='power')\n",
    "\n",
    "print(tfr_array.shape)  # Should be (n_epochs,n_channels, n_freqs, n_times)\n",
    "\n",
    "tfr_array_squeezed = tfr_array.squeeze()\n",
    "print(tfr_array_squeezed.shape)  # Should be (n_freqs, n_times)\n",
    "\n",
    "plt.imshow(tfr_array_squeezed, aspect='auto', origin='lower', extent=[-2, 0, fmin, fmax])\n",
    "plt.colorbar(label='Power')\n",
    "#for task_channel, data in channel_experiment_group:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "def compute_tfr(data_array, fmin=1, fmax=100, fs=2000):\n",
    "    data_array = data_array.reshape((1, 1, -1))\n",
    "    freqs = np.arange(fmin, fmax)\n",
    "    n_cycles = freqs / 3.  # different number of cycles per frequency\n",
    "    tfr_array = tfr_array_morlet(data_array, sfreq=fs, freqs=freqs, n_cycles=n_cycles, n_jobs=1, output='power')\n",
    "    tfr_array_squeezed = tfr_array.squeeze()\n",
    "    #tfr_normalized = scipy.stats.zscore(tfr_array_squeezed, axis=1)\n",
    "    tfr_normalized = 10*np.log10(tfr_array_squeezed) #dB normalization\n",
    "    return tfr_normalized\n",
    "\n",
    "df['data_tfr'] = df['data'].apply(compute_tfr)\n",
    "\n",
    "\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "fig, axs= plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Baseline Power Spectrograms', fontsize=20)\n",
    "axs=axs.flatten()\n",
    "for i, (task_channel, data) in enumerate(channel_experiment_group):\n",
    "    ax = axs[i]\n",
    "    print(task_channel)\n",
    "    data_array_tfr = np.array(data['data_tfr'].tolist())\n",
    "    print(data_array_tfr.shape)  # Should be (n_epochs, n_freqs, n_times)\n",
    "    \n",
    "    data_array_tfr_mean = np.mean(data_array_tfr, axis=0)\n",
    "    print(data_array_tfr_mean.shape)  # Should be (n_freqs, n_times)\n",
    "    ax.imshow(data_array_tfr_mean, aspect='auto', origin='lower', extent=[-2, 0, 1, 100])\n",
    "\n",
    "    ax.set_title(f'{task_channel[0]} {task_channel[1]}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "fig.colorbar(ax.images[0], ax=axs, label='Power (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the power spectra for each rat and the mean power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the power spectra for the complete trial # [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "fig.suptitle('Power Spectral Density')\n",
    "linestyles = {'AON': '-', 'vHp': '--'}\n",
    "\n",
    "for i,rati in enumerate(rat_list):\n",
    "    rat_data=power_df[power_df['rat']==rati]\n",
    "    rat_data=rat_data.reset_index(drop=True)\n",
    "    rat_data_grouped=rat_data.groupby(['task','channel'])\n",
    "    for (task, channel),group in rat_data_grouped:\n",
    "        print(task, channel)\n",
    "        group=group.reset_index(drop=True)\n",
    "        col='complete_trial'\n",
    "        data = np.array(group[col])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        freq = np.linspace(0, 1000, len(data_mean))        \n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{rati}')\n",
    "        ax.plot(freq, data_mean, color=colors[task], linestyle=linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=colors[task])\n",
    "        ax.set_xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Average Power Spectra across all rats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Event Power Spectra individual Rats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Events PSD Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "\n",
    "time_window=0.7\n",
    "fs=2000\n",
    "\n",
    "##################\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['complete_trial','pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "\n",
    "power_df.loc[:,columns]=power_df.loc[:,columns].applymap(lambda x:power_functions.apply_welch_transform(x))\n",
    "events_dict={'pre_door':' Pre Door','post_door':'Post Door','pre_dig':'Pre Dig','post_dig':'Post Dig'}\n",
    "fig, axs=plt.subplots(1,4, figsize=(40,10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer=pd.ExcelWriter(savepath+'events_power_spectral_density.xlsx')\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "\n",
    "    data = power_df[['rat','task','channel',event]]\n",
    "    data['channel']=data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups=data.groupby(['task','channel'])\n",
    "    mean_data_dict={}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group=group.reset_index(drop=True)\n",
    "        data = np.array(group[event])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        mean_data_dict[task+'_'+channel+'_mean']=data_mean\n",
    "        mean_data_dict[task+'_'+channel+'_sem']=data_sem\n",
    "        freq = np.linspace(0, 1000, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2/Hz)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    mean_data_dict['frequency'] = freq\n",
    "    mean_df=pd.DataFrame(mean_data_dict)\n",
    "    mean_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "fig.savefig(savepath+f'pow_events_psd{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events PSD MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window=0.4\n",
    "fs=2000\n",
    "###############\n",
    "\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "# Apply multitaper PSD to each event column\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=100, adaptive=True, bandwidth=6, normalization='length', verbose=0, max_iter=1000)\n",
    "    #psd = 10 * np.log10(psd)\n",
    "    return psd\n",
    "\n",
    "power_df.loc[:, columns] = power_df.loc[:, columns].applymap(multitaper_transform)\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "events_dict = {'pre_door': ' Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer = pd.ExcelWriter(savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.xlsx')\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    data = power_df[['rat', 'task', 'channel', event]]\n",
    "    data['channel'] = data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups = data.groupby(['task', 'channel'])\n",
    "    mean_data_dict = {}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group = group.reset_index(drop=True)\n",
    "        data_arr = np.array(group[event])\n",
    "        data_mean = np.mean(data_arr, axis=0)\n",
    "        data_sem = scipy.stats.sem(data_arr, axis=0)\n",
    "        mean_data_dict[task + '_' + channel + '_mean'] = data_mean\n",
    "        mean_data_dict[task + '_' + channel + '_sem'] = data_sem\n",
    "        freq = np.linspace(0, 100, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel], label=f'{task_dict[task]} {channel}')\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        # ax.set_yscale('log')\n",
    "        ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2/Hz)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    mean_data_dict['frequency'] = freq\n",
    "    mean_df = pd.DataFrame(mean_data_dict)\n",
    "    mean_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper right', fontsize=20)\n",
    "fig.savefig(savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['experiment', 'date', 'rat_id', 'task', 'mne_baseline',\n",
      "       'mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before',\n",
      "       'mne_epoch_dig_after', 'mne_epoch_around_door', 'mne_epoch_around_dig'],\n",
      "      dtype='object')\n",
      "Processing rat dk1, task BWnocontext, date 20230609 (1/27)\n",
      "Processing rat dk3, task BWnocontext, date 20230609 (2/27)\n",
      "Processing rat dk1, task BWnocontext, date 20230610 (3/27)\n",
      "Processing rat dk3, task BWnocontext, date 20230610 (4/27)\n",
      "Processing rat dk5, task BWcontext, date 20230615 (5/27)\n",
      "Processing rat dk6, task BWcontext, date 20230615 (6/27)\n",
      "Processing rat dk5, task BWcontext, date 20230616 (7/27)\n",
      "Processing rat dk6, task BWcontext, date 20230616 (8/27)\n",
      "Processing rat dk1, task BWcontext, date 20230623 (9/27)\n",
      "Processing rat dk1, task BWcontext, date 20230626 (10/27)\n",
      "Processing rat dk5, task BWnocontext, date 20230626 (11/27)\n",
      "Processing rat dk6, task BWnocontext, date 20230626 (12/27)\n",
      "Processing rat dk1, task BWcontext, date 20230627 (13/27)\n",
      "Processing rat dk5, task BWnocontext, date 20230627 (14/27)\n",
      "Processing rat dk6, task BWnocontext, date 20230628 (15/27)\n",
      "Processing rat dk3, task BWcontext, date 20230807 (16/27)\n",
      "Processing rat dk3, task BWcontext, date 20230808 (17/27)\n",
      "Processing rat dk5, task BWnocontext, date 20230808 (18/27)\n",
      "Processing rat dk5, task BWnocontext, date 20230810 (19/27)\n",
      "Processing rat dk1, task BWcontext, date 20230817 (20/27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mne\\time_frequency\\multitaper.py:161: RuntimeWarning: invalid value encountered in divide\n",
      "  d_k = psd_iter / (\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n",
      "C:\\Users\\sinha\\AppData\\Local\\Temp\\ipykernel_29476\\1085879714.py:41: RuntimeWarning: Iterative multi-taper PSD computation did not converge.\n",
      "  test_epoch_psd = test_epoch.compute_psd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rat dk1, task BWcontext, date 20230818 (21/27)\n",
      "Processing rat dk3, task BWcontext, date 20230818 (22/27)\n",
      "Processing rat dk3, task BWcontext, date 20230821 (23/27)\n",
      "Processing rat dk5, task BWcontext, date 20230821 (24/27)\n",
      "Processing rat dk1, task BWnocontext, date 20230822 (25/27)\n",
      "Processing rat dk1, task BWnocontext, date 20230823 (26/27)\n",
      "Processing rat dk5, task BWcontext, date 20230823 (27/27)\n",
      "\n",
      "Aggregating across rats...\n",
      "mne_epoch_door_before: 101 frequency bins, 9 columns\n",
      "mne_epoch_dig_before: 101 frequency bins, 9 columns\n",
      "mne_epoch_dig_after: 101 frequency bins, 9 columns\n",
      "\n",
      "Saving PSD mean/SEM to C:\\Users\\sinha\\Dropbox\\CPLab\\results\\pow_events_psd_1000ms.xlsx...\n",
      "Saved sheet: door_before (101 rows, 9 columns)\n",
      "Saved sheet: dig_before (101 rows, 9 columns)\n",
      "Saved sheet: dig_after (101 rows, 9 columns)\n",
      "\n",
      "PSD Mean/SEM Analysis Done!\n",
      "\n",
      "=== PSD Mean/SEM Sample ===\n",
      "\n",
      "mne_epoch_door_before:\n",
      "   frequency  BWnocontext_AON_mean  BWnocontext_AON_sem  BWnocontext_vHp_mean  \\\n",
      "0        0.0              0.003677             0.000385              0.003338   \n",
      "1        1.0              0.008873             0.000820              0.007538   \n",
      "2        2.0              0.012251             0.000996              0.009999   \n",
      "3        3.0              0.017744             0.001372              0.014583   \n",
      "4        4.0              0.022409             0.001664              0.019432   \n",
      "5        5.0              0.026821             0.001843              0.023351   \n",
      "6        6.0              0.030186             0.001961              0.040668   \n",
      "7        7.0              0.033301             0.002108              0.055392   \n",
      "8        8.0              0.034219             0.002116              0.058779   \n",
      "9        9.0              0.031751             0.001989              0.058288   \n",
      "\n",
      "   BWnocontext_vHp_sem  BWcontext_AON_mean  BWcontext_AON_sem  \\\n",
      "0             0.000227            0.006120           0.003011   \n",
      "1             0.000444            0.014321           0.007684   \n",
      "2             0.000525            0.022047           0.011759   \n",
      "3             0.000733            0.034055           0.017858   \n",
      "4             0.000980            0.044731           0.024238   \n",
      "5             0.001213            0.054914           0.029869   \n",
      "6             0.002252            0.063201           0.032350   \n",
      "7             0.002555            0.068106           0.034472   \n",
      "8             0.002629            0.059446           0.027545   \n",
      "9             0.002572            0.051717           0.021744   \n",
      "\n",
      "   BWcontext_vHp_mean  BWcontext_vHp_sem  \n",
      "0            0.004674           0.001541  \n",
      "1            0.011022           0.003963  \n",
      "2            0.015233           0.005580  \n",
      "3            0.023018           0.008478  \n",
      "4            0.029496           0.011004  \n",
      "5            0.037680           0.014315  \n",
      "6            0.052799           0.015066  \n",
      "7            0.065578           0.014025  \n",
      "8            0.065103           0.011739  \n",
      "9            0.062763           0.008980  \n",
      "Shape: (101, 9)\n",
      "Columns: ['frequency', 'BWnocontext_AON_mean', 'BWnocontext_AON_sem', 'BWnocontext_vHp_mean', 'BWnocontext_vHp_sem', 'BWcontext_AON_mean', 'BWcontext_AON_sem', 'BWcontext_vHp_mean', 'BWcontext_vHp_sem']\n",
      "\n",
      "mne_epoch_dig_before:\n",
      "   frequency  BWnocontext_AON_mean  BWnocontext_AON_sem  BWnocontext_vHp_mean  \\\n",
      "0        0.0              0.004265             0.000633              0.002411   \n",
      "1        1.0              0.007932             0.001051              0.005203   \n",
      "2        2.0              0.011609             0.001826              0.007660   \n",
      "3        3.0              0.016295             0.002877              0.011426   \n",
      "4        4.0              0.020953             0.004667              0.016742   \n",
      "5        5.0              0.022272             0.004763              0.027900   \n",
      "6        6.0              0.023550             0.004959              0.035862   \n",
      "7        7.0              0.024531             0.005301              0.038952   \n",
      "8        8.0              0.026282             0.005999              0.040629   \n",
      "9        9.0              0.028005             0.005210              0.041515   \n",
      "\n",
      "   BWnocontext_vHp_sem  BWcontext_AON_mean  BWcontext_AON_sem  \\\n",
      "0             0.000323            0.029580           0.006858   \n",
      "1             0.000503            0.060453           0.012505   \n",
      "2             0.000707            0.074506           0.015255   \n",
      "3             0.001230            0.112336           0.027982   \n",
      "4             0.002251            0.156306           0.042719   \n",
      "5             0.002807            0.176427           0.049888   \n",
      "6             0.003098            0.179008           0.051153   \n",
      "7             0.003544            0.186558           0.053974   \n",
      "8             0.003791            0.190723           0.055437   \n",
      "9             0.003651            0.161669           0.037477   \n",
      "\n",
      "   BWcontext_vHp_mean  BWcontext_vHp_sem  \n",
      "0            0.013209           0.003022  \n",
      "1            0.028186           0.005264  \n",
      "2            0.034548           0.005965  \n",
      "3            0.053060           0.011034  \n",
      "4            0.071659           0.014299  \n",
      "5            0.085651           0.016905  \n",
      "6            0.090946           0.017430  \n",
      "7            0.098472           0.019126  \n",
      "8            0.101439           0.020144  \n",
      "9            0.096714           0.015676  \n",
      "Shape: (101, 9)\n",
      "Columns: ['frequency', 'BWnocontext_AON_mean', 'BWnocontext_AON_sem', 'BWnocontext_vHp_mean', 'BWnocontext_vHp_sem', 'BWcontext_AON_mean', 'BWcontext_AON_sem', 'BWcontext_vHp_mean', 'BWcontext_vHp_sem']\n",
      "\n",
      "mne_epoch_dig_after:\n",
      "   frequency  BWnocontext_AON_mean  BWnocontext_AON_sem  BWnocontext_vHp_mean  \\\n",
      "0        0.0              0.004328             0.001095              0.002301   \n",
      "1        1.0              0.013279             0.005876              0.007436   \n",
      "2        2.0              0.015456             0.006621              0.009669   \n",
      "3        3.0              0.019729             0.007475              0.013122   \n",
      "4        4.0              0.024847             0.010053              0.020468   \n",
      "5        5.0              0.029685             0.013835              0.031892   \n",
      "6        6.0              0.026455             0.011609              0.033613   \n",
      "7        7.0              0.024722             0.009874              0.034708   \n",
      "8        8.0              0.025738             0.011106              0.036337   \n",
      "9        9.0              0.025795             0.011936              0.034912   \n",
      "\n",
      "   BWnocontext_vHp_sem  BWcontext_AON_mean  BWcontext_AON_sem  \\\n",
      "0             0.000504            0.015541           0.003554   \n",
      "1             0.002771            0.033023           0.008824   \n",
      "2             0.003054            0.042486           0.010239   \n",
      "3             0.003333            0.059632           0.015200   \n",
      "4             0.004374            0.077894           0.020713   \n",
      "5             0.006129            0.085332           0.022499   \n",
      "6             0.005005            0.086411           0.024475   \n",
      "7             0.004805            0.091493           0.027893   \n",
      "8             0.005632            0.088158           0.027446   \n",
      "9             0.005895            0.079756           0.024124   \n",
      "\n",
      "   BWcontext_vHp_mean  BWcontext_vHp_sem  \n",
      "0            0.006813           0.001270  \n",
      "1            0.014197           0.002445  \n",
      "2            0.020283           0.003559  \n",
      "3            0.027268           0.004448  \n",
      "4            0.038906           0.005987  \n",
      "5            0.048814           0.006822  \n",
      "6            0.052146           0.007307  \n",
      "7            0.054986           0.007906  \n",
      "8            0.053953           0.007679  \n",
      "9            0.051048           0.006874  \n",
      "Shape: (101, 9)\n",
      "Columns: ['frequency', 'BWnocontext_AON_mean', 'BWnocontext_AON_sem', 'BWnocontext_vHp_mean', 'BWnocontext_vHp_sem', 'BWcontext_AON_mean', 'BWcontext_AON_sem', 'BWcontext_vHp_mean', 'BWcontext_vHp_sem']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "event_list = ['mne_epoch_door_before', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "def get_channel_groups(channel_names, task):\n",
    "    \"\"\"\n",
    "    Identify channel groups based on channel names and task.\n",
    "    Returns dictionary with channel indices for each group.\n",
    "    \"\"\"\n",
    "    aon_channels = [ch for ch in channel_names if 'AON' in ch]\n",
    "    vhp_channels = [ch for ch in channel_names if 'vHp' in ch]\n",
    "    \n",
    "    groups = {\n",
    "        f'{task}_AON': aon_channels,\n",
    "        f'{task}_vHp': vhp_channels\n",
    "    }\n",
    "    \n",
    "    return groups\n",
    "\n",
    "print(con_data_df_clean.columns)\n",
    "\n",
    "# Dictionary to store PSD data for each event and task combination\n",
    "# Structure: event_psd_data[event][task][group_name] = list of (n_trials, n_freqs) arrays\n",
    "event_psd_data = {event: {} for event in event_list}\n",
    "freqs_array = None  # Will store frequency values\n",
    "\n",
    "for i in range(len(con_data_df_clean)):\n",
    "    rat = con_data_df_clean.loc[i, 'rat_id']\n",
    "    task = con_data_df_clean.loc[i, 'task']\n",
    "    date = con_data_df_clean.loc[i, 'date']\n",
    "    \n",
    "    print(f\"Processing rat {rat}, task {task}, date {date} ({i+1}/{len(con_data_df_clean)})\")\n",
    "    \n",
    "    for event in event_list:\n",
    "        test_epoch = con_data_df_clean.loc[i, event]\n",
    "        \n",
    "        # Compute PSD\n",
    "        test_epoch_psd = test_epoch.compute_psd(\n",
    "            method='multitaper', \n",
    "            fmin=0, \n",
    "            fmax=100, \n",
    "            adaptive=True, \n",
    "            bandwidth=6, \n",
    "            normalization='full', \n",
    "            verbose=0,\n",
    "            exclude=['Ref']\n",
    "        )\n",
    "        \n",
    "        # Get PSD data and frequencies\n",
    "        psd_array = test_epoch_psd.get_data()  # shape: (n_trials, n_channels, n_freqs)\n",
    "        freqs = test_epoch_psd.freqs\n",
    "        channel_names = test_epoch_psd.ch_names\n",
    "        \n",
    "        # Store frequency array (same for all)\n",
    "        if freqs_array is None:\n",
    "            freqs_array = freqs\n",
    "        \n",
    "        # Identify channel groups based on task and channel names\n",
    "        channel_groups = get_channel_groups(channel_names, task)\n",
    "        \n",
    "        # Initialize task dictionary if needed\n",
    "        if task not in event_psd_data[event]:\n",
    "            event_psd_data[event][task] = {group: [] for group in channel_groups.keys()}\n",
    "        \n",
    "        # Process each channel group\n",
    "        for group_name, group_channels in channel_groups.items():\n",
    "            # Find indices of channels in this group\n",
    "            channel_indices = [idx for idx, ch in enumerate(channel_names) \n",
    "                             if ch in group_channels]\n",
    "            \n",
    "            if len(channel_indices) > 0:\n",
    "                # Get PSD data for these channels: (n_trials, n_channels_in_group, n_freqs)\n",
    "                group_psd = psd_array[:, channel_indices, :]\n",
    "                \n",
    "                # Average across channels: (n_trials, n_freqs)\n",
    "                group_psd_avg_channels = np.mean(group_psd, axis=1)\n",
    "                \n",
    "                # Store this rat's data\n",
    "                event_psd_data[event][task][group_name].append(group_psd_avg_channels)\n",
    "\n",
    "# Now aggregate across rats for each event and task\n",
    "print(\"\\nAggregating across rats...\")\n",
    "final_psd_dfs = {}\n",
    "\n",
    "for event in event_list:\n",
    "    # Dictionary to hold columns for this event\n",
    "    df_dict = {'frequency': freqs_array}  # Add frequency column first\n",
    "    \n",
    "    # Get all tasks for this event\n",
    "    for task in event_psd_data[event].keys():\n",
    "        # Process each channel group\n",
    "        for group_name in event_psd_data[event][task].keys():\n",
    "            rat_data = event_psd_data[event][task][group_name]\n",
    "            \n",
    "            if len(rat_data) > 0:\n",
    "                # rat_data is a list of (n_trials, n_freqs) arrays, one per rat\n",
    "                # Concatenate all rats' trials: (total_trials_all_rats, n_freqs)\n",
    "                all_trials = np.concatenate(rat_data, axis=0)\n",
    "                \n",
    "                # Calculate mean and SEM across all trials from all rats\n",
    "                psd_mean = np.mean(all_trials, axis=0)\n",
    "                psd_sem = stats.sem(all_trials, axis=0)\n",
    "                \n",
    "                # Add as columns\n",
    "                df_dict[f'{group_name}_mean'] = psd_mean\n",
    "                df_dict[f'{group_name}_sem'] = psd_sem\n",
    "            else:\n",
    "                df_dict[f'{group_name}_mean'] = np.full(len(freqs_array), np.nan)\n",
    "                df_dict[f'{group_name}_sem'] = np.full(len(freqs_array), np.nan)\n",
    "    \n",
    "    # Create dataframe where each row is a frequency bin\n",
    "    final_psd_dfs[event] = pd.DataFrame(df_dict)\n",
    "    print(f\"{event}: {len(final_psd_dfs[event])} frequency bins, {len(df_dict)} columns\")\n",
    "\n",
    "# Save PSD Mean/SEM to Excel\n",
    "excel_filename_psd = savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.xlsx'\n",
    "print(f\"\\nSaving PSD mean/SEM to {excel_filename_psd}...\")\n",
    "\n",
    "with pd.ExcelWriter(excel_filename_psd, engine='openpyxl') as writer:\n",
    "    for event, df in final_psd_dfs.items():\n",
    "        sheet_name = event.replace('mne_epoch_', '')[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Saved sheet: {sheet_name} ({len(df)} rows, {len(df.columns)} columns)\")\n",
    "\n",
    "print(\"\\nPSD Mean/SEM Analysis Done!\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n=== PSD Mean/SEM Sample ===\")\n",
    "for event, df in final_psd_dfs.items():\n",
    "    print(f\"\\n{event}:\")\n",
    "    print(df.head(10))\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating plots...\n",
      "Plot saved to C:\\Users\\sinha\\Dropbox\\CPLab\\results\\pow_events_psd_1000ms.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Plotting =====\n",
    "print(\"\\nCreating plots...\")\n",
    "\n",
    "# Create figure with 3 subplots in a row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# Event titles for subplots\n",
    "event_titles = {\n",
    "    'mne_epoch_door_before': 'Door Before',\n",
    "    'mne_epoch_dig_before': 'Dig Before',\n",
    "    'mne_epoch_dig_after': 'Dig After'\n",
    "}\n",
    "\n",
    "for idx, event in enumerate(event_list):\n",
    "    ax = axes[idx]\n",
    "    df = final_psd_dfs[event]\n",
    "    freqs = df['frequency'].values\n",
    "    \n",
    "    # Get all column names except frequency\n",
    "    data_columns = [col for col in df.columns if col != 'frequency']\n",
    "    \n",
    "    # Extract task and region from column names and plot\n",
    "    plotted_lines = []\n",
    "    for col in data_columns:\n",
    "        if '_mean' in col:\n",
    "            # Parse column name: e.g., 'BWContext_AON_mean'\n",
    "            col_name = col.replace('_mean', '')\n",
    "            \n",
    "            mean_col = col\n",
    "            sem_col = col.replace('_mean', '_sem')\n",
    "            \n",
    "            if mean_col in df.columns and sem_col in df.columns:\n",
    "                mean = df[mean_col].values\n",
    "                sem = df[sem_col].values\n",
    "                \n",
    "                # Determine color and linestyle based on column name\n",
    "                if 'BWcontext' in col_name:\n",
    "                    color = 'blue'\n",
    "                elif 'BWnocontext' in col_name or 'BWNocontext' in col_name:\n",
    "                    color = 'orange'\n",
    "                else:\n",
    "                    color = 'black'\n",
    "                \n",
    "                if 'AON' in col_name:\n",
    "                    linestyle = '-'\n",
    "                elif 'vHp' in col_name:\n",
    "                    linestyle = '--'\n",
    "                else:\n",
    "                    linestyle = '-'\n",
    "                \n",
    "                # Create label\n",
    "                label = col_name.replace('_', ' ')\n",
    "                \n",
    "                # Plot mean line\n",
    "                line = ax.plot(freqs, mean, color=color, linestyle=linestyle, \n",
    "                       linewidth=2, label=label)\n",
    "                \n",
    "                # Add shaded SEM\n",
    "                ax.fill_between(freqs, mean - sem, mean + sem, \n",
    "                               color=color, alpha=0.2)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Power Spectral Density (mV^2/Hz)', fontsize=12)\n",
    "    ax.set_title(event_titles[event], fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim([freqs.min(), freqs.max()])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plot_filename = savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.png'\n",
    "plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Plot saved to {plot_filename}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectrograms for each each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.7\n",
    "fs=2000\n",
    "mne_epochs = pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "## Test Epoch\n",
    "\n",
    "test_epoch_pre_door = mne_epochs['mne_epoch_door_before'].iloc[0]\n",
    "test_epoch_pre_dig = mne_epochs['mne_epoch_dig_before'].iloc[0]\n",
    "fmin=2.5\n",
    "fmax=100\n",
    "fs=2000\n",
    "freqs = np.arange(fmin,fmax)\n",
    "n_cycles = freqs/3\n",
    "\n",
    "power_pre_door = test_epoch_pre_door.compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False\n",
    ")\n",
    "\n",
    "power_pre_door_data = power_pre_door.get_data()\n",
    "print(power_pre_door_data.shape)\n",
    "power_pre_dig = test_epoch_pre_dig.compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False\n",
    ")\n",
    "power_pre_dig_data = power_pre_dig.get_data()\n",
    "print(power_pre_dig_data.shape)\n",
    "channel_names = power_pre_door.ch_names\n",
    "print(channel_names)\n",
    "plt.imshow(power_pre_door_data[0, 0, :, :], aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(power_pre_dig_data[0, 0, :, :], aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_of_cols = power_pre_door_data.shape[0]\n",
    "num_of_rows = power_pre_door_data.shape[1]\n",
    "\n",
    "fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(20, 10), sharex=True, sharey=True)\n",
    "vmin_global = 0\n",
    "vmax_global = 0\n",
    "\n",
    "for i in range(num_of_rows):\n",
    "    for j in range(num_of_cols):\n",
    "        pre_door = power_pre_door_data[j,i, :, :]\n",
    "        pre_dig = power_pre_dig_data[j,i, :, :]\n",
    "        net_power = pre_dig - pre_door\n",
    "        axs[i, j].imshow(pre_door, aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel(f'{channel_names[i]}', fontsize=10)\n",
    "        if i==0:\n",
    "            axs[i, j].set_title(f'trial {j}', fontsize=10)\n",
    "            \n",
    "        vmin_global = min(vmin_global, pre_door.min())\n",
    "        vmax_global = max(vmax_global, pre_door.max())\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     # Set color limits for all axes to the global min/max\n",
    "#     for im in ax.get_images():\n",
    "#         im.set_clim(vmin_global, vmax_global)\n",
    "fig.colorbar(axs[0, 0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_epochs = pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "def get_power_tfr(epoch):\n",
    "    fmin=2.5\n",
    "    fmax=100\n",
    "    fs=2000\n",
    "    freqs = np.arange(fmin,fmax)\n",
    "    n_cycles = freqs/3\n",
    "\n",
    "    power = epoch.compute_tfr(\n",
    "        method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False, method_kw\n",
    "        \n",
    "    )\n",
    "\n",
    "    return power\n",
    "results = []\n",
    "for row in mne_epochs.itertuples(index=False):\n",
    "    experiment, rat_id, task = row.experiment, row.rat_id, row.task\n",
    "    door_before,door_after = row.mne_epoch_door_before, row.mne_epoch_door_after\n",
    "    dig_before,dig_after = row.mne_epoch_dig_before, row.mne_epoch_dig_after\n",
    "    around_door, around_dig = row.mne_epoch_around_door, row.mne_epoch_around_dig\n",
    "\n",
    "    power_door_before = get_power_tfr(door_before)\n",
    "    power_door_after = get_power_tfr(door_after)\n",
    "    power_dig_before = get_power_tfr(dig_before)\n",
    "    power_dig_after = get_power_tfr(dig_after)\n",
    "    power_around_door = get_power_tfr(around_door)\n",
    "    power_around_dig = get_power_tfr(around_dig)\n",
    "\n",
    "    net_power = power_dig_before - power_door_before\n",
    "    channel_names = door_before.ch_names\n",
    "    new_row = [experiment, rat_id, task,power_door_before,power_door_after,power_dig_before,power_dig_after, power_around_door, power_around_dig, net_power, channel_names]\n",
    "    results.append(new_row)\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['experiment', 'rat_id', 'task', 'power_pre_door', 'power_post_door','power_pre_dig','power_post_dig','power_around_door','power_around_dig','net_power_pre_dig_pre_door', 'channel_names'])\n",
    "results_df.to_pickle(savepath + 'power_tfr_epochs_mrlt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_power_epoch = results_df['power_pre_door'].iloc[0]\n",
    "test_power_epoch_2 = results_df['power_pre_door'].iloc[1]\n",
    "def plot_power_spec_from_epochs(test_power_epoch):\n",
    "    print(test_power_epoch.ch_names)\n",
    "    aon_channels = [channel for channel in test_power_epoch.ch_names if \"AON\" in channel]\n",
    "    vhp_channels = [channel for channel in test_power_epoch.ch_names if \"vHp\" in channel]\n",
    "    print(aon_channels,vhp_channels)\n",
    "    averaged_epoch_power = test_power_epoch.average(dim='epochs')\n",
    "    averaged_epoch_power.plot(title=\"auto\", vlim = (0, None))\n",
    "    averaged_epoch_power.plot(picks=aon_channels,title=\"AON power\", combine='mean', vlim = (0, None))\n",
    "    averaged_epoch_power.plot(picks=vhp_channels, title=\"VHP power\", combine='mean', vlim = (0, None))\n",
    "    return averaged_epoch_power, aon_channels,vhp_channels\n",
    "epoch1_avg, aon_1, vhp_1 = plot_power_spec_from_epochs(test_power_epoch)\n",
    "epoch2_avg, aon_2, vhp_2 = plot_power_spec_from_epochs(test_power_epoch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1400,8)\n",
    "list(np.arange(0,1600,200))\n",
    "list(np.round(np.arange(0,0.8,0.1), decimals = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(savepath+'power_tfr_epochs_mrlt.pkl')\n",
    "\n",
    "def make_averaged_power(epoch, area):\n",
    "    #print(epoch.ch_names)\n",
    "    area_channels = [channel for channel in epoch.ch_names if area in channel]\n",
    "    #print(area_channels)\n",
    "\n",
    "    if len(area_channels)==0:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    else:\n",
    "        area_epoch = epoch.copy()\n",
    "        area_epoch.pick(area_channels)\n",
    "        averaged_epoch_power = area_epoch.average(dim='epochs')\n",
    "        print(f\"Data shape before mean: {averaged_epoch_power.shape}\")  # DEBUG\n",
    "        mean_ch_power = np.mean(averaged_epoch_power.get_data(), axis = 0)\n",
    "        print(f\"Data shape after mean: {mean_ch_power.shape}\")  # DEBUG\n",
    "        return mean_ch_power\n",
    "\n",
    "# test_averaged_epoch_power = make_averaged_power(test_power_epoch, \"vHp\")\n",
    "# print(test_averaged_epoch_power.shape)\n",
    "\n",
    "for area in [\"AON\", \"vHp\"]:\n",
    "    area_df = pd.DataFrame()\n",
    "    fig, axs = plt.subplots(2,3, figsize= (15,10))\n",
    "    fig.suptitle(f'Average {area} Power')\n",
    "    for rowi, task in enumerate([\"BWcontext\", \"BWnocontext\"]):\n",
    "        task_data=results_df[results_df['task']==task]\n",
    "        print(f\"\\nTask: {task}, Area: {area}, Rows in task_data: {len(task_data)}\")\n",
    "        for coli, event in enumerate(['power_pre_door', 'power_pre_dig','power_post_dig']):\n",
    "            print(coli,event, task, area)\n",
    "            event_arrays = task_data[event].apply(lambda x: make_averaged_power(x, area))\n",
    "            \n",
    "            valid_arrays = [arr for arr in event_arrays.values if arr is not None]\n",
    "            \n",
    "            print(f\"Valid arrays found: {len(valid_arrays)}\")\n",
    "            \n",
    "            if len(valid_arrays) > 0:\n",
    "                averaged_array = np.mean(np.stack(valid_arrays), axis=0)\n",
    "                print(f\"Averaged array shape: {averaged_array.shape}\")\n",
    "                \n",
    "                ax = axs[rowi, coli]\n",
    "                im = ax.imshow(X= averaged_array, cmap = 'viridis', aspect='auto', origin='lower')\n",
    "                                # Add titles and labels\n",
    "                ax.set_title(f'{event.replace(\"_\", \" \").title()}')\n",
    "                ax.set_xlabel('Time (samples)')\n",
    "                ax.set_ylabel('Frequency (Hz)')\n",
    "                ax.set_xticks(list(np.arange(0,1600,200)))\n",
    "                ax.set_xticklabels(list(np.round(np.arange(0,0.8,0.1), decimals = 1)))\n",
    "                # Add colorbar\n",
    "                plt.colorbar(im, ax=ax, label='Power (mV^2/Hz)')\n",
    "                \n",
    "                # Add row labels\n",
    "                if coli == 0:\n",
    "                    ax.set_ylabel(f'{task}\\nFrequency (Hz)', fontweight='bold')\n",
    "                # Add your plotting code here\n",
    "            else:\n",
    "                print(f\"WARNING: No valid data for {area}, {task}, {event}\")\n",
    "                ax = axs[rowi, coli]\n",
    "                ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'power_spectrogram_{area}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for resulti in results_df.itertuples(index=False):\n",
    "    net_power = resulti.net_power_pre_dig_pre_door\n",
    "    vmin=net_power.min()\n",
    "    vmax=net_power.max()\n",
    "    num_of_trials = net_power.shape[0]\n",
    "    num_of_channels = net_power.shape[1]\n",
    "    fig, axs = plt.subplots(nrows=num_of_channels, ncols=num_of_trials,figsize=(10, 5))\n",
    "    for channeli in range(num_of_channels):\n",
    "        for triali in range(num_of_trials):\n",
    "            net_power_tfr = net_power[triali, channeli, :, :]\n",
    "            ax= axs[channeli, triali]\n",
    "            ax.imshow(net_power_tfr, aspect='auto', origin='lower', extent=[-0.7, 0, 2.5, 100], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.colorbar(ax.images[0], ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_around_dig.shape)\n",
    "\n",
    "net_power = power_dig_before - power_door_before\n",
    "\n",
    "print(net_power.shape)\n",
    "print(net_power[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Power for 1s around digging only [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list=['around_dig','around_door']\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "writer=pd.ExcelWriter(savepath+'events_power_spectral_density.xlsx')\n",
    "for i, event in enumerate(events_list):\n",
    "\n",
    "    data = power_df[['rat','task','channel',event]]\n",
    "    data['channel']=data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups=data.groupby(['task','channel'])\n",
    "    mean_data_dict={}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group=group.reset_index(drop=True)\n",
    "        data = np.array(group[event])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        mean_data_dict[task+'_'+channel+'_mean']=data_mean\n",
    "        mean_data_dict[task+'_'+channel+'_sem']=data_sem\n",
    "        freq = np.linspace(0, 1000, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{event}')\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_xlabel('Frequency (Hz)')\n",
    "        ax.set_ylabel('Power uV^2/Hz')\n",
    "    mean_df=pd.DataFrame(mean_data_dict)\n",
    "    #mean_df.to_excel(writer, sheet_name=event)\n",
    "#writer.close()\n",
    "#plt.savefig(savepath+'events_power_spectral_density.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events Power Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Power Boxplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Trial [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df=compiled_data_all_epochs.__deepcopy__()\n",
    "\n",
    "boxplot_df.loc[:,['pre_door','post_door','pre_dig','post_dig']]=boxplot_df.loc[:,['pre_door','post_door','pre_dig','post_dig']].applymap(lambda x: power_functions.apply_welch_transform(x))\n",
    "new_boxplot_df=boxplot_df[['rat', 'task', 'date', 'channel','trial']].copy()\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "for col in ['pre_door','post_door','pre_dig','post_dig']:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        new_boxplot_df[band + '_' + col] = boxplot_df[col].apply(lambda x: power_functions.get_band_power(x, band_start, band_end))\n",
    "\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task']+ '_' + new_boxplot_df['date']\n",
    "\n",
    "all_boxplot_df=new_boxplot_df.__deepcopy__()\n",
    "\n",
    "all_boxplot_df['channel'] = all_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "aon_channels=all_boxplot_df[all_boxplot_df['channel']=='AON']\n",
    "vhp_channels=all_boxplot_df[all_boxplot_df['channel']=='vHp']\n",
    "\n",
    "area_list= ['AON', 'vHp']\n",
    "for area in area_list:\n",
    "    area_channels = all_boxplot_df[all_boxplot_df['channel'] == area]\n",
    "    writer=pd.ExcelWriter(savepath+'events_power_per_band_{}_truncated.xlsx'.format(area), engine='xlsxwriter')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "\n",
    "    axs=axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        area_df=area_channels.__deepcopy__()\n",
    "        event_cols = [col for col in area_df.columns if event in col]\n",
    "        print(event_cols)\n",
    "        event_df = area_df[['rat', 'task', 'channel','trial', *event_cols]]\n",
    "        event_df_melted = pd.melt(event_df, id_vars=['rat', 'task', 'channel','trial'], var_name='band', value_name='power')\n",
    "        event_df_melted['band'] = event_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "        ax=axs[i]\n",
    "        #sns.boxplot(data=event_df_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, showfliers=False, ax=axs[i])\n",
    "        #sns.stripplot(data=event_df_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, dodge=True, alpha=0.5, jitter=0.2, ax=axs[i], linewidth=1, legend=False )\n",
    "        sns.violinplot(x='band',y='power',hue='task',hue_order=['BWcontext','BWnocontext'],data=event_df_melted, ax=ax)\n",
    "        #sns.stripplot(x='band',y='power',hue='task',hue_order=['BWcontext','BWnocontext'],data=event_df,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax, color=\".3\", size=2)\n",
    "\n",
    "        ax.set_title(f'{events_dict[event]} {area}', fontsize=20)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        #axs[i].set_yscale('log')\n",
    "        #axs[i].set_ylim(1e-3, 1e3)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel('Power (V^2)', fontsize=25)\n",
    "        event_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    plt.savefig(savepath+'events_power_per_band_{}_truncated.png'.format(area), format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Trial Multitaper [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath + 'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df = compiled_data_all_epochs.__deepcopy__()\n",
    "\n",
    "event_cols = ['pre_door', 'post_door', 'pre_dig', 'post_dig']\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "sfreq = 2000\n",
    "epsilon = 1e-12  # for log-normalization\n",
    "\n",
    "# Apply multitaper PSD to each event column\n",
    "for col in event_cols:\n",
    "    boxplot_df[col] = boxplot_df[col].apply(lambda x: psd_array_multitaper(x, sfreq=sfreq, fmin=0, fmax=1000, adaptive=True, normalization='full', verbose=0, max_iter=500, bandwidth=4)[0])\n",
    "\n",
    "# Calculate band power from multitaper PSD and log-normalize\n",
    "new_boxplot_df = boxplot_df[['rat', 'task', 'date', 'channel', 'trial']].copy()\n",
    "for col in event_cols:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        new_boxplot_df[f'{band}_{col}_mt'] = boxplot_df[col].apply(lambda x: np.log10(power_functions.get_band_power(x, band_start, band_end) + epsilon))\n",
    "\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task'] + '_' + new_boxplot_df['date']\n",
    "all_boxplot_df = new_boxplot_df.__deepcopy__()\n",
    "all_boxplot_df['channel'] = all_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "all_boxplot_df.to_excel(savepath + 'power_per_trial_mt.xlsx', index=False)\n",
    "area_list = ['AON', 'vHp']\n",
    "for area in area_list:\n",
    "    area_channels = all_boxplot_df[all_boxplot_df['channel'] == area]\n",
    "    writer = pd.ExcelWriter(savepath + f'events_power_per_band_multitaper_log10_{area}_truncated.xlsx', engine='xlsxwriter')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict = {'pre_door': 'Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_cols_mt = [f'{band}_{event}_mt' for band in bands_dict.keys()]\n",
    "        event_df = area_channels[['rat', 'task', 'channel', 'trial', *event_cols_mt]]\n",
    "        event_df_melted = pd.melt(event_df, id_vars=['rat', 'task', 'channel', 'trial'], var_name='band', value_name='power')\n",
    "        event_df_melted['band'] = event_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "        ax = axs[i]\n",
    "        sns.violinplot(x='band', y='power', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_df_melted, ax=ax)\n",
    "        ax.set_title(f'{events_dict[event]} {area} (Multitaper, log10)', fontsize=20)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('log10 Power (V^2)', fontsize=25)\n",
    "        event_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    plt.savefig(savepath + f'events_power_per_band_multitaper_log10_{area}_truncated.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean across all trials Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df=compiled_data_all_epochs.__deepcopy__()\n",
    "event_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "boxplot_df.loc[:,event_list]=boxplot_df.loc[:,event_list].applymap(lambda x: power_functions.apply_welch_transform(x))\n",
    "new_boxplot_df=power_functions.get_all_band_power_from_welchdf(boxplot_df, event_list)\n",
    "new_boxplot_df['channel'] = new_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task']+ '_' + new_boxplot_df['date']\n",
    "print(new_boxplot_df.columns)\n",
    "# Group by unique_id and channel, then take the mean across rows for columns containing 'pre' or 'post'\n",
    "pre_post_cols = [col for col in new_boxplot_df.columns if ('pre' in col or 'post' in col)]\n",
    "mean_data_list = []\n",
    "\n",
    "mean_boxplot_df=new_boxplot_df.__deepcopy__()\n",
    "unique_id_list=list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list=[]\n",
    "\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df=mean_boxplot_df[mean_boxplot_df['unique_id']==unique_id]\n",
    "    unique_id_df_grouped=unique_id_df.groupby(['channel'])\n",
    "    for channel, group in unique_id_df_grouped:\n",
    "        print(channel)\n",
    "        group=group.reset_index(drop=True)\n",
    "        columns = [col for col in group.columns if 'pre' in col or 'post' in col]\n",
    "        print(columns)\n",
    "        rat_id=group['rat'].iloc[0]\n",
    "        task_id=group['task'].iloc[0]\n",
    "        date_id=group['date'].iloc[0]\n",
    "        channel_id=group['channel'].iloc[0]\n",
    "        mean_data_dict={}\n",
    "        for col in columns:\n",
    "            data=np.array(group[col])\n",
    "            data_mean=np.mean(data,axis=0)\n",
    "            data_sem=scipy.stats.sem(data,axis=0)\n",
    "            mean_data_dict[col+'_mean']=data_mean\n",
    "            mean_data_dict[col+'_sem']=data_sem\n",
    "        mean_data_dict['rat']=rat_id\n",
    "        mean_data_dict['task']=task_id\n",
    "        mean_data_dict['date']=date_id\n",
    "        mean_data_dict['channel']=channel_id\n",
    "        mean_data_list.append(mean_data_dict)\n",
    "mean_df=pd.DataFrame(mean_data_list)\n",
    "mean_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "\n",
    "mean_df_melted=pd.melt(mean_df, id_vars=['rat','task','channel'], var_name='band', value_name='power')\n",
    "mean_df_melted['band name']=mean_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event']=mean_df_melted['band'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event']=mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted['type']=mean_df_melted['band'].apply(lambda x: x.split('_')[-1])\n",
    "cols = list(mean_df_melted.columns)\n",
    "cols.append(cols.pop(cols.index('power')))\n",
    "mean_df_melted = mean_df_melted[cols]\n",
    "mean_df_melted.drop(columns=['band'], inplace=True)\n",
    "mean_df_melted=mean_df_melted[mean_df_melted['band name']!= 'total'] #Remove total band if it exists\n",
    "mean_df_melted_grouped=mean_df_melted.groupby(['event'])\n",
    "writer=pd.ExcelWriter(savepath+'mean_across_trials_power_truncated.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group=group.reset_index(drop=True)\n",
    "    group.to_excel(writer, sheet_name=event[0])\n",
    "writer.close()\n",
    "arealist=['AON','vHp']\n",
    "for area in arealist:\n",
    "    fig,axs=plt.subplots(1,4,figsize=(40,10), sharey=True)\n",
    "    axs=axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig'}\n",
    "    for i,event in enumerate(events_dict.keys()):\n",
    "        ax=axs[i]\n",
    "        ## Plotting AON mean power\n",
    "        plotting_df=mean_df_melted[(mean_df_melted['channel'].str.contains(area)) & (mean_df_melted['type']=='mean') & (mean_df_melted['event']==event)] \n",
    "        # Remove outliers using the IQR method for each band name\n",
    "        def remove_outliers_iqr(df, value_col='power', group_col='band name'):\n",
    "            def iqr_filter(group):\n",
    "                q1 = group[value_col].quantile(0.25)\n",
    "                q3 = group[value_col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                lower = q1 - 1.5 * iqr\n",
    "                upper = q3 + 1.5 * iqr\n",
    "                return group[(group[value_col] >= lower) & (group[value_col] <= upper)]\n",
    "            return df.groupby(group_col, group_keys=False).apply(iqr_filter)\n",
    "\n",
    "        plotting_df = remove_outliers_iqr(plotting_df)\n",
    "        sns.boxplot(x='band name',y='power',hue='task',data=plotting_df,ax=ax, showfliers=False)\n",
    "        sns.stripplot(x='band name',y='power',hue='task',data=plotting_df,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax, color=\".3\", size=2)\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.legend(loc='upper left', fontsize=15)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2)', fontsize=25)\n",
    "        ax.set_title(f'{area} power {events_dict[event]}', fontsize=20)\n",
    "    fig.savefig(savepath+f'mean_power_across_trials_{area}_truncated.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#mean_df=pd.DataFrame(mean_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multitaper Mean across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "\n",
    "##############\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "# Apply multitaper PSD to each event column\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=1000, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000)\n",
    "    return psd\n",
    "\n",
    "event_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "power_df.loc[:, columns] = power_df.loc[:, columns].applymap(multitaper_transform)\n",
    "new_boxplot_df = power_functions.get_all_band_power_from_mt(power_df, event_list)\n",
    "#new_boxplot_df['channel'] = new_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp') #TRIAL\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task'] + '_' + new_boxplot_df['date']\n",
    "print(new_boxplot_df.columns)\n",
    "\n",
    "pre_post_cols = [col for col in new_boxplot_df.columns if ('pre' in col or 'post' in col)]\n",
    "mean_data_list = []\n",
    "\n",
    "mean_boxplot_df = new_boxplot_df.__deepcopy__()\n",
    "unique_id_list = list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list = []\n",
    "\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df = mean_boxplot_df[mean_boxplot_df['unique_id'] == unique_id]\n",
    "    unique_id_df_grouped = unique_id_df.groupby(['channel'])\n",
    "    for channel, group in unique_id_df_grouped:\n",
    "        print(channel)\n",
    "        group = group.reset_index(drop=True)\n",
    "        columns = [col for col in group.columns if 'pre' in col or 'post' in col]\n",
    "        print(columns)\n",
    "        rat_id = group['rat'].iloc[0]\n",
    "        task_id = group['task'].iloc[0]\n",
    "        date_id = group['date'].iloc[0]\n",
    "        channel_id = group['channel'].iloc[0]\n",
    "        mean_data_dict = {}\n",
    "        for col in columns:\n",
    "            data = np.array(group[col])\n",
    "            data_mean = np.mean(data, axis=0)\n",
    "            data_sem = scipy.stats.sem(data, axis=0)\n",
    "            mean_data_dict[col + '_mean'] = data_mean\n",
    "            mean_data_dict[col + '_sem'] = data_sem\n",
    "        mean_data_dict['rat'] = rat_id\n",
    "        mean_data_dict['task'] = task_id\n",
    "        mean_data_dict['date'] = date_id\n",
    "        mean_data_dict['channel'] = channel_id\n",
    "        mean_data_list.append(mean_data_dict)\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "mean_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df, value_col='power', group_col='band name'):\n",
    "    def iqr_filter(group):\n",
    "        q1 = group[value_col].quantile(0.25)\n",
    "        q3 = group[value_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        return group[(group[value_col] >= lower) & (group[value_col] <= upper)]\n",
    "    return df.groupby(group_col, group_keys=False).apply(iqr_filter)\n",
    "\n",
    "mean_df_melted = pd.melt(mean_df, id_vars=['rat', 'task', 'channel'], var_name='band', value_name='power')\n",
    "mean_df_melted['band name'] = mean_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event'] = mean_df_melted['band'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event'] = mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted['type'] = mean_df_melted['band'].apply(lambda x: x.split('_')[-1])\n",
    "cols = list(mean_df_melted.columns)\n",
    "cols.append(cols.pop(cols.index('power')))\n",
    "mean_df_melted = mean_df_melted[cols]\n",
    "mean_df_melted.drop(columns=['band'], inplace=True)\n",
    "#mean_df_melted=mean_df_melted[mean_df_melted['band name']!= 'total'] #Remove total band if it exists\n",
    "mean_df_melted_grouped = mean_df_melted.groupby(['event'])\n",
    "\n",
    "writer_mt = pd.ExcelWriter(savepath + f'pow_events_perband_{int(time_window*fs/2)}ms.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group = group.reset_index(drop=True)\n",
    "    group.to_excel(writer_mt, sheet_name=event[0])\n",
    "writer_mt.close()\n",
    "arealist = ['AON', 'vHp']\n",
    "fig = plt.figure(figsize=(40, 20), layout='constrained')\n",
    "fig.suptitle('Power per band (Multitaper)', fontsize=30)\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for area_num,area in enumerate(arealist):\n",
    "    axs = subfigs[area_num].subplots(nrows=1, ncols=4, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict = {'pre_door': 'Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        ax = axs[i]\n",
    "        plotting_df = mean_df_melted[\n",
    "            (mean_df_melted['channel'].str.contains(area)) &\n",
    "            (mean_df_melted['type'] == 'mean') &\n",
    "            (mean_df_melted['event'] == event)\n",
    "        ]\n",
    "\n",
    "        plotting_df = remove_outliers_iqr(plotting_df) ## REMOVE OUTLIERS\n",
    "        band_order = ['theta', 'beta', 'gamma','total']\n",
    "        sns.barplot(x='band name', y='power', hue='task', data=plotting_df, order=band_order, ax=ax)\n",
    "        sns.stripplot(x='band name', y='power', hue='task', data=plotting_df, order=band_order, dodge=True, palette=colors, jitter=True, legend=False, ax=ax, linewidth=1, alpha=0.8)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "        ax.legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        #ax.legend(loc='upper left', fontsize=15)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (mV^2)', fontsize=25)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.set_title(f'{area} power {events_dict[event]}', fontsize=20)\n",
    "fig.savefig(savepath + f'pow_events_perband_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Power using MNE Epochs [NOT MEAN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "test_epoch = con_data_df_clean['mne_epoch_dig_before'].iloc[0]\n",
    "test_epoch_array=test_epoch.get_data()\n",
    "print(test_epoch_array.shape)\n",
    "test_epoch_psd = test_epoch.compute_psd(method='multitaper', fmin=0, fmax=100, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000, exclude=['Ref'])\n",
    "print(test_epoch_psd.get_data().shape)\n",
    "\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=1000, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000)\n",
    "    return psd\n",
    "\n",
    "single_data = test_epoch_array[0,0,:]\n",
    "psd_single_data = multitaper_transform(single_data)\n",
    "\n",
    "print(test_epoch_psd.get_data()[0,0,:])\n",
    "print(psd_single_data)\n",
    "\n",
    "\n",
    "mne_psd_array=test_epoch_psd.get_data()\n",
    "mne_psd_array_mean=np.mean(mne_psd_array, axis=0)\n",
    "\n",
    "# Create dataframe with channel names and PSD arrays\n",
    "mne_psd_array_df = pd.DataFrame({\n",
    "    'channel': test_epoch_psd.ch_names,\n",
    "    'pre_dig': list(mne_psd_array_mean),\n",
    "    'rat_id':'dk3'\n",
    "})\n",
    "\n",
    "new_boxplot_df = power_functions.get_all_band_power_from_mt(mne_psd_array_df, ['pre_dig'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Power using MNE Epochs [USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "event_list = ['mne_epoch_door_before', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "# Define frequency bands\n",
    "freq_bands = {\n",
    "        'theta': (4, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 80),\n",
    "        'total': (0, 100),\n",
    "}\n",
    "\n",
    "def calculate_band_power(psd, freqs, fmin, fmax):\n",
    "    \"\"\"Calculate average power in a frequency band\"\"\"\n",
    "    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    if np.sum(freq_mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(psd[freq_mask])\n",
    "\n",
    "print(con_data_df_clean.columns)\n",
    "\n",
    "# Dictionary to store dataframes for each event\n",
    "event_dataframes = {event: [] for event in event_list}\n",
    "\n",
    "for i in range(len(con_data_df_clean)):\n",
    "    rat = con_data_df_clean.loc[i, 'rat_id']\n",
    "    task = con_data_df_clean.loc[i, 'task']\n",
    "    date = con_data_df_clean.loc[i, 'date']\n",
    "    \n",
    "    print(f\"Processing rat {rat}, task {task}, date {date} ({i+1}/{len(con_data_df_clean)})\")\n",
    "    \n",
    "    for event in event_list:\n",
    "        test_epoch = con_data_df_clean.loc[i, event]\n",
    "        \n",
    "        # Compute PSD\n",
    "        test_epoch_psd = test_epoch.compute_psd(\n",
    "            method='multitaper', \n",
    "            fmin=0, \n",
    "            fmax=100, \n",
    "            adaptive=True, \n",
    "            bandwidth=6, \n",
    "            normalization='full', \n",
    "            verbose=0,\n",
    "            exclude=['Ref']\n",
    "        )\n",
    "        \n",
    "        # Get PSD data and frequencies\n",
    "        psd_array = test_epoch_psd.get_data()\n",
    "        freqs = test_epoch_psd.freqs\n",
    "        channel_names = test_epoch_psd.ch_names\n",
    "        \n",
    "        # Create rows with band power\n",
    "        band_rows = []\n",
    "        for trial in range(psd_array.shape[0]):\n",
    "            for ch_idx, channel in enumerate(channel_names):\n",
    "                psd = psd_array[trial, ch_idx, :]\n",
    "                \n",
    "                # Calculate power for each frequency band\n",
    "                for band_name, (fmin, fmax) in freq_bands.items():\n",
    "                    power = calculate_band_power(psd, freqs, fmin, fmax)\n",
    "                    \n",
    "                    band_rows.append({\n",
    "                        'rat': rat,\n",
    "                        'date': date,\n",
    "                        'task': task,\n",
    "                        'trial_num': trial,\n",
    "                        'channel': channel,\n",
    "                        'band': band_name,\n",
    "                        'power': power\n",
    "                    })\n",
    "        \n",
    "        # Add to the event's dataframe list\n",
    "        event_dataframes[event].extend(band_rows)\n",
    "\n",
    "# Combine all rows for each event into dataframes\n",
    "print(\"\\nCreating final dataframes...\")\n",
    "final_dfs = {}\n",
    "for event in event_list:\n",
    "    df = pd.DataFrame(event_dataframes[event])\n",
    "    final_dfs[event] = df\n",
    "    print(f\"{event}: {len(df)} rows\")\n",
    "\n",
    "# Save to Excel with multiple sheets\n",
    "excel_filename = savepath + f'pow_events_perband_pertrial_{int(time_window*fs/2)}ms.xlsx'\n",
    "print(f\"\\nSaving to {excel_filename}...\")\n",
    "\n",
    "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "    for event, df in final_dfs.items():\n",
    "        # Clean up sheet name (Excel has 31 char limit)\n",
    "        sheet_name = event.replace('mne_epoch_', '')[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Saved sheet: {sheet_name} ({len(df)} rows)\")\n",
    "\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "# Display sample from each dataframe\n",
    "for event, df in final_dfs.items():\n",
    "    print(f\"\\n{event} - First 10 rows:\")\n",
    "    print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a mean across channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_boxplot_df=boxplot_df.__deepcopy__()\n",
    "unique_id_list=list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list=[]\n",
    "sem_data_list=[]\n",
    "mean_boxplot_df['channel']=mean_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "mean_boxplot_df_grouped=mean_boxplot_df.groupby(['task', 'channel', 'trial'])\n",
    "for (task, channel, trial), group in mean_boxplot_df_grouped:\n",
    "    print(task, channel, trial)\n",
    "    group=group.reset_index(drop=True)\n",
    "    columns=group.columns[-21:-1]\n",
    "    data_array=np.array(group[columns])\n",
    "    data_mean=np.mean(data_array, axis=0)\n",
    "    data_sem=scipy.stats.sem(data_array, axis=0)\n",
    "    print(data_mean)\n",
    "    print(data_sem)\n",
    "    mean_data_dict = {col: data_mean[idx] for idx, col in enumerate(columns)}\n",
    "    sem_data_dict = {col: data_sem[idx] for idx, col in enumerate(columns)}\n",
    "    mean_data_dict['task'] = task\n",
    "    mean_data_dict['channel'] = channel\n",
    "    mean_data_dict['trial'] = trial\n",
    "    sem_data_dict['task'] = task\n",
    "    sem_data_dict['channel'] = channel\n",
    "    sem_data_dict['trial'] = trial\n",
    "    mean_data_list.append(mean_data_dict)\n",
    "    sem_data_list.append(sem_data_dict)\n",
    "\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for task in ['BWcontext', 'BWnocontext']:\n",
    "    task_data = mean_df[(mean_df['task'] == task) & (mean_df['channel'] == 'AON')]\n",
    "    ax.plot(task_data['trial'], task_data['total_complete_trial'], label=task, marker='o')\n",
    "ax.set_xlabel('Trial Number')\n",
    "ax.set_ylabel('AON Power in total complete trial')\n",
    "ax.set_title('AON Power in total complete trial across Trials')\n",
    "ax.set_xticks(np.arange(0, 20, 1))\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean in groups of 5 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df_grouped=boxplot_df.groupby(['unique_id'])\n",
    "mean_data_list=[]\n",
    "for unique_id, group in boxplot_df_grouped:\n",
    "    print(unique_id)\n",
    "    num_of_trials=len(group['trial'].unique())\n",
    "    print(num_of_trials)\n",
    "    group=group.reset_index(drop=True)\n",
    "    print()\n",
    "    for channel in group['channel'].unique():\n",
    "        i=0\n",
    "        group_channel=group[group['channel']==channel]\n",
    "        group_channel=group_channel.reset_index(drop=True)\n",
    "        \n",
    "        while i < 16:\n",
    "            print(i)\n",
    "            group_trial = group_channel[(group_channel['trial'] >= i) & (group_channel['trial'] < i + 4)]\n",
    "            group_trial_data_array = np.array(group_trial.loc[:, 'beta_pre_door':'total_around_dig'])\n",
    "            data_mean= group_trial_data_array.mean(axis=0)\n",
    "            row = {**group_channel.iloc[0][['rat', 'task', 'channel', 'unique_id']].to_dict(),\n",
    "                   **{'trial': f'{i}-{i + 4}'},\n",
    "                   **dict(zip(group_trial.loc[:, 'beta_pre_door':'total_around_dig'].columns, data_mean))}\n",
    "            mean_data_list.append(row)\n",
    "\n",
    "            i=i+4\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "mean_df_melted=pd.melt(mean_df, id_vars=['rat','task','channel','trial', 'unique_id'], var_name='band_event', value_name='power')\n",
    "mean_df_melted['band name']=mean_df_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event']=mean_df_melted['band_event'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event']=mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted_grouped=mean_df_melted.groupby(['event'])\n",
    "writer=pd.ExcelWriter(savepath+'power_boxplot_average_per_4_trials.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group=group.reset_index(drop=True)\n",
    "    group.drop(columns=['band_event','event'], inplace=True)\n",
    "    group.to_excel(writer, sheet_name=event[0])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Power Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "\n",
    "power_spec_df = compiled_data_all_epochs.__deepcopy__()\n",
    "print(power_spec_df.iloc[0,-2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spec_df.iloc[:, -2:] = power_spec_df.iloc[:, -2:].applymap(lambda x: spectrogram(x, fs=2000, nperseg=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_spec_df.iloc[0,-2][1])\n",
    "for col in ['around_door','around_dig']:\n",
    "\n",
    "    power_spec_df[col+'_f'] = power_spec_df[col].apply(lambda x: x[0])\n",
    "    power_spec_df[col+'_t'] = power_spec_df[col].apply(lambda x: x[1])\n",
    "    power_spec_df[col+'_sxx'] = power_spec_df[col].apply(lambda x: x[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spec_df['channel'] = power_spec_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "power_spec_df_grouped = power_spec_df.groupby(['task', 'channel'])\n",
    "for (task, channel), group in power_spec_df_grouped:\n",
    "    group = group.reset_index(drop=True)\n",
    "    for col in ['around_door', 'around_dig']:\n",
    "        data = np.array(group[col + '_sxx'])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        print(data_mean.shape)\n",
    "        freq = group[col + '_f'].iloc[0]\n",
    "        time = group[col + '_t'].iloc[0]\n",
    "        time_adjusted=np.linspace(-2,2,len(time))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 10), constrained_layout=True)\n",
    "        im = ax.pcolormesh(time_adjusted, freq, data_mean, shading='gouraud', vmin=0, vmax=0.5)\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'{task} {channel} {col}')\n",
    "        ax.set_ylim(0, 100)\n",
    "        # ax.set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "        # ax.set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "        ax.vlines(0, 0, 100, color='red', linestyle='--')\n",
    "        ax.set_xlabel('Time (s)', fontsize=20)\n",
    "\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        i = i + 1\n",
    "        fig.savefig(savepath + f'power_mean_spectrogram_{task}_{channel}_{col}.png', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Coherence Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Coherence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating static data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "importlib.reload(coherence_functions)\n",
    "# --- Basic Parameters ---\n",
    "sfreq = 1000  # Sampling frequency in Hz\n",
    "n_epochs = 20  # Number of trials\n",
    "n_times = 2000  # Number of time points per trial (2 seconds of data)\n",
    "times = np.arange(n_times) / sfreq  # Time vector for one epoch\n",
    "n_signals = 3  # We'll create 3 channels\n",
    "\n",
    "# We will test connectivity in the beta band\n",
    "freq_of_interest = 20.0  # 20 Hz\n",
    "# --- Generate Data for Static Connectivity ---\n",
    "\n",
    "# Initialize data array: (n_epochs, n_signals, n_times)\n",
    "static_data = np.random.randn(n_epochs, n_signals, n_times) * 0.1  # Add background noise\n",
    "\n",
    "# Create the shared 20 Hz sine wave component\n",
    "shared_signal = np.sin(2 * np.pi * freq_of_interest * times)\n",
    "\n",
    "# Add the shared signal to the first two channels for all epochs\n",
    "static_data[:, 0, :] += shared_signal\n",
    "static_data[:, 1, :] += shared_signal\n",
    "\n",
    "print(\"Shape of static_data:\", static_data.shape)\n",
    "ch_names=['AON', 'vHp', 'PFC']  # Example channel names\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "static_data_mne=mne.EpochsArray(static_data, info)\n",
    "print(static_data_mne)\n",
    "# Plot the static_data for each channel in the first epoch\n",
    "fig, axs = plt.subplots(n_signals, 1, figsize=(12, 6), sharex=True)\n",
    "for i, ch in enumerate(ch_names):\n",
    "    axs[i].plot(times, static_data[0, i, :], label=f'Channel: {ch}')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend(loc='upper right')\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.suptitle('Static Data Example (Epoch 0)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "coherence_band_sce = coherence_functions.convert_epoch_to_coherence(static_data_mne)\n",
    "print(coherence_band_sce)\n",
    "coherence_band_time=coherence_functions.convert_epoch_to_coherence_time(static_data_mne)\n",
    "print(coherence_band_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncating LFP data and loading it into MNE arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import sys\n",
    "importlib.reload(lfp_pre_processing_functions)\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230616_dk6_BW_context_day2.mat']\n",
    "event_data_df=[]\n",
    "con_data_df=[]\n",
    "\n",
    "con_data_df_shuffled=[]\n",
    "shuffled_event_data_df=[]\n",
    "events_codes_all = {}\n",
    "random_baseline_data=[]\n",
    "baseline_lfp_all=[]\n",
    "\n",
    "time_window = 0.7\n",
    "fs= 2000\n",
    "\n",
    "files_short=[files[10]] ### TEST CHANGE THIS \n",
    "\n",
    "\n",
    "for file_num,file in enumerate(files):\n",
    "    #if 'dk1' in file:\n",
    "        \n",
    "        #print(file)\n",
    "        base_name = os.path.basename(file)\n",
    "        base_name, _ = os.path.splitext(base_name)\n",
    "\n",
    "        date, rat_id, task = lfp_pre_processing_functions.exp_params(base_name)\n",
    "        print(date, rat_id, task)\n",
    "        if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "            task = 'nocontext'\n",
    "        if task =='nocontext':\n",
    "            continue\n",
    "        # if rat_id=='dk1': #REMOVING DK1 TEMPORARLILY . PLEASE CHANGE LATER\n",
    "        #     continue\n",
    "        f = h5py.File(file, 'r')\n",
    "        channels = list(f.keys())\n",
    "        #print(channels)\n",
    "         \n",
    "        if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "            print(\"No AON or vHp channels in this file\")\n",
    "            continue\n",
    "\n",
    "        events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "        global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "        \n",
    "        ## Reference electrode finding and padding\n",
    "        reference_time = np.array(reference_electrode['times']).flatten()\n",
    "        reference_value = np.array(reference_electrode['values']).flatten()\n",
    "        padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "        events_codes = np.array(events['codes'][0])\n",
    "        events_times = np.array(events['times'][0])\n",
    "        events_codes_all[base_name] = events_codes\n",
    "        epochs = lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "        #epochs = functions.generate_specific_num_of_epochs_with_first_event(events_codes, events_times,5)\n",
    "        aon_lfp_channels=[x for x in channels if 'AON' in x ]\n",
    "        vHp_lfp_channels=[x for x in channels if 'vHp' in x ]\n",
    "        all_channels=np.concatenate((aon_lfp_channels,vHp_lfp_channels))\n",
    "        #print(all_channels)\n",
    "        \n",
    "        mne_baseline_data=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        mne_epoch_around_dig=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        \n",
    "        mne_baseline_data_shuffled=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "        mne_epoch_around_dig_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "\n",
    "        print(f'File {rat_id} {task} {date} has {len(epochs)} epochs and {len(all_channels)} channels')\n",
    "\n",
    "\n",
    "        first_event = events_times[0]\n",
    "        \n",
    "        for channel_num,channeli in enumerate(all_channels):\n",
    "            if \"AON\" in channeli or \"vHp\" in channeli:\n",
    "                channel_id = channeli\n",
    "                data_all = f[channeli]\n",
    "                raw_data = np.array(data_all['values']).flatten()\n",
    "                raw_time = np.array(data_all['times']).flatten()\n",
    "                sampling_rate = int(1 / data_all['interval'][0][0])\n",
    "                #print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "                padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "                subtracted_data = padded_data - padd_ref_data\n",
    "                raw_data=subtracted_data\n",
    "                notch_data = lfp_pre_processing_functions.iir_notch(raw_data, sampling_rate, 60) ###CHANGE notch_data to notch_filtered_data\n",
    "\n",
    "                print(notch_data.nbytes)\n",
    "                notch_data_detrended = scipy.signal.detrend(notch_data)\n",
    "                notch_filtered_data=lfp_pre_processing_functions.sosbandpass(notch_data_detrended, fs=2000, start_freq=1,end_freq=100, order=8) ###CHANGE THIS FOR NOT BANDBASS FILTERTING\n",
    "                print(notch_filtered_data.nbytes)\n",
    "                \n",
    "                data_before, time, baseline_mean, baseline_std=lfp_pre_processing_functions.baseline_data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "                first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "\n",
    "                mne_baseline_data[0,channel_num,:]=list(data_before)\n",
    "                mne_baseline_data_shuffled[0,channel_num,:]=list(np.random.permutation(data_before))\n",
    "                total = notch_filtered_data\n",
    "\n",
    "                \n",
    "                for i, epochi in enumerate(epochs):\n",
    "                    door_timestamp = epochi[0][0]\n",
    "                    trial_type = epochi[0][1]\n",
    "                    dig_type = epochi[1, 1]\n",
    "                    #print(dig_type)\n",
    "                    dig_timestamp = epochi[1, 0]\n",
    "                    #print(door_timestamp, trial_type, dig_timestamp, dig_type)\n",
    "                    data_trial_before, data_trial_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,door_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_dig_before, data_dig_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,dig_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_around_door=np.concatenate((data_trial_before, data_trial_after))\n",
    "                    data_around_dig=np.concatenate((data_dig_before, data_dig_after))\n",
    "\n",
    "                    epoch_data = [data_trial_before, data_trial_after, data_dig_before, data_dig_after, data_around_door, data_around_dig]\n",
    "                    event_data_list = [lfp_pre_processing_functions.zscore_event_data(x, baseline_std) for x in epoch_data]\n",
    "\n",
    "                    mne_epoch_door_before[i,channel_num,:]=list(event_data_list[0][-int(time_window*fs):])\n",
    "                    mne_epoch_door_after[i,channel_num,:]=list(event_data_list[1][:int(time_window*fs)])\n",
    "                    mne_epoch_dig_before[i,channel_num,:]=list(event_data_list[2][-int(time_window*fs):])\n",
    "                    mne_epoch_dig_after[i,channel_num,:]=list(event_data_list[3][:int(time_window*fs)])\n",
    "                    mid_point = int(len(event_data_list[4]) / 2)\n",
    "                    mne_epoch_around_door[i,channel_num,:]=list(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "                    mne_epoch_around_dig[i,channel_num,:]=list(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "\n",
    "                    mne_epoch_door_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[0][-int(time_window*fs):]))\n",
    "                    mne_epoch_door_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[1][:int(time_window*fs)]))\n",
    "                    mne_epoch_dig_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[2][-int(time_window*fs):]))\n",
    "                    mne_epoch_dig_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[3][:int(time_window*fs)]))\n",
    "                    mne_epoch_around_door_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "                    mne_epoch_around_dig_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "\n",
    "        if len(all_channels)>0:\n",
    "            fs=2000\n",
    "            freqs = np.arange(1,100)\n",
    "            n_cycles = freqs/3\n",
    "            info = mne.create_info(ch_names=list(all_channels), sfreq=fs, ch_types='eeg')\n",
    "            mne_baseline = mne.EpochsArray(mne_baseline_data, info)\n",
    "            mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "            mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "            mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "            mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "            mne_epoch_around_door = mne.EpochsArray(mne_epoch_around_door, info)\n",
    "            mne_epoch_around_dig = mne.EpochsArray(mne_epoch_around_dig, info)\n",
    "            \n",
    "            row_list=[file_num,date,rat_id,task,mne_baseline,mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after,mne_epoch_around_door,mne_epoch_around_dig]\n",
    "            \n",
    "            mne_baseline_shuffled = mne.EpochsArray(mne_baseline_data_shuffled, info)\n",
    "            mne_epoch_door_before_shuffled = mne.EpochsArray(mne_epoch_door_before_shuffled, info)\n",
    "            mne_epoch_door_after_shuffled = mne.EpochsArray(mne_epoch_door_after_shuffled, info)\n",
    "            mne_epoch_dig_before_shuffled = mne.EpochsArray(mne_epoch_dig_before_shuffled, info)\n",
    "            mne_epoch_dig_after_shuffled = mne.EpochsArray(mne_epoch_dig_after_shuffled, info)\n",
    "            mne_epoch_around_door_shuffled = mne.EpochsArray(mne_epoch_around_door_shuffled, info)\n",
    "            mne_epoch_around_dig_shuffled = mne.EpochsArray(mne_epoch_around_dig_shuffled, info)\n",
    "            row_list_shuffled=[file_num,date,rat_id,task,mne_baseline_shuffled,mne_epoch_door_before_shuffled,mne_epoch_door_after_shuffled,mne_epoch_dig_before_shuffled,mne_epoch_dig_after_shuffled,mne_epoch_around_door_shuffled,mne_epoch_around_dig_shuffled]\n",
    "            shuffled_event_data_df.append(row_list_shuffled)\n",
    "\n",
    "            con_data_df.append(row_list)\n",
    "            con_data_df_shuffled.append(row_list_shuffled)\n",
    "\n",
    "\n",
    "con_data_df=pd.DataFrame(con_data_df, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df.to_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "con_data_df_shuffled=pd.DataFrame(con_data_df_shuffled, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df_shuffled.to_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import signal\n",
    "\n",
    "# Before filter\n",
    "f_before, psd_before = signal.welch(notch_data, fs=2000, nperseg=1024)\n",
    "\n",
    "# After filter\n",
    "f_after, psd_after = signal.welch(notch_data_detrended, fs=2000, nperseg=1024)\n",
    "fig,axs=plt.subplots(2,1, figsize = (10,5), sharey=True)\n",
    "axs=axs.flatten()\n",
    "axs[0].semilogy(f_before, psd_before, label='Before filter')\n",
    "axs[1].semilogy(f_after, psd_after, label='After filter')\n",
    "# .xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Power Spectral Density')\n",
    "axs[0].set_xlim([0, 10])  # Focus on your filter range\n",
    "axs[1].set_xlim([0, 10])  # Focus on your filter range\n",
    "\n",
    "# plt.axvline(1, color='r', linestyle='--', label='Start freq (1 Hz)')\n",
    "# plt.axvline(100, color='g', linestyle='--', label='End freq (100 Hz)')\n",
    "# plt.legend()\n",
    "# plt.title('Frequency Domain')\n",
    "# plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Baseline Coherence Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "#con_data_df=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "baseline_df=con_data_df.__deepcopy__()\n",
    "baseline_df['mne_baseline']=baseline_df['mne_baseline'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_density(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1, 1, figsize=(10, 5), sharex=True, sharey=True)\n",
    "writer=pd.ExcelWriter(savepath+'coh_baseline_density_normalized.xlsx')\n",
    "baseline_df_grouped=baseline_df.groupby(['task'])\n",
    "task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "baseline_dict={}\n",
    "for (task, group) in baseline_df_grouped:\n",
    "    print(task[0])\n",
    "    group=group.reset_index(drop=True)\n",
    "    data = np.array(group['mne_baseline'].tolist())\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_sem = scipy.stats.sem(data, axis=0)\n",
    "    freq = np.linspace(0, 100, len(data_mean))\n",
    "    ax.plot(freq, data_mean, label=task_dict[task[0]])\n",
    "    ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_title(f'Baseline AON-vHp Coherence Density')\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Coherence (Z-transformed)')\n",
    "    ax.legend()\n",
    "    baseline_dict[f'{task[0]}_mean'] = data_mean\n",
    "    baseline_dict[f'{task[0]}_sem'] = data_sem\n",
    "baseline_dict['frequency'] = freq\n",
    "mean_df = pd.DataFrame(baseline_dict)\n",
    "mean_df.to_excel(writer, sheet_name='mean_coherence_density')\n",
    "writer.close()\n",
    "\n",
    "fig.savefig(savepath+'coh_baseline_density_normalized.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Baseline Coherence Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "baseline_df=con_data_df.__deepcopy__()\n",
    "task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "for col in ['mne_baseline']:\n",
    "    print(col)\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        baseline_df[band + '_' + col] = baseline_df[col].apply(lambda x: coherence_functions.convert_epoch_to_coherence_baseline(x, band_start=band_start, band_end=band_end))\n",
    "baseline_df.drop(columns=['mne_baseline', 'mne_epoch_door_before', 'mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'], inplace=True)\n",
    "baseline_df_melted=pd.melt(baseline_df, id_vars=['experiment','rat_id','task','date'], var_name='band', value_name='coherence')\n",
    "baseline_df_melted['band']=baseline_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "####Plotting coherence per band\n",
    "fig, axs= plt.subplots(1, 1, figsize=(20, 10), sharex=True, sharey=True)\n",
    "sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df_melted, legend=True, ax=axs)\n",
    "sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "axs.set_title('Baseline Coherence per band', fontsize=20)\n",
    "axs.set_ylabel('Coherence (Z-transformed)', fontsize=20)\n",
    "axs.set_xlabel('')\n",
    "axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, [task_dict[l] for l in labels], loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath+'coh_baseline_perband_channelpair_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "###Writing the baseline coherence per band to excel\n",
    "writer=pd.ExcelWriter(savepath+'coh_baseline_perband_channelpair_normalized.xlsx')\n",
    "baseline_df_melted.to_excel(writer)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "tanh_norm = True\n",
    "###########\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='normalized'\n",
    "else:\n",
    "    suffix = 'nonnormalized'\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "columns_to_process = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_baseline']\n",
    "baseline_df = coherence_functions.convert_baseline_to_coherence_mt_expanded(con_data_df[columns_to_process + ['rat_id', 'task']],rat_ids=con_data_df['rat_id'], tasks=con_data_df['task'],columns_to_process=['mne_baseline'], tanh_norm=tanh_norm)\n",
    "baseline_df.drop(columns=['event_type'], inplace=True)\n",
    "baseline_df.to_excel(savepath+f'coh_baseline_perband_channelpair_{suffix}.xlsx')\n",
    "\n",
    "####Plotting coherence per band\n",
    "fig, axs= plt.subplots(1, 1, figsize=(20, 10), sharex=True, sharey=True)\n",
    "sns.barplot(x='frequency_band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df, legend=True, ax=axs)\n",
    "sns.stripplot(x='frequency_band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "axs.set_title('Baseline Coherence per band', fontsize=20)\n",
    "axs.set_ylabel('Coherence (Z-transformed)', fontsize=20)\n",
    "axs.set_xlabel('')\n",
    "axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, [task_dict[l] for l in labels], loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath+f'coh_baseline_perband_channelpair_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Coherence around events [door before, door after, dig before, dig after]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AON-vHp connectivity Spectrogram from Epochs Array and Saving if as a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "def randomize_timepoints(epochs, seed=None):\n",
    "    \"\"\"Shuffle time points independently for each channel and epoch.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    data = epochs.get_data()\n",
    "    randomized_data = data.copy()\n",
    "    \n",
    "    for epoch_idx in range(randomized_data.shape[0]):\n",
    "        for channel_idx in range(randomized_data.shape[1]):\n",
    "            rng.shuffle(randomized_data[epoch_idx, channel_idx, :])\n",
    "    \n",
    "    return mne.EpochsArray(randomized_data, epochs.info, \n",
    "                          events=epochs.events, tmin=epochs.tmin)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def coherogram_pkl(time_window, fs, tanh_norm, shuffle=False):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "    if shuffle:\n",
    "        shuffled = 'shuffled'\n",
    "    else:\n",
    "        shuffled =''\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "                        \n",
    "                        if shuffle:\n",
    "                            event_epoch = randomize_timepoints(event_epoch, seed=42) ### TURN ON FOR RANDOMIZING\n",
    "\n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'coherence_spectrogram_before_after_door_dig_truncated_{}{}{}.pkl'.format(int(time_window*fs), suffix, shuffled))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "shuffle = False\n",
    "###############\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='_normalized'\n",
    "else:\n",
    "    suffix ='_non-normalized'\n",
    "\n",
    "if shuffle:\n",
    "    shuffled = '_shuffled'\n",
    "else:\n",
    "    shuffled =''\n",
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'coherence_spectrogram_before_after_door_dig_truncated_{}{}{}.pkl'.format(int(time_window*fs), suffix, shuffled))\n",
    "event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "times=np.arange(0, time_window, 1/fs)\n",
    "fig, axs=plt.subplots(2,3, figsize=(15,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Before Door','Before Dig','After Dig']\n",
    "\n",
    "writer = pd.ExcelWriter(savepath + 'coh_events_spectrogram_averaged{}_{}ms{}.xlsx'.format(suffix,int(time_window*fs/2), shuffled))\n",
    "\n",
    "\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('Time (s)')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[0,i].set_title(event_names[i])\n",
    "\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)')\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[1,i].set_title(event_names[i])\n",
    "    axs[0,0].text(-0.3, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.3, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    \n",
    "    print(all_con_data_df[event][0].shape)\n",
    "    \n",
    "    freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, all_con_data_df[event][0].shape[0])]\n",
    "    freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "    print(len(freqs))\n",
    "    time_points = [f'{np.round(t, 3)}s' for t in np.linspace(0, time_window, all_con_data_df[event][0].shape[1])]\n",
    "\n",
    "    df_context = pd.DataFrame(all_con_data_df[event][0])\n",
    "    df_context.loc[-1] = time_points  # Add time points as the first row\n",
    "    df_context.index = df_context.index + 1  # Shift index\n",
    "    df_context = df_context.sort_index()\n",
    "    df_context.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "    df_context.to_excel(writer, sheet_name=f'{event_names[i]}_Context', index=False)\n",
    "\n",
    "    df_nocontext = pd.DataFrame(all_con_data_df[event][1])\n",
    "    df_nocontext.loc[-1] = time_points  # Add time points as the first row\n",
    "    df_nocontext.index = df_nocontext.index + 1  # Shift index\n",
    "    df_nocontext = df_nocontext.sort_index()\n",
    "    df_nocontext.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "    df_nocontext.to_excel(writer, sheet_name=f'{event_names[i]}_NoContext', index=False)\n",
    "    \n",
    "    # Add a colorbar\n",
    "writer.close()\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Z-Coherence (A.U.)', fontsize=12)\n",
    "fig.savefig(savepath+f'coh_events_spectrogram_averaged{suffix}_{int(time_window*fs/2)}ms{shuffled}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Coherence around events [around door and around dig]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AON-vHp connectivity around door and dig and saving it in a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 0.4\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_pkl(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_{}.pkl'.format(int(time_window*fs)))\n",
    "\n",
    "    event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "\n",
    "\n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'coherence_spectrogram_around_door_dig_truncated_{}{}.pkl'.format(int(time_window*fs), suffix))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected range check\n",
    "print(\"Expected coherence ranges:\")\n",
    "print(\"Raw coherence: 0 to 1\")\n",
    "print(\"Fisher Z-transform: 0 to infinity (practically -3 to 3)\")\n",
    "\n",
    "# Check if your values are reasonable\n",
    "all_data = np.concatenate([all_con_data_df[event][i].flatten() \n",
    "                          for event in event_list for i in range(2)])\n",
    "\n",
    "if np.any(all_data < -5) or np.any(all_data > 5):\n",
    "    print(\"WARNING: Unusually extreme Fisher Z values detected!\")\n",
    "    print(\"Consider checking your coherence calculation.\")\n",
    "\n",
    "# Check the actual data values\n",
    "print(\"Data statistics:\")\n",
    "for event in event_list:\n",
    "    for i, task in enumerate(['Context', 'No Context']):\n",
    "        data = all_con_data_df[event][i]\n",
    "        print(f\"{task} - {event}:\")\n",
    "        print(f\"  Min: {np.min(data):.3f}\")\n",
    "        print(f\"  Max: {np.max(data):.3f}\")\n",
    "        print(f\"  Mean: {np.mean(data):.3f}\")\n",
    "        print(f\"  Std: {np.std(data):.3f}\")\n",
    "        print(f\"  Median: {np.median(data):.3f}\")\n",
    "        print(f\"  25th percentile: {np.percentile(data, 25):.3f}\")\n",
    "        print(f\"  75th percentile: {np.percentile(data, 75):.3f}\")\n",
    "\n",
    "print(f\"\\nGlobal vmin: {vmin:.3f}\")\n",
    "print(f\"Global vmax: {vmax:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence spectrogram [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window = 0.4\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "\n",
    "def plot_coherogram(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    all_con_data_df=pd.read_pickle(savepath+'coherence_spectrogram_around_door_dig_truncated_{}{}.pkl'.format(int(time_window*fs),suffix))\n",
    "    event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "    fs=2000\n",
    "    times=np.arange(-1*time_window, time_window, 1/fs)\n",
    "    fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "    vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "    vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "    event_names=['Around Door','Around Dig']\n",
    "    writer = pd.ExcelWriter(savepath + 'coh_events_spectrogram_averaged_normalized_{}{}.xlsx'.format(int(time_window*fs),suffix))\n",
    "\n",
    "    for i, event in enumerate(event_list):\n",
    "        axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                    aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        axs[0,i].set_xlabel('')\n",
    "\n",
    "        axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "        axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "        axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                    aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "        axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "        axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "        axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "        axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "        axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[0,i].set_xticks(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-ticks from -1 to 1 seconds\n",
    "        axs[0,i].set_xticklabels(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-tick labels from -1 to 1 seconds\n",
    "        axs[1,i].set_xticks(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-ticks from -1 to 1 seconds\n",
    "        axs[1,i].set_xticklabels(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-tick labels from -1 to 1 seconds\n",
    "\n",
    "        print(all_con_data_df[event][0].shape)\n",
    "        \n",
    "        freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, all_con_data_df[event][0].shape[0])]\n",
    "        freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "        print(len(freqs))\n",
    "        time_points = [f'{np.round(t, 3)}s' for t in np.linspace(-1*time_window, time_window, all_con_data_df[event][0].shape[1])]\n",
    "\n",
    "        df_context = pd.DataFrame(all_con_data_df[event][0])\n",
    "        df_context.loc[-1] = time_points  # Add time points as the first row\n",
    "        df_context.index = df_context.index + 1  # Shift index\n",
    "        df_context = df_context.sort_index()\n",
    "        df_context.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "        df_context.to_excel(writer, sheet_name=f'{event_names[i]}_Context', index=False)\n",
    "    \n",
    "        df_nocontext = pd.DataFrame(all_con_data_df[event][1])\n",
    "        df_nocontext.loc[-1] = time_points  # Add time points as the first row\n",
    "        df_nocontext.index = df_nocontext.index + 1  # Shift index\n",
    "        df_nocontext = df_nocontext.sort_index()\n",
    "        df_nocontext.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "        df_nocontext.to_excel(writer, sheet_name=f'{event_names[i]}_NoContext', index=False)\n",
    "\n",
    "    writer.close()\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Coherence', loc='center', fontsize=20, labelpad=10)\n",
    "    cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "    fig.savefig(savepath + f'\\\\aon_vhp_coherence_event_spectrogram_{int(time_window*fs)}{suffix}.png',format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_coherogram(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Coherogram for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_perexperiment_pkl(time_window, fs, tanh_norm):\n",
    "\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "\n",
    "    test_list = [con_data_df_clean.iloc[0]]\n",
    "    mean_con_data=pd.DataFrame()\n",
    "    def epoch_coherogram(epoch, fmin=1, fmax=100, fs=2000):\n",
    "            print(epoch.events.shape)\n",
    "        # if epoch.events.shape[0] < 5:\n",
    "        #     print(\"Not enough events in the epoch\")\n",
    "        #     return None\n",
    "        # else:\n",
    "            freqs = np.arange(fmin, fmax)\n",
    "            n_cycles = freqs / 3\n",
    "            con = mne_connectivity.spectral_connectivity_epochs(epoch, method='coh', sfreq=int(fs),\n",
    "                                                                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "            coh = con.get_data(output='dense')\n",
    "            indices = con.names\n",
    "            aon_vHp_con = []\n",
    "            for i in range(coh.shape[0]):\n",
    "                for j in range(coh.shape[1]):\n",
    "                    if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                        coherence= coh[i,j,:,:]\n",
    "                        if tanh_norm:\n",
    "                            coherence=np.arctanh(coherence)\n",
    "                        aon_vHp_con.append(coherence)\n",
    "            \n",
    "            mean_con = np.mean(aon_vHp_con, axis=0)\n",
    "            return mean_con\n",
    "    mean_con_data['mne_epoch_door_before'] = con_data_df_clean['mne_epoch_door_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_before'] = con_data_df_clean['mne_epoch_dig_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_after'] = con_data_df_clean['mne_epoch_dig_after'].apply(epoch_coherogram)\n",
    "\n",
    "    mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "    mean_con_data['date'] = con_data_df_clean['date']\n",
    "    mean_con_data['task'] = con_data_df_clean['task']\n",
    "    mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "    mean_con_data.dropna(inplace=True)\n",
    "    mean_con_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    mean_con_data.to_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}.pkl')\n",
    "\n",
    "coherogram_perexperiment_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "#################\n",
    "\n",
    "event_of_interest_dict = {'mne_epoch_door_before':'door_before','mne_epoch_dig_before':'dig_before','mne_epoch_dig_after':'dig_after'}\n",
    "\n",
    "event_of_interest = 'mne_epoch_dig_after'\n",
    "\n",
    "def plot_coherogram_perexperiment(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    mean_con_data=pd.read_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}.pkl')\n",
    "    vmin = mean_con_data[event_of_interest].apply(np.min).min()\n",
    "    vmax = mean_con_data[event_of_interest].apply(np.max).max()\n",
    "\n",
    "    BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "    BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "    rat_ids, rat_nums = np.unique(BWcontext_data['rat_id'], return_counts=True)\n",
    "    print(rat_ids, rat_nums)\n",
    "    rat_nums_max = rat_nums.max()\n",
    "    print(rat_nums_max)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for group_name, group_df in task_data_dict.items():\n",
    "        writer = pd.ExcelWriter(savepath + f'coh_events_spectrogram_perexp_{group_name}_{event_of_interest_dict[event_of_interest]}_{int(time_window*fs/2)}.xlsx')\n",
    "\n",
    "        print(f\"Plotting group: {group_name}\")\n",
    "        group_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "        rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "        rat_nums_max = rat_nums.max()\n",
    "\n",
    "        num_of_rows = 4 # Each row should be a rats\n",
    "        num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "        fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "        dk1_count = 0\n",
    "        dk3_count = 0\n",
    "        dk5_count = 0\n",
    "        dk6_count = 0\n",
    "        for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "            rat_id = row['rat_id']\n",
    "            data = np.array(row[event_of_interest])\n",
    "            if rat_id == 'dk1':\n",
    "                ax=axs[0, dk1_count]\n",
    "                dk1_count += 1\n",
    "            elif rat_id == 'dk3':\n",
    "                ax=axs[1, dk3_count]\n",
    "                dk3_count += 1\n",
    "            elif rat_id == 'dk5':\n",
    "                ax=axs[2, dk5_count]\n",
    "                dk5_count += 1\n",
    "            elif rat_id == 'dk6':\n",
    "                ax=axs[3, dk6_count]\n",
    "                dk6_count += 1\n",
    "            im = ax.imshow(data, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "            ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "\n",
    "            ##### Writing to excel\n",
    "\n",
    "            freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, data.shape[0])]\n",
    "            freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "            print(len(freqs))\n",
    "            time_points = [f'{np.round(t, 3)}s' for t in np.linspace(0, time_window, data.shape[1])]\n",
    "\n",
    "            df_towrite = pd.DataFrame(data)\n",
    "            df_towrite.loc[-1] = time_points  # Add time points as the first row\n",
    "            df_towrite.index = df_towrite.index + 1  # Shift index\n",
    "            df_towrite = df_towrite.sort_index()\n",
    "            df_towrite.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "            df_towrite.to_excel(writer, sheet_name=f'{group_dict[group_name]}_{rat_id}_{row[\"date\"]}', index=False)\n",
    "\n",
    "        for j in range(i + 1, len(axs)):\n",
    "            fig.delaxes(axs[j])\n",
    "        fig.suptitle(f\"{group_dict[group_name]} {suffix} {event_of_interest_dict[event_of_interest]}\", fontsize=16)\n",
    "        fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02, label=f'{suffix} Coherence(A.U.)')\n",
    "        fig.savefig(savepath + f'coh_events_spectrogram_perexp_{group_name}_{event_of_interest_dict[event_of_interest]}_{int(time_window*fs/2)}ms.png', dpi=300, bbox_inches='tight')\n",
    "        #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "        writer.close()\n",
    "plot_coherogram_perexperiment(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Coherograms of single trials [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "single_epochs_df=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "unique_id_list = single_epochs_df['unique_id'].unique()\n",
    "\n",
    "print(unique_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_list = unique_id_list[0:1]\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df = single_epochs_df[single_epochs_df['unique_id'] == unique_id]\n",
    "    trial_nums = len(unique_id_df['trial'].unique())\n",
    "    fig, axs = plt.subplots(8, trial_nums, figsize=(20, 10), sharex=True)\n",
    "    fig.suptitle(f'Unique ID: {unique_id} - AON-vHp Coherence Around Dig', fontsize=16)\n",
    "    for trial_idi in unique_id_df['trial'].unique():\n",
    "        trial_df = unique_id_df[unique_id_df['trial'] == trial_idi]\n",
    "        mne_epoch_around_dig = trial_df['around_dig'].iloc[0]\n",
    "        fmin=1\n",
    "        fmax=100\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.spectral_connectivity_epochs(mne_epoch_around_dig, method='coh', sfreq=int(fs),\n",
    "                                                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False, n_jobs=-1)\n",
    "        coh = con.get_data(output='dense')\n",
    "        indices = con.names\n",
    "        aon_vHp_con = []\n",
    "        channel_pair =0\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    coherence= coh[i,j,:,:]\n",
    "                    coherence=np.arctanh(coherence)\n",
    "                    aon_vHp_con.append(coherence)\n",
    "                    axs[channel_pair, trial_idi].imshow(coherence, extent=[-time_window, time_window, 1, 100], aspect='auto', origin='lower')\n",
    "                    if channel_pair == 0:\n",
    "                        axs[channel_pair, trial_idi].set_title(f'Trial {trial_idi}')\n",
    "                    if trial_idi == 0:\n",
    "                        axs[channel_pair, trial_idi].set_ylabel(f'{indices[i]}-{indices[j]}')\n",
    "                    channel_pair += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Coherence Boxplots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Aon-vHp connectivity per band and storing it in pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "time_window = 0.7\n",
    "fs = 2000  # Sampling frequency\n",
    "############\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "single_baseline_epoch=con_data_df_clean['mne_epoch_door_before'].iloc[0]\n",
    "theta_band=[4,8]\n",
    "\n",
    "theta_coherence=coherence_functions.convert_epoch_to_coherence_time(single_baseline_epoch)\n",
    "print(theta_coherence)\n",
    "\n",
    "print(coherence_functions.convert_epoch_to_coherence_mt(single_baseline_epoch, tanh_norm=True))\n",
    "\n",
    "\n",
    "def convert_epoch_to_coherence_mt_per_channel(epoch, tanh_norm=True, fmin=1, fmax=100, fs=2000):\n",
    "    band_dict={'beta':[12,30],'gamma':[30,80],'total':[1,100], 'theta':[4,12]}\n",
    "    coherence_dict={}\n",
    "    coherence_channel_dict={}\n",
    "    for band in band_dict.keys():\n",
    "        \n",
    "        fmin=band_dict[band][0]\n",
    "        fmax=band_dict[band][1]\n",
    "        freqs = np.arange(fmin,fmax)\n",
    "        #print(n_cycles)\n",
    "        con=mne_connectivity.spectral_connectivity_epochs(epoch, method='coh', sfreq=int(2000), fmin=fmin, fmax=fmax,faverage=True, mode='multitaper',mt_bandwidth = 2.8,mt_adaptive=True, mt_low_bias=True, verbose=False, n_jobs=-1)\n",
    "        coh = con.get_data(output='dense')\n",
    "        #print(coh)\n",
    "        indices = con.names\n",
    "        #print(indices)\n",
    "        aon_vhp_con=[]\n",
    "        print(coh.shape)\n",
    "        channel_dict={}\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                #print(i,j)\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    print('AON and vHp found')\n",
    "                    coherence = coh[i,j,:]\n",
    "                    if tanh_norm:\n",
    "                        coherence=np.arctanh(coherence)  # Convert to Fisher Z-score\n",
    "                    channel_dict[f'{indices[i]}-{indices[j]}']=coherence\n",
    "                    \n",
    "                    aon_vhp_con.append(np.mean(coherence))\n",
    "                    #print('freqs averaged',coh[i,j,0,:].shape)\n",
    "                    #print(coh[0,i,j,:])\n",
    "                else:\n",
    "                    continue\n",
    "        if aon_vhp_con==[]:\n",
    "            print('no coherence found')\n",
    "        else:\n",
    "            #print(aon_vhp_con)\n",
    "            aon_vhp_con_mean=np.mean(aon_vhp_con, axis=0)\n",
    "            #print(aon_vhp_con_mean, 'coherenece')\n",
    "            coherence_dict[band]=aon_vhp_con_mean\n",
    "            coherence_channel_dict[band]=channel_dict\n",
    "    return coherence_dict, coherence_channel_dict\n",
    "\n",
    "single_baseline_epoch=con_data_df_clean['mne_epoch_door_before'].iloc[0]\n",
    "band_coherence, channel_coherence=convert_epoch_to_coherence_mt_per_channel(single_baseline_epoch, tanh_norm=True)\n",
    "print(band_coherence)\n",
    "print(channel_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(coherence_functions)\n",
    "def epoch_coherence_channelpair_multiple(time_window, fs, tanh_norm=True):\n",
    "    \"\"\"\n",
    "    Process multiple epoch columns and return coherence DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    time_window : float\n",
    "        Time window in seconds\n",
    "    fs : int\n",
    "        Sampling frequency\n",
    "    tanh_norm : bool\n",
    "        Whether to apply Fisher Z-transformation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Coherence DataFrame with event types\n",
    "    \n",
    "    \"\"\"\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    #con_data_df_shuffled = pd.read_pickle(savepath + f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "    columns_to_process = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "    coherence_df = coherence_functions.convert_epochs_to_coherence_mt_expanded(\n",
    "        \n",
    "        con_data_df_clean[columns_to_process + ['rat_id', 'task']],  # Include necessary columns\n",
    "        con_data_df_clean['rat_id'], \n",
    "        con_data_df_clean['task'],\n",
    "        columns_to_process,\n",
    "        tanh_norm=tanh_norm\n",
    "    )\n",
    "    shuffled_coherence_df = coherence_functions.convert_epochs_to_coherence_mt_expanded(\n",
    "        con_data_df_clean[columns_to_process + ['rat_id', 'task']],  # Include necessary columns\n",
    "        con_data_df_clean['rat_id'], \n",
    "        con_data_df_clean['task'],\n",
    "        columns_to_process,\n",
    "        tanh_norm=tanh_norm,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    coherence_df.to_pickle(savepath + f'coherence_channelpair_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    shuffled_coherence_df.to_pickle(savepath + f'coherence_channelpair_shuffled_{int(time_window*fs)}_{suffix}.pkl')\n",
    "\n",
    "def plot_coherence_channelpair(time_window, fs, tanh_norm=True):\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "    coherence_df = pd.read_pickle(savepath + f'coherence_channelpair_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    shuffled_coherence_df = pd.read_pickle(savepath + f'coherence_channelpair_shuffled_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    generate_events_boxplots(time_window, fs, suffix, coherence_df)\n",
    "    generate_events_boxplots(time_window, fs, suffix+'_shuffled', shuffled_coherence_df)\n",
    "\n",
    "\n",
    "def generate_events_boxplots(time_window, fs, suffix, coherence_df):\n",
    "    event_dict = {\n",
    "        'mne_epoch_door_before': 'Door Before',\n",
    "        'mne_epoch_door_after': 'Door After',\n",
    "        'mne_epoch_dig_before': 'Dig Before',\n",
    "        'mne_epoch_dig_after': 'Dig After'\n",
    "    }\n",
    "    coherence_df['event_type'] = coherence_df['event_type'].map(event_dict)\n",
    "    \n",
    "    vmin = coherence_df['coherence'].min()\n",
    "    vmax = coherence_df['coherence'].max()\n",
    "    print(f\"Global vmin: {vmin}, vmax: {vmax}\")\n",
    "\n",
    "    event_types = coherence_df['event_type'].unique()\n",
    "    num_event_types = len(event_types)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_channelpair_{suffix}_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_event_types, figsize=(40,10), sharey=True)\n",
    "    task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "    band_order = ['theta', 'beta','theta+beta','gamma', 'total']\n",
    "    \n",
    "    for i, event_type in enumerate(event_types):\n",
    "        ax=axs[i] if num_event_types > 1 else axs\n",
    "        event_data_df_melted = coherence_df[coherence_df['event_type'] == event_type]\n",
    "        event_data_df_melted['band'] = pd.Categorical(event_data_df_melted['frequency_band'], categories=band_order, ordered=True)\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, order=band_order, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, order=band_order, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        axs[i].set_title(f'{event_type}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.drop(columns=['event_type'], inplace=True)\n",
    "        event_data_df_melted.rename(columns={'frequency_band': 'band', 'epoch_idx': 'experiment'}, inplace=True)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event_type)\n",
    "\n",
    "    writer.close()\n",
    "    plt.suptitle(f'AON-vHp Coherence per Channel Pair ({suffix})', fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.savefig(savepath + f'coh_events_perband_channelpair_{suffix}_{int(time_window*fs/2)}ms.png', dpi=300)\n",
    "    plt.show()\n",
    "# Usage example:\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "tanh_norm = True\n",
    "\n",
    "# Specify which columns to process\n",
    "\n",
    "# Process multiple columns\n",
    "epoch_coherence_channelpair_multiple(\n",
    "    time_window=time_window, \n",
    "    fs=fs, \n",
    "    tanh_norm=tanh_norm\n",
    ")\n",
    "plot_coherence_channelpair(\n",
    "    time_window=time_window, \n",
    "    fs=fs, \n",
    "    tanh_norm=tanh_norm\n",
    ")  \n",
    "\n",
    "# print(\"Coherence DataFrame shape:\", coherence_df.shape)\n",
    "# print(\"Coherence DataFrame columns:\", coherence_df.columns.tolist())\n",
    "# print(\"Sample output:\")\n",
    "# print(coherence_df.head())\n",
    "# print(\"\\nEvent types:\")\n",
    "# print(coherence_df['event_type'].unique())\n",
    "# print(\"\\nFrequency bands:\")\n",
    "# print(coherence_df['frequency_band'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "\n",
    "time_window = 1\n",
    "fs=2000\n",
    "tanh_norm = True\n",
    "##############\n",
    "\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "\n",
    "def coherence_boxplot_pkl(time_window, fs, tanh_norm):\n",
    "\n",
    "    importlib.reload(coherence_functions)\n",
    "\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "    con_data_df_clean['coherence_door_before']=con_data_df_clean['mne_epoch_door_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_door_after']=con_data_df_clean['mne_epoch_door_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_dig_before']=con_data_df_clean['mne_epoch_dig_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_dig_after']=con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean.drop(columns=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'], inplace=True)\n",
    "    con_data_df_clean.to_pickle(savepath+f'coherence_boxplot_mt_{int(fs*time_window)}_{suffix}.pkl')\n",
    "\n",
    "    con_data_df_shuffled=pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    \n",
    "    con_data_df_shuffled['coherence_door_before']=con_data_df_shuffled['mne_epoch_door_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_door_after']=con_data_df_shuffled['mne_epoch_door_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_dig_before']=con_data_df_shuffled['mne_epoch_dig_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_dig_after']=con_data_df_shuffled['mne_epoch_dig_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled.drop(columns=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'], inplace=True)\n",
    "    con_data_df_shuffled.to_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}_{suffix}.pkl')\n",
    "\n",
    "coherence_boxplot_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "\n",
    "time_window = 1\n",
    "fs=2000\n",
    "tanh_norm = True\n",
    "###################\n",
    "def plot_coherence_boxplot(time_window, fs, tanh_norm):\n",
    "    importlib.reload(coherence_functions)\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "    print(suffix)\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(savepath+f'coherence_boxplot_mt_{int(fs*time_window)}_{suffix}.pkl')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "    fig.suptitle(f'Coherence {time_window}s', fontsize=24)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms.xlsx')\n",
    "    events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "    task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "    band_order = ['theta', 'beta','theta+beta', 'gamma', 'total']\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=band_order, var_name='band', value_name='coherence')\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    fig.savefig(savepath+f'coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms.png', format='png',dpi=300, bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"Shuffled coherence boxplot per band\"\"\"\n",
    "\n",
    "\n",
    "    con_data_df_shuffled=pd.read_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}_{suffix}.pkl')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "    fig.suptitle(f'Shuffled Coherence {time_window}s', fontsize=24)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms_shuffled.xlsx')\n",
    "    events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_data = con_data_df_shuffled[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_shuffled['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_shuffled['task'].reset_index(drop=True)\n",
    "        event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=band_order, var_name='band', value_name='coherence')\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "\n",
    "        axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    fig.savefig(savepath+f'coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms_shuffled.png', format='png',dpi=300, bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coherence_boxplot(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}.pkl')\n",
    "fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer=pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_boxplot_mt_shuffled_{int(fs*time_window)}.xlsx')\n",
    "events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    event_data = con_data_df_clean[event]\n",
    "    event_data_df = pd.DataFrame(event_data.tolist())\n",
    "    event_data_df.reset_index(drop=True, inplace=True)\n",
    "    event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "    event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "    event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=['total', 'theta', 'beta', 'gamma'], var_name='band', value_name='coherence')\n",
    "    sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "    sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "    #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "    axs[i].legend(title='Task', fontsize=20, title_fontsize=20, loc='upper right')\n",
    "    \n",
    "    axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel('Coherence (A.U.)', fontsize=20)\n",
    "    else:\n",
    "        axs[i].set_ylabel('')\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Prepare data for repeated measures ANOVA\n",
    "    # Each rat_id is a subject, band is within-subject, task is between-subject\n",
    "    anova_results = {}\n",
    "    posthoc_results = {}\n",
    "\n",
    "    # Only keep rats that have both tasks for proper repeated measures\n",
    "    rats_with_both = event_data_df_melted.groupby('rat_id')['task'].nunique()\n",
    "    rats_with_both = rats_with_both[rats_with_both == 2].index.tolist()\n",
    "    filtered_df = event_data_df_melted[event_data_df_melted['rat_id'].isin(rats_with_both)]\n",
    "\n",
    "    # Pivot to wide format for repeated measures ANOVA\n",
    "    for band in ['total', 'theta', 'beta', 'gamma']:\n",
    "        band_df = filtered_df[filtered_df['band'] == band]\n",
    "        # ANOVA: repeated measures on band, between on task\n",
    "        # For each rat, we need both tasks\n",
    "        # We'll use a mixed-effects model for repeated measures\n",
    "        model = ols('coherence ~ C(task)', data=band_df).fit()\n",
    "        aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "        anova_results[band] = aov_table\n",
    "\n",
    "        # Posthoc: LSD (least significant difference) test\n",
    "        mc = MultiComparison(band_df['coherence'], band_df['task'])\n",
    "        posthoc = mc.tukeyhsd()  # Tukey is more conservative, but LSD is not directly available in statsmodels\n",
    "        posthoc_results[band] = posthoc.summary()\n",
    "        print(f\"ANOVA results for {band} band in {events_dict[event]}\")\n",
    "        print(aov_table)\n",
    "        print(f\"Posthoc (Tukey HSD) results for {band} band:\")\n",
    "        print(posthoc.summary())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherogram and Boxplots together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=2000\n",
    "for time_window in [1]:\n",
    "    for tanh_norm in [True]:\n",
    "\n",
    "        # coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherogram(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        \n",
    "        # coherence_boxplot_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherence_boxplot(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "\n",
    "        # coherogram_perexperiment_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherogram_perexperiment(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "\n",
    "        epoch_coherence_channelpair_multiple(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        plot_coherence_channelpair(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting AON-vHp connectivity separated by Bands ## [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'coherence_boxplot_per_event_per_band_single_value.pkl')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axs = axs.flatten()\n",
    "writer = pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_band_per_event.xlsx')\n",
    "\n",
    "bands = ['total', 'theta', 'beta', 'gamma']\n",
    "events = ['coherence_door_before', 'coherence_door_after', 'coherence_dig_before', 'coherence_dig_after']\n",
    "\n",
    "for i, band in enumerate(bands):\n",
    "    band_data = []\n",
    "    for event in events:\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df['event'] = event\n",
    "        event_data_df['band'] = band\n",
    "        event_data_df['coherence'] = event_data_df[band]\n",
    "        band_data.append(event_data_df[['rat_id', 'task', 'event', 'band', 'coherence']])\n",
    "    \n",
    "    band_data_df = pd.concat(band_data, ignore_index=True)\n",
    "    sns.boxplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, showfliers=False, legend=False, ax=axs[i])\n",
    "    sns.stripplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "    axs[i].set_xticklabels(['Door Before', 'Door After', 'Dig Before', 'Dig After'], rotation=0)\n",
    "    axs[i].set_title(band.capitalize())\n",
    "    axs[i].set_ylabel('Coherence')\n",
    "    axs[i].set_xlabel('')\n",
    "    band_data_df.to_excel(writer, sheet_name=band)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# Create custom legend handles and labels\n",
    "from matplotlib.lines import Line2D\n",
    "colors = {'BWnocontext': '#ff7f0e', 'BWcontext': '#1f77b4'}\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], color=colors['BWcontext'], marker='o', linestyle='', markersize=10, label='BWcontext'),\n",
    "    Line2D([0], [0], color=colors['BWnocontext'], marker='o', linestyle='', markersize=10, label='BWnocontext')\n",
    "]\n",
    "\n",
    "# Add the custom legend to the figure\n",
    "fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(1.1, 1), title='Task')\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_band_per_event.png', dpi=600)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same boxplot as above but for a single band ## [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'coherence_boxplot_per_event_per_band_single_value.pkl')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "bands = ['beta']\n",
    "events = ['coherence_door_before', 'coherence_door_after', 'coherence_dig_before', 'coherence_dig_after']\n",
    "\n",
    "for i, band in enumerate(bands):\n",
    "    band_data = []\n",
    "    for event in events:\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df['event'] = event\n",
    "        event_data_df['band'] = band\n",
    "        event_data_df['coherence'] = event_data_df[band]\n",
    "        band_data.append(event_data_df[['rat_id', 'task', 'event', 'band', 'coherence']])\n",
    "    \n",
    "    band_data_df = pd.concat(band_data, ignore_index=True)\n",
    "    sns.boxplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, showfliers=False, legend=False, ax=axs)\n",
    "    sns.stripplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "    axs.set_xticklabels(['Pre Door', 'Post Door', 'Pre Dig', 'Post Dig'], rotation=0)\n",
    "    axs.set_title(band.capitalize()+' Band Coherence between AON and vHp', fontsize=20)\n",
    "    \n",
    "    axs.set_ylabel('Coherence', fontsize=20)\n",
    "    axs.set_xlabel('Behavior Events', fontsize=20)\n",
    "    axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs.tick_params(axis='both', which='minor', labelsize=20)\n",
    "    #axs.legend(title='', fontsize=20, loc='upper right' )\n",
    "# # Create custom legend handles and labels\n",
    "from matplotlib.lines import Line2D\n",
    "colors = {'BWnocontext': '#ff7f0e', 'BWcontext': '#1f77b4'}\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], color=colors['BWcontext'], marker='o', linestyle='', markersize=10, label='Context'),\n",
    "    Line2D([0], [0], color=colors['BWnocontext'], marker='o', linestyle='', markersize=10, label='No Context')\n",
    "]\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add the custom legend to the figure\n",
    "fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(0.4, 0.95), title='', fontsize=20, ncol=1)\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_beta_band_per_event.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Based Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating phase coherograms for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "#############\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_{}.pkl'.format(int(time_window*fs)))\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "def epoch_coherogram(epoch, fmin=1, fmax=100, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        return None\n",
    "    else:\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.spectral_connectivity_epochs(epoch, method='plv', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "        coh = con.get_data(output='dense')\n",
    "        indices = con.names\n",
    "        aon_vHp_con = []\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    coherence= coh[i,j,:,:]\n",
    "                    #coherence=np.arctanh(coherence)\n",
    "                    aon_vHp_con.append(coherence)\n",
    "        \n",
    "        mean_con = np.mean(aon_vHp_con, axis=0)\n",
    "        return mean_con\n",
    "test_pli = epoch_coherogram(test_list[0]['mne_epoch_around_door'])\n",
    "plt.imshow(test_pli, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "mean_con_data['around_dig_mean_con'] = con_data_df_clean['mne_epoch_around_dig'].apply(epoch_coherogram)\n",
    "mean_con_data['around_door_mean_con'] = con_data_df_clean['mne_epoch_around_door'].apply(epoch_coherogram)\n",
    "\n",
    "mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "mean_con_data['task'] = con_data_df_clean['task']\n",
    "mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "mean_con_data['date'] = con_data_df_clean['date']\n",
    "\n",
    "mean_con_data.dropna(inplace=True)\n",
    "mean_con_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = mean_con_data['around_dig_mean_con'].apply(np.min).min()\n",
    "vmax = mean_con_data['around_dig_mean_con'].apply(np.max).max()\n",
    "\n",
    "BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for group_name, group_df in task_data_dict.items():\n",
    "    \n",
    "    rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "    rat_nums_max = rat_nums.max()\n",
    "\n",
    "    num_of_rows = 4 # Each row should be a rats\n",
    "    num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    dk1_count = 0\n",
    "    dk3_count = 0\n",
    "    dk5_count = 0\n",
    "    dk6_count = 0\n",
    "    for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "        rat_id = row['rat_id']\n",
    "        data = np.array(row['around_dig_mean_con'])\n",
    "        if rat_id == 'dk1':\n",
    "            ax=axs[0, dk1_count]\n",
    "            dk1_count += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax=axs[1, dk3_count]\n",
    "            dk3_count += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax=axs[2, dk5_count]\n",
    "            dk5_count += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax=axs[3, dk6_count]\n",
    "            dk6_count += 1\n",
    "        im = ax.imshow(data, extent=[-1*time_window, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    \n",
    "    \n",
    "    # fig, axs = plt.subplots(group_df.shape[0] // 5 + int(group_df.shape[0] % 5 != 0), 5, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    # axs = axs.flatten()\n",
    "    # for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "    #     data = np.array(row['around_dig_mean_con'])\n",
    "    #     ax = axs[i]\n",
    "    #     im = ax.imshow(data, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    #     ax.set_title(f\"{row['rat_id']} {row['experiment']}\")\n",
    "    #     ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "    #     ax.axhline(12, color='green', linestyle='--')\n",
    "    #     ax.axhline(30, color='green', linestyle='--')\n",
    "    # for j in range(i + 1, len(axs)):\n",
    "    #     fig.delaxes(axs[j])\n",
    "    fig.suptitle(f\"{group_name} AON-vHp PLV Around Dig\", fontsize=16)\n",
    "    fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    fig.savefig(savepath + f'plv_around_dig_{group_name}.png', dpi=300, bbox_inches='tight')\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average PLI around door and dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "\n",
    "all_con_data=[]\n",
    "all_con_data_mean=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "        row=[task_name]\n",
    "         #print(row)\n",
    "        row_2=[task_name]\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            aon_vHp_con=[]\n",
    "            for event_epoch in event_epoch_list:\n",
    "                    #print(row,event, event_epoch) \n",
    "                    if event_epoch.events.shape[0] <5:\n",
    "                        print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                        continue\n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    fs=2000\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/3\n",
    "                    # con= mne_connectivity.spectral_connectivity_time(event_epoch, method='coh', sfreq=int(fs), average=False,\n",
    "                    #                                      mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                    #                                      n_cycles=n_cycles, verbose=False, fmin=1, fmax=100, faverage=False)\n",
    "                    # coh = con.get_data(output='dense')\n",
    "                    # indices = con.names\n",
    "                    # print(coh.shape, indices)a\n",
    "                    # for i in range(coh.shape[0]):\n",
    "                    #     for j in range(coh.shape[1]):\n",
    "                    #         if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    #             coherence= coh[i,j,:]\n",
    "                    #             coherence=np.arctanh(coherence)\n",
    "                    #             aon_vHp_con.append(coherence)\n",
    "\n",
    "                    con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='pli', sfreq=int(fs),\n",
    "                                                         mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                         cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                    coh = con.get_data(output='dense')\n",
    "                    indices = con.names\n",
    "                    \n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                coherence= coh[i,j,:,:]\n",
    "                                #coherence=np.arctanh(coherence)\n",
    "                                aon_vHp_con.append(coherence)\n",
    "            row.append(np.mean(aon_vHp_con, axis=0))\n",
    "            row_2.append(np.mean(aon_vHp_con))\n",
    "        all_con_data.append(row)                    \n",
    "        all_con_data_mean.append(row_2)\n",
    "# Convert all_con_data to a DataFrame for easier manipulation\n",
    "all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "all_con_data_df.to_pickle(savepath+'pli_coherogram_around_door_dig_truncated.pkl')\n",
    "fs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'pli_coherogram_around_door_dig_truncated.pkl')\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "fig.suptitle('AON-vHp Phase Lag Index Around Door and Dig', fontsize=20)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=0, vmax=1)\n",
    "    axs[0,i].set_xlabel('')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].hlines(12, times[0], times[-1], color='green', linestyle='--')\n",
    "    axs[0,i].hlines(30, times[0], times[-1], color='green', linestyle='--')\n",
    "    \n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=0, vmax=1)\n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[1,i].hlines(12, times[0], times[-1], color='green', linestyle='--')\n",
    "    axs[1,i].hlines(30, times[0], times[-1], color='green', linestyle='--')\n",
    "    \n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    # axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('PLI', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_pli_coherogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Slope Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "#epoch_psi(epoch, fmin=1, fmax=100, fs=2000):\n",
    "def epoch_psi(epoch, fmin, fmax, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    aon_indices = [i for i, ch in enumerate(epoch.ch_names) if 'AON' in ch]\n",
    "    vHp_indices = [i for i, ch in enumerate(epoch.ch_names) if 'vHp' in ch]\n",
    "    indices = mne_connectivity.seed_target_indices(aon_indices, vHp_indices)\n",
    "\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        # Return empty arrays or np.nan to avoid TypeError\n",
    "        return [], []\n",
    "    else:\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.phase_slope_index(\n",
    "            epoch, indices=indices, sfreq=int(fs),\n",
    "            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax\n",
    "        )\n",
    "        coh = con.get_data()\n",
    "        print(coh.shape)\n",
    "        indices = con.names\n",
    "\n",
    "        mean_con = np.mean(coh, axis=0)\n",
    "        mean_con = list(mean_con[0, :])\n",
    "        all_cons = np.array([coh[i, 0, :] for i in range(coh.shape[0])])\n",
    "        return mean_con, all_cons\n",
    "\n",
    "epoch = test_list[0]['mne_epoch_around_door']\n",
    "mean_con, all_cons = epoch_psi(epoch, fmin=12, fmax=30, fs=2000)\n",
    "\n",
    "def generate_simulated_epoch(n_channels=4, n_times=2000, n_events=10, sfreq=2000):\n",
    "    ch_names = ['AON_1', 'AON_2', 'vHp_1', 'vHp_2']\n",
    "    ch_types = ['eeg'] * n_channels\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    data = np.random.randn(n_events, n_channels, n_times)  # Random data for simulation\n",
    "    events = np.array([[i, 0, 1] for i in range(n_events)])  # Dummy events\n",
    "    epoch = mne.EpochsArray(data, info, events)\n",
    "    return epoch\n",
    "\n",
    "simulated_epoch = generate_simulated_epoch()\n",
    "mean_con, all_cons = epoch_psi(simulated_epoch)\n",
    "plt.plot(mean_con)\n",
    "\n",
    "psi_data_df = pd.DataFrame()\n",
    "psi_data_df['around_dig_mean_con'], psi_data_df['around_dig_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_dig'].apply(epoch_psi))\n",
    "psi_data_df['around_door_mean_con'], psi_data_df['around_door_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_door'].apply(epoch_psi))\n",
    "psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "psi_data_df['task'] = con_data_df_clean['task']\n",
    "psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "psi_data_df.dropna(inplace=True)\n",
    "psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0) & psi_data_df['around_door_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "psi_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "BWcontext_data = psi_data_df[(psi_data_df['task'] == 'BWcontext')]\n",
    "BWnocontext_data = psi_data_df[(psi_data_df['task'] == 'BWnocontext')]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_mean_con'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_mean_con'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='orange', alpha=0.3)\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='blue', alpha=0.3)\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a cumulative figure with all bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "##############\n",
    "\n",
    "\n",
    "bands_list =[(4,8), (12,30), (30,80)]  # Theta, Beta, Gamma\n",
    "band_names = ['theta', 'beta', 'gamma']\n",
    "\n",
    "real_con_data = pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "shuffled_con_data = pd.read_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "def clean_and_merge_data(psi_data_df, con_data_df_clean):\n",
    "    psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "    psi_data_df['task'] = con_data_df_clean['task']\n",
    "    psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "    psi_data_df.dropna(inplace=True)\n",
    "    #psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "    psi_data_df.reset_index(drop=True, inplace=True)\n",
    "    return psi_data_df\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(60, 10), sharey='row', sharex=True)\n",
    "fig.suptitle('AON-vHp Phase Slope Index Around Dig', fontsize=24)\n",
    "for band_idx, (fmin, fmax) in enumerate(bands_list):\n",
    "    print(f\"Processing band: {band_names[band_idx]} ({fmin}-{fmax} Hz)\")\n",
    "    real_data_psi = pd.DataFrame()\n",
    "    real_data_psi['around_dig_mean_con'], real_data_psi['around_dig_all_cons'] = zip(*real_con_data['mne_epoch_around_dig'].apply(lambda x: epoch_psi(x, fmin=fmin, fmax=fmax)))\n",
    "\n",
    "    shuffled_data_psi = pd.DataFrame()\n",
    "    shuffled_data_psi['around_dig_mean_con'], shuffled_data_psi['around_dig_all_cons'] = zip(*shuffled_con_data['mne_epoch_around_dig'].apply(lambda x: epoch_psi(x, fmin=fmin, fmax=fmax)))\n",
    "\n",
    "    real_data_psi = clean_and_merge_data(real_data_psi, real_con_data)\n",
    "    shuffled_data_psi = clean_and_merge_data(shuffled_data_psi, shuffled_con_data)\n",
    "\n",
    "    for i, data in enumerate([real_data_psi, shuffled_data_psi]):\n",
    "        print(f\"Processing {'real' if i == 0 else 'shuffled'} data\")\n",
    "        BWcontext_data = data[(data['task'] == 'BWcontext')]\n",
    "        BWnocontext_data = data[(data['task'] == 'BWnocontext')]\n",
    "        \n",
    "        bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "        bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "        bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "        bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "        bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "        bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "        \n",
    "        ax = axs[band_idx, i]\n",
    "        ax.plot(times, bwnocontext_mean, label=' No Context', color='grey')\n",
    "        ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='grey', alpha=0.3)\n",
    "        ax.plot(times, bwcontext_mean, label='Context', color='black')\n",
    "        ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='black', alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f'{band_names[band_idx].capitalize()} {\"Real\" if i == 0 else \"Shuffled\"}', fontsize=16)\n",
    "        ax.axhline(0, color='blue', linestyle='--')\n",
    "        ax.axvline(0, color='red', linestyle='-', linewidth=2)\n",
    "        if band_idx == 2:\n",
    "            ax.set_xlabel('Time (s)', fontsize=14)\n",
    "        else:\n",
    "            ax.set_xlabel('')\n",
    "        ax.set_ylabel('Phase Slope Index', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, loc='upper left', fontsize=12)\n",
    "        \n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig_bands_real_vs_shuffled.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSI for each frequency point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(type(low_fs), low_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "#epoch_psi(epoch, fmin=1, fmax=100, fs=2000):\n",
    "def epoch_psi(epoch, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    aon_indices = [i for i, ch in enumerate(epoch.ch_names) if 'AON' in ch]\n",
    "    vHp_indices = [i for i, ch in enumerate(epoch.ch_names) if 'vHp' in ch]\n",
    "    indices = mne_connectivity.seed_target_indices(aon_indices, vHp_indices)\n",
    "    print(indices)\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        # Return empty arrays or np.nan to avoid TypeError\n",
    "        return [], []\n",
    "    else:\n",
    "        low_fs = np.arange(1, 100,1)\n",
    "        high_fs = np.arange(2, 101,1)\n",
    "        \n",
    "        for bandi,(fmin, fmax) in enumerate(zip(low_fs, high_fs)):\n",
    "            \n",
    "            print(f\"{bandi}:Processing frequency band: {fmin}-{fmax} Hz\")\n",
    "            freqs = np.arange(fmin, fmax)\n",
    "            n_cycles = freqs / 3\n",
    "            con = mne_connectivity.phase_slope_index(\n",
    "                epoch, indices=indices, sfreq=int(fs),\n",
    "                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax\n",
    "            )\n",
    "            coh = con.get_data()\n",
    "            print(coh.shape)\n",
    "            indices = con.names\n",
    "\n",
    "            # mean_con = np.mean(coh, axis=0)\n",
    "            # mean_con = list(mean_con[0, :])\n",
    "            # all_cons = np.array([coh[i, 0, :] for i in range(coh.shape[0])])\n",
    "#    return mean_con, all_cons\n",
    "\n",
    "epoch = test_list[0]['mne_epoch_around_door']\n",
    "epoch_psi(epoch, fs=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_simulated_epoch(n_channels=4, n_times=2000, n_events=10, sfreq=2000):\n",
    "    ch_names = ['AON_1', 'AON_2', 'vHp_1', 'vHp_2']\n",
    "    ch_types = ['eeg'] * n_channels\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    data = np.random.randn(n_events, n_channels, n_times)  # Random data for simulation\n",
    "    events = np.array([[i, 0, 1] for i in range(n_events)])  # Dummy events\n",
    "    epoch = mne.EpochsArray(data, info, events)\n",
    "    return epoch\n",
    "\n",
    "simulated_epoch = generate_simulated_epoch()\n",
    "mean_con, all_cons = epoch_psi(simulated_epoch)\n",
    "plt.plot(mean_con)\n",
    "\n",
    "psi_data_df = pd.DataFrame()\n",
    "psi_data_df['around_dig_mean_con'], psi_data_df['around_dig_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_dig'].apply(epoch_psi))\n",
    "psi_data_df['around_door_mean_con'], psi_data_df['around_door_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_door'].apply(epoch_psi))\n",
    "psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "psi_data_df['task'] = con_data_df_clean['task']\n",
    "psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "psi_data_df.dropna(inplace=True)\n",
    "psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0) & psi_data_df['around_door_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "psi_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "BWcontext_data = psi_data_df[(psi_data_df['task'] == 'BWcontext')]\n",
    "BWnocontext_data = psi_data_df[(psi_data_df['task'] == 'BWnocontext')]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_mean_con'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_mean_con'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='orange', alpha=0.3)\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='blue', alpha=0.3)\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=test_list[0]['mne_epoch_around_door']\n",
    "epoch.ch_names\n",
    "\n",
    "print(aon_indices, vHp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_con_data['around_dig_mean_con'] = con_data_df_clean['mne_epoch_around_dig'].apply(epoch_coherogram)\n",
    "mean_con_data['around_door_mean_con'] = con_data_df_clean['mne_epoch_around_door'].apply(epoch_coherogram)\n",
    "\n",
    "mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "mean_con_data['task'] = con_data_df_clean['task']\n",
    "mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "mean_con_data.dropna(inplace=True)\n",
    "mean_con_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference in coherence between BWContext and BWnOContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_con_data_df_net=all_con_data_df.__deepcopy__()\n",
    "all_con_data_df_net.set_index('task', inplace=True)\n",
    "all_con_data_df_net.loc['difference'] = all_con_data_df_net.loc['BWcontext'] - all_con_data_df_net.loc['BWnocontext']\n",
    "all_con_data_df_net.reset_index(inplace=True)\n",
    "\n",
    "fs=2000\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "times=np.arange(-2, 2, 1/fs)\n",
    "fig, axs=plt.subplots(1,2, figsize=(20,10), sharey=True)\n",
    "fig.suptitle('Difference in Coherence between BW Context and BW No Context')\n",
    "axs=axs.flatten()\n",
    "vmin = all_con_data_df_net[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df_net[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[i].imshow(all_con_data_df_net[event][2], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_xlabel('Time (s)')\n",
    "    axs[i].set_ylabel('Frequency (Hz)')\n",
    "    axs[i].set_title(event_names[i])\n",
    "    axs[i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "cbar = fig.colorbar(axs[0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_coherence_event_spectrogram.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Difference manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "\n",
    "\n",
    "for row in con_data_df_clean.itertuples(index=False):\n",
    "    experiment = row.experiment\n",
    "    rat_id = row.rat_id\n",
    "    task = row.task\n",
    "    mne_epoch = row.mne_epoch_door_before\n",
    "    data_around_dig = row.mne_epoch_around_dig\n",
    "    data_before_dig = row.mne_epoch_dig_before\n",
    "    data_after_dig = row.mne_epoch_dig_after\n",
    "    data_before_door = row.mne_epoch_door_before\n",
    "    data_after_door = row.mne_epoch_door_after\n",
    "\n",
    "    event_of_interest = data_before_dig ### CHANGE THIS TO THE DESIRED EVENT\n",
    "\n",
    "    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "    print(event_of_interest.get_data().shape)  # Should be (n_epochs, n_channels,n_times)\n",
    "    single_data = event_of_interest.get_data()[0, 0, :]  # Get data for the first channel\n",
    "    print(single_data.shape)  # Should be (n_times,)\n",
    "    fs=2000\n",
    "    l_freq =12\n",
    "    h_freq = 30\n",
    "    iir_filter = mne.filter.create_filter(single_data, sfreq=fs,l_freq=l_freq, h_freq=h_freq, method='iir', verbose=False)\n",
    "    event_of_interest.filter(l_freq=l_freq, h_freq=h_freq, method='iir', iir_params=iir_filter, verbose=False)\n",
    "    event_of_interest.apply_hilbert(envelope=False, n_jobs=1, verbose=False)\n",
    "\n",
    "    aon_indices = [i for i, ch in enumerate(event_of_interest.ch_names) if 'AON' in ch]\n",
    "    vhp_indices = [i for i, ch in enumerate(event_of_interest.ch_names) if 'vHp' in ch]\n",
    "    aon_channels = [event_of_interest.ch_names[i] for i in aon_indices]\n",
    "    vhp_channels = [event_of_interest.ch_names[i] for i in vhp_indices]\n",
    "    print(aon_indices, vhp_indices, aon_channels, vhp_channels)\n",
    "    aon_vhp_pairs = [(aon_ch, vhp_ch) for aon_ch in aon_channels for vhp_ch in vhp_channels]\n",
    "    print(aon_vhp_pairs)\n",
    "    num_of_cols = event_of_interest.get_data().shape[0]\n",
    "    num_of_rows = len(aon_vhp_pairs)\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_cols, subplot_kw={'projection': 'polar'},figsize=(40, 10))\n",
    "    fig.suptitle(f'AON-vHp Phase Difference Around Dig for Rat: {rat_id}, Experiment: {experiment}, Task: {task}', fontsize=20)\n",
    "    for i, (aon_ch, vhp_ch) in enumerate(aon_vhp_pairs):\n",
    "        for j in range(num_of_cols):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_xticklabels([])          # remove theta labels\n",
    "            ax.set_yticklabels([])          # remove radial labels\n",
    "            # or hide ticks entirely:\n",
    "            #ax.xaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticks([])\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'{aon_ch} - {vhp_ch}', fontsize=10)\n",
    "            aon_index = aon_indices[aon_channels.index(aon_ch)]\n",
    "            vhp_index = vhp_indices[vhp_channels.index(vhp_ch)]\n",
    "            aon_epoch_data = np.angle(event_of_interest.get_data()[j,aon_index, :])\n",
    "            vhp_epoch_data = np.angle(event_of_interest.get_data()[j,vhp_index, :])\n",
    "            #print(aon_index, vhp_index, aon_epoch_data.shape, vhp_epoch_data.shape)\n",
    "            phase_diff = aon_epoch_data - vhp_epoch_data\n",
    "            ispc = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "            pli = abs(np.mean(np.sign(np.imag(np.exp(1j * phase_diff)))))\n",
    "            phase_diff_wrapped = np.mod(phase_diff, 2 * np.pi)\n",
    "            ax.hist(phase_diff_wrapped, bins=50, color='red', alpha=0.7, density=True)\n",
    "            if i== 0:\n",
    "                ax.set_title(f'trial {j}\\nispc:{ispc:.2f} pli:{pli:.2f}', fontsize=10)\n",
    "            else:\n",
    "                ax.set_title(f'ispc:{ispc:.2f} pli:{pli:.2f}', fontsize=10)\n",
    "    fig.savefig(savepath + f'{task}_{rat_id}_{experiment}_phase_difference_aon_vhp_before_dig.png', dpi=100, bbox_inches='tight')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GC measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "##############\n",
    "\n",
    "\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "#con_data_df=pd.DataFrame(con_data_df, columns=['rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after',\n",
    "                                               #'mne_epoch_dig_before','mne_epoch_dig_after', 'mne_epoch_around_door', 'mne_epoch_around_dig'])\n",
    "\n",
    "def calculate_net_gc(mne_data):\n",
    "        \n",
    "        mne_data=mne_data.resample(500)\n",
    "        \n",
    "        aon_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(aon_signals)\n",
    "        vhp_signals=[\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "            if \"vHp\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(vhp_signals)\n",
    "\n",
    "        indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "        indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "        print(\"indices_aon_vhp:\", indices_aon_vhp, \"indices_vhp_aon:\", indices_vhp_aon)\n",
    "        gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "        mne_data,\n",
    "        method=[\"gc\"],\n",
    "        indices=indices_aon_vhp,\n",
    "        fmin=2.5,\n",
    "        fmax=100,\n",
    "        rank=None,\n",
    "        gc_n_lags=50,\n",
    "        )\n",
    "        freqs = gc_ab.freqs\n",
    "\n",
    "        gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "            mne_data,\n",
    "            method=[\"gc\"],\n",
    "            indices=indices_vhp_aon,\n",
    "            fmin=2.5,\n",
    "            fmax=100,\n",
    "            rank=None,\n",
    "            gc_n_lags=50,\n",
    "        )\n",
    "        freqs = gc_ba.freqs\n",
    "\n",
    "        net_gc = gc_ab.get_data() - gc_ba.get_data()\n",
    "        return gc_ab.get_data()[0], gc_ba.get_data()[0],net_gc[0], freqs\n",
    "\n",
    "def calculate_gc_indch(mne_data):\n",
    "    mne_data = mne_data.resample(500)\n",
    "\n",
    "    aon_signals = [\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "    vhp_signals = [\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for aon_idx in aon_signals:\n",
    "        for vhp_idx in vhp_signals:\n",
    "            indices_aon_vhp = (np.array([[aon_idx]]), np.array([[vhp_idx]]))\n",
    "            indices_vhp_aon = (np.array([[vhp_idx]]), np.array([[aon_idx]]))\n",
    "            print(\"indices_aon_vhp:\", indices_aon_vhp, \"indices_vhp_aon:\", indices_vhp_aon)\n",
    "            gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "                mne_data,\n",
    "                method=[\"gc\"],\n",
    "                indices=indices_aon_vhp,\n",
    "                fmin=2.5,\n",
    "                fmax=100,\n",
    "                rank=None,\n",
    "                gc_n_lags=50,\n",
    "            )\n",
    "            gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "                mne_data,\n",
    "                method=[\"gc\"],\n",
    "                indices=indices_vhp_aon,\n",
    "                fmin=2.5,\n",
    "                fmax=100,\n",
    "                rank=None,\n",
    "                gc_n_lags=50,\n",
    "            )\n",
    "            freqs = gc_ab.freqs\n",
    "            net_gc = gc_ab.get_data()[0] - gc_ba.get_data()[0]\n",
    "\n",
    "            aon_ch = mne_data.info[\"chs\"][aon_idx][\"ch_name\"]\n",
    "            vhp_ch = mne_data.info[\"chs\"][vhp_idx][\"ch_name\"]\n",
    "\n",
    "            results.append({\n",
    "                \"channelpair\": (aon_ch, vhp_ch),\n",
    "                \"gc_aon_vhp\": gc_ab.get_data()[0],\n",
    "                \"gc_vhp_aon\": gc_ba.get_data()[0],\n",
    "                \"net_gc\": net_gc,\n",
    "                \"freqs\": freqs\n",
    "            })\n",
    "    return results\n",
    "\n",
    "test_mne = con_data_df_clean.iloc[0]['mne_epoch_dig_after']\n",
    "test_netgc = calculate_net_gc(test_mne)\n",
    "test_indch = calculate_gc_indch(test_mne)\n",
    "print(test_indch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc_columns = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before', 'mne_epoch_dig_after', 'mne_epoch_around_door', 'mne_epoch_around_dig']\n",
    "\n",
    "aon_vhp_gc_results = []\n",
    "vhp_aon_gc_results = []\n",
    "net_gc_results = []\n",
    "\n",
    "for idx, row in con_data_df_clean.iterrows():\n",
    "\n",
    "    for col in gc_columns:\n",
    "        gc_list = calculate_gc_indch(row[col])\n",
    "\n",
    "        for pair_idx, gc_dict in enumerate(gc_list):\n",
    "            aon_vhp_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['gc_aon_vhp'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "            vhp_aon_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['gc_vhp_aon'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "            net_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['net_gc'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "        # aon_vhp_gc_results.append(row_result_aon_vhp)\n",
    "        # vhp_aon_gc_results.append(row_result_vhp_aon)\n",
    "        # net_gc_results.append(row_result_net_gc)\n",
    "\n",
    "# Convert to DataFrames\n",
    "aon_vhp_gc_df = pd.DataFrame(aon_vhp_gc_results)\n",
    "vhp_aon_gc_df = pd.DataFrame(vhp_aon_gc_results)\n",
    "net_gc_df = pd.DataFrame(net_gc_results)\n",
    "\n",
    "# Expand the DataFrame so each AON-vHp channel pair has its own column for each epoch type\n",
    "\n",
    "# Example: save to disk\n",
    "aon_vhp_gc_df.to_pickle(savepath + f'vhp_aon_gc_shuffled.pkl')\n",
    "vhp_aon_gc_df.to_pickle(savepath + f'aon_vhp_gc_shuffled.pkl')\n",
    "net_gc_df.to_pickle(savepath + f'net_gc_shuffled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "aon_vhp_gc_df=pd.read_pickle(savepath + f'aon_vhp_gc.pkl')\n",
    "vhp_aon_gc_df=pd.read_pickle(savepath + f'vhp_aon_gc.pkl')\n",
    "net_gc_df=pd.read_pickle(savepath + f'net_gc.pkl')\n",
    "\n",
    "def calculate_gc_per_band(gc_array,freqs_array, bands_dict):\n",
    "    freqs_array = np.array(freqs_array)  # Convert freqs_array to numpy array\n",
    "    print(len(gc_array))\n",
    "    gc_bands_dict={}\n",
    "    for band in bands_dict.keys():\n",
    "        band_indices=np.where((freqs_array>=bands_dict[band][0]) & (freqs_array<=bands_dict[band][1]))\n",
    "        gc_band=gc_array[band_indices]\n",
    "        gc_bands_dict[band]=np.sum(gc_band)*(freqs_array[1]-freqs_array[0])\n",
    "        #gc_bands_dict[band]=(np.sum(gc_band)*0.5)/len(gc_band)\n",
    "    return gc_bands_dict\n",
    "\n",
    "test_row = aon_vhp_gc_df.iloc[0]\n",
    "row_list= [test_row]\n",
    "bands_dict = {\n",
    "    'theta': (4, 8),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 100),\n",
    "    'theta+early_beta': (4, 20),\n",
    "    'total': (2.5, 100)\n",
    "}\n",
    "\n",
    "for row in row_list:\n",
    "    gc_values = row['gc_values']\n",
    "    freqs = row['freqs']\n",
    "    gc_bands = calculate_gc_per_band(gc_values, freqs, bands_dict)\n",
    "    print(row['channelpair'], row['epoch_type'], gc_bands)\n",
    "    for band in gc_bands.keys():\n",
    "        row[f'{band}'] = gc_bands[band]\n",
    "    print(row)\n",
    "events_dict = {\n",
    "    'mne_epoch_door_before': 'door_before',\n",
    "    'mne_epoch_door_after': 'door_after',\n",
    "    'mne_epoch_dig_before': 'dig_before',\n",
    "    'mne_epoch_dig_after': 'dig_after',\n",
    "    'mne_epoch_around_door': 'around_door',\n",
    "    'mne_epoch_around_dig': 'around_dig'\n",
    "}\n",
    "gc_df_dict = {'AON to vHp': aon_vhp_gc_df, 'vHp to AON': vhp_aon_gc_df, 'Net GC': net_gc_df}\n",
    "writer = pd.ExcelWriter(savepath + 'gc_band_results.xlsx')\n",
    "for i, gc_df in enumerate(gc_df_dict.values()):\n",
    "    band_results = []\n",
    "\n",
    "    for idx, row in gc_df.iterrows():\n",
    "        gc_values = row['gc_values']\n",
    "        freqs = row['freqs']\n",
    "        gc_bands = calculate_gc_per_band(gc_values, freqs, bands_dict)\n",
    "        for band in gc_bands.keys():\n",
    "            row[f'{band}'] = gc_bands[band]\n",
    "        row['event'] = events_dict[row['epoch_type']]\n",
    "        row.drop(['gc_values', 'freqs', 'epoch_type'], inplace=True)\n",
    "        band_results.append(row)\n",
    "    band_df = pd.DataFrame(band_results)\n",
    "    band_df_melted = band_df.melt(id_vars=['rat_id', 'task', 'experiment', 'date', 'event', 'channelpair'],\n",
    "                                  value_vars=list(bands_dict.keys()), var_name='band', value_name='gc_value')\n",
    "    band_df_melted.to_excel(writer, sheet_name=list(gc_df_dict.keys())[i], index=False)\n",
    "    \n",
    "    ########### Plotting ###########\n",
    "    \n",
    "\n",
    "    fig, axs=plt.subplots(3,2, sharex=False, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle(f'{list(gc_df_dict.keys())[i]} Granger causality per band')\n",
    "    for axi, event in enumerate(events_dict.values()):\n",
    "        print(axi, event)\n",
    "        ax=axs[axi]\n",
    "        ax.axhline(0, color='black', lw=1)\n",
    "        sns.barplot(x='band',y='gc_value',hue='task',hue_order=['BWcontext','BWnocontext'],data=band_df_melted[band_df_melted['event']==event], ax=ax)\n",
    "        #sns.stripplot(x='band',y='gc_value',hue='task',hue_order=['BWcontext','BWnocontext'],data=band_df_melted,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax)\n",
    "        ax.set_title(f\"{event}\", fontsize=10)\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'gc_events_perband_{list(gc_df_dict.keys())[i]}_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_gc_df=pd.DataFrame()\n",
    "aon_vhp_gc_df = pd.DataFrame()\n",
    "vhp_aon_gc_df = pd.DataFrame()\n",
    "\n",
    "for col in ['rat_id', 'task', 'experiment', 'date']:\n",
    "    net_gc_df[col] = con_data_df_clean[col]\n",
    "    aon_vhp_gc_df[col] = con_data_df_clean[col]\n",
    "    vhp_aon_gc_df[col] = con_data_df_clean[col]\n",
    "for event in ['door_before', 'door_after', 'dig_before', 'dig_after', 'around_door', 'around_dig']:\n",
    "    mne_col = f'mne_epoch_{event}' if event not in ['around_door', 'around_dig'] else f'mne_epoch_{event}'\n",
    "    aon_vhp_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[0])\n",
    "    vhp_aon_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[1])\n",
    "    net_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[2])\n",
    "\n",
    "\n",
    "net_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "net_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "net_gc_df=pd.DataFrame(net_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door','around_dig', 'freqs', 'freqs_door'])\n",
    "\n",
    "aon_vhp_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "aon_vhp_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "aon_vhp_gc_df=pd.DataFrame(aon_vhp_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door',\n",
    "                                                'around_dig', 'freqs', 'freqs_door'])\n",
    "\n",
    "vhp_aon_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_net_gc(x)[3])\n",
    "vhp_aon_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_net_gc(x)[3])\n",
    "vhp_aon_gc_df=pd.DataFrame(vhp_aon_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door',\n",
    "                                                    'around_dig', 'freqs', 'freqs_door']) \n",
    "\n",
    "\n",
    "net_gc_df.to_pickle(savepath+f'net_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "aon_vhp_gc_df.to_pickle(savepath+f'aon_vhp_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "vhp_aon_gc_df.to_pickle(savepath+f'vhp_aon_gc_events_density_{int(time_window*fs/2)}ms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "##############\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "gc_dict = {'net': 'Net', 'aon_vhp': 'AON -> vHP', 'vhp_aon': 'vHP -> AON'}\n",
    "\n",
    "for gc_type in gc_dict.keys():\n",
    "    gc_data_df=pd.read_pickle(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "\n",
    "    gc_data_df_bwcontext=gc_data_df[gc_data_df['task']=='BWcontext']\n",
    "    gc_data_df_bwnocontext=gc_data_df[gc_data_df['task']=='BWnocontext']\n",
    "    writer=pd.ExcelWriter(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "    fig,axs=plt.subplots(3,2, sharex=True, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle(f'Context vs No Context {gc_dict[gc_type]} Granger Causality')\n",
    "    events_dict={'door_before': 'Door Before','door_after': 'Door After','dig_before': 'Dig Before','dig_after': 'Dig After','around_door': 'Around Door','around_dig': 'Around Dig'}\n",
    "    for i,event in enumerate(events_dict.keys()):\n",
    "        ax=axs[i]\n",
    "        bwcontext_mean=np.mean(gc_data_df_bwcontext[event], axis=0)\n",
    "        bwnocontext_mean=np.mean(gc_data_df_bwnocontext[event], axis=0)\n",
    "        bwcontext_sem=scipy.stats.sem(gc_data_df_bwcontext[event], axis=0)\n",
    "        bwnocontext_sem=scipy.stats.sem(gc_data_df_bwnocontext[event], axis=0)\n",
    "        \n",
    "        freqs=np.linspace(2.5,100,len(bwcontext_mean))\n",
    "        \n",
    "        mean_dict={'frequency':freqs,'bwcontext':bwcontext_mean,'bwnocontext':bwnocontext_mean,'bwcontext_sem':bwcontext_sem,'bwnocontext_sem':bwnocontext_sem}\n",
    "        mean_df=pd.DataFrame(mean_dict)\n",
    "        mean_df.to_excel(writer, sheet_name=event)\n",
    "\n",
    "\n",
    "        ax.plot(freqs, bwcontext_mean, linewidth=2, label='Context')\n",
    "        ax.fill_between(freqs, bwcontext_mean - bwcontext_sem, bwcontext_mean + bwcontext_sem, alpha=0.2)\n",
    "        ax.plot(freqs, gc_data_df_bwnocontext[event].mean(), linewidth=2, label='No Context')\n",
    "        ax.fill_between(freqs, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, alpha=0.2)    \n",
    "        ax.plot((freqs[0], freqs[-1]), (0, 0), linewidth=2, linestyle=\"--\", color=\"k\")\n",
    "        ax.axvspan(4,12, alpha=0.2, color='red', label='Theta Range')\n",
    "        ax.axvspan(12,30, alpha=0.2, color='green', label='Beta Range')\n",
    "        ax.axvspan(30,80, alpha=0.2, color='grey', label='Gamma Range')\n",
    "        ax.set_title(f\"{events_dict[event]}\", fontsize=8)\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "    writer.close()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#%matplotlib qt\n",
    "bands_dict={'total':[2.5,100],'theta': [4,12],'beta':[12,30],'gamma':[30,80], 'beta+theta':[4,30], 'early_beta':[12,20], 'late_beta':[20,30]}\n",
    "\n",
    "gc_dict = {'net': 'Net', 'aon_vhp': 'AON -> vHP', 'vhp_aon': 'vHP -> AON'}\n",
    "\n",
    "for gc_type in gc_dict.keys():\n",
    "    gc_data_df=pd.read_pickle(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "    gc_data_df_bwcontext=gc_data_df[gc_data_df['task']=='BWcontext']\n",
    "    gc_data_df_bwnocontext=gc_data_df[gc_data_df['task']=='BWnocontext']\n",
    "    def calculate_gc_per_band(gc_array,freqs_array, bands_dict):\n",
    "        freqs_array = np.array(freqs_array)  # Convert freqs_array to numpy array\n",
    "        print(len(gc_array))\n",
    "        gc_bands_dict={}\n",
    "        for band in bands_dict.keys():\n",
    "            band_indices=np.where((freqs_array>=bands_dict[band][0]) & (freqs_array<=bands_dict[band][1]))\n",
    "            gc_band=gc_array[band_indices]\n",
    "            gc_bands_dict[band]=np.sum(gc_band)*(freqs_array[1]-freqs_array[0])\n",
    "            #gc_bands_dict[band]=(np.sum(gc_band)*0.5)/len(gc_band)\n",
    "        return gc_bands_dict\n",
    "\n",
    "    test_gc=gc_data_df_bwcontext['door_before'].iloc[0]\n",
    "    test_freqs=gc_data_df_bwcontext['freqs'].iloc[0]\n",
    "    test_gc_band=calculate_gc_per_band(test_gc,test_freqs, bands_dict)\n",
    "    print(test_gc_band)\n",
    "\n",
    "    gc_cols = ['door_before', 'door_after', 'dig_before', 'dig_after','around_door','around_dig']\n",
    "    gc_data_df_bands = []\n",
    "\n",
    "    for index, row in gc_data_df.iterrows():\n",
    "        rat_id = row['rat_id']\n",
    "        task = row['task']\n",
    "        for gc_col in gc_cols:\n",
    "            if gc_col=='around_door_truncated' or gc_col=='around_dig_truncated':\n",
    "                freqs = row['freqs_trunc']\n",
    "            elif gc_col=='around_door' or gc_col=='around_dig':\n",
    "                freqs = row['freqs_door']\n",
    "            else:\n",
    "                freqs = row['freqs']\n",
    "            gc_values = calculate_gc_per_band(row[gc_col], freqs, bands_dict)\n",
    "            for band, gc_value in gc_values.items():\n",
    "                gc_data_df_bands.append({\n",
    "                    'rat_id': rat_id,\n",
    "                    'task': task,\n",
    "                    'event': gc_col,\n",
    "                    'band': band,\n",
    "                    'gcvalue': gc_value\n",
    "                })\n",
    "\n",
    "    gc_data_df_bands = pd.DataFrame(gc_data_df_bands)\n",
    "    gc_data_df_bands=gc_data_df_bands[gc_data_df_bands['task']!='nocontext']\n",
    "    print(gc_data_df_bands)\n",
    "    writer=pd.ExcelWriter(savepath+f'gc_events_perband_{int(time_window*fs/2)}ms.xlsx')\n",
    "    fig, axs=plt.subplots(3,2, sharex=False, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle('Average Net AON -> vHp granger causality per band')\n",
    "    for i, event in enumerate(gc_cols):\n",
    "        print(i, event)\n",
    "        ax=axs[i]\n",
    "        gc_event=gc_data_df_bands[gc_data_df_bands['event']==event]\n",
    "        gc_event.to_excel(writer, sheet_name=event)\n",
    "        ax.axhline(0, color='black', lw=1)\n",
    "        sns.boxplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,showfliers=False, ax=ax)\n",
    "        sns.stripplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax)\n",
    "        ax.set_title(f\"{event}\", fontsize=10)\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'gc_events_perband_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making GC Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Case\n",
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "\n",
    "test_epoch = con_data_df_clean['mne_epoch_around_dig'].iloc[0]\n",
    "fmin=2.5\n",
    "fmax=100\n",
    "fs=2000\n",
    "freqs = np.arange(fmin,fmax)\n",
    "n_cycles = freqs/3\n",
    "\n",
    "###Specifying the Indices for AON and vHp channels\n",
    "aon_signals=[\n",
    "idx\n",
    "for idx, ch_info in enumerate(test_epoch.info[\"chs\"])\n",
    "if \"AON\" in ch_info[\"ch_name\"]\n",
    "]\n",
    "print(aon_signals)\n",
    "vhp_signals=[\n",
    "    idx\n",
    "    for idx, ch_info in enumerate(test_epoch.info[\"chs\"])\n",
    "    if \"vHp\" in ch_info[\"ch_name\"]\n",
    "]\n",
    "print(vhp_signals)\n",
    "\n",
    "indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "print(indices_aon_vhp)\n",
    "import itertools\n",
    "\n",
    "indices_pairs = list(itertools.product(aon_signals, vhp_signals))\n",
    "indices = (\n",
    "    np.array([pair[0] for pair in indices_pairs]),\n",
    "    np.array([pair[1] for pair in indices_pairs])\n",
    ")\n",
    "print(indices)\n",
    "# indices = [([aon], [vhp]) for aon in aon_signals for vhp in vhp_signals]\n",
    "# print(indices)\n",
    "\n",
    "\n",
    "con = mne_connectivity.spectral_connectivity_epochs(test_epoch, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "                                        mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                        cwt_n_cycles=n_cycles, verbose=True, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=40, n_jobs=-1)\n",
    "coh = con.get_data()\n",
    "indices = con.names\n",
    "aon_vHp_con = []\n",
    "print(coh.shape, indices)\n",
    "\n",
    "plt.imshow(coh[0, :, :], extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "all_gc_data=[]\n",
    "for row in con_data_df_clean.itertuples(index=False):\n",
    "    experiment = row.experiment\n",
    "    rat_id = row.rat_id\n",
    "    task = row.task\n",
    "    mne_epoch = row.mne_epoch_door_before\n",
    "    data_around_dig = row.mne_epoch_around_dig\n",
    "    data_before_dig = row.mne_epoch_dig_before\n",
    "    data_after_dig = row.mne_epoch_dig_after\n",
    "    data_before_door = row.mne_epoch_door_before\n",
    "    data_after_door = row.mne_epoch_door_after\n",
    "\n",
    "    \n",
    "    event_of_interest = data_around_dig  ### CHANGE THIS TO THE DESIRED EVENT\n",
    "\n",
    "    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "    #print(event_of_interest.get_data().shape)  # Should be (n_epochs, n_channels,n_times)\n",
    "\n",
    "    aon_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "    #print(aon_signals)\n",
    "    vhp_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "    #print(vhp_signals)\n",
    "\n",
    "    indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "    print(indices_aon_vhp)\n",
    "    indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "\n",
    "    con_aon_vhp = mne_connectivity.spectral_connectivity_epochs(event_of_interest, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "                                        mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                        cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=20, n_jobs=-1)\n",
    "    con_vhp_aon = mne_connectivity.spectral_connectivity_epochs(event_of_interest, method='gc', sfreq=int(fs), indices=indices_vhp_aon,\n",
    "                                        mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                        cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=20, n_jobs=-1)\n",
    "    coh_aon_vhp = con_aon_vhp.get_data()[0,:,:]\n",
    "    coh_vhp_aon = con_vhp_aon.get_data()[0,:,:]\n",
    "    \n",
    "    new_row = [experiment, rat_id, task, coh_aon_vhp, coh_vhp_aon]\n",
    "    all_gc_data.append(new_row)\n",
    "all_gc_data_df = pd.DataFrame(all_gc_data, columns=['experiment', 'rat_id', 'task', 'gc_aon_vhp', 'gc_vhp_aon'])\n",
    "all_gc_data_df.to_pickle(savepath+'gc_around_dig.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making 2 plots of BWcontext and BWNocontext with Net GC in each subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gc_data_df.to_pickle(savepath+'gc_around_dig.pkl')\n",
    "\n",
    "all_gc_data_df['net_gc'] = all_gc_data_df['gc_aon_vhp'] - all_gc_data_df['gc_vhp_aon']\n",
    "\n",
    "vmin = all_gc_data_df['net_gc'].apply(np.min).min()\n",
    "vmax = all_gc_data_df['net_gc'].apply(np.max).max()\n",
    "\n",
    "BWcontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWcontext')]\n",
    "BWnocontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "for group_name, group_df in task_data_dict.items():\n",
    "    fig, axs = plt.subplots(group_df.shape[0] // 5 + int(group_df.shape[0] % 5 != 0), 5, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "        data = np.array(row['net_gc'])\n",
    "        ax = axs[i]\n",
    "        im = ax.imshow(data, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{row['rat_id']} {row['experiment']}\")\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        fig.delaxes(axs[j])\n",
    "    fig.suptitle(f\"{group_name} AON -> vHp net GC\", fontsize=16)\n",
    "    fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    #fig.savefig(savepath + f'coherence_around_dig_{group_name}.png', dpi=300, bbox_inches='tight')\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "gc_list = ['gc_aon_vhp', 'gc_vhp_aon', 'net_gc']\n",
    "for gc in gc_list:\n",
    "    bw_context_mean=BWcontext_data[gc].mean()\n",
    "    bw_nocontext_mean=BWnocontext_data[gc].mean()\n",
    "    #print(bw_context_mean.shape, bw_nocontext_mean.shape)\n",
    "    vmin = min(bw_context_mean.min(), bw_nocontext_mean.min())\n",
    "    vmax = max(bw_context_mean.max(), bw_nocontext_mean.max())\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.suptitle(f'Average {gc} Around Dig')\n",
    "    axs[0].imshow(bw_context_mean, extent=[-0.7, 0.7, 1, 100], aspect='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title('Context')\n",
    "    axs[1].imshow(bw_nocontext_mean, extent=[-0.7, 0.7, 1, 100], aspect='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title('No Context')\n",
    "    for ax in axs:\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    fig.colorbar(axs[0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gc_data_df = pd.read_pickle(savepath+'gc_around_dig.pkl')\n",
    "\n",
    "for row in all_gc_data_df.itertuples(index=False):\n",
    "    experiment = row.experiment\n",
    "    rat_id = row.rat_id\n",
    "    task = row.task\n",
    "    gc_aon_vhp = row.gc_aon_vhp\n",
    "    gc_vhp_aon = row.gc_vhp_aon\n",
    "    net_gc = gc_aon_vhp - gc_vhp_aon\n",
    "    vmin = min(gc_aon_vhp.min(), gc_vhp_aon.min(), net_gc.min())\n",
    "    vmax = max(gc_aon_vhp.max(), gc_vhp_aon.max(), net_gc.max())\n",
    "    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "    fig.suptitle(f'Granger Causality Rat: {rat_id}, Experiment: {experiment}, Task: {task}', fontsize=20)\n",
    "\n",
    "    im = axs[0].imshow(gc_aon_vhp, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title('AON -> vHp')\n",
    "    axs[0].set_xlabel('Time (s)')\n",
    "    axs[0].set_ylabel('Frequency (Hz)')\n",
    "    \n",
    "    axs[1].imshow(gc_vhp_aon, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title('vHp -> AON')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "\n",
    "    axs[2].imshow(net_gc, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[2].set_title('Difference (AON -> vHp) - (vHp -> AON)')\n",
    "    axs[2].set_xlabel('Time (s)')\n",
    "    axs[2].set_ylabel('Frequency (Hz)')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    # Create a common colorbar for all three subplots\n",
    "    # Remove the previous imshow call for axs[2] above, use this one for colorbar\n",
    "    cbar = fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(savepath + f'{task}_{rat_id}_{experiment}_gc_around_dig.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "rat_list=np.unique(con_data_df_clean['rat_id'])\n",
    "print(rat_list)\n",
    "all_con_data=[]\n",
    "all_con_data_mean=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "    #print(task_name)\n",
    "    # for rat_num, rat_name in enumerate(rat_list):\n",
    "    #     rat_task_data=task_data[task_data['rat_id']==rat_name]\n",
    "        row=[task_name]\n",
    "    #     #print(row)\n",
    "        row_2=[task_name]\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            aon_vHp_con=[]\n",
    "            for event_epoch in event_epoch_list:\n",
    "                    #print(row,event, event_epoch) \n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/2\n",
    "                    \n",
    "                    ###Specifying the Indices for AON and vHp channels\n",
    "                    aon_signals=[\n",
    "                    idx\n",
    "                    for idx, ch_info in enumerate(event_epoch.info[\"chs\"])\n",
    "                    if \"AON\" in ch_info[\"ch_name\"]\n",
    "                    ]\n",
    "                    print(aon_signals)\n",
    "                    vhp_signals=[\n",
    "                        idx\n",
    "                        for idx, ch_info in enumerate(event_epoch.info[\"chs\"])\n",
    "                        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "                    ]\n",
    "                    print(vhp_signals)\n",
    "\n",
    "                    indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "                    indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))      \n",
    "                    gc_ab = mne_connectivity.spectral_connectivity_epochs(event_epoch, method=[\"gc\"], indices=indices_aon_vhp, fmin=2.5, fmax=100, rank=None,gc_n_lags=20)\n",
    "                    gc_ba= mne_connectivity.spectral_connectivity_epochs(event_epoch, method=[\"gc\"], indices=indices_vhp_aon, fmin=2.5, fmax=100, rank=None,gc_n_lags=20)\n",
    "                    net_gc= gc_ab.get_data() - gc_ba.get_data()\n",
    "                    print(net_gc.shape)\n",
    "\n",
    "                    coh = net_gc[0]\n",
    "                    #coh=np.abs(coh)\n",
    "                    print(coh.shape)\n",
    "                    indices = coh.names\n",
    "                    print(indices)\n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                aon_vHp_con.append(coh[i,j,:,:])\n",
    "            row.append(np.mean(aon_vHp_con, axis=0))\n",
    "            row_2.append(np.mean(aon_vHp_con))\n",
    "        all_con_data.append(row)                    \n",
    "        all_con_data_mean.append(row_2)\n",
    "# Convert all_con_data to a DataFrame for easier manipulation\n",
    "all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "#all_con_data_df.to_pickle(savepath+'coherence_spectrogram_around_door_dig.pkl')\n",
    "fs=2000\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-2, 2, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('')\n",
    "\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_coherence_event_spectrogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating complex coherence values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Coherence with Quiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "#################\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_list=['mne_epoch_door_before', 'mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "rat_list=np.unique(con_data_df_clean['rat_id'])\n",
    "print(rat_list)\n",
    "all_coh_abs_data=[]\n",
    "all_coh_abs_data_mean=[]\n",
    "all_coh_phase_data=[]\n",
    "all_coh_phase_data_mean=[]\n",
    "ind_rows_df=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "    #print(task_name)\n",
    "    # for rat_num, rat_name in enumerate(rat_list):\n",
    "    #     rat_task_data=task_data[task_data['rat_id']==rat_name]\n",
    "        row_coh_abs=[task_name]\n",
    "        row_coh_abs_mean=[task_name]\n",
    "        row_coh_phase=[task_name]\n",
    "        row_coh_phase_mean=[task_name]\n",
    "\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            rat_id_list=task_data['rat_id']\n",
    "            exp_list=task_data['experiment']\n",
    "            \n",
    "            aon_vhp_coh_abs=[]\n",
    "            aon_vhp_coh_phase=[]\n",
    "            for rowi,event_epoch in enumerate(event_epoch_list):\n",
    "                    #print(row,event, event_epoch) \n",
    "                    rat_id=rat_id_list.iloc[rowi]\n",
    "                    experiment=exp_list.iloc[rowi]\n",
    "                    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task_name}, Event: {event}')\n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/3\n",
    "                           \n",
    "                    con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='cohy', sfreq=int(fs),\n",
    "                                                         mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                         cwt_n_cycles=n_cycles, verbose=False, fmin=1, fmax=100, faverage=False)\n",
    "                    coh = con.get_data(output='dense')\n",
    "                    coh_abs = np.abs(coh)\n",
    "                    coh_phase = np.angle(coh)\n",
    "\n",
    "                    indices = con.names\n",
    "                    print(indices)\n",
    "                    print(coh.shape)\n",
    "                    print(coh_abs.shape)\n",
    "                    print(coh_phase.shape)\n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                coherence_abs=coh_abs[i,j,:,:]\n",
    "                                coherence_abs=np.arctanh(coherence_abs)  # Apply Fisher transformation\n",
    "                                aon_vhp_coh_abs.append(coherence_abs)\n",
    "                                aon_vhp_coh_phase.append(coh_phase[i,j,:,:])\n",
    "                                ind_row =[rat_id, experiment, task_name, event, f'{indices[j]}-{indices[i]}', coh_phase[i,j,:,:]]\n",
    "\n",
    "                                ind_rows_df.append(ind_row)\n",
    "\n",
    "            row_coh_abs.append(np.mean(aon_vhp_coh_abs, axis=0))\n",
    "            row_coh_abs_mean.append(np.mean(aon_vhp_coh_abs))\n",
    "            row_coh_phase.append(np.mean(aon_vhp_coh_phase, axis=0))\n",
    "            row_coh_phase_mean.append(np.mean(aon_vhp_coh_phase))\n",
    "        all_coh_abs_data.append(row_coh_abs)\n",
    "        all_coh_abs_data_mean.append(row_coh_abs_mean)\n",
    "        all_coh_phase_data.append(row_coh_phase)\n",
    "        all_coh_phase_data_mean.append(row_coh_phase_mean)\n",
    "        \n",
    "ind_rows_df = pd.DataFrame(ind_rows_df, columns=['rat_id', 'experiment', 'task', 'event', 'channel_pair', 'coherence_phase'])\n",
    "ind_rows_df.to_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_abs_data_df = pd.DataFrame(all_coh_abs_data, columns=['task'] + event_list)\n",
    "all_coh_abs_data_df.to_pickle(savepath+f'coherence_abs_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df = pd.DataFrame(all_coh_phase_data, columns=['task'] + event_list)\n",
    "all_coh_phase_data_df.to_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "fs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = aon_vhp_coh_phase[0]\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 12\n",
    "fmax = 30\n",
    "tmin = 0.5\n",
    "tmax = 0.9\n",
    "\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "\n",
    "truncated_phase_data_real = all_coh_phase_data_df_real['mne_epoch_around_dig'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "# phase_context = np.array(all_coh_phase_data_df.loc[all_coh_phase_data_df['task'] == 'BWcontext', 'mne_epoch_around_dig'].iloc[0]).flatten()\n",
    "# phase_nocontext = np.array(all_coh_phase_data_df.loc[all_coh_phase_data_df['task'] == 'BWnocontext', 'mne_epoch_around_dig'].iloc[0]).flatten()\n",
    "phase_context = np.array(truncated_phase_data_real[all_coh_phase_data_df_real['task'] == 'BWcontext'].iloc[0]).flatten()\n",
    "phase_nocontext = np.array(truncated_phase_data_real[all_coh_phase_data_df_real['task'] == 'BWnocontext'].iloc[0]).flatten()\n",
    "\n",
    "truncated_phase_data_shuffled = all_coh_phase_data_df_shuffled['mne_epoch_around_dig'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "phase_context_shuffled = np.array(truncated_phase_data_shuffled[all_coh_phase_data_df_shuffled['task'] == 'BWcontext'].iloc[0]).flatten()\n",
    "phase_nocontext_shuffled = np.array(truncated_phase_data_shuffled[all_coh_phase_data_df_shuffled['task'] == 'BWnocontext'].iloc[0]).flatten()\n",
    "\n",
    "# Convert phase to [0, 2pi]\n",
    "phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "phase_context_shuffled = np.mod(phase_context_shuffled, 2 * np.pi)\n",
    "phase_nocontext_shuffled = np.mod(phase_nocontext_shuffled, 2 * np.pi)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, subplot_kw={'projection': 'polar'}, figsize=(12, 6))\n",
    "axs=axs.flatten()\n",
    "colors = {'BWcontext': 'blue', 'BWnocontext': 'orange'}\n",
    "\n",
    "# Plot BW Context\n",
    "axs[0].hist(phase_context, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "axs[0].set_title('Phase Difference Histogram\\nBW Context', fontsize=16)\n",
    "axs[0].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[0].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "# Plot BW No Context\n",
    "axs[1].hist(phase_nocontext, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "axs[1].set_title('Phase Difference Histogram\\nBW No Context', fontsize=16)\n",
    "axs[1].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[1].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "axs[2].hist(phase_context_shuffled, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "axs[2].set_title('Phase Difference Histogram (Shuffled)\\nBW Context', fontsize=16)\n",
    "axs[2].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[2].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "axs[3].hist(phase_nocontext_shuffled, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "axs[3].set_title('Phase Difference Histogram (Shuffled)\\nBW No Context', fontsize=16)\n",
    "axs[3].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[3].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(savepath+f'coherence_phase_histogram_around_dig_truncated_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "# Use the Kolmogorov-Smirnov test to compare the two phase distributions\n",
    "ks_stat, p_value = ks_2samp(phase_context, phase_nocontext)\n",
    "print(f\"KS statistic: {ks_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the phase distributions of the two tasks.\")\n",
    "else:\n",
    "    print(\"No significant difference between the phase distributions of the two tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the polar plot but without averaging across experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 30 \n",
    "fmax = 80\n",
    "tmin = 0.4\n",
    "tmax = 0.7\n",
    "\n",
    "\n",
    "# all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "# all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "writer = pd.ExcelWriter(savepath+f'coherence_phase_analysis_around_door_dig_truncated_{int(time_window*fs)}.xlsx')\n",
    "bands_dict = {\n",
    "    'Theta': (4, 8),\n",
    "    'Beta': (12, 30),\n",
    "    'Gamma': (30, 80)\n",
    "}\n",
    "\n",
    "for band_name, (fmin, fmax) in bands_dict.items():\n",
    "    all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "    all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "    all_coh_phase_data_df_real['coherence_phase'] = all_coh_phase_data_df_real['coherence_phase'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "    all_coh_phase_data_df_real['coherence_phase'] = all_coh_phase_data_df_real['coherence_phase'].apply(lambda x: x.flatten())  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "    bw_context_data = all_coh_phase_data_df_real[(all_coh_phase_data_df_real['task'] == 'BWcontext') & (all_coh_phase_data_df_real['event']=='mne_epoch_around_dig')]\n",
    "    phase_context = np.array([value for lst in bw_context_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "    bw_nocontext_data = all_coh_phase_data_df_real[(all_coh_phase_data_df_real['task'] == 'BWnocontext') & (all_coh_phase_data_df_real['event']=='mne_epoch_around_dig')]\n",
    "    phase_nocontext = np.array([value for lst in bw_nocontext_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    all_coh_phase_data_df_shuffled['coherence_phase'] = all_coh_phase_data_df_shuffled['coherence_phase'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "    all_coh_phase_data_df_shuffled['coherence_phase'] = all_coh_phase_data_df_shuffled['coherence_phase'].apply(lambda x: x.flatten())  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "    bw_context_data_shuffled = all_coh_phase_data_df_shuffled[(all_coh_phase_data_df_shuffled['task'] == 'BWcontext') & (all_coh_phase_data_df_shuffled['event']=='mne_epoch_around_dig')]\n",
    "    phase_context_shuffled = np.array([value for lst in bw_context_data_shuffled['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    bw_nocontext_data_shuffled = all_coh_phase_data_df_shuffled[(all_coh_phase_data_df_shuffled['task'] == 'BWnocontext') & (all_coh_phase_data_df_shuffled['event']=='mne_epoch_around_dig')]\n",
    "    phase_nocontext_shuffled = np.array([value for lst in bw_nocontext_data_shuffled['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    # Convert phase to [0, 2pi]\n",
    "    phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "    phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "    phase_context_shuffled = np.mod(phase_context_shuffled, 2 * np.pi)\n",
    "    phase_nocontext_shuffled = np.mod(phase_nocontext_shuffled, 2 * np.pi)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, subplot_kw={'projection': 'polar'}, figsize=(12, 6))\n",
    "    fig.suptitle('Coherence Phase Freq - {}-{} Hz, Time - {}-{} s'.format(fmin, fmax, tmin, tmax), fontsize=16)\n",
    "    axs=axs.flatten()\n",
    "    colors = {'BWcontext': 'black', 'BWnocontext': 'grey'}\n",
    "\n",
    "    # Plot BW Context\n",
    "    axs[0].hist(phase_context, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[0].set_title('Context', fontsize=16)\n",
    "    axs[0].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[0].set_xlim(0, 2 * np.pi)\n",
    "    counts, edges = np.histogram(phase_context, bins=100, range=(0, 2*np.pi))\n",
    "\n",
    "    # 5. Get bin centers\n",
    "    # This is the Python/NumPy way to find the midpoint of each bin\n",
    "    locs = (edges[:-1] + edges[1:]) / 2\n",
    "    closed_locs = np.append(locs, locs[0])\n",
    "    closed_counts = np.append(counts, counts[0])\n",
    "    # 6. Plot the line (MATLAB: plot(locs, counts, 'LineWidth', 3);)\n",
    "    axs[0].plot(closed_locs, closed_counts, 'black', linewidth=1, label='Bin Centers Line') # 'r-' adds color\n",
    "\n",
    "    # Plot BW No Context\n",
    "    axs[1].hist(phase_nocontext, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[1].set_title('No Context', fontsize=16)\n",
    "    axs[1].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[1].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "    axs[2].hist(phase_context_shuffled, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[2].set_title('Context(Shuffled)', fontsize=16)\n",
    "    axs[2].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[2].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "    axs[3].hist(phase_nocontext_shuffled, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[3].set_title('No Context(Shuffled)', fontsize=16)\n",
    "    axs[3].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[3].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'coherence_phase_polarhist_around_dig_{fmin}_{fmax}_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "\n",
    "    #########Plotting in a simple histogram##########\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle('Coherence Phase Freq - {}-{} Hz, Time - {}-{} s'.format(fmin, fmax, tmin, tmax), fontsize=16)\n",
    "    colors = {'BWcontext': 'black', 'BWnocontext': 'grey'}\n",
    "\n",
    "    # Convert phase values from [0, 2] to [-, ]\n",
    "    phase_context_centered = np.where(phase_context > np.pi, phase_context - 2*np.pi, phase_context)\n",
    "    phase_nocontext_centered = np.where(phase_nocontext > np.pi, phase_nocontext - 2*np.pi, phase_nocontext)\n",
    "    phase_context_shuffled_centered = np.where(phase_context_shuffled > np.pi, phase_context_shuffled - 2*np.pi, phase_context_shuffled)\n",
    "    phase_nocontext_shuffled_centered = np.where(phase_nocontext_shuffled > np.pi, phase_nocontext_shuffled - 2*np.pi, phase_nocontext_shuffled)\n",
    "\n",
    "    # Plotting the histograms with centered x-axis\n",
    "    axs[0].hist(phase_context_centered, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[0].set_title('Context', fontsize=16)\n",
    "    axs[0].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[0].set_xticklabels(['-', '-2/3', '-/3', '0', '/3', '2/3', ''])\n",
    "    axs[0].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[1].hist(phase_nocontext_centered, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[1].set_title('No Context', fontsize=16)\n",
    "    axs[1].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[1].set_xticklabels(['-', '-2/3', '-/3', '0', '/3', '2/3', ''])\n",
    "    axs[1].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[2].hist(phase_context_shuffled_centered, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[2].set_title('Context(Shuffled)', fontsize=16)\n",
    "    axs[2].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[2].set_xticklabels(['-', '-2/3', '-/3', '0', '/3', '2/3', ''])\n",
    "    axs[2].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[3].hist(phase_nocontext_shuffled_centered, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[3].set_title('No Context(Shuffled)', fontsize=16)\n",
    "    axs[3].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[3].set_xticklabels(['-', '-2/3', '-/3', '0', '/3', '2/3', ''])\n",
    "    axs[3].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'coherence_phase_histogram_around_dig_{fmin}_{fmax}_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "    data_dict = {'context_real': phase_context,\n",
    "                 'nocontext_real': phase_nocontext,\n",
    "                 'context_shuffled': phase_context_shuffled,\n",
    "                 'nocontext_shuffled': phase_nocontext_shuffled}\n",
    "    df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data_dict.items()]))\n",
    "    df.to_excel(writer, sheet_name=f'{band_name}_phase_data', index=False)\n",
    "writer.close()\n",
    "\n",
    "ks_stat, p_value = ks_2samp(phase_context, phase_nocontext)\n",
    "print(f\"KS statistic: {ks_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the phase distributions of the two tasks.\")\n",
    "else:\n",
    "    print(\"No significant difference between the phase distributions of the two tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making polar plots with Context and No Context in single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 30 \n",
    "fmax = 80\n",
    "tmin = 0.4\n",
    "tmax = 0.7\n",
    "\n",
    "\n",
    "# all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "# all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "writer = pd.ExcelWriter(savepath+f'coherence_phase_analysis_around_door_dig_truncated_{int(time_window*fs)}.xlsx')\n",
    "bands_dict = {\n",
    "    'Theta': (4, 8),\n",
    "    'Beta': (12, 30),\n",
    "    'Gamma': (30, 80)\n",
    "}\n",
    "\n",
    "tmin = 0\n",
    "tmax = 0.7\n",
    "\n",
    "tmin_idx = int(tmin * fs)\n",
    "tmax_idx = int(tmax * fs)\n",
    "\n",
    "events_dict = {\n",
    "'mne_epoch_door_before': 'Door Before',\n",
    "'mne_epoch_dig_before': 'Dig Before',\n",
    "'mne_epoch_dig_after': 'Dig After',\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(3,3, subplot_kw={'projection': 'polar'}, figsize=(18, 12))\n",
    "\n",
    "for axi_row,(band_name, (fmin, fmax)) in enumerate(bands_dict.items()):\n",
    "\n",
    "    for axi_col,(event_key, event_name) in enumerate(events_dict.items()):\n",
    "\n",
    "        for data_type in ['real', 'shuffled']:\n",
    "            if data_type == 'real':\n",
    "                all_coh_phase_data_df = pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "                linestyle = 'solid'  \n",
    "            else:\n",
    "                all_coh_phase_data_df = pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "                linestyle = 'dashed'\n",
    "            print(f'{axi_row} {axi_col} Processing Band: {band_name}, Event: {event_name}, Data Type: {data_type}')\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            all_coh_phase_data_df['coherence_phase'] = all_coh_phase_data_df['coherence_phase'].apply(lambda x: x[fmin:fmax, tmin_idx:tmax_idx])\n",
    "            all_coh_phase_data_df['coherence_phase'] = all_coh_phase_data_df['coherence_phase'].apply(lambda x: x.flatten())  \n",
    "\n",
    "            bw_context_data = all_coh_phase_data_df[(all_coh_phase_data_df['task'] == 'BWcontext') & (all_coh_phase_data_df['event']==event_key)]\n",
    "            phase_context = np.array([value for lst in bw_context_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "            bw_nocontext_data = all_coh_phase_data_df[(all_coh_phase_data_df['task'] == 'BWnocontext') & (all_coh_phase_data_df['event']==event_key)]\n",
    "            phase_nocontext = np.array([value for lst in bw_nocontext_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "            # Convert phase to [0, 2pi]\n",
    "            phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "            phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "            ax = axs[axi_row, axi_col]    \n",
    "            \n",
    "            counts, edges = np.histogram(phase_context, bins=100, range=(0, 2*np.pi), density=True)\n",
    "            locs = (edges[:-1] + edges[1:]) / 2\n",
    "            closed_locs = np.append(locs, locs[0])\n",
    "            closed_counts = np.append(counts, counts[0])\n",
    "            ax.fill(closed_locs, closed_counts, color='blue', alpha=0.3)  # Fill the area with black color\n",
    "            ax.plot(closed_locs, closed_counts, 'blue', linewidth=1, label=f'Context ({data_type})', linestyle=linestyle) # 'r-' adds color\n",
    "\n",
    "            counts, edges = np.histogram(phase_nocontext, bins=100, range=(0, 2*np.pi), density=True)\n",
    "            locs = (edges[:-1] + edges[1:]) / 2\n",
    "            closed_locs = np.append(locs, locs[0])\n",
    "            closed_counts = np.append(counts, counts[0])\n",
    "            ax.fill(closed_locs, closed_counts, color='orange', alpha=0.3)  # Fill the area with grey color\n",
    "            ax.plot(closed_locs, closed_counts, 'orange', linewidth=1, label=f'No Context ({data_type})', linestyle=linestyle)  #ax.set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "            ax.set_xlim(0, 2 * np.pi)\n",
    "            ax.set_rticks([])  # Remove radial ticks for clarity\n",
    "            # if axi_row == 0 and axi_col == 0:\n",
    "            #     ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "            ax.set_title(f'{band_name} Band - {event_name}', fontsize=12)\n",
    "            #ax.set_rmax(0.5)  # Set maximum radius for better visualization\n",
    "# Create custom labels that combine color, style and condition\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color='blue', linestyle='solid', label='Context (real)'),\n",
    "    plt.Line2D([0], [0], color='blue', linestyle='dashed', label='Context (shuffled)'),\n",
    "    plt.Line2D([0], [0], color='orange', linestyle='solid', label='No Context (real)'),\n",
    "    plt.Line2D([0], [0], color='orange', linestyle='dashed', label='No Context (shuffled)')\n",
    "]\n",
    "\n",
    "# Add legend at the bottom\n",
    "fig.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, 0), \n",
    "          ncol=4, fontsize=12)\n",
    "\n",
    "# Adjust subplot spacing to make room for legend\n",
    "plt.subplots_adjust(bottom=0.12)\n",
    "fig.suptitle(f'Coherence Phase Analysis {tmin}s-{tmax}s', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(savepath+f'coherence_phase_polarhist_all_events_{int(tmin*fs)}-{int(tmax*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "all_con_data_df=all_coh_abs_data_df\n",
    "aon_vhp_phase=all_coh_phase_data_df\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "freqs=np.arange(2.5, 100, 0.5)\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    coh_phase = aon_vhp_phase[event][0]\n",
    "    X, Y = np.meshgrid(np.linspace(times[0], times[-1], coh_phase.shape[1]), np.linspace(freqs[0], freqs[-1], coh_phase.shape[0]))\n",
    "\n",
    "    U = np.cos(coh_phase)\n",
    "    V = np.sin(coh_phase)\n",
    "    f_x = 100\n",
    "    f_y = 5\n",
    "    axs[0, i].quiver(X[2::f_y, ::f_x], Y[2::f_y, ::f_x], U[2::f_y, ::f_x], V[2::f_y, ::f_x], angles='uv', scale=40, alpha=0.7)\n",
    "\n",
    "    axs[0,i].set_xlabel('')\n",
    "\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    coh_phase = aon_vhp_phase[event][1]\n",
    "    X, Y = np.meshgrid(np.linspace(times[0], times[-1], coh_phase.shape[1]), np.linspace(freqs[0], freqs[-1], coh_phase.shape[0]))\n",
    "\n",
    "    U = np.cos(coh_phase)\n",
    "    V = np.sin(coh_phase)\n",
    "    f_x = 100\n",
    "    f_y = 5\n",
    "    axs[1, i].quiver(X[2::f_y, ::f_x], Y[2::f_y, ::f_x], U[2::f_y, ::f_x], V[2::f_y, ::f_x], angles='uv', scale=40, alpha=0.7)\n",
    "\n",
    "    \n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    # axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence (Z-transformed)', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "fig.savefig(savepath+'aon_vhp_coherogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Behavior Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Behavior Correlation with Power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_df=pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "behavior_df.iloc[:,-5:]=behavior_df.iloc[:,-5:].applymap(lambda x: scipy.signal.welch(x, fs=2000, nperseg=2000)[1])\n",
    "\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "for col in behavior_df.columns[-7:]:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        behavior_df[band + '_' + col] = behavior_df[col].apply(lambda x: functions.get_band_power(x, band_start, band_end))\n",
    "\n",
    "behavior_df['channel'] = behavior_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "\n",
    "behavior_df_grouped=behavior_df.groupby(['task', 'channel'])\n",
    "writer=pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_power_correlation.xlsx')\n",
    "for (task, channel), group in behavior_df_grouped:\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "    axs = axs.flatten()\n",
    "    group=behavior_df[(behavior_df['channel']==channel) & (behavior_df['task']==task)]\n",
    "\n",
    "    power_columns=group.columns[17:]\n",
    "    print(power_columns)\n",
    "    group_melted=pd.melt(group, id_vars=['rat', 'task', 'channel', 'correct?'], value_vars=power_columns, var_name='band_event', value_name='power')\n",
    "    group_melted['band']=group_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "    group_melted['event']=group_melted['band_event'].apply(lambda x: x.split('_')[1:])\n",
    "    group_melted['event']=group_melted['event'].apply(lambda x: x[0]+'_'+x[1])\n",
    "    group_melted['correct?']=group_melted['correct?'].apply(lambda x: 'Incorrect' if x=='0' else 'Correct')\n",
    "    \n",
    "    group_melted.to_excel(writer, sheet_name=f'{channel}_{task}')\n",
    "\n",
    "\n",
    "    correct_counts = group_melted[group_melted['correct?'] == 'Correct'].shape[0]\n",
    "    incorrect_counts = group_melted[group_melted['correct?'] == 'Incorrect'].shape[0]\n",
    "    print(f\"Number of Corrects: {correct_counts}\")\n",
    "    print(f\"Number of Incorrects: {incorrect_counts}\")\n",
    "    events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "    for i, event in enumerate(events_list):\n",
    "        ax=axs[i]\n",
    "        sns.boxplot(x='band', y='power', hue='correct?', data=group_melted[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "        #sns.stripplot(x='band', y='power', hue='correct?', data=aon_behavior_df_melted[aon_behavior_df_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax)\n",
    "        ax.set_title(event)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Power')\n",
    "        ax.legend(title='Correct?')\n",
    "    fig.suptitle(f'{channel} {task}')\n",
    "    fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_power_{channel}_{task}.png')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Behavior Correlation with Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "time_window=  1\n",
    "fs=2000\n",
    "behavior_coherence_df=pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "behavior_coherence_df_marked=pd.read_pickle(savepath+f'marked_mne_epochs_array_df_truncated_2000_251125.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "behavior_coherence_df['unique_id']=behavior_coherence_df['rat']+'_'+behavior_coherence_df['task']+behavior_coherence_df['date']\n",
    "behavior_coherence_df_grouped=behavior_coherence_df.groupby(['unique_id', 'trial'])\n",
    "behavior_coherence_compiled_data_df=[]\n",
    "\n",
    "for (unique_id, trial), group in behavior_coherence_df_grouped:\n",
    "    print(unique_id, trial)\n",
    "    channels_list=list(group['channel'].unique())\n",
    "    print(channels_list)\n",
    "    info=mne.create_info(ch_names=channels_list, sfreq=fs, ch_types='eeg')\n",
    "\n",
    "    mne_epoch_door_before=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_door_after=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_dig_before=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_dig_after=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_around_door=np.zeros((1,len(channels_list),int(time_window*fs)*2))\n",
    "    mne_epoch_around_dig=np.zeros((1,len(channels_list),int(time_window*fs)*2))\n",
    "\n",
    "    for channel_num, channel_id in enumerate(channels_list):\n",
    "        data=group[group['channel']==channel_id]\n",
    "        mne_epoch_door_before[0,channel_num,:]=data['pre_door'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_door_after[0,channel_num,:]=data['post_door'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_dig_before[0,channel_num,:]=data['pre_dig'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_dig_after[0,channel_num,:]=data['post_dig'].values[0][:int(time_window*fs)]\n",
    "        mid_point = int(len(data['around_door'].values[0])/2)\n",
    "        mne_epoch_around_door[0,channel_num,:]=data['around_door'].values[0][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]\n",
    "        mne_epoch_around_dig[0,channel_num,:]=data['around_dig'].values[0][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]\n",
    "\n",
    "    # mne_epoch_around_door_truncated = mne_epoch_around_door[:, :, 3000:5000]\n",
    "    # mne_epoch_around_dig_truncated = mne_epoch_around_dig[:, :, 3000:5000]\n",
    "    mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "    mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "    mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "    mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "    mne_epoch_around_door = mne.EpochsArray(mne_epoch_around_door, info)\n",
    "    mne_epoch_around_dig = mne.EpochsArray(mne_epoch_around_dig, info)\n",
    "    \n",
    "    behavior_coherence_compiled_data={\n",
    "        'rat': group['rat'].values[0],\n",
    "        'task': group['task'].values[0],\n",
    "        'date': group['date'].values[0],\n",
    "        'unique_id': unique_id,\n",
    "        'trial': trial,\n",
    "        'side': group['side'].values[0],\n",
    "        'correct?': group['correct'].values[0],\n",
    "        'time_to_dig': group['timestamps'].iloc[0][1] - group['timestamps'].iloc[0][0],\n",
    "        'pre_door': mne_epoch_door_before,\n",
    "        'post_door': mne_epoch_door_after,\n",
    "        'pre_dig': mne_epoch_dig_before,\n",
    "        'post_dig': mne_epoch_dig_after,\n",
    "        'around_door': mne_epoch_around_door,\n",
    "        'around_dig': mne_epoch_around_dig\n",
    "        ,'around_door_truncated': mne_epoch_around_door,\n",
    "        'around_dig_truncated': mne_epoch_around_dig}\n",
    "    \n",
    "    behavior_coherence_compiled_data_df.append(behavior_coherence_compiled_data)\n",
    "behavior_coherence_compiled_data_df=pd.DataFrame(behavior_coherence_compiled_data_df)\n",
    "behavior_coherence_compiled_data_df.to_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "# def lfp_to_mne_epoch(lfp_data):\n",
    "#     fs=2000\n",
    "#     freqs = np.arange(1,100)\n",
    "#     n_cycles = freqs/2\n",
    "#     empty_array=np.zeros((1,1,len(lfp_data)))\n",
    "#     empty_array[0,0,:]=lfp_data\n",
    "#     info = mne.create_info(ch_names=['1'], sfreq=fs, ch_types='eeg')\n",
    "#     mne_epoch = mne.EpochsArray(empty_array, info)\n",
    "#     return mne_epoch\n",
    "\n",
    "# behavior_coherence_df[['pre_door','post_door', 'pre_dig', 'post_dig']]=behavior_coherence_df[['pre_door','post_door', 'pre_dig', 'post_dig']].applymap(lambda x: lfp_to_mne_epoch(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "time_window=  1\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "print(behavior_coherence_compiled_data_df_truncated.columns)\n",
    "common_cols = ['rat', 'task', 'date', 'unique_id', 'trial', 'side', 'correct?','time_to_dig']\n",
    "\n",
    "pre_door_df = behavior_coherence_compiled_data_df_truncated[common_cols+['pre_door']]\n",
    "pre_dig_df = behavior_coherence_compiled_data_df_truncated[common_cols+['pre_dig']]\n",
    "post_dig_df = behavior_coherence_compiled_data_df_truncated[common_cols+['post_dig']]\n",
    "\n",
    "annotated_file = pd.read_csv(savepath+'con_data_df_annotation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bad_pre_door =0\n",
    "total_bad_pre_dig =0\n",
    "total_bad_post_dig =0\n",
    "\n",
    "for index, row in annotated_file.iterrows():\n",
    "    door_before_bad_epochs = len(json.loads(row['annotation_door_before']))\n",
    "    dig_before_bad_epochs = len(json.loads(row['annotation_dig_before']))\n",
    "    dig_after_bad_epochs = len(json.loads(row['annotation_dig_after']))\n",
    "    \n",
    "    total_bad_pre_door = total_bad_pre_door + door_before_bad_epochs \n",
    "    total_bad_pre_dig = total_bad_pre_dig + dig_before_bad_epochs\n",
    "    total_bad_post_dig  =   total_bad_post_dig + dig_after_bad_epochs\n",
    "\n",
    "print(total_bad_pre_door)\n",
    "print(total_bad_pre_dig)\n",
    "print(total_bad_post_dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_door_df_filtered = []\n",
    "pre_dig_df_filtered = []\n",
    "post_dig_df_filtered = []\n",
    "# Iterate over rows using iterrows()\n",
    "\n",
    "\n",
    "\n",
    "for index, row in annotated_file.iterrows():\n",
    "    print(index)\n",
    "    unique_id = f\"{row['rat_id']}_{row['task']}{row['date']}\"\n",
    "    print(unique_id)\n",
    "    pre_door_exp_df = pre_door_df[pre_door_df['unique_id']==unique_id]\n",
    "    pre_dig_exp_df = pre_dig_df[pre_dig_df['unique_id']==unique_id]\n",
    "    post_dig_exp_df = post_dig_df[post_dig_df['unique_id']==unique_id]\n",
    "    \n",
    "    door_before_bad_epochs = json.loads(row['annotation_door_before'])\n",
    "    dig_before_bad_epochs = json.loads(row['annotation_dig_before'])\n",
    "    dig_after_bad_epochs = json.loads(row['annotation_dig_after'])\n",
    "    \n",
    "    pre_door_exp_df_filtered = pre_door_exp_df[~pre_door_exp_df['trial'].isin(door_before_bad_epochs)]\n",
    "    pre_dig_exp_df_filtered = pre_dig_exp_df[~pre_dig_exp_df['trial'].isin(dig_before_bad_epochs)]\n",
    "    post_dig_exp_df_filtered = post_dig_exp_df[~post_dig_exp_df['trial'].isin(dig_after_bad_epochs)]\n",
    "    \n",
    "    pre_door_df_filtered.append(pre_door_exp_df_filtered)\n",
    "    pre_dig_df_filtered.append(pre_dig_exp_df_filtered)\n",
    "    post_dig_df_filtered.append(post_dig_exp_df_filtered)\n",
    "\n",
    "    \n",
    "pre_door_df_filtered=pd.concat(pre_door_df_filtered).reset_index(drop=True)\n",
    "pre_dig_df_filtered=pd.concat(pre_dig_df_filtered).reset_index(drop=True)\n",
    "post_dig_df_filtered=pd.concat(post_dig_df_filtered).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12],'theta+beta':[4,30] ,'total': [1, 100]}\n",
    "for band, (band_start, band_end) in bands_dict.items():\n",
    "    pre_door_df_filtered[band + '_' + 'pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    pre_dig_df_filtered[band + '_' + 'pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    post_dig_df_filtered[band + '_' + 'post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "\n",
    "pre_door_df_filtered.to_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered.to_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered.to_pickle(savepath + 'coh_beh_post_dig_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_door_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_post_dig_df.pkl')\n",
    "\n",
    "pre_door_df_filtered=pre_door_df_filtered.drop('pre_door', axis=1)\n",
    "pre_dig_df_filtered=pre_dig_df_filtered.drop('pre_dig', axis=1)\n",
    "post_dig_df_filtered=post_dig_df_filtered.drop('post_dig', axis=1)\n",
    "\n",
    "pre_door_df_filtered.to_csv(savepath + 'coh_beh_pre_door_1000ms.csv')\n",
    "pre_dig_df_filtered.to_csv(savepath + 'coh_beh_pre_dig_1000ms.csv')\n",
    "post_dig_df_filtered.to_csv(savepath + 'coh_beh_post_dig_1000ms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "pre_door_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_post_dig_df.pkl')\n",
    "\n",
    "band = 'beta'\n",
    "event_of_interest = 'pre_dig'\n",
    "\n",
    "event_band = f'{band}_{event_of_interest}'\n",
    "\n",
    "\n",
    "task_experiments = pre_dig_df_filtered.groupby(['task','unique_id'])\n",
    "task_list= pre_dig_df_filtered['task'].unique()\n",
    "print(task_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for task in task_list:\n",
    "    task_data  = pre_dig_df_filtered[pre_dig_df_filtered['task']==task]\n",
    "    ax.scatter(task_data['time_to_dig'], task_data[event_band], label = task)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for task in task_list:\n",
    "    task_data = pre_dig_df_filtered[pre_dig_df_filtered['task'] == task]\n",
    "    unique_experiments = task_data['unique_id'].unique()\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(20, 20))\n",
    "    fig.suptitle(f'{task} - Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "    dk1_i=0\n",
    "    dk3_i=0\n",
    "    dk5_i=0\n",
    "    dk6_i=0\n",
    "    for experiment in unique_experiments:\n",
    "        print(task, experiment)    \n",
    "        task_exp_data =  task_data[task_data['unique_id'] == experiment]\n",
    "        time_to_dig = task_exp_data['time_to_dig']\n",
    "        coherence_value = task_exp_data[event_band]\n",
    "        \n",
    "        rat_id = task_exp_data['rat'].values[0]\n",
    "        if rat_id == 'dk1':\n",
    "            ax = axs[0, dk1_i]\n",
    "            dk1_i += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax = axs[1, dk3_i]\n",
    "            dk3_i += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax = axs[2, dk5_i]\n",
    "            dk5_i += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax = axs[3, dk6_i]\n",
    "            dk6_i += 1\n",
    "        else:\n",
    "            continue  # Skip if rat_id is not one of the specified rats\n",
    "        ax.scatter(time_to_dig, coherence_value, label=experiment)\n",
    "        \n",
    "        ## Plotting Regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(time_to_dig, coherence_value)\n",
    "        ax.plot(time_to_dig, intercept + slope * time_to_dig, color='red', label=f'Fit: y={slope:.2f}x+{intercept:.2f}\\nR={r_value**2:.2f}, p={p_value:.4f}')\n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "                \n",
    "        \n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the short MNE Epochs to coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "for time_window in [0.7]:\n",
    "    behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "    print(behavior_coherence_compiled_data_df_truncated.head())\n",
    "    importlib.reload(coherence_functions)\n",
    "    bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "    for col in ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig']:\n",
    "        print(col)\n",
    "        for band, (band_start, band_end) in bands_dict.items():\n",
    "            behavior_coherence_compiled_data_df_truncated[band + '_' + col] = behavior_coherence_compiled_data_df_truncated[col].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    behavior_coherence_compiled_data_df_truncated.drop(columns=['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig'], inplace=True)\n",
    "    behavior_coherence_compiled_data_df_truncated.to_pickle(savepath+f'\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Coherence vs Time to Dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.7\n",
    "fs=2000\n",
    "from scipy.stats import linregress\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "#behavior_coherence_compiled_data_df_truncated['beta_pre_dig'] = behavior_coherence_compiled_data_df_truncated['beta_pre_dig'] - behavior_coherence_compiled_data_df_truncated['beta_pre_door']\n",
    "#behavior_coherence_compiled_data_df_truncated['theta_pre_dig'] = behavior_coherence_compiled_data_df_truncated['theta_pre_dig'] - behavior_coherence_compiled_data_df_truncated['theta_pre_door']\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3,2,figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig_hist, axs_hist = plt.subplots(3, 2, figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs_hist = axs_hist.flatten()\n",
    "\n",
    "grouped_df=behavior_coherence_compiled_data_df_truncated.groupby(['task'])\n",
    "band='theta'\n",
    "event='around_dig'\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "\n",
    "events_dict ={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig', 'around_door':'Around Door', 'around_dig':'Around Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    ax = axs[i]\n",
    "    ax_hist = axs_hist[i]\n",
    "    print(np.where(behavior_coherence_compiled_data_df_truncated['{}_{}'.format(band,event)]==0))\n",
    "    for task, group in grouped_df:\n",
    "        print(task)\n",
    "        print('{}_{}'.format(band,event))\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)]))>0]\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group = group[(np.abs(group['time_to_dig'] - group['time_to_dig'].mean()) <= (3 * group['time_to_dig'].std()))] # Removing Outliers from Time\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)] - group['{}_{}'.format(band,event)].mean()) <= (3 * group['{}_{}'.format(band,event)].std()))]  #Removing Outliers from Coherence\n",
    "        \n",
    "        #Plotting Regression\n",
    "        sns.regplot(y='time_to_dig', x='{}_{}'.format(band,event), data=group, ax=ax, label=task[0])\n",
    "        y= group['time_to_dig'].values\n",
    "        x= group['{}_{}'.format(band,event)].values\n",
    "        slope, intercept, r, p, se = linregress(x, y)\n",
    "        print(f'{task[0]}: Slope: {slope}, Intercept: {intercept}, R-squared: {r**2}, P-value: {p}')\n",
    "        \n",
    "        ## Plotting Histogram\n",
    "        sns.histplot(group['{}_{}'.format(band,event)], bins=30, kde=True, ax=ax_hist, label=task[0], color=colors[task[0]], stat='density', alpha=0.5)\n",
    "        ax_hist.axvline(group['{}_{}'.format(band,event)].mean(), color=colors[task[0]], linestyle='--', label=f'{task[0]} Mean')\n",
    "        ax_hist.axvline(group['{}_{}'.format(band,event)].median(), color=colors[task[0]], linestyle=':', label=f'{task[0]} Median')\n",
    "    \n",
    "    #Setting Histogram axis labels and title and legend\n",
    "    ax_hist.set_title(f'{events_dict[event]} - {band} Coherence Histogram', fontsize=16)\n",
    "    ax_hist.set_xlabel('Beta Coherence (Z-transformed)', fontsize=14)            \n",
    "    handles, labels = ax_hist.get_legend_handles_labels()\n",
    "    ax_hist.legend()\n",
    "    #ax_hist.legend(handles, [task_dict[l] for l in labels], title='Task', loc='upper right', fontsize=12)    \n",
    "    \n",
    "    \n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    ax.set_xlabel('Beta Coherence (Z-transformed)', fontsize=14)\n",
    "    ax.set_ylabel('Time to Dig (s)', fontsize=14)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, [task_dict[l] for l in labels], title='Task', loc='upper right', fontsize=12)\n",
    "    #ax.legend(title='Task')\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle(f'{band} Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "#fig.savefig(savepath+f'{band}_coherence_vs_time_to_dig_{int(time_window*fs)}.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence vs Time to Dig per rat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.4\n",
    "fs=2000\n",
    "event_of_interest = 'post_dig'\n",
    "band_of_interest = 'gamma'\n",
    "\n",
    "event_band = f'{band_of_interest}_{event_of_interest}'\n",
    "\n",
    "from scipy.stats import linregress\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "task_experiments = behavior_coherence_compiled_data_df_truncated.groupby(['task','unique_id'])\n",
    "task_list= behavior_coherence_compiled_data_df_truncated['task'].unique()\n",
    "print(task_list)\n",
    "for task in task_list:\n",
    "    task_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == task]\n",
    "    unique_experiments = task_data['unique_id'].unique()\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(20, 20))\n",
    "    fig.suptitle(f'{task} - Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "    dk1_i=0\n",
    "    dk3_i=0\n",
    "    dk5_i=0\n",
    "    dk6_i=0\n",
    "    for experiment in unique_experiments:\n",
    "        print(task, experiment)    \n",
    "        task_exp_data =  task_data[task_data['unique_id'] == experiment]\n",
    "        time_to_dig = task_exp_data['time_to_dig']\n",
    "        coherence_value = task_exp_data[event_band]\n",
    "        \n",
    "        rat_id = task_exp_data['rat'].values[0]\n",
    "        if rat_id == 'dk1':\n",
    "            ax = axs[0, dk1_i]\n",
    "            dk1_i += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax = axs[1, dk3_i]\n",
    "            dk3_i += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax = axs[2, dk5_i]\n",
    "            dk5_i += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax = axs[3, dk6_i]\n",
    "            dk6_i += 1\n",
    "        else:\n",
    "            continue  # Skip if rat_id is not one of the specified rats\n",
    "        ax.scatter(time_to_dig, coherence_value, label=experiment)\n",
    "        \n",
    "        ## Plotting Regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(time_to_dig, coherence_value)\n",
    "        ax.plot(time_to_dig, intercept + slope * time_to_dig, color='red', label=f'Fit: y={slope:.2f}x+{intercept:.2f}\\nR={r_value**2:.2f}, p={p_value:.4f}')\n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "                \n",
    "        \n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Coherence through trials as experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_of_interest = 'pre_dig' \n",
    "band_of_interest = 'beta'\n",
    "time_window = 0.4  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "power_per_trial_df = pd.read_excel(savepath+'power_per_trial_mt.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "band_event = band_of_interest+'_'+event_of_interest\n",
    "\n",
    "vmin = behavior_coherence_compiled_data_df_truncated[band_event].min()\n",
    "vmax = behavior_coherence_compiled_data_df_truncated[band_event].max()\n",
    "\n",
    "coherence_bwcontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWcontext']\n",
    "coherence_bwnocontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWnocontext']\n",
    "\n",
    "power_bwcontext_data = power_per_trial_df[power_per_trial_df['task'] == 'BWcontext']\n",
    "power_bwnocontext_data = power_per_trial_df[power_per_trial_df['task'] == 'BWnocontext']\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs = axs.flatten()\n",
    "#task_data_dict = {'BWcontext': coherence_bwcontext_data, 'BWnocontext': coherence_bwnocontext_data}\n",
    "# task_list =[ 'BWcontext', 'BWnocontext']\n",
    "# for axi,(task_name, task_data) in enumerate(task_data_dict.items()):\n",
    "#     print(f\"Task: {task_name}\")\n",
    "#     experiment_ids = task_data['unique_id'].unique()\n",
    "#     print(f\"Number of unique IDs for {task_name}: {len(experiment_ids)}\")\n",
    "#     task_data_dict = {}\n",
    "#     for experiment_idi in experiment_ids:\n",
    "#         experiment_data=task_data[task_data['unique_id'] == experiment_idi]\n",
    "#         rat_date = experiment_idi.split('_')[0] +'_'+experiment_idi.split('_')[1][-8:]\n",
    "#         task_data_dict[rat_date] = experiment_data[band_event].values\n",
    "#     task_data_dict['trials'] = np.arange(start=1,stop=21,step=1, dtype=int)  # Assuming 20 trials per unique ID\n",
    "#     task_data_df = pd.DataFrame.from_dict(task_data_dict, orient='index').T\n",
    "#     task_data_df = task_data_df.fillna(0)  # Fill NaN values with 0\n",
    "#     task_data_df = task_data_df.loc[:, (task_data_df != 0).any(axis=0)]\n",
    "#     ax = axs[axi]\n",
    "#     ax.set_title(f'{task_name} - {band_of_interest} {event_of_interest}', fontsize=16)\n",
    "#     ax.set_xlabel('Trials', fontsize=14)\n",
    "#     ax.set_ylabel(f'{band_of_interest} Coherence (Z-transformed)', fontsize=14)\n",
    "#     sns.heatmap(task_data_df.set_index('trials').T, cmap='Purples', ax=ax, cbar_kws={'label': f'{band_of_interest} Coherence (Z-transformed)'}, vmin=vmin, vmax=vmax)\n",
    "    # If you want to see the unique IDs themselves, uncomment the next line\n",
    "    # print(f\"Unique IDs: {unique_ids}\")\n",
    "aon_power_per_trial_df = power_per_trial_df[power_per_trial_df['channel'] == 'AON']\n",
    "vHp_power_per_trial_df = power_per_trial_df[power_per_trial_df['channel'] == 'vHp']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, constrained_layout=True)    \n",
    "task_list = ['BWcontext', 'BWnocontext']\n",
    "for axi, task_name in enumerate(task_list):\n",
    "    print(f\"Task: {task_name}\")\n",
    "    coherence_task_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == task_name]\n",
    "    aon_power_task_data = aon_power_per_trial_df[aon_power_per_trial_df['task'] == task_name]\n",
    "    vhp_power_task_data = vHp_power_per_trial_df[vHp_power_per_trial_df['task'] == task_name]    \n",
    "    coherence_task_dict = {}\n",
    "    aon_power_task_dict = {}\n",
    "    vhp_power_task_dict = {}\n",
    "    experiment_ids = coherence_task_data['unique_id'].unique()\n",
    "    for experiment_idi in experiment_ids:\n",
    "        \n",
    "        rat_idi = experiment_idi.split('_')[0]\n",
    "        date_idi = experiment_idi.split('_')[1][-8:]\n",
    "        rat_date = rat_idi + '_' + date_idi\n",
    "\n",
    "        coherence_experiment_data=coherence_task_data[coherence_task_data['unique_id'] == experiment_idi]\n",
    "        \n",
    "        ## Power Data\n",
    "        aon_power_experiment_data = aon_power_task_data[aon_power_task_data['unique_id'] == rat_idi+\"_\"+task_name+'_'+date_idi]\n",
    "        vhp_power_experiment_data = vhp_power_task_data[vhp_power_task_data['unique_id'] == rat_idi+\"_\"+task_name+'_'+date_idi]\n",
    "        \n",
    "        aon_power_per_trial_list=[]\n",
    "        vhp_power_per_trial_list=[]\n",
    "        for triali in range(0, 20):\n",
    "            if triali not in aon_power_experiment_data['trial'].values:\n",
    "                print(f\"Trial {triali} not found in AON power data for {experiment_idi}. Skipping...\")\n",
    "                aon_power_per_trial_list.append(0)\n",
    "            else:\n",
    "                aon_power_trial = aon_power_experiment_data[aon_power_experiment_data['trial'] == triali][f'{band_event}_mt'].values\n",
    "                aon_power_per_trial_list.append(aon_power_trial.mean())\n",
    "            \n",
    "            if triali not in vhp_power_experiment_data['trial'].values:\n",
    "                print(f\"Trial {triali} not found in vHp power data for {experiment_idi}. Skipping...\")\n",
    "                vhp_power_per_trial_list.append(0)\n",
    "            else:\n",
    "                vhp_power_trial = vhp_power_experiment_data[vhp_power_experiment_data['trial'] == triali][f'{band_event}_mt'].values\n",
    "                vhp_power_per_trial_list.append(vhp_power_trial.mean())\n",
    "        aon_power_per_trial_list = np.array(aon_power_per_trial_list)\n",
    "        vhp_power_per_trial_list = np.array(vhp_power_per_trial_list)\n",
    "        \n",
    "        coherence_task_dict[rat_date] = coherence_experiment_data[band_event].values\n",
    "        aon_power_task_dict[rat_date] = aon_power_per_trial_list\n",
    "        vhp_power_task_dict[rat_date] = vhp_power_per_trial_list\n",
    "        \n",
    "    def dict_to_df(task_data_dict):\n",
    "        # Exclude 'trials' key from min/max calculation\n",
    "        arrays = [v for k, v in task_data_dict.items() if k != 'trials']\n",
    "        vmin = np.min(np.concatenate(arrays))\n",
    "        vmax = np.max(np.concatenate(arrays))\n",
    "        task_data_dict['trials'] = np.arange(start=1,stop=21,step=1, dtype=int)\n",
    "        task_data_df = pd.DataFrame.from_dict(task_data_dict, orient='index').T\n",
    "        task_data_df = task_data_df.fillna(0)  # Fill NaN values with 0\n",
    "        #task_data_df = task_data_df.loc[:, (task_data_df != 0).any(axis=0)]\n",
    "        return task_data_df, vmin, vmax\n",
    "    task_data_dicts ={ 'Coherence' : coherence_task_dict,\n",
    "                        'AON Power': aon_power_task_dict,\n",
    "                        'vHp Power': vhp_power_task_dict}\n",
    "    for j, (task_data_name, task_data_dict) in enumerate(task_data_dicts.items()):\n",
    "        task_data_df,vmin,vmax = dict_to_df(task_data_dict)\n",
    "        print(f\"Task Data for {task_data_name}:\", vmin, vmax)\n",
    "        ax = axs[j, axi]\n",
    "        ax.set_title(f'{task_name} - {band_of_interest} {event_of_interest} - {task_data_name}', fontsize=16)\n",
    "        ax.set_xlabel('Trials', fontsize=14)\n",
    "        ax.set_ylabel(f'{task_data_name} (Z-transformed)', fontsize=14)\n",
    "        sns.heatmap(task_data_df.set_index('trials').T, cmap='Purples', ax=ax, cbar_kws={'label': f'{task_data_name} (Z-transformed)'}, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xticklabels(task_data_df['trials'], rotation=45)\n",
    "fig.savefig(savepath+f'{band_of_interest}_coherence_power_vs_trials_{event_of_interest}.png', format='png', dpi=600, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Mann Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.4\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_of_interest = 'around_dig' \n",
    "band_of_interest = 'beta'\n",
    "\n",
    "band_event = band_of_interest+'_'+event_of_interest\n",
    "\n",
    "vmin = behavior_coherence_compiled_data_df_truncated[band_event].min()\n",
    "vmax = behavior_coherence_compiled_data_df_truncated[band_event].max()\n",
    "\n",
    "bwcontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWcontext']\n",
    "bwnocontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWnocontext']\n",
    "\n",
    "t,p = scipy.stats.mannwhitneyu(bwcontext_data[band_event], bwnocontext_data[band_event])\n",
    "print(f\"Mann - Whitney U test between BWcontext and BWNocontext for {band_event}: t={t}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Phase Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the short MNE Epochs to Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.7\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "print(behavior_coherence_compiled_data_df_truncated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "bands_dict = {'beta': [12, 30]}#, 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "for col in ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig']:\n",
    "    print(col)\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        behavior_coherence_compiled_data_df_truncated[band + '_' + col] = behavior_coherence_compiled_data_df_truncated[col].apply(lambda x: coherence_functions.convert_epoch_to_phase_behavior(x, band_start=band_start, band_end=band_end))\n",
    "behavior_coherence_compiled_data_df_truncated.drop(columns=['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig'], inplace=True)\n",
    "behavior_coherence_compiled_data_df_truncated.to_pickle(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_phase_compiled_data_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_phase_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3,2,figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "grouped_df=behavior_coherence_compiled_data_df_truncated.groupby(['task'])\n",
    "band='beta'\n",
    "event='around_dig'\n",
    "events_dict ={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig', 'around_door':'Around Door', 'around_dig':'Around Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    ax = axs[i]\n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    print(np.where(behavior_coherence_compiled_data_df_truncated['{}_{}'.format(band,event)]==0))\n",
    "    for task, group in grouped_df:\n",
    "        print(task)\n",
    "        print('{}_{}'.format(band,event))\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)]))>0]\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group['{}_{}'.format(band,event)] = group['{}_{}'.format(band,event)].apply(lambda x: np.arctanh(x))\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group = group[(np.abs(group['time_to_dig'] - group['time_to_dig'].mean()) <= (3 * group['time_to_dig'].std()))]\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)] - group['{}_{}'.format(band,event)].mean()) <= (3 * group['{}_{}'.format(band,event)].std()))]\n",
    "        sns.regplot(x='time_to_dig', y='{}_{}'.format(band,event), data=group, ax=ax, label=task)\n",
    "    ax.set_ylabel('Beta PLI', fontsize=14)\n",
    "    ax.set_xlabel('Time to Dig (s)', fontsize=14)\n",
    "    ax.legend(title='Task')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle(f'Beta pli vs Time to Dig', fontsize=20, y=1.02)\n",
    "#fig.savefig(savepath+'beta_coherence_vs_time_to_dig.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of beta values for each event, comparing BW Context and BW No Context\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "events = list(events_dict.keys())\n",
    "for i, event in enumerate(events):\n",
    "    ax = axs[i]\n",
    "    for task in ['BWcontext', 'BWnocontext']:\n",
    "        data = behavior_coherence_compiled_data_df_truncated[\n",
    "            behavior_coherence_compiled_data_df_truncated['task'] == task\n",
    "        ]['{}_{}'.format(band, event)].dropna()\n",
    "        ax.hist(data, bins=30, alpha=0.6, label=task, density=True)\n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    ax.set_xlabel('Beta Value', fontsize=14)\n",
    "    ax.set_ylabel('Density', fontsize=14)\n",
    "    ax.legend(title='Task')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Histogram of Beta Values per Event', fontsize=20, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Behavior Coherence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.4\n",
    "fs=2000\n",
    "\n",
    "loaded_df=pd.read_pickle(savepath+f'\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "print(loaded_df.head())\n",
    "coherence_band_event_df=loaded_df.loc[:,'beta_pre_door':]\n",
    "print(coherence_band_event_df.columns)\n",
    "group_melted=pd.melt(loaded_df, id_vars=['rat', 'task', 'date', 'trial','correct?', 'time_to_dig'], value_vars=coherence_band_event_df.columns, var_name='band_event', value_name='coherence')\n",
    "group_melted['band']=group_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "group_melted['event']=group_melted['band_event'].apply(lambda x: x.split('_')[1:])\n",
    "group_melted['event']=group_melted['event'].apply(lambda x: x[0]+'_'+x[1])\n",
    "group_melted.drop(columns=['band_event'], inplace=True)\n",
    "group_melted['correct?']=group_melted['correct?'].apply(lambda x: 'Incorrect' if x=='0' else 'Correct')\n",
    "events_list=['pre_door','post_door','pre_dig','post_dig', 'around_door', 'around_dig']\n",
    "writer=pd.ExcelWriter(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.xlsx')\n",
    "for event in events_list:\n",
    "    event_df=group_melted[group_melted['event']==event]\n",
    "    event_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "loaded_df=loaded_df.drop(columns=['around_door_truncated','around_dig_truncated'])\n",
    "writer=pd.ExcelWriter(savepath+f'beh_dig_coh_compiled_{int(time_window*fs/2)}ms.xlsx')\n",
    "loaded_df.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This plots the number of correct vs incorrect trials and the coherence. The idea is to check if the correct trials in general had a higher coherence than incorrect trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bwcontext_df=group_melted[group_melted['task']=='BWcontext']\n",
    "correct_counts = bwcontext_df[bwcontext_df['correct?'] == 'Correct'].shape[0]\n",
    "incorrect_counts = bwcontext_df[bwcontext_df['correct?'] == 'Incorrect'].shape[0]\n",
    "print(f\"Number of Corrects: {correct_counts}\", f\"Number of Incorrects: {incorrect_counts}\", 'bwcontext')\n",
    "bwnocontext_df=group_melted[group_melted['task']=='BWnocontext']\n",
    "correct_counts = bwnocontext_df[bwnocontext_df['correct?'] == 'Correct'].shape[0]\n",
    "incorrect_counts = bwnocontext_df[bwnocontext_df['correct?'] == 'Incorrect'].shape[0]\n",
    "print(f\"Number of Corrects: {correct_counts}\", f\"Number of Incorrects: {incorrect_counts}\", 'bwnocontext')\n",
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, event in enumerate(events_list):\n",
    "    ax=axs[i]\n",
    "    sns.boxplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwcontext_df[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "    sns.stripplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwcontext_df[group_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax, size=1, legend=False)\n",
    "    ax.set_title(event)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.legend(title='Correct?')\n",
    "fig.suptitle(f'BW Context Coherence and Correctness')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_BWcontext.png')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, event in enumerate(events_list):\n",
    "    ax=axs[i]\n",
    "    sns.boxplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwnocontext_df[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "    sns.stripplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwnocontext_df[group_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax, size=1, legend=False)\n",
    "    ax.set_title(event)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.legend(title='Correct?')\n",
    "fig.suptitle(f'BW No Context Coherence and Correctness')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_BWnocontext.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=['BWcontext','BWnocontext']\n",
    "loaded_df['correct?']=loaded_df['correct?'].apply(lambda x: 'Correct' if x=='1' else 'Incorrect')\n",
    "correctness=['Correct','Incorrect']\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10))\n",
    "axs=axs.flatten()\n",
    "axi=0\n",
    "for task in tasks:\n",
    "    for dig_type in correctness:\n",
    "\n",
    "        ax=axs[axi]\n",
    "        task_df=loaded_df[(loaded_df['task']==task) & (loaded_df['correct?']==dig_type)]\n",
    "        events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "        bands=['total','beta','theta','gamma']\n",
    "        \n",
    "        correlation_matrix = np.zeros((len(events_list), len(bands)))\n",
    "\n",
    "        for i, event in enumerate(events_list):\n",
    "            for j, band in enumerate(bands):\n",
    "                column_name = f'{band}_{event}'\n",
    "                correlation_matrix[i, j] = task_df['time_to_dig'].corr(task_df[column_name])\n",
    "        \n",
    "        cax = ax.matshow(correlation_matrix, cmap='coolwarm')\n",
    "        fig.colorbar(cax, ax=ax)\n",
    "\n",
    "        ax.set_xticks(np.arange(len(bands)))\n",
    "        ax.set_yticks(np.arange(len(events_list)))\n",
    "        ax.set_xticklabels(bands)\n",
    "        ax.set_yticklabels(events_list)\n",
    "        ax.set_title(f'{task} {dig_type}')\n",
    "        axi=axi+1\n",
    "fig.tight_layout()\n",
    "# plt.show()\n",
    "# plt.xlabel('Bands')\n",
    "# plt.ylabel('Events')\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()        \n",
    "# bwcontext_df=loaded_df[(loaded_df['task']=='BWcontext') & (loaded_df['correct?']=='0')]\n",
    "# events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "# bands=['total','beta','theta','gamma']\n",
    "\n",
    "# correlation_matrix = np.zeros((len(events_list), len(bands)))\n",
    "\n",
    "# for i, event in enumerate(events_list):\n",
    "#     for j, band in enumerate(bands):\n",
    "#         column_name = f'{band}_{event}'\n",
    "#         correlation_matrix[i, j] = bwcontext_df['time_to_dig'].corr(bwcontext_df[column_name])\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# cax = ax.matshow(correlation_matrix, cmap='coolwarm')\n",
    "# fig.colorbar(cax)\n",
    "\n",
    "# ax.set_xticks(np.arange(len(bands)))\n",
    "# ax.set_yticks(np.arange(len(events_list)))\n",
    "# ax.set_xticklabels(bands)\n",
    "# ax.set_yticklabels(events_list)\n",
    "\n",
    "# plt.xlabel('Bands')\n",
    "# plt.ylabel('Events')\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "loaded_df=pd.read_pickle(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "print(loaded_df.head())\n",
    "loaded_df=loaded_df[loaded_df['rat']!='dk3']\n",
    "print(loaded_df.head())\n",
    "\n",
    "fig, ax=plt.subplots(1,1, figsize=(10,10))\n",
    "tasks=['BWcontext','BWnocontext']\n",
    "loaded_df['correct?']=loaded_df['correct?'].apply(lambda x: 'Correct' if x=='1' else 'Incorrect')\n",
    "correctness=['Correct','Incorrect']\n",
    "bwcontext_incorrect_df=loaded_df[(loaded_df['task']=='BWcontext')]\n",
    "bwnocontext_incorrect_df=loaded_df[(loaded_df['task']=='BWnocontext')]\n",
    "x=bwcontext_incorrect_df['time_to_dig']\n",
    "y=bwcontext_incorrect_df['beta_pre_dig']\n",
    "df = pd.DataFrame({'coherence': y, 'time': x})\n",
    "df.drop(df[df['coherence'] == 0].index, inplace=True)  # Remove rows with coherence = 0\n",
    "\n",
    "try:\n",
    "    correlation_coefficient, p_value = pearsonr(df['coherence'], df['time'])\n",
    "\n",
    "    print(f\"Pearson Correlation Coefficient (r): {correlation_coefficient:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    correlation_coefficient_s, p_value_s = spearmanr(df['coherence'], df['time'])\n",
    "\n",
    "    print(f\"\\nSpearman Rank Correlation Coefficient (rs): {correlation_coefficient_s:.4f}\")\n",
    "    print(f\"P-value: {p_value_s:.4f}\")\n",
    "\n",
    "    # --- Interpretation ---\n",
    "    alpha = 0.05 # Set your significance level\n",
    "    print(f\"\\nSignificance Level (alpha): {alpha}\")\n",
    "\n",
    "    if p_value <= alpha:\n",
    "        print(\"Result: Reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is a statistically significant linear relationship between the variables.\")\n",
    "    else:\n",
    "        print(\"Result: Fail to reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is NOT enough evidence for a statistically significant linear relationship.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure 'coherence_data' and 'time_data' are populated correctly with numerical lists or arrays of the same length.\")\n",
    "# --- Create a Pandas DataFrame ---\n",
    "\n",
    "print(f\"Original number of data points: {len(df)}\")\n",
    "\n",
    "# --- Calculate IQR Fences for BOTH variables ---\n",
    "Q1_coherence = df['coherence'].quantile(0.25)\n",
    "Q3_coherence = df['coherence'].quantile(0.75)\n",
    "IQR_coherence = Q3_coherence - Q1_coherence\n",
    "lower_fence_coherence = Q1_coherence - 1.5 * IQR_coherence\n",
    "upper_fence_coherence = Q3_coherence + 1.5 * IQR_coherence\n",
    "\n",
    "Q1_time = df['time'].quantile(0.25)\n",
    "Q3_time = df['time'].quantile(0.75)\n",
    "IQR_time = Q3_time - Q1_time\n",
    "lower_fence_time = Q1_time - 1.5 * IQR_time\n",
    "upper_fence_time = Q3_time + 1.5 * IQR_time\n",
    "\n",
    "\n",
    "print(\"\\n--- Outlier Fences ---\")\n",
    "print(f\"Coherence: Lower={lower_fence_coherence:.2f}, Upper={upper_fence_coherence:.2f}\")\n",
    "print(f\"Time:      Lower={lower_fence_time:.2f}, Upper={upper_fence_time:.2f}\")\n",
    "\n",
    "# --- Identify outliers (points outside fences for EITHER variable) ---\n",
    "outlier_condition = (\n",
    "    (df['coherence'] < lower_fence_coherence) | (df['coherence'] > upper_fence_coherence) |\n",
    "    (df['time'] < lower_fence_time) | (df['time'] > upper_fence_time)\n",
    ")\n",
    "\n",
    "outliers = df[outlier_condition]\n",
    "print(f\"\\nIdentified {len(outliers)} potential outliers:\")\n",
    "print(outliers)\n",
    "# --- Filter out the outliers ---\n",
    "df_filtered = df[~outlier_condition] # Use ~ to negate the condition, keeping non-outliers\n",
    "print(f\"\\nNumber of data points after removing outliers: {len(df_filtered)}\")\n",
    "\n",
    "\n",
    "# --- Recalculate Correlation on Filtered Data ---\n",
    "if len(df_filtered) > 1: # Need at least 2 points to calculate correlation\n",
    "    # Extract the filtered data columns\n",
    "    coherence_filtered = df_filtered['coherence']\n",
    "    time_filtered = df_filtered['time']\n",
    "\n",
    "    # Calculate original correlation (optional comparison)\n",
    "    try:\n",
    "      original_r, original_p = pearsonr(df['coherence'], df['time'])\n",
    "      print(f\"\\nOriginal Correlation (r): {original_r:.4f}, p-value: {original_p:.4f}\")\n",
    "    except Exception as e:\n",
    "      print(f\"\\nCould not calculate original correlation: {e}\")\n",
    "\n",
    "\n",
    "    # Calculate filtered correlation\n",
    "    try:\n",
    "      filtered_r, filtered_p = pearsonr(coherence_filtered, time_filtered)\n",
    "      print(f\"Filtered Correlation (r): {filtered_r:.4f}, p-value: {filtered_p:.4f}\")\n",
    "\n",
    "      # Interpretation (using alpha = 0.05)\n",
    "      alpha = 0.05\n",
    "      if filtered_p <= alpha:\n",
    "          print(\"Result (Filtered): Reject H0. Statistically significant linear relationship found.\")\n",
    "      else:\n",
    "          print(\"Result (Filtered): Fail to reject H0. No statistically significant linear relationship found.\")\n",
    "    except Exception as e:\n",
    "      print(f\"Could not calculate filtered correlation: {e}\")\n",
    "\n",
    "sns.regplot(y=df['coherence'], x=df['time'], label='Context', ax=ax)\n",
    "sns.regplot(x=bwnocontext_incorrect_df['time_to_dig'], y=bwnocontext_incorrect_df['beta_pre_dig'], label='No context', ax=ax)\n",
    "plt.xlabel('Time to Dig (s)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Coherence', fontsize=20)\n",
    "plt.title('AON-VHP Beta Pre Dig Coherence vs Time to Dig', fontsize=20)\n",
    "plt.legend(fontsize=20) \n",
    "plt.tight_layout()\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\beta_pre_dig_vs_time_to_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# bwcontext_correct_df=loaded_df[(loaded_df['task']=='BWcontext') & (loaded_df['correct?']=='Correct')]\n",
    "# bwnocontext_correct_df=loaded_df[(loaded_df['task']=='BWnocontext') & (loaded_df['correct?']=='Correct')]\n",
    "# sns.regplot(x=bwcontext_correct_df['time_to_dig'], y=bwcontext_correct_df['gamma_pre_dig'], label='BWcontext',robust=True, order=2)\n",
    "# sns.regplot(x=bwnocontext_correct_df['time_to_dig'], y=bwnocontext_correct_df['gamma_pre_dig'], label='BWnocontext',robust=True, order=2)\n",
    "# plt.xlabel('Time to Dig')\n",
    "# plt.ylabel('Beta Pre Dig')\n",
    "# plt.title('Beta Pre Dig vs Time to Dig for Correct Trials')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# --- Plot SVM regression for BWcontext and BWnocontext separately ---\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Prepare data for each task\n",
    "for task_name, color in colors.items():\n",
    "  task_df = loaded_df[(loaded_df['task'] == task_name) & (~outlier_condition)]\n",
    "  if task_df.empty:\n",
    "    print(f\"Skipping {task_name}: no data after outlier removal.\")\n",
    "    continue\n",
    "  X_task = task_df['time_to_dig'].values.reshape(-1, 1)\n",
    "  y_task = task_df['beta_pre_dig'].values\n",
    "\n",
    "  # Fit SVM regression\n",
    "  svm_poly_task = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "  )\n",
    "  svm_poly_task.fit(X_task, y_task)\n",
    "  x_range_task = np.linspace(X_task.min(), X_task.max(), 200).reshape(-1, 1)\n",
    "  y_pred_task = svm_poly_task.predict(x_range_task)\n",
    "\n",
    "  # Scatter and SVM fit\n",
    "  ax2.scatter(X_task, y_task, color=color, alpha=0.5, label=f'{task_name} data')\n",
    "  ax2.plot(x_range_task, y_pred_task, color=color, linestyle='-', linewidth=2, label=f'{task_name} SVM fit')\n",
    "\n",
    "ax2.set_xlabel('Time to Dig (s)', fontsize=20)\n",
    "ax2.set_ylabel('Coherence', fontsize=20)\n",
    "ax2.set_title('SVM Poly Fit: BWcontext vs BWnocontext', fontsize=20)\n",
    "ax2.legend(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Get residuals for each group\n",
    "residuals = {}\n",
    "for task_name in colors.keys():\n",
    "  task_df = loaded_df[(loaded_df['task'] == task_name) & (~outlier_condition)]\n",
    "  if task_df.empty:\n",
    "    print(f\"Skipping {task_name} residuals: no data after outlier removal.\")\n",
    "    continue\n",
    "  X_task = task_df['time_to_dig'].values.reshape(-1, 1)\n",
    "  y_task = task_df['beta_pre_dig'].values\n",
    "  svm_poly_task = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "  )\n",
    "  svm_poly_task.fit(X_task, y_task)\n",
    "  y_pred_task = svm_poly_task.predict(X_task)\n",
    "  residuals[task_name] = y_task - y_pred_task\n",
    "\n",
    "# t-test on residuals (only if both groups have data)\n",
    "if all(k in residuals and len(residuals[k]) > 0 for k in ['BWcontext', 'BWnocontext']):\n",
    "  t_stat, p_val = ttest_ind(residuals['BWcontext'], residuals['BWnocontext'], equal_var=False)\n",
    "  print(f\"Residuals t-test: t={t_stat:.4f}, p={p_val:.4g}\")\n",
    "  if p_val < 0.05:\n",
    "    print(\"Statistically significant difference in SVM fit residuals between BWcontext and BWnocontext.\")\n",
    "  else:\n",
    "    print(\"No statistically significant difference in SVM fit residuals between BWcontext and BWnocontext.\")\n",
    "else:\n",
    "  print(\"Not enough data for both groups to perform residuals t-test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print(f\"Number of data points: {len(df)}\")\n",
    "coherence_data = df['coherence']\n",
    "time_data = df['time']\n",
    "# --- Perform the Spearman Rank Correlation Test ---\n",
    "try:\n",
    "    correlation_coefficient_s, p_value_s = spearmanr(coherence_data, time_data)\n",
    "\n",
    "    print(f\"\\nSpearman Rank Correlation Coefficient (rs): {correlation_coefficient_s:.4f}\")\n",
    "    print(f\"P-value: {p_value_s:.4f}\")\n",
    "\n",
    "    # --- Interpretation ---\n",
    "    alpha = 0.05 # Set your significance level\n",
    "    print(f\"\\nSignificance Level (alpha): {alpha}\")\n",
    "\n",
    "    if p_value_s <= alpha:\n",
    "        print(\"Result: Reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is a statistically significant monotonic relationship between the variables.\")\n",
    "    else:\n",
    "        print(\"Result: Fail to reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is NOT enough evidence for a statistically significant monotonic relationship.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure 'coherence_data' and 'time_data' are populated correctly with numerical lists or arrays of the same length.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
