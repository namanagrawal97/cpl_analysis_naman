{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Importing packages and the functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import getpass\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import functions\n",
    "import lfp_pre_processing_functions\n",
    "import power_functions\n",
    "import coherence_functions\n",
    "import spectrogram_plotting_functions\n",
    "import plotting_styles\n",
    "import scipy.stats\n",
    "import mne_connectivity\n",
    "import mne\n",
    "importlib.reload(functions) #loads our custom made functions.py file\n",
    "importlib.reload(spectrogram_plotting_functions)\n",
    "importlib.reload(plotting_styles)\n",
    "\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Loading the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fetches the current 'user' by using getpass. Then it sets the basepath, loads the files and specifies the savepath. Note that the basepath, files and savepath need to be changed depending on where you have kept the files and where you want the results to be stored. In this case, I have set it up to be in a particular folder in my Dropbox account, which is stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the current user\n",
    "user= (getpass.getuser())\n",
    "print(\"Hello\", user)\n",
    "\n",
    "if user == 'CPLab':\n",
    "    base='D:\\\\Dropbox\\\\CPLab'\n",
    "else:\n",
    "    base='C:\\\\Users\\\\{}\\\\Dropbox\\\\CPLab'.format(user)\n",
    "#Set the basepath, savepath and load the data files\n",
    "files = glob.glob(base+'\\\\all_data_mat_250825\\\\*.mat')\n",
    "savepath = base+'\\\\results\\\\'\n",
    "print(\"Base path:\", base)\n",
    "print(\"Save path:\", savepath)\n",
    "print(files)\n",
    "\n",
    "\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keyboard_dict={'98':'b','119':'w','120':'nc','49':'1','48':'0'} #specifying the map of keyboard annotations to their meanings.\n",
    "all_bands={'total':[1,100],'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "importlib.reload(lfp_pre_processing_functions) #Reloading the lfp_pre_processing_functions module to ensure we have the latest version\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat_filtered\\\\20230615_dk6_BW_context_day1.mat', f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230626_dk6_BW_nocontext_day1.mat'] #This is just for testing purposes\n",
    "time_window=1\n",
    "fs=2000\n",
    "#Initializing a few empty things to store data\n",
    "events_codes_all = {}\n",
    "compiled_data_all_epochs = []\n",
    "compiled_data_list=[]\n",
    "compiled_shuffled_data_list = []\n",
    "baseline_lfp_all = []\n",
    "normalization_comparison_all = []\n",
    "for file in files: #Looping through data files\n",
    "    \n",
    "    ## Get the date, mouse_id and task from the file name\n",
    "    base_name = os.path.basename(file)\n",
    "    base_name, _ = os.path.splitext(base_name)\n",
    "    date, mouse_id, task=lfp_pre_processing_functions.exp_params(base_name) #Using a custom made function [see functions.py]\n",
    "    print(date, mouse_id, task)\n",
    "    if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "        task = 'nocontext'\n",
    "    if task =='nocontext':\n",
    "        continue\n",
    "    f=h5py.File(file, 'r')  ## Open the data file\n",
    "    channels = list(f.keys()) ## Extract channels list from the data file\n",
    "    print(channels)\n",
    "    if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "        continue\n",
    "    events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    events_codes=np.array(events['codes'][0]) #saving the keyboard annotations of the events (door open, door close etc.)\n",
    "    events_times=np.array(events['times'][0]) #saving when the events happened\n",
    "    events_codes_all[base_name] = events_codes #saving the codes in a dictionary to be analyzed later for events other than the ones in our keyboard_dict map\n",
    "    \n",
    "    #Generating epochs from events (epochs are basically start of a trial and end of a trial)\n",
    "    epochs=lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "\n",
    "    # task Start time\n",
    "    first_event=events_times[0]\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "    global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "    \n",
    "    ## Reference electrode finding and padding\n",
    "    reference_time = np.array(reference_electrode['times']).flatten()\n",
    "    reference_value = np.array(reference_electrode['values']).flatten()\n",
    "    padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "\n",
    "    for channeli in channels:\n",
    "        if \"AON\" in channeli or  \"vHp\" in channeli :\n",
    "            \n",
    "            channel_id=channeli\n",
    "            # Extracting raw data and time\n",
    "            data_all=f[channeli]\n",
    "            raw_data=np.array(data_all['values']).flatten()\n",
    "            raw_time = np.array(data_all['times']).flatten()\n",
    "            sampling_rate = 2000\n",
    "            print(channel_id)\n",
    "            print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "            \n",
    "            padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "            subtracted_data = padded_data - padd_ref_data\n",
    "            raw_data=subtracted_data\n",
    "            notch_filtered_data = lfp_pre_processing_functions.iir_notch(raw_data, sampling_rate, 60)\n",
    "            \n",
    "            data_before, time, baseline_mean, baseline_std=lfp_pre_processing_functions.baseline_data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "            first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "\n",
    "            baseline_row=[mouse_id,task,channel_id,np.array(data_before)]\n",
    "            baseline_lfp_all.append(baseline_row)\n",
    "            normalized_data=notch_filtered_data\n",
    "\n",
    "            #Saving non-normalized data and normalized data for plotting\n",
    "            normalization_row=[mouse_id,task,channel_id,[notch_filtered_data[first_event_index:first_event_index+30*sampling_rate]],np.mean(data_before),np.std(data_before),[normalized_data[first_event_index:first_event_index+30*sampling_rate]]]\n",
    "            normalization_comparison_all.append(normalization_row)\n",
    "\n",
    "\n",
    "            for i,epochi in enumerate(epochs):\n",
    "                \n",
    "                compiled_data = pd.DataFrame() # Initializing a dataframe to store the data of a single epoch\n",
    "                compiled_shuffled_data = pd.DataFrame() # Initializing a dataframe to store the shuffled data of a single epoch\n",
    "                door_timestamp = epochi[0][0]\n",
    "                trial_type = epochi[0][1]\n",
    "                dig_type = epochi[1, 1]\n",
    "                dig_timestamp = epochi[1, 0]\n",
    "                print(door_timestamp,trial_type,dig_timestamp,dig_type)\n",
    "                \n",
    "                \n",
    "                data_complete_trial=lfp_pre_processing_functions.extract_complete_trial_data(notch_filtered_data,time,door_timestamp,dig_timestamp,sampling_rate,time_window)\n",
    "                data_trial_before, data_trial_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,door_timestamp,sampling_rate,time_window)\n",
    "                data_dig_before, data_dig_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,dig_timestamp,sampling_rate,time_window)\n",
    "                data_door_around=np.append(data_trial_before, data_trial_after)\n",
    "                data_dig_around=np.append(data_dig_before, data_dig_after)\n",
    "                epoch_data = [data_complete_trial, data_trial_before, data_trial_after, data_dig_before, data_dig_after, data_door_around, data_dig_around]\n",
    "                epoch_data = [lfp_pre_processing_functions.zscore_event_data(x, baseline_std) for x in epoch_data]\n",
    "                shuffled_epoch_data = [np.random.permutation(x) for x in epoch_data]  # Shuffle the epoch data\n",
    "                compiled_data = dict(rat=mouse_id, date=date, task=task, channel=channel_id, trial=i, timestamps=[door_timestamp, dig_timestamp],\n",
    "                                     side=keyboard_dict.get(str(int(trial_type)), ''), correct=keyboard_dict.get(str(int(dig_type)), ''), time=time,\n",
    "                                     **dict(zip(['complete_trial', 'pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig'], epoch_data)))\n",
    "                compiled_shuffled_data = dict(rat=mouse_id, date=date, task=task, channel=channel_id, trial=i, timestamps=[door_timestamp, dig_timestamp],\n",
    "                                     side=keyboard_dict.get(str(int(trial_type)), ''), correct=keyboard_dict.get(str(int(dig_type)), ''), time=time,\n",
    "                                     **dict(zip(['complete_trial', 'pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig'], shuffled_epoch_data)))\n",
    "                compiled_data_list.append(compiled_data)\n",
    "                compiled_shuffled_data_list.append(compiled_shuffled_data)\n",
    "def combine_and_save_data(data_list, name):\n",
    "    compiled_data_all_epochs = []\n",
    "    compiled_data_all_epochs.extend(data_list)\n",
    "    compiled_data_all_epochs = pd.DataFrame(compiled_data_all_epochs)\n",
    "    compiled_data_all_epochs= compiled_data_all_epochs[compiled_data_all_epochs['task']!='nocontext']\n",
    "    compiled_data_all_epochs.to_pickle(savepath+'{}.pkl'.format(name))\n",
    "\n",
    "combine_and_save_data(compiled_data_list, f'compiled_data_all_epochs_truncated_{int(time_window*fs)}')\n",
    "combine_and_save_data(compiled_shuffled_data_list, f'compiled_shuffled_data_all_epochs_truncated_{int(time_window*fs)}')\n",
    "\n",
    "baseline_lfp_all = pd.DataFrame(baseline_lfp_all, columns=['rat', 'task', 'channel', 'data'])\n",
    "baseline_lfp_all.to_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "normalization_comparison_all = pd.DataFrame(normalization_comparison_all, columns=['rat', 'task', 'channel', 'non_normalized_data', 'baseline_mean', 'baseline_std', 'normalized_data'])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Waveform Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Rat 1-100Hz around door and digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "waveform_data_all = compiled_data_all_epochs.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data_all['channel'] = waveform_data_all['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "event_dictionary = {'around_door':'Before and After door open', 'around_dig': 'Before and After Digging'}\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "rat_list=['dk5']\n",
    "for rat in rat_list:\n",
    "    writer=pd.ExcelWriter(os.path.join(savepath, f'{rat}_waveform_data.xlsx'), engine='xlsxwriter')\n",
    "    \n",
    "    waveform_data = waveform_data_all[waveform_data_all['rat'] == rat]\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "    fig.suptitle(f'{rat} LFP (1-100Hz)', fontsize=20)\n",
    "    \n",
    "    subfigs = fig.subfigures(2, 1)\n",
    "    subfigs=subfigs.flatten()\n",
    "    for subfig in subfigs:\n",
    "        subfig.patch.set_edgecolor('black')\n",
    "        subfig.patch.set_linewidth(2)\n",
    "\n",
    "    areas=['AON','vHp']\n",
    "    for outerind, area in enumerate(areas):\n",
    "        subfig=subfigs[outerind]\n",
    "        axs = subfig.subplots(1, 2)\n",
    "        subfig.suptitle(f'{area}', fontsize=16)\n",
    "        waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "        waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "\n",
    "        for innerind, col in enumerate(['around_door', 'around_dig']):\n",
    "            data = np.array(waveform_data_area[col].tolist())  # Ensure data is a numpy array\n",
    "            ax = axs[innerind]  # Correct indexing for axs\n",
    "            ax.set_title(f'{event_dictionary[col]}', fontsize=16)            \n",
    "            sheet_dict={}\n",
    "            for task in (['BWcontext', 'BWnocontext']):\n",
    "                task_data = data[waveform_data_area['task'] == task]\n",
    "                \n",
    "                if len(task_data) > 0:\n",
    "                    task_data = np.array([functions.freq_band(row, all_bands_dict['total'][0], all_bands_dict['total'][1], 2000) for row in task_data])\n",
    "                    data_mean = np.mean(task_data, axis=0)\n",
    "                    data_sem = scipy.stats.sem(task_data, axis=0)\n",
    "                    time_axis = np.linspace(-0.7, 0.7, len(data_mean))\n",
    "                    ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                    ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "                    sheet_dict[f'{task}_mean'] = data_mean\n",
    "                    sheet_dict[f'{task}_sem'] = data_sem\n",
    "            sheet_dict['time'] = time_axis\n",
    "            sheet_df=pd.DataFrame(sheet_dict)\n",
    "            sheet_df.to_excel(writer, sheet_name=f'{area}_{col}', index=False)\n",
    "            ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "            ax.set_xlabel('Time (s)', fontsize=14)\n",
    "            ax.set_ylabel('Amplitude (uV)', fontsize=14)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "            #ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    #writer.close()\n",
    "    #fig.savefig(os.path.join(savepath,f' LFP_total_waveform_{rat}'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All rats alls bands around door and digging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "rat_list=list(np.unique(compiled_data_all_epochs['rat']))\n",
    "window = [-2, 2]  # Set the window for the waveform\n",
    "\n",
    "#band = 'total'  # Insert the band of interest\n",
    "tasks = ['BWcontext', 'BWnocontext']\n",
    "areas=['AON','vHp']\n",
    "compiled_data_all_epochs['around_door'] = compiled_data_all_epochs['pre_door'].apply(lambda x: x.tolist()) + compiled_data_all_epochs['post_door'].apply(lambda x: x.tolist())\n",
    "compiled_data_all_epochs['around_dig'] = compiled_data_all_epochs['pre_dig'].apply(lambda x: x.tolist()) + compiled_data_all_epochs['post_dig'].apply(lambda x: x.tolist())\n",
    "print(np.array(compiled_data_all_epochs['around_door'][0]).shape, np.array(compiled_data_all_epochs['around_dig'][0]).shape)\n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "\n",
    "for rati in rat_list:\n",
    "    rat_dict = {}\n",
    "    rat_data = compiled_data_all_epochs[compiled_data_all_epochs['rat'] == rati]\n",
    "    rat_data['channel']=rat_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    rat_data = rat_data.reset_index(drop=True)\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(10, 10))    \n",
    "    subfigs = fig.subfigures(2, 1)\n",
    "    subfigs=subfigs.flatten()\n",
    "    subfigs[1].set_facecolor('0.85')\n",
    "    fig.suptitle(f'{rati}')\n",
    "    \n",
    "    for outerind, area in enumerate(areas):\n",
    "        subfig=subfigs[outerind]\n",
    "        axs = subfig.subplots(4, 2)\n",
    "        \n",
    "        rat_data_area = rat_data[rat_data['channel'] == area]\n",
    "        rat_data_area = rat_data_area.reset_index(drop=True)   \n",
    "    \n",
    "        for i, band in enumerate(all_bands_dict.keys()):\n",
    "            rat_data_band=rat_data_area.__deepcopy__()\n",
    "            for col in (['around_door', 'around_dig']):\n",
    "                rat_data_band[col] = rat_data_area[col].apply(lambda x: functions.freq_band(x, all_bands_dict[band][0], all_bands_dict[band][1], 2000))\n",
    "\n",
    "            rat_data_band_grouped = rat_data_band.groupby(['task', 'channel'])\n",
    "            for (task, channel), group in rat_data_band_grouped:\n",
    "                group=group.reset_index(drop=True)\n",
    "                print(group.shape)\n",
    "                #group['around_dig']=np.concatenate([group['pre_dig'], group['post_dig']], axis=1)\n",
    "                for j, col in enumerate(['around_door', 'around_dig']):\n",
    "                    data = np.array(group[col])\n",
    "                    data_mean = np.mean(data, axis=0)\n",
    "                    data_sem = scipy.stats.sem(data, axis=0)\n",
    "                    time_axis = np.linspace(-0.7, 0.7, len(data_mean))\n",
    "                    ax = axs[i, j]\n",
    "                    ax.set_title(f'{band} {channel} {col}')\n",
    "                    ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                    ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "                    ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "    #fig.savefig(os.path.join(savepath,f' LFP_waveform{rati}'), dpi=300)\n",
    "    plt.show()\n",
    "    #plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged across rats single band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = compiled_data_all_epochs.copy()\n",
    "waveform_data['channel'] = waveform_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "event_dictionary = {'around_door':'Before and After door open', 'around_dig': 'Before and After Digging'}\n",
    "fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "fig.suptitle(f'raw LFP averaged across rats', fontsize=20)\n",
    "\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "subfigs=subfigs.flatten()\n",
    "for subfig in subfigs:\n",
    "    subfig.patch.set_edgecolor('black')\n",
    "    subfig.patch.set_linewidth(0.5)\n",
    "areas=['AON','vHp']\n",
    "for outerind, area in enumerate(areas):\n",
    "    subfig=subfigs[outerind]\n",
    "    axs = subfig.subplots(1, 2)\n",
    "    subfig.suptitle(f'{area}', fontsize= 16) \n",
    "    waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "    waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "\n",
    "    for innerind, col in enumerate(['around_door', 'around_dig']):\n",
    "        data = np.array(waveform_data_area[col].tolist())  # Ensure data is a numpy array\n",
    "        ax = axs[innerind]  # Correct indexing for axs\n",
    "        ax.set_title(f'{event_dictionary[col]}', fontsize=14)\n",
    "        for task in (['BWcontext', 'BWnocontext']):\n",
    "            task_data = data[waveform_data_area['task'] == task]\n",
    "            if len(task_data) > 0:\n",
    "            \n",
    "                data_mean = np.mean(task_data, axis=0)\n",
    "                data_sem = scipy.stats.sem(task_data, axis=0)\n",
    "                time_axis = np.linspace(-2, 2, len(data_mean))\n",
    "                \n",
    "                ax.plot(time_axis, data_mean, color=plotting_styles.colors[task])\n",
    "                ax.fill_between(time_axis, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "        ax.set_xlabel('Time (s)', fontsize=14)\n",
    "        ax.set_ylabel('Amplitude (uV)', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "#fig.savefig(os.path.join(savepath,f' LFP_raw_waveform_averaged'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged across rats all bands (To be Deleted later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data = compiled_data_all_epochs.copy()\n",
    "waveform_data['channel'] = waveform_data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "waveform_data = waveform_data.reset_index(drop=True)\n",
    "fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "subfigs = fig.subfigures(2, 1)\n",
    "subfigs=subfigs.flatten()\n",
    "subfigs[1].set_facecolor('0.85')\n",
    "fig.suptitle(f'Waveform')\n",
    "\n",
    "for i, band in enumerate(all_bands_dict.keys()):\n",
    "    print(band)\n",
    "\n",
    "waveform_data_grouped = waveform_data.groupby(['task', 'channel'])\n",
    "for outerind, area in enumerate(areas):\n",
    "    subfig=subfigs[outerind]\n",
    "    axs = subfig.subplots(4, 2)\n",
    "    waveform_data_area = waveform_data[waveform_data['channel'] == area]\n",
    "    waveform_data_area = waveform_data_area.reset_index(drop=True)\n",
    "    \n",
    "    for i, band in enumerate(all_bands_dict.keys()):\n",
    "        for col in (['around_door', 'around_dig']):\n",
    "            waveform_data_area[col+'_'+band] = waveform_data_area[col].apply(lambda x: functions.freq_band(x, all_bands_dict[band][0], all_bands_dict[band][1], 2000))\n",
    "\n",
    "        data = waveform_data_area[[f'around_door_{band}', f'around_dig_{band}']]\n",
    "        data_mean = data.groupby(waveform_data_area['task']).mean() \n",
    "        data_sem = data.groupby(waveform_data_area['task']).sem()\n",
    "        time_axis = np.linspace(-2, 2, len(data_mean.columns))\n",
    "        for j, task in enumerate(tasks):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_title(f'{band} {task}')\n",
    "            ax.plot(time_axis, data_mean.loc[task], color=plotting_styles.colors[task])\n",
    "            ax.fill_between(time_axis, data_mean.loc[task] - data_sem.loc[task], data_mean.loc[task] + data_sem.loc[task], alpha=0.2, color=plotting_styles.colors[task])\n",
    "            ax.vlines(0, ax.get_ylim()[0], ax.get_ylim()[1], color='k', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting waveform using MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 1\n",
    "fs =2000\n",
    "lfp_data = pd.read_pickle(savepath +f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "test_epoch = lfp_data['mne_epoch_door_before'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "epochs_filtered = test_epoch.copy().filter(\n",
    "    l_freq=4, \n",
    "    h_freq=12, \n",
    "    method='iir',\n",
    "    iir_params={'order': 4, 'ftype': 'butter'}\n",
    ")\n",
    "\n",
    "def get_epoch_lfp_single(test_epoch, time_window):\n",
    "    channels = list(test_epoch.ch_names)\n",
    "    aon_channels = [channel for channel in channels if \"AON\" in channel]\n",
    "    vhp_channels = [channel for channel in channels if \"vHp\" in channel]\n",
    "    test_epoch_aon = test_epoch.get_data(picks=aon_channels)\n",
    "    test_epoch_vhp = test_epoch.get_data(picks=vhp_channels)\n",
    "    test_epoch_aon_mean = list(np.mean(test_epoch_aon, axis=(0,1)))\n",
    "    test_epoch_vhp_mean = list(np.mean(test_epoch_vhp, axis = (0,1)))\n",
    "    times = np.linspace(0, time_window, len(test_epoch_aon_mean))\n",
    "    return test_epoch_aon_mean, test_epoch_vhp_mean, times\n",
    "\n",
    "def get_epoch_lfp_single(test_epoch, time_window, trial_num):\n",
    "    channels = list(test_epoch.ch_names)\n",
    "    aon_channels = [channel for channel in channels if \"AON\" in channel]\n",
    "    vhp_channels = [channel for channel in channels if \"vHp\" in channel]\n",
    "    test_epoch_aon = test_epoch.get_data(picks=aon_channels)\n",
    "    test_epoch_vhp = test_epoch.get_data(picks=vhp_channels)\n",
    "    test_epoch_aon = list(test_epoch_aon[trial_num,0,:])\n",
    "    test_epoch_vhp = list(test_epoch_vhp[trial_num,0,:])\n",
    "    times = list(np.linspace(0, time_window, len(test_epoch_aon)))\n",
    "    return test_epoch_aon, test_epoch_vhp, times\n",
    "\n",
    "\n",
    "total_aon, total_vhp, total_time = get_epoch_lfp_single(test_epoch, time_window=1, trial_num=0)\n",
    "beta_aon, beta_vhp, beta_time = get_epoch_lfp_single(epochs_filtered, time_window=1, trial_num=0)\n",
    "\n",
    "total_aon_single, total_vhp_single, total_time_single = get_epoch_lfp_single(test_epoch, time_window=1, trial_num=0)\n",
    "beta_aon_single, beta_vhp_single, beta_time_single = get_epoch_lfp_single(epochs_filtered, time_window=1, trial_num=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize =(15,5))\n",
    "\n",
    "ax.plot(total_time_single, total_aon_single, label ='total', color = 'blue')\n",
    "ax.plot(total_time_single, total_vhp_single, label =\"beta\", color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=1\n",
    "fs=2000\n",
    "trial_num =4\n",
    "## Potential Candidates - 3, \n",
    "lfp_data = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "dk6_bwcontext = lfp_data[(lfp_data['rat_id']=='dk6') & (lfp_data['task']=='BWcontext')]\n",
    "dk6_bwnocontext = lfp_data[(lfp_data['rat_id']=='dk6') & (lfp_data['task']=='BWnocontext')]\n",
    "\n",
    "\n",
    "event_dict = {\n",
    "    'mne_epoch_door_before': 'Before Door',\n",
    "    'mne_epoch_dig_before': 'Before Dig',\n",
    "    'mne_epoch_dig_after': 'After Dig'\n",
    "}\n",
    "all_bands_dict = {\n",
    "    'total': [1, 100],\n",
    "    'theta': [4, 12],\n",
    "    'beta': [12, 30],\n",
    "    'gamma': [30, 80]\n",
    "}\n",
    "time_window = 1.0\n",
    "\n",
    "def filter_epoch(epoch, l_freq, h_freq):\n",
    "    \"\"\"Apply bandpass filter to epoch\"\"\"\n",
    "    return epoch.copy().filter(\n",
    "        l_freq=l_freq,\n",
    "        h_freq=h_freq,\n",
    "        method='iir',\n",
    "        iir_params={'order': 4, 'ftype': 'butter'}\n",
    "    )\n",
    "    \n",
    "aon_fig, aon_axs = plt.subplots(4, 3, figsize=(15, 16), sharey='row')\n",
    "aon_fig.suptitle('AON LFP')\n",
    "aon_writer = pd.ExcelWriter(savepath + f'lfp_events_aon_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "vhp_fig, vhp_axs = plt.subplots(4, 3, figsize=(15, 16), sharey='row')\n",
    "vhp_fig.suptitle('vHC LFP')\n",
    "vhp_writer = pd.ExcelWriter(savepath + f'lfp_events_vhp_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "bwcontext_fig, bwcontext_axs = plt.subplots(4, 3, figsize=(15, 16), sharey='row')\n",
    "bwcontext_fig.suptitle('Context LFP')\n",
    "bwcontext_writer = pd.ExcelWriter(savepath + f'lfp_events_bwcontext_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "bwnocontext_fig, bwnocontext_axs = plt.subplots(4, 3, figsize=(15, 16), sharey='row')\n",
    "bwnocontext_fig.suptitle('No Context LFP')\n",
    "bwnocontext_writer = pd.ExcelWriter(savepath + f'lfp_events_bwnocontext_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "for event_idx, event in enumerate(event_dict.keys()):\n",
    "    aon_dict = {}\n",
    "    vhp_dict = {}\n",
    "    \n",
    "    bwcontext_dict = {}\n",
    "    bwnocontext_dict={}\n",
    "    \n",
    "    bwcontext_epoch_object = dk6_bwcontext[event].iloc[0]\n",
    "    bwnocontext_epoch_object = dk6_bwnocontext[event].iloc[0]\n",
    "    \n",
    "    print(bwcontext_epoch_object)\n",
    "    \n",
    "    for band_idx, (band_name, (l_freq, h_freq)) in enumerate(all_bands_dict.items()):\n",
    "        print(f\"  Processing {band_name} band ({l_freq}-{h_freq} Hz)\")\n",
    "        bwcontext_epoch_object_filtered = filter_epoch(bwcontext_epoch_object, l_freq, h_freq)\n",
    "        bwnocontext_epoch_object_filtered = filter_epoch(bwnocontext_epoch_object, l_freq, h_freq) \n",
    "        \n",
    "        aon_bwcontext,vhp_bwcontext,time_bwcontext = get_epoch_lfp_single(bwcontext_epoch_object_filtered, time_window, trial_num)\n",
    "        aon_bwnocontext,vhp_bwnocontext,time_bwnocontext = get_epoch_lfp_single(bwnocontext_epoch_object_filtered, time_window, trial_num)\n",
    "        \n",
    "        #==============Plot AON====================================\n",
    "        \n",
    "        ax_aon = aon_axs[band_idx, event_idx]\n",
    "        ax_aon.plot(time_bwcontext, aon_bwcontext, label='Context', linewidth=2, color='blue')\n",
    "        ax_aon.plot(time_bwnocontext, aon_bwnocontext, label='No Context', linewidth=2, color='Orange')\n",
    "        \n",
    "        if event_idx == 0:\n",
    "            ax_aon.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (mV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_aon.set_title(f'{event_dict[event]}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_aon.set_xlabel('Time (s)', fontsize=10)\n",
    "        ax_aon.legend(loc='best', fontsize=8)\n",
    "\n",
    "        #==============Plot vHp====================================\n",
    "        \n",
    "        ax_vhp = vhp_axs[band_idx, event_idx]\n",
    "        ax_vhp.plot(time_bwcontext, vhp_bwcontext, label='Context', linewidth=2, color='blue')\n",
    "        ax_vhp.plot(time_bwnocontext, vhp_bwnocontext, label='No Context', linewidth=2, color='Orange')\n",
    "        \n",
    "        if event_idx == 0:\n",
    "            ax_vhp.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (mV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_vhp.set_title(f'{event_dict[event]}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_vhp.set_xlabel('Time (s)', fontsize=10)\n",
    "        ax_vhp.legend(loc='best', fontsize=8)\n",
    "\n",
    "        #====================Plotting BW Context ==================\n",
    "        ax_bwcontext = bwcontext_axs[band_idx, event_idx]\n",
    "        ax_bwcontext.plot(time_bwcontext, aon_bwcontext, label='AON', linewidth=2, color='blue')\n",
    "        ax_bwcontext.plot(time_bwcontext, vhp_bwcontext, label='vHp', linewidth=2, color='Orange')\n",
    "        \n",
    "        if event_idx == 0:\n",
    "            ax_bwcontext.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (mV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_bwcontext.set_title(f'{event_dict[event]}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_bwcontext.set_xlabel('Time (s)', fontsize=10)\n",
    "        ax_bwcontext.legend(loc='best', fontsize=8)\n",
    "        #====================Plotting BW No Context ==================\n",
    "        ax_bwnocontext = bwnocontext_axs[band_idx, event_idx]\n",
    "        ax_bwnocontext.plot(time_bwnocontext, aon_bwnocontext, label='AON', linewidth=2, color='blue')\n",
    "        ax_bwnocontext.plot(time_bwnocontext, vhp_bwnocontext, label='vHp', linewidth=2, color='Orange')\n",
    "        \n",
    "        if event_idx == 0:\n",
    "            ax_bwnocontext.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (mV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_bwnocontext.set_title(f'{event_dict[event]}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_bwnocontext.set_xlabel('Time (s)', fontsize=10)\n",
    "        ax_bwnocontext.legend(loc='best', fontsize=8)\n",
    "\n",
    "        #=================Saving in AON -vHp CSV===================\n",
    "        if time_bwcontext==time_bwnocontext:\n",
    "            aon_dict['time'] = time_bwcontext\n",
    "        else:\n",
    "            print(\"WTF Why are times different\")\n",
    "            break\n",
    "        aon_dict[f'bwcontext_{band_name}'] = aon_bwcontext\n",
    "        aon_dict[f'bwnocontext_{band_name}'] = aon_bwnocontext\n",
    "        \n",
    "        if time_bwcontext==time_bwnocontext:\n",
    "            vhp_dict['time'] = time_bwcontext\n",
    "        else:\n",
    "            print(\"WTF Why are times different\")\n",
    "            break\n",
    "        vhp_dict[f'bwcontext_{band_name}'] = vhp_bwcontext\n",
    "        vhp_dict[f'bwnocontext_{band_name}'] = vhp_bwnocontext\n",
    "        \n",
    "        aon_df = pd.DataFrame(aon_dict)\n",
    "        vhp_df = pd.DataFrame(vhp_dict)\n",
    "        \n",
    "        aon_df.to_excel(aon_writer, sheet_name=event_dict[event])\n",
    "        vhp_df.to_excel(vhp_writer, sheet_name=event_dict[event])\n",
    "\n",
    "        #=================Saving in Context - NoContext CSV===================\n",
    "        if time_bwcontext==time_bwnocontext:\n",
    "            bwcontext_dict['time'] = time_bwcontext\n",
    "        else:\n",
    "            print(\"WTF Why are times different\")\n",
    "            break\n",
    "        bwcontext_dict[f'aon_{band_name}'] = aon_bwcontext\n",
    "        bwcontext_dict[f'vhp_{band_name}'] = vhp_bwcontext\n",
    "        \n",
    "        if time_bwcontext==time_bwnocontext:\n",
    "            vhp_dict['time'] = time_bwcontext\n",
    "        else:\n",
    "            print(\"WTF Why are times different\")\n",
    "            break\n",
    "        bwnocontext_dict[f'aon_{band_name}'] = aon_bwnocontext\n",
    "        bwnocontext_dict[f'vhp_{band_name}'] = vhp_bwnocontext\n",
    "                \n",
    "        bwcontext_df = pd.DataFrame(bwcontext_dict)\n",
    "        bwnocontext_df = pd.DataFrame(bwnocontext_dict)\n",
    "        \n",
    "        bwcontext_df.to_excel(bwcontext_writer, sheet_name=event_dict[event])\n",
    "        bwnocontext_df.to_excel(bwnocontext_writer, sheet_name=event_dict[event])\n",
    "\n",
    "aon_writer.close()\n",
    "vhp_writer.close()\n",
    "bwcontext_writer.close()\n",
    "bwnocontext_writer.close()\n",
    "\n",
    "aon_fig.savefig(savepath+f'lfp_events_aon_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "vhp_fig.savefig(savepath+f'lfp_events_vhp_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "bwcontext_fig.savefig(savepath+f'lfp_events_bwcontext_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "bwnocontext_fig.savefig(savepath+f'lfp_events_bwnocontext_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aon_fig, aon_axs = plt.subplots(4, 3, figsize=(15, 16))\n",
    "vhp_fig, vhp_axs = plt.subplots(4, 3, figsize=(15, 16))\n",
    "\n",
    "# Process each frequency band\n",
    "for band_idx, (band_name, (l_freq, h_freq)) in enumerate(all_bands_dict.items()):\n",
    "    print(f\"  Processing {band_name} band ({l_freq}-{h_freq} Hz)\")\n",
    "    \n",
    "    # Process each event type\n",
    "    for event_idx, (col, event_name) in enumerate(event_dict.items()):\n",
    "        \n",
    "        # Filter and process context data\n",
    "        if len(dk6_bwcontext) > 0:\n",
    "            context_filtered = filter_epoch(dk6_bwcontext[col], l_freq, h_freq)\n",
    "\n",
    "            context_results = get_epoch_lfp_single(context_filtered, time_window)\n",
    "            \n",
    "            # Extract components correctly\n",
    "            context_times = np.array(context_results.iloc[0][2])\n",
    "            context_aon_list = [result[0] for result in context_results]\n",
    "            context_vhp_list = [result[1] for result in context_results]\n",
    "            \n",
    "            context_aon_means = np.array(context_aon_list)\n",
    "            context_vhp_means = np.array(context_vhp_list)\n",
    "            \n",
    "            context_aon_avg = np.mean(context_aon_means, axis=0)\n",
    "            context_aon_sem = np.std(context_aon_means, axis=0) / np.sqrt(len(context_aon_means))\n",
    "            \n",
    "            context_vhp_avg = np.mean(context_vhp_means, axis=0)\n",
    "            context_vhp_sem = np.std(context_vhp_means, axis=0) / np.sqrt(len(context_vhp_means))\n",
    "        \n",
    "        # Filter and process no context data\n",
    "        if len(dk6_bwnocontext) > 0:\n",
    "            nocontext_filtered = filter_epoch(dk6_bwnocontext[col], l_freq, h_freq)\n",
    "\n",
    "            nocontext_results = get_epoch_lfp_single(nocontext_filtered, time_window)\n",
    "            \n",
    "            # Extract components correctly\n",
    "            nocontext_times = np.array(nocontext_results.iloc[0][2])\n",
    "            nocontext_aon_list = [result[0] for result in nocontext_results]\n",
    "            nocontext_vhp_list = [result[1] for result in nocontext_results]\n",
    "            \n",
    "            nocontext_aon_means = np.array(nocontext_aon_list)\n",
    "            nocontext_vhp_means = np.array(nocontext_vhp_list)\n",
    "            \n",
    "            nocontext_aon_avg = np.mean(nocontext_aon_means, axis=0)\n",
    "            nocontext_aon_sem = np.std(nocontext_aon_means, axis=0) / np.sqrt(len(nocontext_aon_means))\n",
    "            \n",
    "            nocontext_vhp_avg = np.mean(nocontext_vhp_means, axis=0)\n",
    "            nocontext_vhp_sem = np.std(nocontext_vhp_means, axis=0) / np.sqrt(len(nocontext_vhp_means))\n",
    "        \n",
    "        # ============ AON PLOTS ============\n",
    "        ax_aon = aon_axs[band_idx, event_idx]\n",
    "        \n",
    "        if len(dk6_bwcontext) > 0:\n",
    "            ax_aon.plot(context_times, context_aon_avg, label='Context', linewidth=2, color='blue')\n",
    "            ax_aon.fill_between(\n",
    "                context_times,\n",
    "                context_aon_avg - context_aon_sem,\n",
    "                context_aon_avg + context_aon_sem,\n",
    "                alpha=0.3,\n",
    "                color='blue'\n",
    "            )\n",
    "        \n",
    "        if len(dk6_bwnocontext) > 0:\n",
    "            ax_aon.plot(nocontext_times, nocontext_aon_avg, label='No Context', linewidth=2, color='orange')\n",
    "            ax_aon.fill_between(\n",
    "                nocontext_times,\n",
    "                nocontext_aon_avg - nocontext_aon_sem,\n",
    "                nocontext_aon_avg + nocontext_aon_sem,\n",
    "                alpha=0.3,\n",
    "                color='orange'\n",
    "            )\n",
    "        \n",
    "        # Formatting for AON\n",
    "        if event_idx == 0:\n",
    "            ax_aon.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (μV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_aon.set_title(f'{event_name}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_aon.set_xlabel('Time (s)', fontsize=10)\n",
    "        \n",
    "        ax_aon.legend(loc='best', fontsize=8)\n",
    "        ax_aon.grid(True, alpha=0.3)\n",
    "        ax_aon.axvline(x=0, color='k', linestyle='--', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        # ============ vHp PLOTS ============\n",
    "        ax_vhp = vhp_axs[band_idx, event_idx]\n",
    "        \n",
    "        if len(dk6_bwcontext) > 0:\n",
    "            ax_vhp.plot(context_times, context_vhp_avg, label='Context', linewidth=2, color='blue')\n",
    "            ax_vhp.fill_between(\n",
    "                context_times,\n",
    "                context_vhp_avg - context_vhp_sem,\n",
    "                context_vhp_avg + context_vhp_sem,\n",
    "                alpha=0.3,\n",
    "                color='blue'\n",
    "            )\n",
    "        \n",
    "        if len(dk6_bwnocontext) > 0:\n",
    "            ax_vhp.plot(nocontext_times, nocontext_vhp_avg, label='No Context', linewidth=2, color='orange')\n",
    "            ax_vhp.fill_between(\n",
    "                nocontext_times,\n",
    "                nocontext_vhp_avg - nocontext_vhp_sem,\n",
    "                nocontext_vhp_avg + nocontext_vhp_sem,\n",
    "                alpha=0.3,\n",
    "                color='orange'\n",
    "            )\n",
    "        \n",
    "        # Formatting for vHp\n",
    "        if event_idx == 0:\n",
    "            ax_vhp.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (μV)', fontsize=10)\n",
    "        if band_idx == 0:\n",
    "            ax_vhp.set_title(f'{event_name}', fontsize=11, fontweight='bold')\n",
    "        if band_idx == 3:\n",
    "            ax_vhp.set_xlabel('Time (s)', fontsize=10)\n",
    "        \n",
    "        ax_vhp.legend(loc='best', fontsize=8)\n",
    "        ax_vhp.grid(True, alpha=0.3)\n",
    "        ax_vhp.axvline(x=0, color='k', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Add overall titles and adjust layout\n",
    "aon_fig.suptitle(f'Rat {rat} - AON LFP Analysis (Frequency Bands)', fontsize=14, fontweight='bold', y=0.995)\n",
    "vhp_fig.suptitle(f'Rat {rat} - vHp LFP Analysis (Frequency Bands)', fontsize=14, fontweight='bold', y=0.995)\n",
    "\n",
    "aon_fig.tight_layout()\n",
    "vhp_fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "lfp_data = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "rat_list = np.unique(lfp_data['rat_id'])\n",
    "print(f\"Processing {len(rat_list)} rats: {rat_list}\")\n",
    "\n",
    "# Define events and parameters\n",
    "event_dict = {\n",
    "    'mne_epoch_door_before': 'Before Door',\n",
    "    'mne_epoch_dig_before': 'Before Dig',\n",
    "    'mne_epoch_dig_after': 'After Dig'\n",
    "}\n",
    "all_bands_dict = {\n",
    "    'total': [1, 100],\n",
    "    'theta': [4, 12],\n",
    "    'beta': [12, 30],\n",
    "    'gamma': [30, 80]\n",
    "}\n",
    "time_window = 1.0\n",
    "\n",
    "def filter_epoch(epoch, l_freq, h_freq):\n",
    "    \"\"\"Apply bandpass filter to epoch\"\"\"\n",
    "    return epoch.copy().filter(\n",
    "        l_freq=l_freq,\n",
    "        h_freq=h_freq,\n",
    "        method='iir',\n",
    "        iir_params={'order': 4, 'ftype': 'butter'}\n",
    "    )\n",
    "\n",
    "# Process each rat\n",
    "for rat in rat_list:\n",
    "    print(f\"Processing rat: {rat}\")\n",
    "    \n",
    "    # Filter data for current rat\n",
    "    rat_data = lfp_data[lfp_data['rat_id'] == rat].copy()\n",
    "    \n",
    "    # Separate data by task and reset index\n",
    "    bwcontext_data = rat_data[rat_data['task'] == 'BWcontext'].copy().reset_index(drop=True)\n",
    "    bwnocontext_data = rat_data[rat_data['task'] == 'BWnocontext'].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Skip if no data for this rat\n",
    "    if len(bwcontext_data) == 0 and len(bwnocontext_data) == 0:\n",
    "        print(f\"  No data for rat {rat}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Create separate figures for AON and vHp with 4 rows (one per band)\n",
    "    aon_fig, aon_axs = plt.subplots(4, 3, figsize=(15, 16))\n",
    "    vhp_fig, vhp_axs = plt.subplots(4, 3, figsize=(15, 16))\n",
    "    \n",
    "    # Process each frequency band\n",
    "    for band_idx, (band_name, (l_freq, h_freq)) in enumerate(all_bands_dict.items()):\n",
    "        print(f\"  Processing {band_name} band ({l_freq}-{h_freq} Hz)\")\n",
    "        \n",
    "        # Process each event type\n",
    "        for event_idx, (col, event_name) in enumerate(event_dict.items()):\n",
    "            \n",
    "            # Filter and process context data\n",
    "            if len(bwcontext_data) > 0:\n",
    "                context_filtered = bwcontext_data[col].apply(\n",
    "                    lambda epoch: filter_epoch(epoch, l_freq, h_freq)\n",
    "                )\n",
    "                context_results = context_filtered.apply(\n",
    "                    lambda epoch: get_epoch_lfp_single(epoch, time_window)\n",
    "                )\n",
    "                \n",
    "                # Extract components correctly\n",
    "                context_times = np.array(context_results.iloc[0][2])\n",
    "                context_aon_list = [result[0] for result in context_results]\n",
    "                context_vhp_list = [result[1] for result in context_results]\n",
    "                \n",
    "                context_aon_means = np.array(context_aon_list)\n",
    "                context_vhp_means = np.array(context_vhp_list)\n",
    "                \n",
    "                context_aon_avg = np.mean(context_aon_means, axis=0)\n",
    "                context_aon_sem = np.std(context_aon_means, axis=0) / np.sqrt(len(context_aon_means))\n",
    "                \n",
    "                context_vhp_avg = np.mean(context_vhp_means, axis=0)\n",
    "                context_vhp_sem = np.std(context_vhp_means, axis=0) / np.sqrt(len(context_vhp_means))\n",
    "            \n",
    "            # Filter and process no context data\n",
    "            if len(bwnocontext_data) > 0:\n",
    "                nocontext_filtered = bwnocontext_data[col].apply(\n",
    "                    lambda epoch: filter_epoch(epoch, l_freq, h_freq)\n",
    "                )\n",
    "                nocontext_results = nocontext_filtered.apply(\n",
    "                    lambda epoch: get_epoch_lfp_single(epoch, time_window)\n",
    "                )\n",
    "                \n",
    "                # Extract components correctly\n",
    "                nocontext_times = np.array(nocontext_results.iloc[0][2])\n",
    "                nocontext_aon_list = [result[0] for result in nocontext_results]\n",
    "                nocontext_vhp_list = [result[1] for result in nocontext_results]\n",
    "                \n",
    "                nocontext_aon_means = np.array(nocontext_aon_list)\n",
    "                nocontext_vhp_means = np.array(nocontext_vhp_list)\n",
    "                \n",
    "                nocontext_aon_avg = np.mean(nocontext_aon_means, axis=0)\n",
    "                nocontext_aon_sem = np.std(nocontext_aon_means, axis=0) / np.sqrt(len(nocontext_aon_means))\n",
    "                \n",
    "                nocontext_vhp_avg = np.mean(nocontext_vhp_means, axis=0)\n",
    "                nocontext_vhp_sem = np.std(nocontext_vhp_means, axis=0) / np.sqrt(len(nocontext_vhp_means))\n",
    "            \n",
    "            # ============ AON PLOTS ============\n",
    "            ax_aon = aon_axs[band_idx, event_idx]\n",
    "            \n",
    "            if len(bwcontext_data) > 0:\n",
    "                ax_aon.plot(context_times, context_aon_avg, label='Context', linewidth=2, color='blue')\n",
    "                ax_aon.fill_between(\n",
    "                    context_times,\n",
    "                    context_aon_avg - context_aon_sem,\n",
    "                    context_aon_avg + context_aon_sem,\n",
    "                    alpha=0.3,\n",
    "                    color='blue'\n",
    "                )\n",
    "            \n",
    "            if len(bwnocontext_data) > 0:\n",
    "                ax_aon.plot(nocontext_times, nocontext_aon_avg, label='No Context', linewidth=2, color='orange')\n",
    "                ax_aon.fill_between(\n",
    "                    nocontext_times,\n",
    "                    nocontext_aon_avg - nocontext_aon_sem,\n",
    "                    nocontext_aon_avg + nocontext_aon_sem,\n",
    "                    alpha=0.3,\n",
    "                    color='orange'\n",
    "                )\n",
    "            \n",
    "            # Formatting for AON\n",
    "            if event_idx == 0:\n",
    "                ax_aon.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (μV)', fontsize=10)\n",
    "            if band_idx == 0:\n",
    "                ax_aon.set_title(f'{event_name}', fontsize=11, fontweight='bold')\n",
    "            if band_idx == 3:\n",
    "                ax_aon.set_xlabel('Time (s)', fontsize=10)\n",
    "            \n",
    "            ax_aon.legend(loc='best', fontsize=8)\n",
    "            ax_aon.grid(True, alpha=0.3)\n",
    "            ax_aon.axvline(x=0, color='k', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            \n",
    "            # ============ vHp PLOTS ============\n",
    "            ax_vhp = vhp_axs[band_idx, event_idx]\n",
    "            \n",
    "            if len(bwcontext_data) > 0:\n",
    "                ax_vhp.plot(context_times, context_vhp_avg, label='Context', linewidth=2, color='blue')\n",
    "                ax_vhp.fill_between(\n",
    "                    context_times,\n",
    "                    context_vhp_avg - context_vhp_sem,\n",
    "                    context_vhp_avg + context_vhp_sem,\n",
    "                    alpha=0.3,\n",
    "                    color='blue'\n",
    "                )\n",
    "            \n",
    "            if len(bwnocontext_data) > 0:\n",
    "                ax_vhp.plot(nocontext_times, nocontext_vhp_avg, label='No Context', linewidth=2, color='orange')\n",
    "                ax_vhp.fill_between(\n",
    "                    nocontext_times,\n",
    "                    nocontext_vhp_avg - nocontext_vhp_sem,\n",
    "                    nocontext_vhp_avg + nocontext_vhp_sem,\n",
    "                    alpha=0.3,\n",
    "                    color='orange'\n",
    "                )\n",
    "            \n",
    "            # Formatting for vHp\n",
    "            if event_idx == 0:\n",
    "                ax_vhp.set_ylabel(f'{band_name.capitalize()}\\n({l_freq}-{h_freq} Hz)\\nAmplitude (μV)', fontsize=10)\n",
    "            if band_idx == 0:\n",
    "                ax_vhp.set_title(f'{event_name}', fontsize=11, fontweight='bold')\n",
    "            if band_idx == 3:\n",
    "                ax_vhp.set_xlabel('Time (s)', fontsize=10)\n",
    "            \n",
    "            ax_vhp.legend(loc='best', fontsize=8)\n",
    "            ax_vhp.grid(True, alpha=0.3)\n",
    "            ax_vhp.axvline(x=0, color='k', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    # Add overall titles and adjust layout\n",
    "    aon_fig.suptitle(f'Rat {rat} - AON LFP Analysis (Frequency Bands)', fontsize=14, fontweight='bold', y=0.995)\n",
    "    vhp_fig.suptitle(f'Rat {rat} - vHp LFP Analysis (Frequency Bands)', fontsize=14, fontweight='bold', y=0.995)\n",
    "    \n",
    "    aon_fig.tight_layout()\n",
    "    vhp_fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Power Spectra Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Baseline Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting_styles\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "importlib.reload(plotting_styles)\n",
    "importlib.reload(power_functions)\n",
    "linestyle = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "df['channel']=df['channel'].apply(lambda x:'AON' if 'AON' in x else 'vHp')\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "mean_dict={}\n",
    "for channel, data in channel_experiment_group:\n",
    "    print(channel)\n",
    "    data_array=np.vstack(data['data'].to_numpy())\n",
    "    print(data_array.shape)\n",
    "    data_array_welch = np.array([power_functions.apply_welch_transform(row) for row in data_array]) # Applying Welch's method to each row of data_array\n",
    "    print(data_array_welch.shape)\n",
    "    freqs = np.linspace(0,1000,num=int(data_array_welch.shape[1]))  # Assuming the frequency range is 0-1000 Hz\n",
    "    print(freqs.shape)\n",
    "\n",
    "    data_array_welch_mean = np.mean(data_array_welch, axis=0)\n",
    "    data_array_welch_std = np.std(data_array_welch, axis=0)\n",
    "    print(data_array_welch_mean.shape, data_array_welch_std.shape)\n",
    "    mean_dict[channel[0] + '_' + channel[1] + '_mean'] = data_array_welch_mean\n",
    "    mean_dict[channel[0] + '_' + channel[1] + '_std'] = data_array_welch_std\n",
    "    \n",
    "    ax.plot(freqs,data_array_welch_mean, linestyle=linestyle[channel[1]], color=colors[channel[0]], label=f'{channel[0]} {channel[1]}')\n",
    "    ax.fill_between(freqs,data_array_welch_mean-data_array_welch_std,data_array_welch_mean+data_array_welch_std, alpha=0.1, color=colors[channel[0]])\n",
    "    #ax.set_yscale('log')\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.legend(loc='upper right', fontsize=20)\n",
    "    ax.set_title('Baseline Power Spectral Density', fontsize=20)\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "    ax.set_ylabel('Power (V^2/Hz)', fontsize=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "#    ax.set_yscale('log')\n",
    "mean_dict['frequency']=freqs\n",
    "mean_df=pd.DataFrame(mean_dict)\n",
    "#mean_df.to_csv(savepath+'baseline_power_truncated.csv')\n",
    "#plt.savefig(savepath+'baseline_power_truncated.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "# Calculate multitaper PSD for each group and plot\n",
    "fig_mt, ax_mt = plt.subplots(figsize=(15, 10))\n",
    "mt_mean_dict = {}\n",
    "for channel, data in channel_experiment_group:\n",
    "    data_array = np.vstack(data['data'].to_numpy())\n",
    "    # Multitaper PSD: average across trials\n",
    "    psds = []\n",
    "    for row in data_array:\n",
    "        psd, freqs_mt = psd_array_multitaper(row, sfreq=2000,bandwidth=2, fmin=0, fmax=100, adaptive=True, normalization='full', verbose=0)\n",
    "        psds.append(psd)\n",
    "    psds = np.array(psds)\n",
    "    psd_mean = psds.mean(axis=0)\n",
    "    psd_std = psds.std(axis=0)\n",
    "    mt_mean_dict[channel[0] + '_' + channel[1] + '_mean'] = psd_mean\n",
    "    mt_mean_dict[channel[0] + '_' + channel[1] + '_std'] = psd_std\n",
    "    ax_mt.plot(freqs_mt, psd_mean, linestyle=linestyle[channel[1]], color=colors[channel[0]], label=f'{channel[0]}_{channel[1]}')\n",
    "    ax_mt.fill_between(freqs_mt, psd_mean-psd_std, psd_mean+psd_std, alpha=0.1, color=colors[channel[0]])\n",
    "ax_mt.set_xlim(0, 100)\n",
    "handles, labels = ax_mt.get_legend_handles_labels()\n",
    "ax_mt.legend(handles, [channel_dict[l] for l in labels], loc='upper right', fontsize=20)\n",
    "ax_mt.set_title('Baseline Power Spectral Density (Multitaper)', fontsize=20)\n",
    "ax_mt.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "ax_mt.set_ylabel('Power (V^2/Hz)', fontsize=20)\n",
    "ax_mt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "mt_mean_dict['frequency'] = freqs_mt\n",
    "mt_mean_df = pd.DataFrame(mt_mean_dict)\n",
    "mt_mean_df.to_csv(savepath+'baseline_psd_multitaper.csv')\n",
    "plt.savefig(savepath+'baseline_psd_multitaper.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "plt.close(fig_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Prepare data for ANOVA: for each frequency, compare power between tasks\n",
    "# We'll do this for both AON and vHp channels\n",
    "\n",
    "results = {'frequency': [], 'AON_F': [], 'AON_p': [], 'vHp_F': [], 'vHp_p': []}\n",
    "tasks = ['BWcontext', 'BWnocontext']\n",
    "def make_welch_data_dfs(data, task, channel):\n",
    "    data_task_channel = data[(data['task'] == task) & (data['channel'] == channel)]\n",
    "    data_array = np.vstack(data_task_channel['data'].to_numpy())\n",
    "    data_array_welch = np.array([power_functions.apply_welch_transform(row) for row in data_array])  # Applying Welch's method to each row of data_array\n",
    "    return data_array_welch\n",
    "\n",
    "aon_context_vals= make_welch_data_dfs(df, 'BWcontext', 'AON')\n",
    "aon_nocontext_vals= make_welch_data_dfs(df, 'BWnocontext', 'AON')\n",
    "vHp_context_vals= make_welch_data_dfs(df, 'BWcontext', 'vHp')\n",
    "vHp_nocontext_vals= make_welch_data_dfs(df, 'BWnocontext', 'vHp')\n",
    "for freq in range(aon_context_vals.shape[1]):\n",
    "    aon_f, aon_p = f_oneway(aon_context_vals[:, freq], aon_nocontext_vals[:, freq])\n",
    "    vHp_f, vHp_p = f_oneway(vHp_context_vals[:, freq], vHp_nocontext_vals[:, freq])\n",
    "    \n",
    "    results['frequency'].append(freq)\n",
    "    results['AON_F'].append(aon_f)\n",
    "    results['AON_p'].append(aon_p)\n",
    "    results['vHp_F'].append(vHp_f)\n",
    "    results['vHp_p'].append(vHp_p)\n",
    "    # Convert results to DataFrame and filter for frequency 1 to 100\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[(results_df['frequency'] >= 1) & (results_df['frequency'] <= 100)]\n",
    "results_df.to_csv(savepath + 'anova_psd_per_frequency_1_100.csv', index=False)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For each frequency, extract power for each task and channel\n",
    "for i, freq in enumerate(mean_df['frequency']):\n",
    "    # For ANOVA, we need the raw values, not the means, so we go back to the original data\n",
    "    # Get all AON/vHp power values at this frequency for each task\n",
    "    aon_mask = (data['channel'] == 'AON')\n",
    "    vhp_mask = (data['channel'] == 'vHp')\n",
    "    context_mask = (data['task'] == 'BWcontext')\n",
    "    nocontext_mask = (data['task'] == 'BWnocontext')\n",
    "\n",
    "    aon_context_vals = data_array_welch[aon_mask & context_mask, i]\n",
    "    aon_nocontext_vals = data_array_welch[aon_mask & nocontext_mask, i]\n",
    "    vhp_context_vals = data_array_welch[vhp_mask & context_mask, i]\n",
    "    vhp_nocontext_vals = data_array_welch[vhp_mask & nocontext_mask, i]\n",
    "\n",
    "    # ANOVA for AON\n",
    "    if len(aon_context_vals) > 1 and len(aon_nocontext_vals) > 1:\n",
    "        F_aon, p_aon = f_oneway(aon_context_vals, aon_nocontext_vals)\n",
    "    else:\n",
    "        F_aon, p_aon = float('nan'), float('nan')\n",
    "\n",
    "    # ANOVA for vHp\n",
    "    if len(vhp_context_vals) > 1 and len(vhp_nocontext_vals) > 1:\n",
    "        F_vhp, p_vhp = f_oneway(vhp_context_vals, vhp_nocontext_vals)\n",
    "    else:\n",
    "        F_vhp, p_vhp = float('nan'), float('nan')\n",
    "\n",
    "    results['frequency'].append(freq)\n",
    "    results['AON_F'].append(F_aon)\n",
    "    results['AON_p'].append(p_aon)\n",
    "    results['vHp_F'].append(F_vhp)\n",
    "    results['vHp_p'].append(p_vhp)\n",
    "\n",
    "anova_df = pd.DataFrame(results)\n",
    "anova_df.to_csv(savepath + 'anova_psd_per_frequency.csv', index=False)\n",
    "print(anova_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselinePower Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl') #Loading the baseline LFP data\n",
    "df= baseline_lfp_all.__deepcopy__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "importlib.reload(plotting_styles)\n",
    "importlib.reload(power_functions)\n",
    "linestyles = plotting_styles.linestyles\n",
    "colors = plotting_styles.colors\n",
    "brain_areas = ['AON','vHp']\n",
    "\n",
    "\n",
    "number_per_segment = 2000\n",
    "tukey_window = scipy.signal.get_window(('tukey', 0.2), number_per_segment)    \n",
    "all_bands_dict = {'total':[1,100], 'beta':[12,30], 'gamma':[30,80], 'theta':[4,12]}\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "df['data']=df['data'].apply(lambda x:power_functions.apply_welch_transform(x))\n",
    "\n",
    "for band_name, band_values in all_bands_dict.items():\n",
    "    df[band_name+'_power']=df['data'].apply(lambda x:power_functions.get_band_power(x, band_values[0], band_values[1]))\n",
    "\n",
    "writer=pd.ExcelWriter(savepath+'baseline_power_per_band_welch.xlsx')\n",
    "fig, axs = plt.subplots(1,2, figsize=(15, 10), sharey=True)\n",
    "axs=axs.flatten()\n",
    "for i, area in enumerate(brain_areas):\n",
    "    data = df[df['channel'].str.contains(area)]\n",
    "    data_melted = data.melt(id_vars=['rat','task','channel'], value_vars=['total_power','beta_power','gamma_power','theta_power'], var_name='band', value_name='power')\n",
    "    sns.barplot(\n",
    "        data=data_melted, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, ax=axs[i])\n",
    "    sns.stripplot(data=data_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, dodge=True, alpha=0.5, jitter=0.2, ax=axs[i], linewidth=1, legend=False )\n",
    "#    axs[i].set_yscale('log')\n",
    "    axs[i].set_title(f'Baseline {area} Power per Band', fontsize=20)\n",
    "    axs[i].set_xlabel('Band', fontsize=20)\n",
    "    axs[i].set_ylabel('Power V^2', fontsize=20)\n",
    "    axs[i].legend(loc='upper right', fontsize=15)\n",
    "    axs[i].set_xticks(([0,1,2,3]),list(all_bands_dict.keys()))\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=15)\n",
    "    data_melted.to_excel(writer, sheet_name=area)\n",
    "writer.close()\n",
    "plt.savefig(savepath+'baseline_power_per_band_welch.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl') #Loading the baseline LFP data\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "\n",
    "# Calculate multitaper PSD and band power for each row\n",
    "df['data_mt'] = df['data'].apply(lambda x: psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=100, adaptive=True,bandwidth=2, normalization='full', verbose=0, max_iter=500)[0])\n",
    "\n",
    "for band_name, band_values in all_bands_dict.items():\n",
    "    # df[band_name + '_power_mt'] = df['data_mt'].apply(lambda x: psd_array_multitaper(x, sfreq=2000, fmin=band_values[0], fmax=band_values[1], adaptive=True,bandwidth=2, normalization='full', verbose=0, max_iter=500,faverage=True)[0])\n",
    "\n",
    "    df[band_name + '_power_mt'] = df['data_mt'].apply(lambda x: power_functions.get_band_power(x, band_values[0], band_values[1]))\n",
    "    epsilon = 1e-12\n",
    "    #df[band_name + '_power_mt'] = df[band_name + '_power_mt'].apply(lambda x: 10*np.log10(x + epsilon))     # Log-normalize multitaper band power, handling log(0) by adding a small epsilon\n",
    "\n",
    "    # Plot multitaper band power\n",
    "writer_mt = pd.ExcelWriter(savepath + 'baseline_power_per_band_multitaper.xlsx')\n",
    "\n",
    "fig_mt, axs_mt = plt.subplots(1, 2, figsize=(15, 10), sharey=True)\n",
    "axs_mt = axs_mt.flatten()\n",
    "for i, area in enumerate(brain_areas):\n",
    "    data_mt = df[df['channel'].str.contains(area)]\n",
    "    data_melted_mt = data_mt.melt(\n",
    "        id_vars=['rat', 'task', 'channel'],\n",
    "        value_vars=['total_power_mt', 'beta_power_mt', 'gamma_power_mt', 'theta_power_mt'],\n",
    "        var_name='band', value_name='power'\n",
    "    )\n",
    "    # Plot log-normalized multitaper band power\n",
    "    sns.barplot(\n",
    "        data=data_melted_mt, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, ax=axs_mt[i]\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=data_melted_mt, x='band', y='power', hue='task',\n",
    "        hue_order=['BWcontext', 'BWnocontext'], palette=colors, dodge=True, alpha=1, jitter=0.2,\n",
    "        ax=axs_mt[i], linewidth=1, legend=False\n",
    "    )\n",
    "    axs_mt[i].set_title(f'Baseline {area} Power per band', fontsize=20)\n",
    "    axs_mt[i].set_xlabel('Band', fontsize=20)\n",
    "    axs_mt[i].set_ylabel('Power (V^2)', fontsize=20)\n",
    "    handles, labels = axs_mt[i].get_legend_handles_labels()\n",
    "    axs_mt[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "    #axs_mt[i].legend(loc='upper right', fontsize=15)\n",
    "    axs_mt[i].set_xticks([0, 1, 2, 3], list(all_bands_dict.keys()))\n",
    "    axs_mt[i].tick_params(axis='both', which='major', labelsize=15)\n",
    "    data_melted_mt.to_excel(writer_mt, sheet_name=area)\n",
    "writer_mt.close()\n",
    "plt.savefig(savepath + 'baseline_power_per_band_multitaper.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Power Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_lfp_all = pd.read_pickle(savepath+'baseline_lfp_all.pkl')\n",
    "df= baseline_lfp_all.__deepcopy__()\n",
    "df['channel']=df['channel'].apply(lambda x:'AON' if 'AON' in x else 'vHp')\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "\n",
    "\"\"\"\n",
    "Doing a test run\n",
    "\n",
    "test_array = df['data'].iloc[0]\n",
    "print(test_array.shape)\n",
    "\n",
    "test_array_new = test_array.reshape((1,1,-1))\n",
    "print(test_array_new.shape)\n",
    "\n",
    "fmin = 1\n",
    "fmax = 100\n",
    "freqs = np.arange(fmin, fmax)\n",
    "n_cycles = freqs / 3.  # different number of cycles per frequency\n",
    "fs =2000\n",
    "\n",
    "tfr_array = tfr_array_morlet(test_array_new, sfreq=fs, freqs=freqs, n_cycles=n_cycles, n_jobs=-1, output='power')\n",
    "\n",
    "print(tfr_array.shape)  # Should be (n_epochs,n_channels, n_freqs, n_times)\n",
    "\n",
    "tfr_array_squeezed = tfr_array.squeeze()\n",
    "print(tfr_array_squeezed.shape)  # Should be (n_freqs, n_times)\n",
    "\n",
    "plt.imshow(tfr_array_squeezed, aspect='auto', origin='lower', extent=[-2, 0, fmin, fmax])\n",
    "plt.colorbar(label='Power')\n",
    "#for task_channel, data in channel_experiment_group:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "def compute_tfr(data_array, fmin=1, fmax=100, fs=2000):\n",
    "    data_array = data_array.reshape((1, 1, -1))\n",
    "    freqs = np.arange(fmin, fmax)\n",
    "    n_cycles = freqs / 3.  # different number of cycles per frequency\n",
    "    tfr_array = tfr_array_morlet(data_array, sfreq=fs, freqs=freqs, n_cycles=n_cycles, n_jobs=1, output='power')\n",
    "    tfr_array_squeezed = tfr_array.squeeze()\n",
    "    #tfr_normalized = scipy.stats.zscore(tfr_array_squeezed, axis=1)\n",
    "    tfr_normalized = 10*np.log10(tfr_array_squeezed) #dB normalization\n",
    "    return tfr_normalized\n",
    "\n",
    "df['data_tfr'] = df['data'].apply(compute_tfr)\n",
    "\n",
    "\n",
    "channel_experiment_group=df.groupby(['task','channel'])\n",
    "channel_dict = {'BWcontext_AON': 'context AON', 'BWcontext_vHp': 'context vHp',\n",
    "                'BWnocontext_AON': 'No context AON', 'BWnocontext_vHp': 'No context vHp'}\n",
    "fig, axs= plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Baseline Power Spectrograms', fontsize=20)\n",
    "axs=axs.flatten()\n",
    "for i, (task_channel, data) in enumerate(channel_experiment_group):\n",
    "    ax = axs[i]\n",
    "    print(task_channel)\n",
    "    data_array_tfr = np.array(data['data_tfr'].tolist())\n",
    "    print(data_array_tfr.shape)  # Should be (n_epochs, n_freqs, n_times)\n",
    "    \n",
    "    data_array_tfr_mean = np.mean(data_array_tfr, axis=0)\n",
    "    print(data_array_tfr_mean.shape)  # Should be (n_freqs, n_times)\n",
    "    ax.imshow(data_array_tfr_mean, aspect='auto', origin='lower', extent=[-2, 0, 1, 100])\n",
    "\n",
    "    ax.set_title(f'{task_channel[0]} {task_channel[1]}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "fig.colorbar(ax.images[0], ax=axs, label='Power (dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the power spectra for each rat and the mean power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the power spectra for the complete trial # [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "fig.suptitle('Power Spectral Density')\n",
    "linestyles = {'AON': '-', 'vHp': '--'}\n",
    "\n",
    "for i,rati in enumerate(rat_list):\n",
    "    rat_data=power_df[power_df['rat']==rati]\n",
    "    rat_data=rat_data.reset_index(drop=True)\n",
    "    rat_data_grouped=rat_data.groupby(['task','channel'])\n",
    "    for (task, channel),group in rat_data_grouped:\n",
    "        print(task, channel)\n",
    "        group=group.reset_index(drop=True)\n",
    "        col='complete_trial'\n",
    "        data = np.array(group[col])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        freq = np.linspace(0, 1000, len(data_mean))        \n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{rati}')\n",
    "        ax.plot(freq, data_mean, color=colors[task], linestyle=linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=colors[task])\n",
    "        ax.set_xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Average Power Spectra across all rats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Event Power Spectra individual Rats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Events PSD Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "\n",
    "time_window=0.7\n",
    "fs=2000\n",
    "\n",
    "##################\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['complete_trial','pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "\n",
    "power_df.loc[:,columns]=power_df.loc[:,columns].applymap(lambda x:power_functions.apply_welch_transform(x))\n",
    "events_dict={'pre_door':' Pre Door','post_door':'Post Door','pre_dig':'Pre Dig','post_dig':'Post Dig'}\n",
    "fig, axs=plt.subplots(1,4, figsize=(40,10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer=pd.ExcelWriter(savepath+'events_power_spectral_density.xlsx')\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "\n",
    "    data = power_df[['rat','task','channel',event]]\n",
    "    data['channel']=data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups=data.groupby(['task','channel'])\n",
    "    mean_data_dict={}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group=group.reset_index(drop=True)\n",
    "        data = np.array(group[event])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        mean_data_dict[task+'_'+channel+'_mean']=data_mean\n",
    "        mean_data_dict[task+'_'+channel+'_sem']=data_sem\n",
    "        freq = np.linspace(0, 1000, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2/Hz)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    mean_data_dict['frequency'] = freq\n",
    "    mean_df=pd.DataFrame(mean_data_dict)\n",
    "    mean_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "fig.savefig(savepath+f'pow_events_psd{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events PSD MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window=0.4\n",
    "fs=2000\n",
    "###############\n",
    "\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "# Apply multitaper PSD to each event column\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=100, adaptive=True, bandwidth=6, normalization='length', verbose=0, max_iter=1000)\n",
    "    #psd = 10 * np.log10(psd)\n",
    "    return psd\n",
    "\n",
    "power_df.loc[:, columns] = power_df.loc[:, columns].applymap(multitaper_transform)\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "events_dict = {'pre_door': ' Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer = pd.ExcelWriter(savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.xlsx')\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    data = power_df[['rat', 'task', 'channel', event]]\n",
    "    data['channel'] = data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups = data.groupby(['task', 'channel'])\n",
    "    mean_data_dict = {}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group = group.reset_index(drop=True)\n",
    "        data_arr = np.array(group[event])\n",
    "        data_mean = np.mean(data_arr, axis=0)\n",
    "        data_sem = scipy.stats.sem(data_arr, axis=0)\n",
    "        mean_data_dict[task + '_' + channel + '_mean'] = data_mean\n",
    "        mean_data_dict[task + '_' + channel + '_sem'] = data_sem\n",
    "        freq = np.linspace(0, 100, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel], label=f'{task_dict[task]} {channel}')\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        # ax.set_yscale('log')\n",
    "        ax.set_xlabel('Frequency (Hz)', fontsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2/Hz)', fontsize=25)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    mean_data_dict['frequency'] = freq\n",
    "    mean_df = pd.DataFrame(mean_data_dict)\n",
    "    mean_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper right', fontsize=20)\n",
    "fig.savefig(savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "event_list = ['mne_epoch_door_before', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "def get_channel_groups(channel_names, task):\n",
    "    \"\"\"\n",
    "    Identify channel groups based on channel names and task.\n",
    "    Returns dictionary with channel indices for each group.\n",
    "    \"\"\"\n",
    "    aon_channels = [ch for ch in channel_names if 'AON' in ch]\n",
    "    vhp_channels = [ch for ch in channel_names if 'vHp' in ch]\n",
    "    \n",
    "    groups = {\n",
    "        f'{task}_AON': aon_channels,\n",
    "        f'{task}_vHp': vhp_channels\n",
    "    }\n",
    "    \n",
    "    return groups\n",
    "\n",
    "print(con_data_df_clean.columns)\n",
    "\n",
    "# Dictionary to store PSD data for each event and task combination\n",
    "# Structure: event_psd_data[event][task][group_name] = list of (n_trials, n_freqs) arrays\n",
    "event_psd_data = {event: {} for event in event_list}\n",
    "freqs_array = None  # Will store frequency values\n",
    "\n",
    "for i in range(len(con_data_df_clean)):\n",
    "    rat = con_data_df_clean.loc[i, 'rat_id']\n",
    "    task = con_data_df_clean.loc[i, 'task']\n",
    "    date = con_data_df_clean.loc[i, 'date']\n",
    "    \n",
    "    print(f\"Processing rat {rat}, task {task}, date {date} ({i+1}/{len(con_data_df_clean)})\")\n",
    "    \n",
    "    for event in event_list:\n",
    "        test_epoch = con_data_df_clean.loc[i, event]\n",
    "        \n",
    "        # Compute PSD\n",
    "        test_epoch_psd = test_epoch.compute_psd(\n",
    "            method='multitaper', \n",
    "            fmin=0, \n",
    "            fmax=100, \n",
    "            adaptive=True, \n",
    "            bandwidth=6, \n",
    "            normalization='full', \n",
    "            verbose=0,\n",
    "            exclude=['Ref']\n",
    "        )\n",
    "        \n",
    "        # Get PSD data and frequencies\n",
    "        psd_array = test_epoch_psd.get_data()  # shape: (n_trials, n_channels, n_freqs)\n",
    "        freqs = test_epoch_psd.freqs\n",
    "        channel_names = test_epoch_psd.ch_names\n",
    "        \n",
    "        # Store frequency array (same for all)\n",
    "        if freqs_array is None:\n",
    "            freqs_array = freqs\n",
    "        \n",
    "        # Identify channel groups based on task and channel names\n",
    "        channel_groups = get_channel_groups(channel_names, task)\n",
    "        \n",
    "        # Initialize task dictionary if needed\n",
    "        if task not in event_psd_data[event]:\n",
    "            event_psd_data[event][task] = {group: [] for group in channel_groups.keys()}\n",
    "        \n",
    "        # Process each channel group\n",
    "        for group_name, group_channels in channel_groups.items():\n",
    "            # Find indices of channels in this group\n",
    "            channel_indices = [idx for idx, ch in enumerate(channel_names) \n",
    "                             if ch in group_channels]\n",
    "            \n",
    "            if len(channel_indices) > 0:\n",
    "                # Get PSD data for these channels: (n_trials, n_channels_in_group, n_freqs)\n",
    "                group_psd = psd_array[:, channel_indices, :]\n",
    "                \n",
    "                # Average across channels: (n_trials, n_freqs)\n",
    "                group_psd_avg_channels = np.mean(group_psd, axis=1)\n",
    "                \n",
    "                # Store this rat's data\n",
    "                event_psd_data[event][task][group_name].append(group_psd_avg_channels)\n",
    "\n",
    "# Now aggregate across rats for each event and task\n",
    "print(\"\\nAggregating across rats...\")\n",
    "final_psd_dfs = {}\n",
    "\n",
    "for event in event_list:\n",
    "    # Dictionary to hold columns for this event\n",
    "    df_dict = {'frequency': freqs_array}  # Add frequency column first\n",
    "    \n",
    "    # Get all tasks for this event\n",
    "    for task in event_psd_data[event].keys():\n",
    "        # Process each channel group\n",
    "        for group_name in event_psd_data[event][task].keys():\n",
    "            rat_data = event_psd_data[event][task][group_name]\n",
    "            \n",
    "            if len(rat_data) > 0:\n",
    "                # rat_data is a list of (n_trials, n_freqs) arrays, one per rat\n",
    "                # Concatenate all rats' trials: (total_trials_all_rats, n_freqs)\n",
    "                all_trials = np.concatenate(rat_data, axis=0)\n",
    "                \n",
    "                # Calculate mean and SEM across all trials from all rats\n",
    "                psd_mean = np.mean(all_trials, axis=0)\n",
    "                psd_sem = stats.sem(all_trials, axis=0)\n",
    "                \n",
    "                # Add as columns\n",
    "                df_dict[f'{group_name}_mean'] = psd_mean\n",
    "                df_dict[f'{group_name}_sem'] = psd_sem\n",
    "            else:\n",
    "                df_dict[f'{group_name}_mean'] = np.full(len(freqs_array), np.nan)\n",
    "                df_dict[f'{group_name}_sem'] = np.full(len(freqs_array), np.nan)\n",
    "    \n",
    "    # Create dataframe where each row is a frequency bin\n",
    "    final_psd_dfs[event] = pd.DataFrame(df_dict)\n",
    "    print(f\"{event}: {len(final_psd_dfs[event])} frequency bins, {len(df_dict)} columns\")\n",
    "\n",
    "# Save PSD Mean/SEM to Excel\n",
    "excel_filename_psd = savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.xlsx'\n",
    "print(f\"\\nSaving PSD mean/SEM to {excel_filename_psd}...\")\n",
    "\n",
    "with pd.ExcelWriter(excel_filename_psd, engine='openpyxl') as writer:\n",
    "    for event, df in final_psd_dfs.items():\n",
    "        sheet_name = event.replace('mne_epoch_', '')[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Saved sheet: {sheet_name} ({len(df)} rows, {len(df.columns)} columns)\")\n",
    "\n",
    "print(\"\\nPSD Mean/SEM Analysis Done!\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n=== PSD Mean/SEM Sample ===\")\n",
    "for event, df in final_psd_dfs.items():\n",
    "    print(f\"\\n{event}:\")\n",
    "    print(df.head(10))\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Plotting =====\n",
    "print(\"\\nCreating plots...\")\n",
    "\n",
    "# Create figure with 3 subplots in a row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "\n",
    "# Event titles for subplots\n",
    "event_titles = {\n",
    "    'mne_epoch_door_before': 'Door Before',\n",
    "    'mne_epoch_dig_before': 'Dig Before',\n",
    "    'mne_epoch_dig_after': 'Dig After'\n",
    "}\n",
    "\n",
    "for idx, event in enumerate(event_list):\n",
    "    ax = axes[idx]\n",
    "    df = final_psd_dfs[event]\n",
    "    freqs = df['frequency'].values\n",
    "    \n",
    "    # Get all column names except frequency\n",
    "    data_columns = [col for col in df.columns if col != 'frequency']\n",
    "    \n",
    "    # Extract task and region from column names and plot\n",
    "    plotted_lines = []\n",
    "    for col in data_columns:\n",
    "        if '_mean' in col:\n",
    "            # Parse column name: e.g., 'BWContext_AON_mean'\n",
    "            col_name = col.replace('_mean', '')\n",
    "            \n",
    "            mean_col = col\n",
    "            sem_col = col.replace('_mean', '_sem')\n",
    "            \n",
    "            if mean_col in df.columns and sem_col in df.columns:\n",
    "                mean = df[mean_col].values\n",
    "                sem = df[sem_col].values\n",
    "                \n",
    "                # Determine color and linestyle based on column name\n",
    "                if 'BWcontext' in col_name:\n",
    "                    color = 'blue'\n",
    "                elif 'BWnocontext' in col_name or 'BWNocontext' in col_name:\n",
    "                    color = 'orange'\n",
    "                else:\n",
    "                    color = 'black'\n",
    "                \n",
    "                if 'AON' in col_name:\n",
    "                    linestyle = '-'\n",
    "                elif 'vHp' in col_name:\n",
    "                    linestyle = '--'\n",
    "                else:\n",
    "                    linestyle = '-'\n",
    "                \n",
    "                # Create label\n",
    "                label = col_name.replace('_', ' ')\n",
    "                \n",
    "                # Plot mean line\n",
    "                line = ax.plot(freqs, mean, color=color, linestyle=linestyle, \n",
    "                       linewidth=2, label=label)\n",
    "                \n",
    "                # Add shaded SEM\n",
    "                ax.fill_between(freqs, mean - sem, mean + sem, \n",
    "                               color=color, alpha=0.2)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Power Spectral Density (mV^2/Hz)', fontsize=12)\n",
    "    ax.set_title(event_titles[event], fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim([freqs.min(), freqs.max()])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plot_filename = savepath + f'pow_events_psd_{int(time_window*fs/2)}ms.png'\n",
    "plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"Plot saved to {plot_filename}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectrograms for each each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.7\n",
    "fs=2000\n",
    "mne_epochs = pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "## Test Epoch\n",
    "\n",
    "test_epoch_pre_door = mne_epochs['mne_epoch_door_before'].iloc[0]\n",
    "test_epoch_pre_dig = mne_epochs['mne_epoch_dig_before'].iloc[0]\n",
    "fmin=2.5\n",
    "fmax=100\n",
    "fs=2000\n",
    "freqs = np.arange(fmin,fmax)\n",
    "n_cycles = freqs/3\n",
    "\n",
    "power_pre_door = test_epoch_pre_door.compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False\n",
    ")\n",
    "\n",
    "power_pre_door_data = power_pre_door.get_data()\n",
    "print(power_pre_door_data.shape)\n",
    "power_pre_dig = test_epoch_pre_dig.compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False\n",
    ")\n",
    "power_pre_dig_data = power_pre_dig.get_data()\n",
    "print(power_pre_dig_data.shape)\n",
    "channel_names = power_pre_door.ch_names\n",
    "print(channel_names)\n",
    "plt.imshow(power_pre_door_data[0, 0, :, :], aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(power_pre_dig_data[0, 0, :, :], aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_of_cols = power_pre_door_data.shape[0]\n",
    "num_of_rows = power_pre_door_data.shape[1]\n",
    "\n",
    "fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(20, 10), sharex=True, sharey=True)\n",
    "vmin_global = 0\n",
    "vmax_global = 0\n",
    "\n",
    "for i in range(num_of_rows):\n",
    "    for j in range(num_of_cols):\n",
    "        pre_door = power_pre_door_data[j,i, :, :]\n",
    "        pre_dig = power_pre_dig_data[j,i, :, :]\n",
    "        net_power = pre_dig - pre_door\n",
    "        axs[i, j].imshow(pre_door, aspect='auto', origin='lower', extent=[-0.7, 0, fmin, fmax])\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel(f'{channel_names[i]}', fontsize=10)\n",
    "        if i==0:\n",
    "            axs[i, j].set_title(f'trial {j}', fontsize=10)\n",
    "            \n",
    "        vmin_global = min(vmin_global, pre_door.min())\n",
    "        vmax_global = max(vmax_global, pre_door.max())\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     # Set color limits for all axes to the global min/max\n",
    "#     for im in ax.get_images():\n",
    "#         im.set_clim(vmin_global, vmax_global)\n",
    "fig.colorbar(axs[0, 0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_epochs = pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "def get_power_tfr(epoch):\n",
    "    fmin=2.5\n",
    "    fmax=100\n",
    "    fs=2000\n",
    "    freqs = np.arange(fmin,fmax)\n",
    "    n_cycles = freqs/3\n",
    "\n",
    "    power = epoch.compute_tfr(\n",
    "        method=\"morlet\", freqs=freqs, n_cycles=n_cycles, return_itc=False, average=False, method_kw\n",
    "        \n",
    "    )\n",
    "\n",
    "    return power\n",
    "results = []\n",
    "for row in mne_epochs.itertuples(index=False):\n",
    "    experiment, rat_id, task = row.experiment, row.rat_id, row.task\n",
    "    door_before,door_after = row.mne_epoch_door_before, row.mne_epoch_door_after\n",
    "    dig_before,dig_after = row.mne_epoch_dig_before, row.mne_epoch_dig_after\n",
    "    around_door, around_dig = row.mne_epoch_around_door, row.mne_epoch_around_dig\n",
    "\n",
    "    power_door_before = get_power_tfr(door_before)\n",
    "    power_door_after = get_power_tfr(door_after)\n",
    "    power_dig_before = get_power_tfr(dig_before)\n",
    "    power_dig_after = get_power_tfr(dig_after)\n",
    "    power_around_door = get_power_tfr(around_door)\n",
    "    power_around_dig = get_power_tfr(around_dig)\n",
    "\n",
    "    net_power = power_dig_before - power_door_before\n",
    "    channel_names = door_before.ch_names\n",
    "    new_row = [experiment, rat_id, task,power_door_before,power_door_after,power_dig_before,power_dig_after, power_around_door, power_around_dig, net_power, channel_names]\n",
    "    results.append(new_row)\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['experiment', 'rat_id', 'task', 'power_pre_door', 'power_post_door','power_pre_dig','power_post_dig','power_around_door','power_around_dig','net_power_pre_dig_pre_door', 'channel_names'])\n",
    "results_df.to_pickle(savepath + 'power_tfr_epochs_mrlt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_power_epoch = results_df['power_pre_door'].iloc[0]\n",
    "test_power_epoch_2 = results_df['power_pre_door'].iloc[1]\n",
    "def plot_power_spec_from_epochs(test_power_epoch):\n",
    "    print(test_power_epoch.ch_names)\n",
    "    aon_channels = [channel for channel in test_power_epoch.ch_names if \"AON\" in channel]\n",
    "    vhp_channels = [channel for channel in test_power_epoch.ch_names if \"vHp\" in channel]\n",
    "    print(aon_channels,vhp_channels)\n",
    "    averaged_epoch_power = test_power_epoch.average(dim='epochs')\n",
    "    averaged_epoch_power.plot(title=\"auto\", vlim = (0, None))\n",
    "    averaged_epoch_power.plot(picks=aon_channels,title=\"AON power\", combine='mean', vlim = (0, None))\n",
    "    averaged_epoch_power.plot(picks=vhp_channels, title=\"VHP power\", combine='mean', vlim = (0, None))\n",
    "    return averaged_epoch_power, aon_channels,vhp_channels\n",
    "epoch1_avg, aon_1, vhp_1 = plot_power_spec_from_epochs(test_power_epoch)\n",
    "epoch2_avg, aon_2, vhp_2 = plot_power_spec_from_epochs(test_power_epoch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1400,8)\n",
    "list(np.arange(0,1600,200))\n",
    "list(np.round(np.arange(0,0.8,0.1), decimals = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(savepath+'power_tfr_epochs_mrlt.pkl')\n",
    "\n",
    "def make_averaged_power(epoch, area):\n",
    "    #print(epoch.ch_names)\n",
    "    area_channels = [channel for channel in epoch.ch_names if area in channel]\n",
    "    #print(area_channels)\n",
    "\n",
    "    if len(area_channels)==0:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    else:\n",
    "        area_epoch = epoch.copy()\n",
    "        area_epoch.pick(area_channels)\n",
    "        averaged_epoch_power = area_epoch.average(dim='epochs')\n",
    "        print(f\"Data shape before mean: {averaged_epoch_power.shape}\")  # DEBUG\n",
    "        mean_ch_power = np.mean(averaged_epoch_power.get_data(), axis = 0)\n",
    "        print(f\"Data shape after mean: {mean_ch_power.shape}\")  # DEBUG\n",
    "        return mean_ch_power\n",
    "\n",
    "# test_averaged_epoch_power = make_averaged_power(test_power_epoch, \"vHp\")\n",
    "# print(test_averaged_epoch_power.shape)\n",
    "\n",
    "for area in [\"AON\", \"vHp\"]:\n",
    "    area_df = pd.DataFrame()\n",
    "    fig, axs = plt.subplots(2,3, figsize= (15,10))\n",
    "    fig.suptitle(f'Average {area} Power')\n",
    "    for rowi, task in enumerate([\"BWcontext\", \"BWnocontext\"]):\n",
    "        task_data=results_df[results_df['task']==task]\n",
    "        print(f\"\\nTask: {task}, Area: {area}, Rows in task_data: {len(task_data)}\")\n",
    "        #for coli, event in enumerate(['power_pre_door', 'power_pre_dig','power_post_dig']):\n",
    "        for coli, event in enumerate(['power_around_door']):\n",
    "        \n",
    "            print(coli,event, task, area)\n",
    "            event_arrays = task_data[event].apply(lambda x: make_averaged_power(x, area))\n",
    "            \n",
    "            valid_arrays = [arr for arr in event_arrays.values if arr is not None]\n",
    "            \n",
    "            print(f\"Valid arrays found: {len(valid_arrays)}\")\n",
    "            \n",
    "            if len(valid_arrays) > 0:\n",
    "                averaged_array = np.mean(np.stack(valid_arrays), axis=0)\n",
    "                print(f\"Averaged array shape: {averaged_array.shape}\")\n",
    "                \n",
    "                ax = axs[rowi, coli]\n",
    "                im = ax.imshow(X= averaged_array, cmap = 'viridis', aspect='auto', origin='lower')\n",
    "                                # Add titles and labels\n",
    "                ax.set_title(f'{event.replace(\"_\", \" \").title()}')\n",
    "                ax.set_xlabel('Time (samples)')\n",
    "                ax.set_ylabel('Frequency (Hz)')\n",
    "                # ax.set_xticks(list(np.arange(0,1600,200)))\n",
    "                # ax.set_xticklabels(list(np.round(np.arange(0,0.8,0.1), decimals = 1)))\n",
    "                # Add colorbar\n",
    "                plt.colorbar(im, ax=ax, label='Power (mV^2/Hz)')\n",
    "                \n",
    "                # Add row labels\n",
    "                if coli == 0:\n",
    "                    ax.set_ylabel(f'{task}\\nFrequency (Hz)', fontweight='bold')\n",
    "                # Add your plotting code here\n",
    "            else:\n",
    "                print(f\"WARNING: No valid data for {area}, {task}, {event}\")\n",
    "                ax = axs[rowi, coli]\n",
    "                ax.text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'power_spectrogram_{area}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for resulti in results_df.itertuples(index=False):\n",
    "    net_power = resulti.net_power_pre_dig_pre_door\n",
    "    vmin=net_power.min()\n",
    "    vmax=net_power.max()\n",
    "    num_of_trials = net_power.shape[0]\n",
    "    num_of_channels = net_power.shape[1]\n",
    "    fig, axs = plt.subplots(nrows=num_of_channels, ncols=num_of_trials,figsize=(10, 5))\n",
    "    for channeli in range(num_of_channels):\n",
    "        for triali in range(num_of_trials):\n",
    "            net_power_tfr = net_power[triali, channeli, :, :]\n",
    "            ax= axs[channeli, triali]\n",
    "            ax.imshow(net_power_tfr, aspect='auto', origin='lower', extent=[-0.7, 0, 2.5, 100], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.colorbar(ax.images[0], ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_around_dig.shape)\n",
    "\n",
    "net_power = power_dig_before - power_door_before\n",
    "\n",
    "print(net_power.shape)\n",
    "print(net_power[0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Power for 1s around digging only [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list=['around_dig','around_door']\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharex=True, sharey=True)\n",
    "axs=axs.flatten()\n",
    "writer=pd.ExcelWriter(savepath+'events_power_spectral_density.xlsx')\n",
    "for i, event in enumerate(events_list):\n",
    "\n",
    "    data = power_df[['rat','task','channel',event]]\n",
    "    data['channel']=data['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "    data_groups=data.groupby(['task','channel'])\n",
    "    mean_data_dict={}\n",
    "    for (task, channel), group in data_groups:\n",
    "        group=group.reset_index(drop=True)\n",
    "        data = np.array(group[event])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_sem = scipy.stats.sem(data, axis=0)\n",
    "        mean_data_dict[task+'_'+channel+'_mean']=data_mean\n",
    "        mean_data_dict[task+'_'+channel+'_sem']=data_sem\n",
    "        freq = np.linspace(0, 1000, len(data_mean))\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f'{event}')\n",
    "        ax.plot(freq, data_mean, color=plotting_styles.colors[task], linestyle=plotting_styles.linestyles[channel])\n",
    "        ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2, color=plotting_styles.colors[task])\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_xlabel('Frequency (Hz)')\n",
    "        ax.set_ylabel('Power uV^2/Hz')\n",
    "    mean_df=pd.DataFrame(mean_data_dict)\n",
    "    #mean_df.to_excel(writer, sheet_name=event)\n",
    "#writer.close()\n",
    "#plt.savefig(savepath+'events_power_spectral_density.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events Power Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Power Boxplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Trial [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df=compiled_data_all_epochs.__deepcopy__()\n",
    "\n",
    "boxplot_df.loc[:,['pre_door','post_door','pre_dig','post_dig']]=boxplot_df.loc[:,['pre_door','post_door','pre_dig','post_dig']].applymap(lambda x: power_functions.apply_welch_transform(x))\n",
    "new_boxplot_df=boxplot_df[['rat', 'task', 'date', 'channel','trial']].copy()\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "for col in ['pre_door','post_door','pre_dig','post_dig']:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        new_boxplot_df[band + '_' + col] = boxplot_df[col].apply(lambda x: power_functions.get_band_power(x, band_start, band_end))\n",
    "\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task']+ '_' + new_boxplot_df['date']\n",
    "\n",
    "all_boxplot_df=new_boxplot_df.__deepcopy__()\n",
    "\n",
    "all_boxplot_df['channel'] = all_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "aon_channels=all_boxplot_df[all_boxplot_df['channel']=='AON']\n",
    "vhp_channels=all_boxplot_df[all_boxplot_df['channel']=='vHp']\n",
    "\n",
    "area_list= ['AON', 'vHp']\n",
    "for area in area_list:\n",
    "    area_channels = all_boxplot_df[all_boxplot_df['channel'] == area]\n",
    "    writer=pd.ExcelWriter(savepath+'events_power_per_band_{}_truncated.xlsx'.format(area), engine='xlsxwriter')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "\n",
    "    axs=axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        area_df=area_channels.__deepcopy__()\n",
    "        event_cols = [col for col in area_df.columns if event in col]\n",
    "        print(event_cols)\n",
    "        event_df = area_df[['rat', 'task', 'channel','trial', *event_cols]]\n",
    "        event_df_melted = pd.melt(event_df, id_vars=['rat', 'task', 'channel','trial'], var_name='band', value_name='power')\n",
    "        event_df_melted['band'] = event_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "        ax=axs[i]\n",
    "        #sns.boxplot(data=event_df_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, showfliers=False, ax=axs[i])\n",
    "        #sns.stripplot(data=event_df_melted, x='band', y='power', hue='task', hue_order=['BWcontext','BWnocontext'], palette=colors, dodge=True, alpha=0.5, jitter=0.2, ax=axs[i], linewidth=1, legend=False )\n",
    "        sns.violinplot(x='band',y='power',hue='task',hue_order=['BWcontext','BWnocontext'],data=event_df_melted, ax=ax)\n",
    "        #sns.stripplot(x='band',y='power',hue='task',hue_order=['BWcontext','BWnocontext'],data=event_df,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax, color=\".3\", size=2)\n",
    "\n",
    "        ax.set_title(f'{events_dict[event]} {area}', fontsize=20)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        #axs[i].set_yscale('log')\n",
    "        #axs[i].set_ylim(1e-3, 1e3)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel('Power (V^2)', fontsize=25)\n",
    "        event_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    plt.savefig(savepath+'events_power_per_band_{}_truncated.png'.format(area), format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Trial Multitaper [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath + 'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df = compiled_data_all_epochs.__deepcopy__()\n",
    "\n",
    "event_cols = ['pre_door', 'post_door', 'pre_dig', 'post_dig']\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "sfreq = 2000\n",
    "epsilon = 1e-12  # for log-normalization\n",
    "\n",
    "# Apply multitaper PSD to each event column\n",
    "for col in event_cols:\n",
    "    boxplot_df[col] = boxplot_df[col].apply(lambda x: psd_array_multitaper(x, sfreq=sfreq, fmin=0, fmax=1000, adaptive=True, normalization='full', verbose=0, max_iter=500, bandwidth=4)[0])\n",
    "\n",
    "# Calculate band power from multitaper PSD and log-normalize\n",
    "new_boxplot_df = boxplot_df[['rat', 'task', 'date', 'channel', 'trial']].copy()\n",
    "for col in event_cols:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        new_boxplot_df[f'{band}_{col}_mt'] = boxplot_df[col].apply(lambda x: np.log10(power_functions.get_band_power(x, band_start, band_end) + epsilon))\n",
    "\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task'] + '_' + new_boxplot_df['date']\n",
    "all_boxplot_df = new_boxplot_df.__deepcopy__()\n",
    "all_boxplot_df['channel'] = all_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "all_boxplot_df.to_excel(savepath + 'power_per_trial_mt.xlsx', index=False)\n",
    "area_list = ['AON', 'vHp']\n",
    "for area in area_list:\n",
    "    area_channels = all_boxplot_df[all_boxplot_df['channel'] == area]\n",
    "    writer = pd.ExcelWriter(savepath + f'events_power_per_band_multitaper_log10_{area}_truncated.xlsx', engine='xlsxwriter')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharex=True, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict = {'pre_door': 'Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_cols_mt = [f'{band}_{event}_mt' for band in bands_dict.keys()]\n",
    "        event_df = area_channels[['rat', 'task', 'channel', 'trial', *event_cols_mt]]\n",
    "        event_df_melted = pd.melt(event_df, id_vars=['rat', 'task', 'channel', 'trial'], var_name='band', value_name='power')\n",
    "        event_df_melted['band'] = event_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "        ax = axs[i]\n",
    "        sns.violinplot(x='band', y='power', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_df_melted, ax=ax)\n",
    "        ax.set_title(f'{events_dict[event]} {area} (Multitaper, log10)', fontsize=20)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('log10 Power (V^2)', fontsize=25)\n",
    "        event_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    plt.savefig(savepath + f'events_power_per_band_multitaper_log10_{area}_truncated.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean across all trials Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(power_functions)\n",
    "compiled_data_all_epochs=pd.read_pickle(savepath+'compiled_data_all_epochs_truncated.pkl')\n",
    "boxplot_df=compiled_data_all_epochs.__deepcopy__()\n",
    "event_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "boxplot_df.loc[:,event_list]=boxplot_df.loc[:,event_list].applymap(lambda x: power_functions.apply_welch_transform(x))\n",
    "new_boxplot_df=power_functions.get_all_band_power_from_welchdf(boxplot_df, event_list)\n",
    "new_boxplot_df['channel'] = new_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task']+ '_' + new_boxplot_df['date']\n",
    "print(new_boxplot_df.columns)\n",
    "# Group by unique_id and channel, then take the mean across rows for columns containing 'pre' or 'post'\n",
    "pre_post_cols = [col for col in new_boxplot_df.columns if ('pre' in col or 'post' in col)]\n",
    "mean_data_list = []\n",
    "\n",
    "mean_boxplot_df=new_boxplot_df.__deepcopy__()\n",
    "unique_id_list=list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list=[]\n",
    "\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df=mean_boxplot_df[mean_boxplot_df['unique_id']==unique_id]\n",
    "    unique_id_df_grouped=unique_id_df.groupby(['channel'])\n",
    "    for channel, group in unique_id_df_grouped:\n",
    "        print(channel)\n",
    "        group=group.reset_index(drop=True)\n",
    "        columns = [col for col in group.columns if 'pre' in col or 'post' in col]\n",
    "        print(columns)\n",
    "        rat_id=group['rat'].iloc[0]\n",
    "        task_id=group['task'].iloc[0]\n",
    "        date_id=group['date'].iloc[0]\n",
    "        channel_id=group['channel'].iloc[0]\n",
    "        mean_data_dict={}\n",
    "        for col in columns:\n",
    "            data=np.array(group[col])\n",
    "            data_mean=np.mean(data,axis=0)\n",
    "            data_sem=scipy.stats.sem(data,axis=0)\n",
    "            mean_data_dict[col+'_mean']=data_mean\n",
    "            mean_data_dict[col+'_sem']=data_sem\n",
    "        mean_data_dict['rat']=rat_id\n",
    "        mean_data_dict['task']=task_id\n",
    "        mean_data_dict['date']=date_id\n",
    "        mean_data_dict['channel']=channel_id\n",
    "        mean_data_list.append(mean_data_dict)\n",
    "mean_df=pd.DataFrame(mean_data_list)\n",
    "mean_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "\n",
    "mean_df_melted=pd.melt(mean_df, id_vars=['rat','task','channel'], var_name='band', value_name='power')\n",
    "mean_df_melted['band name']=mean_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event']=mean_df_melted['band'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event']=mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted['type']=mean_df_melted['band'].apply(lambda x: x.split('_')[-1])\n",
    "cols = list(mean_df_melted.columns)\n",
    "cols.append(cols.pop(cols.index('power')))\n",
    "mean_df_melted = mean_df_melted[cols]\n",
    "mean_df_melted.drop(columns=['band'], inplace=True)\n",
    "mean_df_melted=mean_df_melted[mean_df_melted['band name']!= 'total'] #Remove total band if it exists\n",
    "mean_df_melted_grouped=mean_df_melted.groupby(['event'])\n",
    "writer=pd.ExcelWriter(savepath+'mean_across_trials_power_truncated.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group=group.reset_index(drop=True)\n",
    "    group.to_excel(writer, sheet_name=event[0])\n",
    "writer.close()\n",
    "arealist=['AON','vHp']\n",
    "for area in arealist:\n",
    "    fig,axs=plt.subplots(1,4,figsize=(40,10), sharey=True)\n",
    "    axs=axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig'}\n",
    "    for i,event in enumerate(events_dict.keys()):\n",
    "        ax=axs[i]\n",
    "        ## Plotting AON mean power\n",
    "        plotting_df=mean_df_melted[(mean_df_melted['channel'].str.contains(area)) & (mean_df_melted['type']=='mean') & (mean_df_melted['event']==event)] \n",
    "        # Remove outliers using the IQR method for each band name\n",
    "        def remove_outliers_iqr(df, value_col='power', group_col='band name'):\n",
    "            def iqr_filter(group):\n",
    "                q1 = group[value_col].quantile(0.25)\n",
    "                q3 = group[value_col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                lower = q1 - 1.5 * iqr\n",
    "                upper = q3 + 1.5 * iqr\n",
    "                return group[(group[value_col] >= lower) & (group[value_col] <= upper)]\n",
    "            return df.groupby(group_col, group_keys=False).apply(iqr_filter)\n",
    "\n",
    "        plotting_df = remove_outliers_iqr(plotting_df)\n",
    "        sns.boxplot(x='band name',y='power',hue='task',data=plotting_df,ax=ax, showfliers=False)\n",
    "        sns.stripplot(x='band name',y='power',hue='task',data=plotting_df,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax, color=\".3\", size=2)\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.legend(loc='upper left', fontsize=15)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (V^2)', fontsize=25)\n",
    "        ax.set_title(f'{area} power {events_dict[event]}', fontsize=20)\n",
    "    fig.savefig(savepath+f'mean_power_across_trials_{area}_truncated.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#mean_df=pd.DataFrame(mean_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multitaper Mean across trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "\n",
    "##############\n",
    "\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "importlib.reload(power_functions)\n",
    "\n",
    "compiled_data_all_epochs = pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df=compiled_data_all_epochs.__deepcopy__()\n",
    "# number_per_segment = 700\n",
    "# tukey_window = scipy.signal.get_window(('tukey', 0.1), number_per_segment)\n",
    "columns= ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door', 'around_dig']\n",
    "# Apply multitaper PSD to each event column\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=1000, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000)\n",
    "    return psd\n",
    "\n",
    "event_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "power_df.loc[:, columns] = power_df.loc[:, columns].applymap(multitaper_transform)\n",
    "new_boxplot_df = power_functions.get_all_band_power_from_mt(power_df, event_list)\n",
    "#new_boxplot_df['channel'] = new_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp') #TRIAL\n",
    "new_boxplot_df['unique_id'] = new_boxplot_df['rat'] + '_' + new_boxplot_df['task'] + '_' + new_boxplot_df['date']\n",
    "print(new_boxplot_df.columns)\n",
    "\n",
    "pre_post_cols = [col for col in new_boxplot_df.columns if ('pre' in col or 'post' in col)]\n",
    "mean_data_list = []\n",
    "\n",
    "mean_boxplot_df = new_boxplot_df.__deepcopy__()\n",
    "unique_id_list = list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list = []\n",
    "\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df = mean_boxplot_df[mean_boxplot_df['unique_id'] == unique_id]\n",
    "    unique_id_df_grouped = unique_id_df.groupby(['channel'])\n",
    "    for channel, group in unique_id_df_grouped:\n",
    "        print(channel)\n",
    "        group = group.reset_index(drop=True)\n",
    "        columns = [col for col in group.columns if 'pre' in col or 'post' in col]\n",
    "        print(columns)\n",
    "        rat_id = group['rat'].iloc[0]\n",
    "        task_id = group['task'].iloc[0]\n",
    "        date_id = group['date'].iloc[0]\n",
    "        channel_id = group['channel'].iloc[0]\n",
    "        mean_data_dict = {}\n",
    "        for col in columns:\n",
    "            data = np.array(group[col])\n",
    "            data_mean = np.mean(data, axis=0)\n",
    "            data_sem = scipy.stats.sem(data, axis=0)\n",
    "            mean_data_dict[col + '_mean'] = data_mean\n",
    "            mean_data_dict[col + '_sem'] = data_sem\n",
    "        mean_data_dict['rat'] = rat_id\n",
    "        mean_data_dict['task'] = task_id\n",
    "        mean_data_dict['date'] = date_id\n",
    "        mean_data_dict['channel'] = channel_id\n",
    "        mean_data_list.append(mean_data_dict)\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "mean_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df, value_col='power', group_col='band name'):\n",
    "    def iqr_filter(group):\n",
    "        q1 = group[value_col].quantile(0.25)\n",
    "        q3 = group[value_col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        return group[(group[value_col] >= lower) & (group[value_col] <= upper)]\n",
    "    return df.groupby(group_col, group_keys=False).apply(iqr_filter)\n",
    "\n",
    "mean_df_melted = pd.melt(mean_df, id_vars=['rat', 'task', 'channel'], var_name='band', value_name='power')\n",
    "mean_df_melted['band name'] = mean_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event'] = mean_df_melted['band'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event'] = mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted['type'] = mean_df_melted['band'].apply(lambda x: x.split('_')[-1])\n",
    "cols = list(mean_df_melted.columns)\n",
    "cols.append(cols.pop(cols.index('power')))\n",
    "mean_df_melted = mean_df_melted[cols]\n",
    "mean_df_melted.drop(columns=['band'], inplace=True)\n",
    "#mean_df_melted=mean_df_melted[mean_df_melted['band name']!= 'total'] #Remove total band if it exists\n",
    "mean_df_melted_grouped = mean_df_melted.groupby(['event'])\n",
    "\n",
    "writer_mt = pd.ExcelWriter(savepath + f'pow_events_perband_{int(time_window*fs/2)}ms.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group = group.reset_index(drop=True)\n",
    "    group.to_excel(writer_mt, sheet_name=event[0])\n",
    "writer_mt.close()\n",
    "arealist = ['AON', 'vHp']\n",
    "fig = plt.figure(figsize=(40, 20), layout='constrained')\n",
    "fig.suptitle('Power per band (Multitaper)', fontsize=30)\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for area_num,area in enumerate(arealist):\n",
    "    axs = subfigs[area_num].subplots(nrows=1, ncols=4, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    events_dict = {'pre_door': 'Pre Door', 'post_door': 'Post Door', 'pre_dig': 'Pre Dig', 'post_dig': 'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        ax = axs[i]\n",
    "        plotting_df = mean_df_melted[\n",
    "            (mean_df_melted['channel'].str.contains(area)) &\n",
    "            (mean_df_melted['type'] == 'mean') &\n",
    "            (mean_df_melted['event'] == event)\n",
    "        ]\n",
    "\n",
    "        plotting_df = remove_outliers_iqr(plotting_df) ## REMOVE OUTLIERS\n",
    "        band_order = ['theta', 'beta', 'gamma','total']\n",
    "        sns.barplot(x='band name', y='power', hue='task', data=plotting_df, order=band_order, ax=ax)\n",
    "        sns.stripplot(x='band name', y='power', hue='task', data=plotting_df, order=band_order, dodge=True, palette=colors, jitter=True, legend=False, ax=ax, linewidth=1, alpha=0.8)\n",
    "        ax.set_xlabel('Band', fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "        ax.legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        #ax.legend(loc='upper left', fontsize=15)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Power (mV^2)', fontsize=25)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.set_title(f'{area} power {events_dict[event]}', fontsize=20)\n",
    "fig.savefig(savepath + f'pow_events_perband_{int(time_window*fs/2)}ms.png', format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Power using MNE Epochs [NOT MEAN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "test_epoch = con_data_df_clean['mne_epoch_dig_before'].iloc[0]\n",
    "test_epoch_array=test_epoch.get_data()\n",
    "print(test_epoch_array.shape)\n",
    "test_epoch_psd = test_epoch.compute_psd(method='multitaper', fmin=0, fmax=100, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000, exclude=['Ref'])\n",
    "print(test_epoch_psd.get_data().shape)\n",
    "\n",
    "def multitaper_transform(x):\n",
    "    # x is a 1D array or list of values\n",
    "    psd, _ = psd_array_multitaper(x, sfreq=2000, fmin=0, fmax=1000, adaptive=True, bandwidth=6, normalization='full', verbose=0, max_iter=1000)\n",
    "    return psd\n",
    "\n",
    "single_data = test_epoch_array[0,0,:]\n",
    "psd_single_data = multitaper_transform(single_data)\n",
    "\n",
    "print(test_epoch_psd.get_data()[0,0,:])\n",
    "print(psd_single_data)\n",
    "\n",
    "\n",
    "mne_psd_array=test_epoch_psd.get_data()\n",
    "mne_psd_array_mean=np.mean(mne_psd_array, axis=0)\n",
    "\n",
    "# Create dataframe with channel names and PSD arrays\n",
    "mne_psd_array_df = pd.DataFrame({\n",
    "    'channel': test_epoch_psd.ch_names,\n",
    "    'pre_dig': list(mne_psd_array_mean),\n",
    "    'rat_id':'dk3'\n",
    "})\n",
    "\n",
    "new_boxplot_df = power_functions.get_all_band_power_from_mt(mne_psd_array_df, ['pre_dig'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Power using MNE Epochs [USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "event_list = ['mne_epoch_door_before', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "# Define frequency bands\n",
    "freq_bands = {\n",
    "        'theta': (4, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 80),\n",
    "        'total': (0, 100),\n",
    "}\n",
    "\n",
    "def calculate_band_power(psd, freqs, fmin, fmax):\n",
    "    \"\"\"Calculate average power in a frequency band\"\"\"\n",
    "    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n",
    "    if np.sum(freq_mask) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(psd[freq_mask])\n",
    "\n",
    "print(con_data_df_clean.columns)\n",
    "\n",
    "# Dictionary to store dataframes for each event\n",
    "event_dataframes = {event: [] for event in event_list}\n",
    "\n",
    "for i in range(len(con_data_df_clean)):\n",
    "    rat = con_data_df_clean.loc[i, 'rat_id']\n",
    "    task = con_data_df_clean.loc[i, 'task']\n",
    "    date = con_data_df_clean.loc[i, 'date']\n",
    "    \n",
    "    print(f\"Processing rat {rat}, task {task}, date {date} ({i+1}/{len(con_data_df_clean)})\")\n",
    "    \n",
    "    for event in event_list:\n",
    "        test_epoch = con_data_df_clean.loc[i, event]\n",
    "        \n",
    "        # Compute PSD\n",
    "        test_epoch_psd = test_epoch.compute_psd(\n",
    "            method='multitaper', \n",
    "            fmin=0, \n",
    "            fmax=100, \n",
    "            adaptive=True, \n",
    "            bandwidth=6, \n",
    "            normalization='full', \n",
    "            verbose=0,\n",
    "            exclude=['Ref']\n",
    "        )\n",
    "        \n",
    "        # Get PSD data and frequencies\n",
    "        psd_array = test_epoch_psd.get_data()\n",
    "        freqs = test_epoch_psd.freqs\n",
    "        channel_names = test_epoch_psd.ch_names\n",
    "        \n",
    "        # Create rows with band power\n",
    "        band_rows = []\n",
    "        for trial in range(psd_array.shape[0]):\n",
    "            for ch_idx, channel in enumerate(channel_names):\n",
    "                psd = psd_array[trial, ch_idx, :]\n",
    "                \n",
    "                # Calculate power for each frequency band\n",
    "                for band_name, (fmin, fmax) in freq_bands.items():\n",
    "                    power = calculate_band_power(psd, freqs, fmin, fmax)\n",
    "                    \n",
    "                    band_rows.append({\n",
    "                        'rat': rat,\n",
    "                        'date': date,\n",
    "                        'task': task,\n",
    "                        'trial_num': trial,\n",
    "                        'channel': channel,\n",
    "                        'band': band_name,\n",
    "                        'power': power\n",
    "                    })\n",
    "        \n",
    "        # Add to the event's dataframe list\n",
    "        event_dataframes[event].extend(band_rows)\n",
    "\n",
    "# Combine all rows for each event into dataframes\n",
    "print(\"\\nCreating final dataframes...\")\n",
    "final_dfs = {}\n",
    "for event in event_list:\n",
    "    df = pd.DataFrame(event_dataframes[event])\n",
    "    final_dfs[event] = df\n",
    "    print(f\"{event}: {len(df)} rows\")\n",
    "\n",
    "# Save to Excel with multiple sheets\n",
    "excel_filename = savepath + f'pow_events_perband_pertrial_{int(time_window*fs/2)}ms.xlsx'\n",
    "print(f\"\\nSaving to {excel_filename}...\")\n",
    "\n",
    "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "    for event, df in final_dfs.items():\n",
    "        # Clean up sheet name (Excel has 31 char limit)\n",
    "        sheet_name = event.replace('mne_epoch_', '')[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Saved sheet: {sheet_name} ({len(df)} rows)\")\n",
    "\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "# Display sample from each dataframe\n",
    "for event, df in final_dfs.items():\n",
    "    print(f\"\\n{event} - First 10 rows:\")\n",
    "    print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a mean across channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_boxplot_df=boxplot_df.__deepcopy__()\n",
    "unique_id_list=list(np.unique(mean_boxplot_df['unique_id']))\n",
    "mean_data_list=[]\n",
    "sem_data_list=[]\n",
    "mean_boxplot_df['channel']=mean_boxplot_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "mean_boxplot_df_grouped=mean_boxplot_df.groupby(['task', 'channel', 'trial'])\n",
    "for (task, channel, trial), group in mean_boxplot_df_grouped:\n",
    "    print(task, channel, trial)\n",
    "    group=group.reset_index(drop=True)\n",
    "    columns=group.columns[-21:-1]\n",
    "    data_array=np.array(group[columns])\n",
    "    data_mean=np.mean(data_array, axis=0)\n",
    "    data_sem=scipy.stats.sem(data_array, axis=0)\n",
    "    print(data_mean)\n",
    "    print(data_sem)\n",
    "    mean_data_dict = {col: data_mean[idx] for idx, col in enumerate(columns)}\n",
    "    sem_data_dict = {col: data_sem[idx] for idx, col in enumerate(columns)}\n",
    "    mean_data_dict['task'] = task\n",
    "    mean_data_dict['channel'] = channel\n",
    "    mean_data_dict['trial'] = trial\n",
    "    sem_data_dict['task'] = task\n",
    "    sem_data_dict['channel'] = channel\n",
    "    sem_data_dict['trial'] = trial\n",
    "    mean_data_list.append(mean_data_dict)\n",
    "    sem_data_list.append(sem_data_dict)\n",
    "\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for task in ['BWcontext', 'BWnocontext']:\n",
    "    task_data = mean_df[(mean_df['task'] == task) & (mean_df['channel'] == 'AON')]\n",
    "    ax.plot(task_data['trial'], task_data['total_complete_trial'], label=task, marker='o')\n",
    "ax.set_xlabel('Trial Number')\n",
    "ax.set_ylabel('AON Power in total complete trial')\n",
    "ax.set_title('AON Power in total complete trial across Trials')\n",
    "ax.set_xticks(np.arange(0, 20, 1))\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean in groups of 5 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df_grouped=boxplot_df.groupby(['unique_id'])\n",
    "mean_data_list=[]\n",
    "for unique_id, group in boxplot_df_grouped:\n",
    "    print(unique_id)\n",
    "    num_of_trials=len(group['trial'].unique())\n",
    "    print(num_of_trials)\n",
    "    group=group.reset_index(drop=True)\n",
    "    print()\n",
    "    for channel in group['channel'].unique():\n",
    "        i=0\n",
    "        group_channel=group[group['channel']==channel]\n",
    "        group_channel=group_channel.reset_index(drop=True)\n",
    "        \n",
    "        while i < 16:\n",
    "            print(i)\n",
    "            group_trial = group_channel[(group_channel['trial'] >= i) & (group_channel['trial'] < i + 4)]\n",
    "            group_trial_data_array = np.array(group_trial.loc[:, 'beta_pre_door':'total_around_dig'])\n",
    "            data_mean= group_trial_data_array.mean(axis=0)\n",
    "            row = {**group_channel.iloc[0][['rat', 'task', 'channel', 'unique_id']].to_dict(),\n",
    "                   **{'trial': f'{i}-{i + 4}'},\n",
    "                   **dict(zip(group_trial.loc[:, 'beta_pre_door':'total_around_dig'].columns, data_mean))}\n",
    "            mean_data_list.append(row)\n",
    "\n",
    "            i=i+4\n",
    "mean_df = pd.DataFrame(mean_data_list)\n",
    "mean_df_melted=pd.melt(mean_df, id_vars=['rat','task','channel','trial', 'unique_id'], var_name='band_event', value_name='power')\n",
    "mean_df_melted['band name']=mean_df_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "mean_df_melted['event']=mean_df_melted['band_event'].apply(lambda x: x.split('_')[1:3])\n",
    "mean_df_melted['event']=mean_df_melted['event'].apply(lambda x: '_'.join(x))\n",
    "mean_df_melted_grouped=mean_df_melted.groupby(['event'])\n",
    "writer=pd.ExcelWriter(savepath+'power_boxplot_average_per_4_trials.xlsx')\n",
    "for event, group in mean_df_melted_grouped:\n",
    "    print(event)\n",
    "    group=group.reset_index(drop=True)\n",
    "    group.drop(columns=['band_event','event'], inplace=True)\n",
    "    group.to_excel(writer, sheet_name=event[0])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Power Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "\n",
    "power_spec_df = compiled_data_all_epochs.__deepcopy__()\n",
    "print(power_spec_df.iloc[0,-2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spec_df.iloc[:, -2:] = power_spec_df.iloc[:, -2:].applymap(lambda x: spectrogram(x, fs=2000, nperseg=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_spec_df.iloc[0,-2][1])\n",
    "for col in ['around_door','around_dig']:\n",
    "\n",
    "    power_spec_df[col+'_f'] = power_spec_df[col].apply(lambda x: x[0])\n",
    "    power_spec_df[col+'_t'] = power_spec_df[col].apply(lambda x: x[1])\n",
    "    power_spec_df[col+'_sxx'] = power_spec_df[col].apply(lambda x: x[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spec_df['channel'] = power_spec_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "power_spec_df_grouped = power_spec_df.groupby(['task', 'channel'])\n",
    "for (task, channel), group in power_spec_df_grouped:\n",
    "    group = group.reset_index(drop=True)\n",
    "    for col in ['around_door', 'around_dig']:\n",
    "        data = np.array(group[col + '_sxx'])\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        print(data_mean.shape)\n",
    "        freq = group[col + '_f'].iloc[0]\n",
    "        time = group[col + '_t'].iloc[0]\n",
    "        time_adjusted=np.linspace(-2,2,len(time))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 10), constrained_layout=True)\n",
    "        im = ax.pcolormesh(time_adjusted, freq, data_mean, shading='gouraud', vmin=0, vmax=0.5)\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.set_title(f'{task} {channel} {col}')\n",
    "        ax.set_ylim(0, 100)\n",
    "        # ax.set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "        # ax.set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "        ax.vlines(0, 0, 100, color='red', linestyle='--')\n",
    "        ax.set_xlabel('Time (s)', fontsize=20)\n",
    "\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax.set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        i = i + 1\n",
    "        fig.savefig(savepath + f'power_mean_spectrogram_{task}_{channel}_{col}.png', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Coherence Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Coherence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating static data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "importlib.reload(coherence_functions)\n",
    "# --- Basic Parameters ---\n",
    "sfreq = 1000  # Sampling frequency in Hz\n",
    "n_epochs = 20  # Number of trials\n",
    "n_times = 2000  # Number of time points per trial (2 seconds of data)\n",
    "times = np.arange(n_times) / sfreq  # Time vector for one epoch\n",
    "n_signals = 3  # We'll create 3 channels\n",
    "\n",
    "# We will test connectivity in the beta band\n",
    "freq_of_interest = 20.0  # 20 Hz\n",
    "# --- Generate Data for Static Connectivity ---\n",
    "\n",
    "# Initialize data array: (n_epochs, n_signals, n_times)\n",
    "static_data = np.random.randn(n_epochs, n_signals, n_times) * 0.1  # Add background noise\n",
    "\n",
    "# Create the shared 20 Hz sine wave component\n",
    "shared_signal = np.sin(2 * np.pi * freq_of_interest * times)\n",
    "\n",
    "# Add the shared signal to the first two channels for all epochs\n",
    "static_data[:, 0, :] += shared_signal\n",
    "static_data[:, 1, :] += shared_signal\n",
    "\n",
    "print(\"Shape of static_data:\", static_data.shape)\n",
    "ch_names=['AON', 'vHp', 'PFC']  # Example channel names\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "static_data_mne=mne.EpochsArray(static_data, info)\n",
    "print(static_data_mne)\n",
    "# Plot the static_data for each channel in the first epoch\n",
    "fig, axs = plt.subplots(n_signals, 1, figsize=(12, 6), sharex=True)\n",
    "for i, ch in enumerate(ch_names):\n",
    "    axs[i].plot(times, static_data[0, i, :], label=f'Channel: {ch}')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend(loc='upper right')\n",
    "axs[-1].set_xlabel('Time (s)')\n",
    "plt.suptitle('Static Data Example (Epoch 0)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "coherence_band_sce = coherence_functions.convert_epoch_to_coherence(static_data_mne)\n",
    "print(coherence_band_sce)\n",
    "coherence_band_time=coherence_functions.convert_epoch_to_coherence_time(static_data_mne)\n",
    "print(coherence_band_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncating LFP data and loading it into MNE arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import mne_connectivity\n",
    "import sys\n",
    "importlib.reload(lfp_pre_processing_functions)\n",
    "#files=[f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\all_data_mat\\\\20230616_dk6_BW_context_day2.mat']\n",
    "event_data_df=[]\n",
    "con_data_df=[]\n",
    "\n",
    "con_data_df_shuffled=[]\n",
    "shuffled_event_data_df=[]\n",
    "events_codes_all = {}\n",
    "random_baseline_data=[]\n",
    "baseline_lfp_all=[]\n",
    "\n",
    "time_window = 0.7\n",
    "fs= 2000\n",
    "\n",
    "files_short=[files[10]] ### TEST CHANGE THIS \n",
    "\n",
    "\n",
    "for file_num,file in enumerate(files):\n",
    "    #if 'dk1' in file:\n",
    "        \n",
    "        #print(file)\n",
    "        base_name = os.path.basename(file)\n",
    "        base_name, _ = os.path.splitext(base_name)\n",
    "\n",
    "        date, rat_id, task = lfp_pre_processing_functions.exp_params(base_name)\n",
    "        print(date, rat_id, task)\n",
    "        if task == 'nocontextday2' or task == 'nocontextos2':\n",
    "            task = 'nocontext'\n",
    "        if task =='nocontext':\n",
    "            continue\n",
    "        # if rat_id=='dk1': #REMOVING DK1 TEMPORARLILY . PLEASE CHANGE LATER\n",
    "        #     continue\n",
    "        f = h5py.File(file, 'r')\n",
    "        channels = list(f.keys())\n",
    "        #print(channels)\n",
    "         \n",
    "        if not any(\"AON\" in channel or \"vHp\" in channel for channel in channels):\n",
    "            print(\"No AON or vHp channels in this file\")\n",
    "            continue\n",
    "\n",
    "        events,reference_electrode=lfp_pre_processing_functions.get_keyboard_and_ref_channels(f,channels)\n",
    "\n",
    "    #finding global start and end time of all channels, since they start and end recordings at different times\n",
    "        global_start_time, global_end_time=lfp_pre_processing_functions.find_global_start_end_times(f,channels)\n",
    "        \n",
    "        ## Reference electrode finding and padding\n",
    "        reference_time = np.array(reference_electrode['times']).flatten()\n",
    "        reference_value = np.array(reference_electrode['values']).flatten()\n",
    "        padd_ref_data,padded_ref_time=lfp_pre_processing_functions.pad_raw_data_raw_time(reference_value,reference_time,global_start_time,global_end_time,sampling_rate=2000)\n",
    "\n",
    "        events_codes = np.array(events['codes'][0])\n",
    "        events_times = np.array(events['times'][0])\n",
    "        events_codes_all[base_name] = events_codes\n",
    "        epochs = lfp_pre_processing_functions.generate_epochs_with_first_event(events_codes, events_times)\n",
    "        #epochs = functions.generate_specific_num_of_epochs_with_first_event(events_codes, events_times,5)\n",
    "        aon_lfp_channels=[x for x in channels if 'AON' in x ]\n",
    "        vHp_lfp_channels=[x for x in channels if 'vHp' in x ]\n",
    "        all_channels=np.concatenate((aon_lfp_channels,vHp_lfp_channels))\n",
    "        #print(all_channels)\n",
    "        \n",
    "        mne_baseline_data=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        mne_epoch_around_dig=np.zeros((len(epochs),len(all_channels),int(time_window*fs)*2))\n",
    "        \n",
    "        mne_baseline_data_shuffled=np.zeros((1,len(all_channels),4000))\n",
    "        mne_epoch_door_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_door_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_before_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_dig_after_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs)))\n",
    "        mne_epoch_around_door_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "        mne_epoch_around_dig_shuffled=np.zeros((len(epochs),len(all_channels),int(time_window*fs*2)))\n",
    "\n",
    "        print(f'File {rat_id} {task} {date} has {len(epochs)} epochs and {len(all_channels)} channels')\n",
    "\n",
    "\n",
    "        first_event = events_times[0]\n",
    "        \n",
    "        for channel_num,channeli in enumerate(all_channels):\n",
    "            if \"AON\" in channeli or \"vHp\" in channeli:\n",
    "                channel_id = channeli\n",
    "                data_all = f[channeli]\n",
    "                raw_data = np.array(data_all['values']).flatten()\n",
    "                raw_time = np.array(data_all['times']).flatten()\n",
    "                sampling_rate = int(1 / data_all['interval'][0][0])\n",
    "                #print(raw_data.shape, raw_time.shape, sampling_rate)\n",
    "                padded_data,padded_time=lfp_pre_processing_functions.pad_raw_data_raw_time(raw_data,raw_time,global_start_time,global_end_time,sampling_rate)\n",
    "                subtracted_data = padded_data - padd_ref_data\n",
    "                raw_data=subtracted_data\n",
    "                notch_data = lfp_pre_processing_functions.iir_notch(raw_data, sampling_rate, 60) ###CHANGE notch_data to notch_filtered_data\n",
    "\n",
    "                print(notch_data.nbytes)\n",
    "                notch_data_detrended = scipy.signal.detrend(notch_data)\n",
    "                notch_filtered_data=lfp_pre_processing_functions.sosbandpass(notch_data_detrended, fs=2000, start_freq=1,end_freq=100, order=8) ###CHANGE THIS FOR NOT BANDBASS FILTERTING\n",
    "                print(notch_filtered_data.nbytes)\n",
    "                \n",
    "                data_before, time, baseline_mean, baseline_std=lfp_pre_processing_functions.baseline_data_normalization(notch_filtered_data, raw_time, first_event, sampling_rate)\n",
    "                first_event_index=np.where(raw_time>first_event)[0][0]\n",
    "\n",
    "                mne_baseline_data[0,channel_num,:]=list(data_before)\n",
    "                mne_baseline_data_shuffled[0,channel_num,:]=list(np.random.permutation(data_before))\n",
    "                total = notch_filtered_data\n",
    "\n",
    "                \n",
    "                for i, epochi in enumerate(epochs):\n",
    "                    door_timestamp = epochi[0][0]\n",
    "                    trial_type = epochi[0][1]\n",
    "                    dig_type = epochi[1, 1]\n",
    "                    #print(dig_type)\n",
    "                    dig_timestamp = epochi[1, 0]\n",
    "                    #print(door_timestamp, trial_type, dig_timestamp, dig_type)\n",
    "                    data_trial_before, data_trial_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,door_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_dig_before, data_dig_after=lfp_pre_processing_functions.extract_event_data(notch_filtered_data,time,dig_timestamp,sampling_rate,truncation_time=time_window)\n",
    "                    data_around_door=np.concatenate((data_trial_before, data_trial_after))\n",
    "                    data_around_dig=np.concatenate((data_dig_before, data_dig_after))\n",
    "\n",
    "                    epoch_data = [data_trial_before, data_trial_after, data_dig_before, data_dig_after, data_around_door, data_around_dig]\n",
    "                    event_data_list = [lfp_pre_processing_functions.zscore_event_data(x, baseline_std) for x in epoch_data]\n",
    "\n",
    "                    mne_epoch_door_before[i,channel_num,:]=list(event_data_list[0][-int(time_window*fs):])\n",
    "                    mne_epoch_door_after[i,channel_num,:]=list(event_data_list[1][:int(time_window*fs)])\n",
    "                    mne_epoch_dig_before[i,channel_num,:]=list(event_data_list[2][-int(time_window*fs):])\n",
    "                    mne_epoch_dig_after[i,channel_num,:]=list(event_data_list[3][:int(time_window*fs)])\n",
    "                    mid_point = int(len(event_data_list[4]) / 2)\n",
    "                    mne_epoch_around_door[i,channel_num,:]=list(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "                    mne_epoch_around_dig[i,channel_num,:]=list(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)])\n",
    "\n",
    "                    mne_epoch_door_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[0][-int(time_window*fs):]))\n",
    "                    mne_epoch_door_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[1][:int(time_window*fs)]))\n",
    "                    mne_epoch_dig_before_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[2][-int(time_window*fs):]))\n",
    "                    mne_epoch_dig_after_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[3][:int(time_window*fs)]))\n",
    "                    mne_epoch_around_door_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[4][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "                    mne_epoch_around_dig_shuffled[i,channel_num,:]=list(np.random.permutation(event_data_list[5][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]))\n",
    "\n",
    "        if len(all_channels)>0:\n",
    "            fs=2000\n",
    "            freqs = np.arange(1,100)\n",
    "            n_cycles = freqs/3\n",
    "            info = mne.create_info(ch_names=list(all_channels), sfreq=fs, ch_types='eeg')\n",
    "            mne_baseline = mne.EpochsArray(mne_baseline_data, info)\n",
    "            mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "            mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "            mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "            mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "            mne_epoch_around_door = mne.EpochsArray(mne_epoch_around_door, info)\n",
    "            mne_epoch_around_dig = mne.EpochsArray(mne_epoch_around_dig, info)\n",
    "            \n",
    "            row_list=[file_num,date,rat_id,task,mne_baseline,mne_epoch_door_before,mne_epoch_door_after,mne_epoch_dig_before,mne_epoch_dig_after,mne_epoch_around_door,mne_epoch_around_dig]\n",
    "            \n",
    "            mne_baseline_shuffled = mne.EpochsArray(mne_baseline_data_shuffled, info)\n",
    "            mne_epoch_door_before_shuffled = mne.EpochsArray(mne_epoch_door_before_shuffled, info)\n",
    "            mne_epoch_door_after_shuffled = mne.EpochsArray(mne_epoch_door_after_shuffled, info)\n",
    "            mne_epoch_dig_before_shuffled = mne.EpochsArray(mne_epoch_dig_before_shuffled, info)\n",
    "            mne_epoch_dig_after_shuffled = mne.EpochsArray(mne_epoch_dig_after_shuffled, info)\n",
    "            mne_epoch_around_door_shuffled = mne.EpochsArray(mne_epoch_around_door_shuffled, info)\n",
    "            mne_epoch_around_dig_shuffled = mne.EpochsArray(mne_epoch_around_dig_shuffled, info)\n",
    "            row_list_shuffled=[file_num,date,rat_id,task,mne_baseline_shuffled,mne_epoch_door_before_shuffled,mne_epoch_door_after_shuffled,mne_epoch_dig_before_shuffled,mne_epoch_dig_after_shuffled,mne_epoch_around_door_shuffled,mne_epoch_around_dig_shuffled]\n",
    "            shuffled_event_data_df.append(row_list_shuffled)\n",
    "\n",
    "            con_data_df.append(row_list)\n",
    "            con_data_df_shuffled.append(row_list_shuffled)\n",
    "\n",
    "\n",
    "con_data_df=pd.DataFrame(con_data_df, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df.to_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "con_data_df_shuffled=pd.DataFrame(con_data_df_shuffled, columns=['experiment','date','rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'])\n",
    "con_data_df_shuffled.to_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import signal\n",
    "\n",
    "# Before filter\n",
    "f_before, psd_before = signal.welch(notch_data, fs=2000, nperseg=1024)\n",
    "\n",
    "# After filter\n",
    "f_after, psd_after = signal.welch(notch_data_detrended, fs=2000, nperseg=1024)\n",
    "fig,axs=plt.subplots(2,1, figsize = (10,5), sharey=True)\n",
    "axs=axs.flatten()\n",
    "axs[0].semilogy(f_before, psd_before, label='Before filter')\n",
    "axs[1].semilogy(f_after, psd_after, label='After filter')\n",
    "# .xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Power Spectral Density')\n",
    "axs[0].set_xlim([0, 10])  # Focus on your filter range\n",
    "axs[1].set_xlim([0, 10])  # Focus on your filter range\n",
    "\n",
    "# plt.axvline(1, color='r', linestyle='--', label='Start freq (1 Hz)')\n",
    "# plt.axvline(100, color='g', linestyle='--', label='End freq (100 Hz)')\n",
    "# plt.legend()\n",
    "# plt.title('Frequency Domain')\n",
    "# plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Baseline Coherence Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "#con_data_df=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "baseline_df=con_data_df.__deepcopy__()\n",
    "baseline_df['mne_baseline']=baseline_df['mne_baseline'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_density(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1, 1, figsize=(10, 5), sharex=True, sharey=True)\n",
    "writer=pd.ExcelWriter(savepath+'coh_baseline_density_normalized.xlsx')\n",
    "baseline_df_grouped=baseline_df.groupby(['task'])\n",
    "task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "baseline_dict={}\n",
    "for (task, group) in baseline_df_grouped:\n",
    "    print(task[0])\n",
    "    group=group.reset_index(drop=True)\n",
    "    data = np.array(group['mne_baseline'].tolist())\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_sem = scipy.stats.sem(data, axis=0)\n",
    "    freq = np.linspace(0, 100, len(data_mean))\n",
    "    ax.plot(freq, data_mean, label=task_dict[task[0]])\n",
    "    ax.fill_between(freq, data_mean - data_sem, data_mean + data_sem, alpha=0.2)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_title(f'Baseline AON-vHp Coherence Density')\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Coherence (Z-transformed)')\n",
    "    ax.legend()\n",
    "    baseline_dict[f'{task[0]}_mean'] = data_mean\n",
    "    baseline_dict[f'{task[0]}_sem'] = data_sem\n",
    "baseline_dict['frequency'] = freq\n",
    "mean_df = pd.DataFrame(baseline_dict)\n",
    "mean_df.to_excel(writer, sheet_name='mean_coherence_density')\n",
    "writer.close()\n",
    "\n",
    "fig.savefig(savepath+'coh_baseline_density_normalized.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Baseline Coherence Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### channel pair averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "baseline_df=con_data_df.__deepcopy__()\n",
    "task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "for col in ['mne_baseline']:\n",
    "    print(col)\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        baseline_df[band + '_' + col] = baseline_df[col].apply(lambda x: coherence_functions.convert_epoch_to_coherence_baseline(x, band_start=band_start, band_end=band_end))\n",
    "baseline_df.drop(columns=['mne_baseline', 'mne_epoch_door_before', 'mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig'], inplace=True)\n",
    "baseline_df_melted=pd.melt(baseline_df, id_vars=['experiment','rat_id','task','date'], var_name='band', value_name='coherence')\n",
    "baseline_df_melted['band']=baseline_df_melted['band'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "\n",
    "####Plotting coherence per band\n",
    "fig, axs= plt.subplots(1, 1, figsize=(20, 10), sharex=True, sharey=True)\n",
    "sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df_melted, legend=True, ax=axs)\n",
    "sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "axs.set_title('Baseline Coherence per band', fontsize=20)\n",
    "axs.set_ylabel('Coherence (Z-transformed)', fontsize=20)\n",
    "axs.set_xlabel('')\n",
    "axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, [task_dict[l] for l in labels], loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath+'coh_baseline_perband_avgchannelpair_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "###Writing the baseline coherence per band to excel\n",
    "writer=pd.ExcelWriter(savepath+'coh_baseline_perband_avgchannelpair_normalized.xlsx')\n",
    "baseline_df_melted.to_excel(writer)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Pair separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "tanh_norm = True\n",
    "###########\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='normalized'\n",
    "else:\n",
    "    suffix = 'nonnormalized'\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "columns_to_process = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_baseline']\n",
    "baseline_df = coherence_functions.convert_baseline_to_coherence_mt_expanded(con_data_df[columns_to_process + ['rat_id', 'task']],rat_ids=con_data_df['rat_id'], tasks=con_data_df['task'],columns_to_process=['mne_baseline'], tanh_norm=tanh_norm)\n",
    "baseline_df.drop(columns=['event_type'], inplace=True)\n",
    "baseline_df.to_excel(savepath+f'coh_baseline_perband_channelpair_{suffix}.xlsx')\n",
    "\n",
    "####Plotting coherence per band\n",
    "fig, axs= plt.subplots(1, 1, figsize=(20, 10), sharex=True, sharey=True)\n",
    "sns.barplot(x='frequency_band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df, legend=True, ax=axs)\n",
    "sns.stripplot(x='frequency_band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=baseline_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "axs.set_title('Baseline Coherence per band', fontsize=20)\n",
    "axs.set_ylabel('Coherence (Z-transformed)', fontsize=20)\n",
    "axs.set_xlabel('')\n",
    "axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = axs.get_legend_handles_labels()\n",
    "axs.legend(handles, [task_dict[l] for l in labels], loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath+f'coh_baseline_perband_channelpair_{suffix}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Coherence around events [door before, door after, dig before, dig after]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AON-vHp connectivity Spectrogram from Epochs Array and Saving if as a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "def randomize_timepoints(epochs, seed=None):\n",
    "    \"\"\"Shuffle time points independently for each channel and epoch.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    data = epochs.get_data()\n",
    "    randomized_data = data.copy()\n",
    "    \n",
    "    for epoch_idx in range(randomized_data.shape[0]):\n",
    "        for channel_idx in range(randomized_data.shape[1]):\n",
    "            rng.shuffle(randomized_data[epoch_idx, channel_idx, :])\n",
    "    \n",
    "    return mne.EpochsArray(randomized_data, epochs.info, \n",
    "                          events=epochs.events, tmin=epochs.tmin)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def coherogram_pkl(time_window, fs, tanh_norm, shuffle=False):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "    if shuffle:\n",
    "        shuffled = 'shuffled'\n",
    "    else:\n",
    "        shuffled =''\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "                        \n",
    "                        if shuffle:\n",
    "                            event_epoch = randomize_timepoints(event_epoch, seed=42) ### TURN ON FOR RANDOMIZING\n",
    "\n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        \n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'coherence_spectrogram_before_after_door_dig_truncated_{}{}{}.pkl'.format(int(time_window*fs), suffix, shuffled))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "shuffle = False\n",
    "###############\n",
    "\n",
    "if tanh_norm:\n",
    "    suffix ='_normalized'\n",
    "else:\n",
    "    suffix ='_non-normalized'\n",
    "\n",
    "if shuffle:\n",
    "    shuffled = '_shuffled'\n",
    "else:\n",
    "    shuffled =''\n",
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'coherence_spectrogram_before_after_door_dig_truncated_{}{}{}.pkl'.format(int(time_window*fs), suffix, shuffled))\n",
    "event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "times=np.arange(0, time_window, 1/fs)\n",
    "fig, axs=plt.subplots(2,3, figsize=(15,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Before Door','Before Dig','After Dig']\n",
    "\n",
    "writer = pd.ExcelWriter(savepath + 'coh_events_spectrogram_averaged{}_{}ms{}.xlsx'.format(suffix,int(time_window*fs/2), shuffled))\n",
    "\n",
    "\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('Time (s)')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[0,i].set_title(event_names[i])\n",
    "\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)')\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)')\n",
    "    axs[1,i].set_title(event_names[i])\n",
    "    axs[0,0].text(-0.3, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.3, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=14, verticalalignment='center', rotation=90)\n",
    "    \n",
    "    print(all_con_data_df[event][0].shape)\n",
    "    \n",
    "    freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, all_con_data_df[event][0].shape[0])]\n",
    "    freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "    print(len(freqs))\n",
    "    time_points = [f'{np.round(t, 3)}s' for t in np.linspace(0, time_window, all_con_data_df[event][0].shape[1])]\n",
    "\n",
    "    df_context = pd.DataFrame(all_con_data_df[event][0])\n",
    "    df_context.loc[-1] = time_points  # Add time points as the first row\n",
    "    df_context.index = df_context.index + 1  # Shift index\n",
    "    df_context = df_context.sort_index()\n",
    "    df_context.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "    df_context.to_excel(writer, sheet_name=f'{event_names[i]}_Context', index=False)\n",
    "\n",
    "    df_nocontext = pd.DataFrame(all_con_data_df[event][1])\n",
    "    df_nocontext.loc[-1] = time_points  # Add time points as the first row\n",
    "    df_nocontext.index = df_nocontext.index + 1  # Shift index\n",
    "    df_nocontext = df_nocontext.sort_index()\n",
    "    df_nocontext.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "    df_nocontext.to_excel(writer, sheet_name=f'{event_names[i]}_NoContext', index=False)\n",
    "    \n",
    "    # Add a colorbar\n",
    "writer.close()\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Z-Coherence (A.U.)', fontsize=12)\n",
    "fig.savefig(savepath+f'coh_events_spectrogram_averaged{suffix}_{int(time_window*fs/2)}ms{shuffled}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Coherence around events [around door and around dig]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AON-vHp connectivity around door and dig and saving it in a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "\n",
    "time_window = 0.4\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_pkl(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_{}.pkl'.format(int(time_window*fs)))\n",
    "\n",
    "    event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "    print(event_list)\n",
    "    BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "    BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "    all_con_data=[]\n",
    "    all_con_data_mean=[]\n",
    "    for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "            task_data=task_data_dict[task_name]\n",
    "            row=[task_name]\n",
    "            #print(row)\n",
    "            row_2=[task_name]\n",
    "            for event in event_list:\n",
    "                #print(event)\n",
    "                event_epoch_list=task_data[event]\n",
    "                aon_vHp_con=[]\n",
    "                for event_epoch in event_epoch_list:\n",
    "                        #print(row,event, event_epoch) \n",
    "                        if event_epoch.events.shape[0] <5:\n",
    "                            print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                            continue\n",
    "                        fmin=1\n",
    "                        fmax=100\n",
    "                        fs=2000\n",
    "                        freqs = np.arange(fmin,fmax)\n",
    "                        n_cycles = freqs/3\n",
    "\n",
    "\n",
    "                        con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='coh', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                        coh = con.get_data(output='dense')\n",
    "                        indices = con.names\n",
    "                        \n",
    "\n",
    "                        for i in range(coh.shape[0]):\n",
    "                            for j in range(coh.shape[1]):\n",
    "                                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                    coherence= coh[i,j,:,:]\n",
    "                                    if tanh_norm:\n",
    "                                        coherence=np.arctanh(coherence)\n",
    "                                    aon_vHp_con.append(coherence)\n",
    "                row.append(np.mean(aon_vHp_con, axis=0))\n",
    "                row_2.append(np.mean(aon_vHp_con))\n",
    "            all_con_data.append(row)                    \n",
    "            all_con_data_mean.append(row_2)\n",
    "    # Convert all_con_data to a DataFrame for easier manipulation\n",
    "    all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "    all_con_data_df.to_pickle(savepath+'coherence_spectrogram_around_door_dig_truncated_{}{}.pkl'.format(int(time_window*fs), suffix))\n",
    "\n",
    "coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected range check\n",
    "print(\"Expected coherence ranges:\")\n",
    "print(\"Raw coherence: 0 to 1\")\n",
    "print(\"Fisher Z-transform: 0 to infinity (practically -3 to 3)\")\n",
    "\n",
    "# Check if your values are reasonable\n",
    "all_data = np.concatenate([all_con_data_df[event][i].flatten() \n",
    "                          for event in event_list for i in range(2)])\n",
    "\n",
    "if np.any(all_data < -5) or np.any(all_data > 5):\n",
    "    print(\"WARNING: Unusually extreme Fisher Z values detected!\")\n",
    "    print(\"Consider checking your coherence calculation.\")\n",
    "\n",
    "# Check the actual data values\n",
    "print(\"Data statistics:\")\n",
    "for event in event_list:\n",
    "    for i, task in enumerate(['Context', 'No Context']):\n",
    "        data = all_con_data_df[event][i]\n",
    "        print(f\"{task} - {event}:\")\n",
    "        print(f\"  Min: {np.min(data):.3f}\")\n",
    "        print(f\"  Max: {np.max(data):.3f}\")\n",
    "        print(f\"  Mean: {np.mean(data):.3f}\")\n",
    "        print(f\"  Std: {np.std(data):.3f}\")\n",
    "        print(f\"  Median: {np.median(data):.3f}\")\n",
    "        print(f\"  25th percentile: {np.percentile(data, 25):.3f}\")\n",
    "        print(f\"  75th percentile: {np.percentile(data, 75):.3f}\")\n",
    "\n",
    "print(f\"\\nGlobal vmin: {vmin:.3f}\")\n",
    "print(f\"Global vmax: {vmax:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence spectrogram [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window = 0.4\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "\n",
    "def plot_coherogram(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='_normalized'\n",
    "    else:\n",
    "        suffix ='_non-normalized'\n",
    "\n",
    "\n",
    "    all_con_data_df=pd.read_pickle(savepath+'coherence_spectrogram_around_door_dig_truncated_{}{}.pkl'.format(int(time_window*fs),suffix))\n",
    "    event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "    fs=2000\n",
    "    times=np.arange(-1*time_window, time_window, 1/fs)\n",
    "    fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "    vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "    vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "    event_names=['Around Door','Around Dig']\n",
    "    writer = pd.ExcelWriter(savepath + 'coh_events_spectrogram_averaged_normalized_{}{}.xlsx'.format(int(time_window*fs),suffix))\n",
    "\n",
    "    for i, event in enumerate(event_list):\n",
    "        axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                    aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        axs[0,i].set_xlabel('')\n",
    "\n",
    "        axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "        axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "        axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                    aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "        axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "        axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "        axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "        axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "        axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "        axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        axs[0,i].set_xticks(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-ticks from -1 to 1 seconds\n",
    "        axs[0,i].set_xticklabels(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-tick labels from -1 to 1 seconds\n",
    "        axs[1,i].set_xticks(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-ticks from -1 to 1 seconds\n",
    "        axs[1,i].set_xticklabels(np.arange(-1*time_window, time_window+0.1, time_window))  # Set x-tick labels from -1 to 1 seconds\n",
    "\n",
    "        print(all_con_data_df[event][0].shape)\n",
    "        \n",
    "        freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, all_con_data_df[event][0].shape[0])]\n",
    "        freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "        print(len(freqs))\n",
    "        time_points = [f'{np.round(t, 3)}s' for t in np.linspace(-1*time_window, time_window, all_con_data_df[event][0].shape[1])]\n",
    "\n",
    "        df_context = pd.DataFrame(all_con_data_df[event][0])\n",
    "        df_context.loc[-1] = time_points  # Add time points as the first row\n",
    "        df_context.index = df_context.index + 1  # Shift index\n",
    "        df_context = df_context.sort_index()\n",
    "        df_context.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "        df_context.to_excel(writer, sheet_name=f'{event_names[i]}_Context', index=False)\n",
    "    \n",
    "        df_nocontext = pd.DataFrame(all_con_data_df[event][1])\n",
    "        df_nocontext.loc[-1] = time_points  # Add time points as the first row\n",
    "        df_nocontext.index = df_nocontext.index + 1  # Shift index\n",
    "        df_nocontext = df_nocontext.sort_index()\n",
    "        df_nocontext.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "        df_nocontext.to_excel(writer, sheet_name=f'{event_names[i]}_NoContext', index=False)\n",
    "\n",
    "    writer.close()\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Coherence', loc='center', fontsize=20, labelpad=10)\n",
    "    cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "    fig.savefig(savepath + f'\\\\aon_vhp_coherence_event_spectrogram_{int(time_window*fs)}{suffix}.png',format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_coherogram(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Coherogram for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "###############\n",
    "def coherogram_perexperiment_pkl(time_window, fs, tanh_norm):\n",
    "\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "    event_list=['mne_epoch_door_before','mne_epoch_dig_before','mne_epoch_dig_after']\n",
    "\n",
    "    print(event_list)\n",
    "\n",
    "    test_list = [con_data_df_clean.iloc[0]]\n",
    "    mean_con_data=pd.DataFrame()\n",
    "    def epoch_coherogram(epoch, fmin=1, fmax=100, fs=2000):\n",
    "            print(epoch.events.shape)\n",
    "        # if epoch.events.shape[0] < 5:\n",
    "        #     print(\"Not enough events in the epoch\")\n",
    "        #     return None\n",
    "        # else:\n",
    "            freqs = np.arange(fmin, fmax)\n",
    "            n_cycles = freqs / 3\n",
    "            con = mne_connectivity.spectral_connectivity_epochs(epoch, method='coh', sfreq=int(fs),\n",
    "                                                                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "            coh = con.get_data(output='dense')\n",
    "            indices = con.names\n",
    "            aon_vHp_con = []\n",
    "            for i in range(coh.shape[0]):\n",
    "                for j in range(coh.shape[1]):\n",
    "                    if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                        coherence= coh[i,j,:,:]\n",
    "                        if tanh_norm:\n",
    "                            coherence=np.arctanh(coherence)\n",
    "                        aon_vHp_con.append(coherence)\n",
    "            \n",
    "            mean_con = np.mean(aon_vHp_con, axis=0)\n",
    "            return mean_con\n",
    "    mean_con_data['mne_epoch_door_before'] = con_data_df_clean['mne_epoch_door_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_before'] = con_data_df_clean['mne_epoch_dig_before'].apply(epoch_coherogram)\n",
    "    mean_con_data['mne_epoch_dig_after'] = con_data_df_clean['mne_epoch_dig_after'].apply(epoch_coherogram)\n",
    "\n",
    "    mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "    mean_con_data['date'] = con_data_df_clean['date']\n",
    "    mean_con_data['task'] = con_data_df_clean['task']\n",
    "    mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "    mean_con_data.dropna(inplace=True)\n",
    "    mean_con_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    mean_con_data.to_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}.pkl')\n",
    "\n",
    "coherogram_perexperiment_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 1\n",
    "fs = 2000  # Sampling frequency\n",
    "tanh_norm = True\n",
    "#################\n",
    "\n",
    "event_of_interest_dict = {'mne_epoch_door_before':'door_before','mne_epoch_dig_before':'dig_before','mne_epoch_dig_after':'dig_after'}\n",
    "\n",
    "event_of_interest = 'mne_epoch_dig_after'\n",
    "\n",
    "def plot_coherogram_perexperiment(time_window, fs, tanh_norm):\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    mean_con_data=pd.read_pickle(savepath + f'marked_coherence_around_events_mean_{int(time_window*fs)}.pkl')\n",
    "    vmin = mean_con_data[event_of_interest].apply(np.min).min()\n",
    "    vmax = mean_con_data[event_of_interest].apply(np.max).max()\n",
    "\n",
    "    BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "    BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "    task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "    rat_ids, rat_nums = np.unique(BWcontext_data['rat_id'], return_counts=True)\n",
    "    print(rat_ids, rat_nums)\n",
    "    rat_nums_max = rat_nums.max()\n",
    "    print(rat_nums_max)\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for group_name, group_df in task_data_dict.items():\n",
    "        writer = pd.ExcelWriter(savepath + f'coh_events_spectrogram_perexp_{group_name}_{event_of_interest_dict[event_of_interest]}_{int(time_window*fs/2)}.xlsx')\n",
    "\n",
    "        print(f\"Plotting group: {group_name}\")\n",
    "        group_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "        rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "        rat_nums_max = rat_nums.max()\n",
    "\n",
    "        num_of_rows = 4 # Each row should be a rats\n",
    "        num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "        fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "        dk1_count = 0\n",
    "        dk3_count = 0\n",
    "        dk5_count = 0\n",
    "        dk6_count = 0\n",
    "        for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "            rat_id = row['rat_id']\n",
    "            data = np.array(row[event_of_interest])\n",
    "            if rat_id == 'dk1':\n",
    "                ax=axs[0, dk1_count]\n",
    "                dk1_count += 1\n",
    "            elif rat_id == 'dk3':\n",
    "                ax=axs[1, dk3_count]\n",
    "                dk3_count += 1\n",
    "            elif rat_id == 'dk5':\n",
    "                ax=axs[2, dk5_count]\n",
    "                dk5_count += 1\n",
    "            elif rat_id == 'dk6':\n",
    "                ax=axs[3, dk6_count]\n",
    "                dk6_count += 1\n",
    "            im = ax.imshow(data, extent=[0, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "            ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "\n",
    "            ##### Writing to excel\n",
    "\n",
    "            freqs = [f'{int(freq)}Hz' for freq in np.linspace(1, 100, data.shape[0])]\n",
    "            freqs.insert(0, 'Frequency (Hz) / Time (s)')\n",
    "            print(len(freqs))\n",
    "            time_points = [f'{np.round(t, 3)}s' for t in np.linspace(0, time_window, data.shape[1])]\n",
    "\n",
    "            df_towrite = pd.DataFrame(data)\n",
    "            df_towrite.loc[-1] = time_points  # Add time points as the first row\n",
    "            df_towrite.index = df_towrite.index + 1  # Shift index\n",
    "            df_towrite = df_towrite.sort_index()\n",
    "            df_towrite.insert(0, 'Frequency (Hz)/ Time (s)', freqs)\n",
    "            df_towrite.to_excel(writer, sheet_name=f'{group_dict[group_name]}_{rat_id}_{row[\"date\"]}', index=False)\n",
    "\n",
    "        for j in range(i + 1, len(axs)):\n",
    "            fig.delaxes(axs[j])\n",
    "        fig.suptitle(f\"{group_dict[group_name]} {suffix} {event_of_interest_dict[event_of_interest]}\", fontsize=16)\n",
    "        fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02, label=f'{suffix} Coherence(A.U.)')\n",
    "        fig.savefig(savepath + f'coh_events_spectrogram_perexp_{group_name}_{event_of_interest_dict[event_of_interest]}_{int(time_window*fs/2)}ms.png', dpi=300, bbox_inches='tight')\n",
    "        #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "        writer.close()\n",
    "plot_coherogram_perexperiment(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Coherograms of single trials [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "single_epochs_df=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "unique_id_list = single_epochs_df['unique_id'].unique()\n",
    "\n",
    "print(unique_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_list = unique_id_list[0:1]\n",
    "for unique_id in unique_id_list:\n",
    "    unique_id_df = single_epochs_df[single_epochs_df['unique_id'] == unique_id]\n",
    "    trial_nums = len(unique_id_df['trial'].unique())\n",
    "    fig, axs = plt.subplots(8, trial_nums, figsize=(20, 10), sharex=True)\n",
    "    fig.suptitle(f'Unique ID: {unique_id} - AON-vHp Coherence Around Dig', fontsize=16)\n",
    "    for trial_idi in unique_id_df['trial'].unique():\n",
    "        trial_df = unique_id_df[unique_id_df['trial'] == trial_idi]\n",
    "        mne_epoch_around_dig = trial_df['around_dig'].iloc[0]\n",
    "        fmin=1\n",
    "        fmax=100\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.spectral_connectivity_epochs(mne_epoch_around_dig, method='coh', sfreq=int(fs),\n",
    "                                                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False, n_jobs=-1)\n",
    "        coh = con.get_data(output='dense')\n",
    "        indices = con.names\n",
    "        aon_vHp_con = []\n",
    "        channel_pair =0\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    coherence= coh[i,j,:,:]\n",
    "                    coherence=np.arctanh(coherence)\n",
    "                    aon_vHp_con.append(coherence)\n",
    "                    axs[channel_pair, trial_idi].imshow(coherence, extent=[-time_window, time_window, 1, 100], aspect='auto', origin='lower')\n",
    "                    if channel_pair == 0:\n",
    "                        axs[channel_pair, trial_idi].set_title(f'Trial {trial_idi}')\n",
    "                    if trial_idi == 0:\n",
    "                        axs[channel_pair, trial_idi].set_ylabel(f'{indices[i]}-{indices[j]}')\n",
    "                    channel_pair += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "\n",
    "# test_epoch = con_data_df['mne_epoch_door_before'].iloc[0]\n",
    "# fmin=1\n",
    "# fmax = 100\n",
    "# tanh_norm = True\n",
    "# con=mne_connectivity.spectral_connectivity_epochs(test_epoch, method='coh', sfreq=int(2000), fmin=fmin, fmax=fmax,faverage=False, mode='multitaper',mt_bandwidth = 2.8,mt_adaptive=True, mt_low_bias=True, verbose=False)\n",
    "# coh = con.get_data(output='dense')\n",
    "# #print(coh)\n",
    "# indices = con.names\n",
    "# #print(indices)\n",
    "# aon_vhp_con=[]\n",
    "# print(coh.shape)\n",
    "# for i in range(coh.shape[0]):\n",
    "#     for j in range(coh.shape[1]):\n",
    "#         #print(i,j)\n",
    "#         if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "#             print('AON and vHp found')\n",
    "#             coherence = coh[i,j,:]\n",
    "#             if tanh_norm:\n",
    "#                 coherence=np.arctanh(coherence)  # Convert to Fisher Z-score\n",
    "#             aon_vhp_con.append(coherence)\n",
    "# aon_vhp_con_mean = np.mean(aon_vhp_con, axis=0)\n",
    "\n",
    "test_epoch_1 = coherence_functions.convert_event_epoch_to_coherence_density_mt(test_epoch, shuffle=False)\n",
    "print(test_epoch_1)\n",
    "\n",
    "shuffled_dict = {True : 'shuffled', False : 'real'}\n",
    "event_dict = {'mne_epoch_door_before' : 'Before Door', 'mne_epoch_dig_before' : 'Before Dig','mne_epoch_dig_after' : 'After Dig'}\n",
    "csd_event_dict = {}\n",
    "writer = pd.ExcelWriter(savepath+'coh_events_density.xlsx')\n",
    "for shuffle in shuffled_dict.keys():\n",
    "    print(shuffle)\n",
    "    con_data_df = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "    for event_name in event_dict.keys():\n",
    "        print(event_name)\n",
    "        con_data_df[event_name]=con_data_df[event_name].apply(lambda x: coherence_functions.convert_event_epoch_to_coherence_density_mt(x, shuffle=shuffle))\n",
    "        con_data_df_grouped=con_data_df.groupby(['task'])\n",
    "        task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "        baseline_dict={}\n",
    "        for (task, group) in con_data_df_grouped:\n",
    "            print(task[0])\n",
    "            group=group.reset_index(drop=True)\n",
    "            data = np.array(group[event_name].tolist())\n",
    "            data_mean = np.mean(data, axis=0)\n",
    "            data_sem = scipy.stats.sem(data, axis=0)\n",
    "            freq = np.linspace(0, 100, len(data_mean))\n",
    "            csd_event_dict[f'{event_dict[event_name]}_{task[0]}_{shuffled_dict[shuffle]}_mean'] = data_mean\n",
    "            csd_event_dict[f'{event_dict[event_name]}_{task[0]}_{shuffled_dict[shuffle]}_sem'] = data_sem\n",
    "csd_event_dict['frequency'] = freq\n",
    "mean_df = pd.DataFrame(csd_event_dict)\n",
    "mean_df.to_excel(writer)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Coherence Boxplots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Aon-vHp connectivity per band and storing it in pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "time_window = 0.7\n",
    "fs = 2000  # Sampling frequency\n",
    "############\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "single_baseline_epoch=con_data_df_clean['mne_epoch_door_before'].iloc[0]\n",
    "theta_band=[4,8]\n",
    "\n",
    "theta_coherence=coherence_functions.convert_epoch_to_coherence_time(single_baseline_epoch)\n",
    "print(theta_coherence)\n",
    "\n",
    "print(coherence_functions.convert_epoch_to_coherence_mt(single_baseline_epoch, tanh_norm=True))\n",
    "\n",
    "\n",
    "def convert_epoch_to_coherence_mt_per_channel(epoch, tanh_norm=True, fmin=1, fmax=100, fs=2000):\n",
    "    band_dict={'beta':[12,30],'gamma':[30,80],'total':[1,100], 'theta':[4,12]}\n",
    "    coherence_dict={}\n",
    "    coherence_channel_dict={}\n",
    "    for band in band_dict.keys():\n",
    "        \n",
    "        fmin=band_dict[band][0]\n",
    "        fmax=band_dict[band][1]\n",
    "        freqs = np.arange(fmin,fmax)\n",
    "        #print(n_cycles)\n",
    "        con=mne_connectivity.spectral_connectivity_epochs(epoch, method='coh', sfreq=int(2000), fmin=fmin, fmax=fmax,faverage=True, mode='multitaper',mt_bandwidth = 2.8,mt_adaptive=True, mt_low_bias=True, verbose=False, n_jobs=-1)\n",
    "        coh = con.get_data(output='dense')\n",
    "        #print(coh)\n",
    "        indices = con.names\n",
    "        #print(indices)\n",
    "        aon_vhp_con=[]\n",
    "        print(coh.shape)\n",
    "        channel_dict={}\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                #print(i,j)\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    print('AON and vHp found')\n",
    "                    coherence = coh[i,j,:]\n",
    "                    if tanh_norm:\n",
    "                        coherence=np.arctanh(coherence)  # Convert to Fisher Z-score\n",
    "                    channel_dict[f'{indices[i]}-{indices[j]}']=coherence\n",
    "                    \n",
    "                    aon_vhp_con.append(np.mean(coherence))\n",
    "                    #print('freqs averaged',coh[i,j,0,:].shape)\n",
    "                    #print(coh[0,i,j,:])\n",
    "                else:\n",
    "                    continue\n",
    "        if aon_vhp_con==[]:\n",
    "            print('no coherence found')\n",
    "        else:\n",
    "            #print(aon_vhp_con)\n",
    "            aon_vhp_con_mean=np.mean(aon_vhp_con, axis=0)\n",
    "            #print(aon_vhp_con_mean, 'coherenece')\n",
    "            coherence_dict[band]=aon_vhp_con_mean\n",
    "            coherence_channel_dict[band]=channel_dict\n",
    "    return coherence_dict, coherence_channel_dict\n",
    "\n",
    "single_baseline_epoch=con_data_df_clean['mne_epoch_door_before'].iloc[0]\n",
    "band_coherence, channel_coherence=convert_epoch_to_coherence_mt_per_channel(single_baseline_epoch, tanh_norm=True)\n",
    "print(band_coherence)\n",
    "print(channel_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(coherence_functions)\n",
    "def epoch_coherence_channelpair_multiple(time_window, fs, tanh_norm=True):\n",
    "    \"\"\"\n",
    "    Process multiple epoch columns and return coherence DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    time_window : float\n",
    "        Time window in seconds\n",
    "    fs : int\n",
    "        Sampling frequency\n",
    "    tanh_norm : bool\n",
    "        Whether to apply Fisher Z-transformation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Coherence DataFrame with event types\n",
    "    \n",
    "    \"\"\"\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    #con_data_df_shuffled = pd.read_pickle(savepath + f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "    columns_to_process = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before', 'mne_epoch_dig_after']\n",
    "\n",
    "    coherence_df = coherence_functions.convert_epochs_to_coherence_mt_expanded(\n",
    "        \n",
    "        con_data_df_clean[columns_to_process + ['rat_id', 'task']],  # Include necessary columns\n",
    "        con_data_df_clean['rat_id'], \n",
    "        con_data_df_clean['task'],\n",
    "        columns_to_process,\n",
    "        tanh_norm=tanh_norm\n",
    "    )\n",
    "    shuffled_coherence_df = coherence_functions.convert_epochs_to_coherence_mt_expanded(\n",
    "        con_data_df_clean[columns_to_process + ['rat_id', 'task']],  # Include necessary columns\n",
    "        con_data_df_clean['rat_id'], \n",
    "        con_data_df_clean['task'],\n",
    "        columns_to_process,\n",
    "        tanh_norm=tanh_norm,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    coherence_df.to_pickle(savepath + f'coherence_channelpair_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    shuffled_coherence_df.to_pickle(savepath + f'coherence_channelpair_shuffled_{int(time_window*fs)}_{suffix}.pkl')\n",
    "\n",
    "def plot_coherence_channelpair(time_window, fs, tanh_norm=True):\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "    coherence_df = pd.read_pickle(savepath + f'coherence_channelpair_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    shuffled_coherence_df = pd.read_pickle(savepath + f'coherence_channelpair_shuffled_{int(time_window*fs)}_{suffix}.pkl')\n",
    "    generate_events_boxplots(time_window, fs, suffix, coherence_df)\n",
    "    generate_events_boxplots(time_window, fs, suffix+'_shuffled', shuffled_coherence_df)\n",
    "\n",
    "\n",
    "def generate_events_boxplots(time_window, fs, suffix, coherence_df):\n",
    "    event_dict = {\n",
    "        'mne_epoch_door_before': 'Door Before',\n",
    "        'mne_epoch_door_after': 'Door After',\n",
    "        'mne_epoch_dig_before': 'Dig Before',\n",
    "        'mne_epoch_dig_after': 'Dig After'\n",
    "    }\n",
    "    coherence_df['event_type'] = coherence_df['event_type'].map(event_dict)\n",
    "    \n",
    "    vmin = coherence_df['coherence'].min()\n",
    "    vmax = coherence_df['coherence'].max()\n",
    "    print(f\"Global vmin: {vmin}, vmax: {vmax}\")\n",
    "\n",
    "    event_types = coherence_df['event_type'].unique()\n",
    "    num_event_types = len(event_types)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_channelpair_{suffix}_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_event_types, figsize=(40,10), sharey=True)\n",
    "    task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "    band_order = ['theta', 'beta','theta+beta','gamma', 'total']\n",
    "    \n",
    "    for i, event_type in enumerate(event_types):\n",
    "        ax=axs[i] if num_event_types > 1 else axs\n",
    "        event_data_df_melted = coherence_df[coherence_df['event_type'] == event_type]\n",
    "        event_data_df_melted['band'] = pd.Categorical(event_data_df_melted['frequency_band'], categories=band_order, ordered=True)\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, order=band_order, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, order=band_order, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        axs[i].set_title(f'{event_type}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.drop(columns=['event_type'], inplace=True)\n",
    "        event_data_df_melted.rename(columns={'frequency_band': 'band', 'epoch_idx': 'experiment'}, inplace=True)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event_type)\n",
    "\n",
    "    writer.close()\n",
    "    plt.suptitle(f'AON-vHp Coherence per Channel Pair ({suffix})', fontsize=18)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    fig.savefig(savepath + f'coh_events_perband_channelpair_{suffix}_{int(time_window*fs/2)}ms.png', dpi=300)\n",
    "    plt.show()\n",
    "# Usage example:\n",
    "time_window = 1\n",
    "fs = 2000\n",
    "tanh_norm = True\n",
    "\n",
    "# Specify which columns to process\n",
    "\n",
    "# Process multiple columns\n",
    "epoch_coherence_channelpair_multiple(\n",
    "    time_window=time_window, \n",
    "    fs=fs, \n",
    "    tanh_norm=tanh_norm\n",
    ")\n",
    "plot_coherence_channelpair(\n",
    "    time_window=time_window, \n",
    "    fs=fs, \n",
    "    tanh_norm=tanh_norm\n",
    ")  \n",
    "\n",
    "# print(\"Coherence DataFrame shape:\", coherence_df.shape)\n",
    "# print(\"Coherence DataFrame columns:\", coherence_df.columns.tolist())\n",
    "# print(\"Sample output:\")\n",
    "# print(coherence_df.head())\n",
    "# print(\"\\nEvent types:\")\n",
    "# print(coherence_df['event_type'].unique())\n",
    "# print(\"\\nFrequency bands:\")\n",
    "# print(coherence_df['frequency_band'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "\n",
    "time_window = 1\n",
    "fs=2000\n",
    "tanh_norm = True\n",
    "##############\n",
    "\n",
    "importlib.reload(coherence_functions)\n",
    "\n",
    "\n",
    "def coherence_boxplot_pkl(time_window, fs, tanh_norm):\n",
    "\n",
    "    importlib.reload(coherence_functions)\n",
    "\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "\n",
    "    con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "\n",
    "    con_data_df_clean['coherence_door_before']=con_data_df_clean['mne_epoch_door_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_door_after']=con_data_df_clean['mne_epoch_door_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_dig_before']=con_data_df_clean['mne_epoch_dig_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean['coherence_dig_after']=con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x, tanh_norm=tanh_norm))\n",
    "    con_data_df_clean.drop(columns=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'], inplace=True)\n",
    "    con_data_df_clean.to_pickle(savepath+f'coherence_boxplot_mt_{int(fs*time_window)}_{suffix}.pkl')\n",
    "\n",
    "    con_data_df_shuffled=pd.read_pickle(savepath + f'marked_mne_epochs_array_df_truncated_{int(time_window*fs)}_251125.pkl')\n",
    "    \n",
    "    con_data_df_shuffled['coherence_door_before']=con_data_df_shuffled['mne_epoch_door_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_door_after']=con_data_df_shuffled['mne_epoch_door_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_dig_before']=con_data_df_shuffled['mne_epoch_dig_before'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled['coherence_dig_after']=con_data_df_shuffled['mne_epoch_dig_after'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_mt(x,tanh_norm=tanh_norm, shuffle=True))\n",
    "    con_data_df_shuffled.drop(columns=['mne_epoch_door_before','mne_epoch_door_after','mne_epoch_dig_before','mne_epoch_dig_after'], inplace=True)\n",
    "    con_data_df_shuffled.to_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}_{suffix}.pkl')\n",
    "\n",
    "coherence_boxplot_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "\n",
    "time_window = 1\n",
    "fs=2000\n",
    "tanh_norm = True\n",
    "###################\n",
    "def plot_coherence_boxplot(time_window, fs, tanh_norm):\n",
    "    importlib.reload(coherence_functions)\n",
    "    if tanh_norm:\n",
    "        suffix ='normalized'\n",
    "    else:\n",
    "        suffix ='nonnormalized'\n",
    "    print(suffix)\n",
    "\n",
    "    con_data_df_clean=pd.read_pickle(savepath+f'coherence_boxplot_mt_{int(fs*time_window)}_{suffix}.pkl')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "    fig.suptitle(f'Coherence {time_window}s', fontsize=24)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms.xlsx')\n",
    "    events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "    task_dict={'BWcontext':'Context','BWnocontext':'No Context'}\n",
    "    band_order = ['theta', 'beta','theta+beta', 'gamma', 'total']\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=band_order, var_name='band', value_name='coherence')\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "        axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    fig.savefig(savepath+f'coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms.png', format='png',dpi=300, bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"Shuffled coherence boxplot per band\"\"\"\n",
    "\n",
    "\n",
    "    con_data_df_shuffled=pd.read_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}_{suffix}.pkl')\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "    fig.suptitle(f'Shuffled Coherence {time_window}s', fontsize=24)\n",
    "    axs = axs.flatten()\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "    writer=pd.ExcelWriter(savepath + f'\\\\coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms_shuffled.xlsx')\n",
    "    events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "    for i, event in enumerate(events_dict.keys()):\n",
    "        event_data = con_data_df_shuffled[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_shuffled['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_shuffled['task'].reset_index(drop=True)\n",
    "        event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=band_order, var_name='band', value_name='coherence')\n",
    "        sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "        sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "        #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        axs[i].legend(handles, [task_dict[l] for l in labels], loc='upper right', fontsize=15)\n",
    "\n",
    "        axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(f'Coherence ({suffix})', fontsize=20)\n",
    "        else:\n",
    "            axs[i].set_ylabel('')\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "        event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    writer.close()\n",
    "    fig.savefig(savepath+f'coh_events_perband_averaged_{suffix}_{int(time_window*fs/2)}ms_shuffled.png', format='png',dpi=300, bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coherence_boxplot(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'coherence_boxplot_mt_shuffled_{int(fs*time_window)}.pkl')\n",
    "fig, axs = plt.subplots(1, 4, figsize=(40, 10), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y', which='both', labelleft=True)\n",
    "writer=pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_boxplot_mt_shuffled_{int(fs*time_window)}.xlsx')\n",
    "events_dict={'coherence_door_before':'Pre Door', 'coherence_door_after': 'Post Door', 'coherence_dig_before':'Pre Dig', 'coherence_dig_after':'Post Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    event_data = con_data_df_clean[event]\n",
    "    event_data_df = pd.DataFrame(event_data.tolist())\n",
    "    event_data_df.reset_index(drop=True, inplace=True)\n",
    "    event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "    event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "    event_data_df_melted = pd.melt(event_data_df, id_vars=['rat_id', 'task'], value_vars=['total', 'theta', 'beta', 'gamma'], var_name='band', value_name='coherence')\n",
    "    sns.barplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, legend=True, ax=axs[i])\n",
    "    sns.stripplot(x='band', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=event_data_df_melted, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "    #axs[i].set_xticklabels(['Total', 'Theta', 'Beta', 'Gamma'])\n",
    "    axs[i].legend(title='Task', fontsize=20, title_fontsize=20, loc='upper right')\n",
    "    \n",
    "    axs[i].set_title(f'{events_dict[event]}', fontsize=20)\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel('Coherence (A.U.)', fontsize=20)\n",
    "    else:\n",
    "        axs[i].set_ylabel('')\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    event_data_df_melted.to_excel(writer, sheet_name=event)\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    # Prepare data for repeated measures ANOVA\n",
    "    # Each rat_id is a subject, band is within-subject, task is between-subject\n",
    "    anova_results = {}\n",
    "    posthoc_results = {}\n",
    "\n",
    "    # Only keep rats that have both tasks for proper repeated measures\n",
    "    rats_with_both = event_data_df_melted.groupby('rat_id')['task'].nunique()\n",
    "    rats_with_both = rats_with_both[rats_with_both == 2].index.tolist()\n",
    "    filtered_df = event_data_df_melted[event_data_df_melted['rat_id'].isin(rats_with_both)]\n",
    "\n",
    "    # Pivot to wide format for repeated measures ANOVA\n",
    "    for band in ['total', 'theta', 'beta', 'gamma']:\n",
    "        band_df = filtered_df[filtered_df['band'] == band]\n",
    "        # ANOVA: repeated measures on band, between on task\n",
    "        # For each rat, we need both tasks\n",
    "        # We'll use a mixed-effects model for repeated measures\n",
    "        model = ols('coherence ~ C(task)', data=band_df).fit()\n",
    "        aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "        anova_results[band] = aov_table\n",
    "\n",
    "        # Posthoc: LSD (least significant difference) test\n",
    "        mc = MultiComparison(band_df['coherence'], band_df['task'])\n",
    "        posthoc = mc.tukeyhsd()  # Tukey is more conservative, but LSD is not directly available in statsmodels\n",
    "        posthoc_results[band] = posthoc.summary()\n",
    "        print(f\"ANOVA results for {band} band in {events_dict[event]}\")\n",
    "        print(aov_table)\n",
    "        print(f\"Posthoc (Tukey HSD) results for {band} band:\")\n",
    "        print(posthoc.summary())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherogram and Boxplots together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=2000\n",
    "for time_window in [1]:\n",
    "    for tanh_norm in [True]:\n",
    "\n",
    "        # coherogram_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherogram(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        \n",
    "        # coherence_boxplot_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherence_boxplot(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "\n",
    "        # coherogram_perexperiment_pkl(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        # plot_coherogram_perexperiment(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "\n",
    "        epoch_coherence_channelpair_multiple(time_window=time_window, fs=fs, tanh_norm=tanh_norm)\n",
    "        plot_coherence_channelpair(time_window=time_window, fs=fs, tanh_norm=tanh_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting AON-vHp connectivity separated by Bands ## [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'coherence_boxplot_per_event_per_band_single_value.pkl')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axs = axs.flatten()\n",
    "writer = pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_band_per_event.xlsx')\n",
    "\n",
    "bands = ['total', 'theta', 'beta', 'gamma']\n",
    "events = ['coherence_door_before', 'coherence_door_after', 'coherence_dig_before', 'coherence_dig_after']\n",
    "\n",
    "for i, band in enumerate(bands):\n",
    "    band_data = []\n",
    "    for event in events:\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df['event'] = event\n",
    "        event_data_df['band'] = band\n",
    "        event_data_df['coherence'] = event_data_df[band]\n",
    "        band_data.append(event_data_df[['rat_id', 'task', 'event', 'band', 'coherence']])\n",
    "    \n",
    "    band_data_df = pd.concat(band_data, ignore_index=True)\n",
    "    sns.boxplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, showfliers=False, legend=False, ax=axs[i])\n",
    "    sns.stripplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs[i])\n",
    "    axs[i].set_xticklabels(['Door Before', 'Door After', 'Dig Before', 'Dig After'], rotation=0)\n",
    "    axs[i].set_title(band.capitalize())\n",
    "    axs[i].set_ylabel('Coherence')\n",
    "    axs[i].set_xlabel('')\n",
    "    band_data_df.to_excel(writer, sheet_name=band)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# Create custom legend handles and labels\n",
    "from matplotlib.lines import Line2D\n",
    "colors = {'BWnocontext': '#ff7f0e', 'BWcontext': '#1f77b4'}\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], color=colors['BWcontext'], marker='o', linestyle='', markersize=10, label='BWcontext'),\n",
    "    Line2D([0], [0], color=colors['BWnocontext'], marker='o', linestyle='', markersize=10, label='BWnocontext')\n",
    "]\n",
    "\n",
    "# Add the custom legend to the figure\n",
    "fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(1.1, 1), title='Task')\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_band_per_event.png', dpi=600)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same boxplot as above but for a single band ## [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'coherence_boxplot_per_event_per_band_single_value.pkl')\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "bands = ['beta']\n",
    "events = ['coherence_door_before', 'coherence_door_after', 'coherence_dig_before', 'coherence_dig_after']\n",
    "\n",
    "for i, band in enumerate(bands):\n",
    "    band_data = []\n",
    "    for event in events:\n",
    "        event_data = con_data_df_clean[event]\n",
    "        event_data_df = pd.DataFrame(event_data.tolist())\n",
    "        event_data_df.reset_index(drop=True, inplace=True)\n",
    "        event_data_df['rat_id'] = con_data_df_clean['rat_id'].reset_index(drop=True)\n",
    "        event_data_df['task'] = con_data_df_clean['task'].reset_index(drop=True)\n",
    "        event_data_df['event'] = event\n",
    "        event_data_df['band'] = band\n",
    "        event_data_df['coherence'] = event_data_df[band]\n",
    "        band_data.append(event_data_df[['rat_id', 'task', 'event', 'band', 'coherence']])\n",
    "    \n",
    "    band_data_df = pd.concat(band_data, ignore_index=True)\n",
    "    sns.boxplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, showfliers=False, legend=False, ax=axs)\n",
    "    sns.stripplot(x='event', y='coherence', hue='task', hue_order=['BWcontext', 'BWnocontext'], data=band_data_df, dodge=True, edgecolor='black', linewidth=1, jitter=True, legend=False, ax=axs)\n",
    "    axs.set_xticklabels(['Pre Door', 'Post Door', 'Pre Dig', 'Post Dig'], rotation=0)\n",
    "    axs.set_title(band.capitalize()+' Band Coherence between AON and vHp', fontsize=20)\n",
    "    \n",
    "    axs.set_ylabel('Coherence', fontsize=20)\n",
    "    axs.set_xlabel('Behavior Events', fontsize=20)\n",
    "    axs.tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs.tick_params(axis='both', which='minor', labelsize=20)\n",
    "    #axs.legend(title='', fontsize=20, loc='upper right' )\n",
    "# # Create custom legend handles and labels\n",
    "from matplotlib.lines import Line2D\n",
    "colors = {'BWnocontext': '#ff7f0e', 'BWcontext': '#1f77b4'}\n",
    "\n",
    "handles = [\n",
    "    Line2D([0], [0], color=colors['BWcontext'], marker='o', linestyle='', markersize=10, label='Context'),\n",
    "    Line2D([0], [0], color=colors['BWnocontext'], marker='o', linestyle='', markersize=10, label='No Context')\n",
    "]\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add the custom legend to the figure\n",
    "fig.legend(handles=handles, loc='upper right', bbox_to_anchor=(0.4, 0.95), title='', fontsize=20, ncol=1)\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\coherence_beta_band_per_event.png', dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Based Connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating phase coherograms for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "#############\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_{}.pkl'.format(int(time_window*fs)))\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "def epoch_coherogram(epoch, fmin=1, fmax=100, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        return None\n",
    "    else:\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.spectral_connectivity_epochs(epoch, method='plv', sfreq=int(fs),\n",
    "                                                            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "        coh = con.get_data(output='dense')\n",
    "        indices = con.names\n",
    "        aon_vHp_con = []\n",
    "        for i in range(coh.shape[0]):\n",
    "            for j in range(coh.shape[1]):\n",
    "                if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    coherence= coh[i,j,:,:]\n",
    "                    #coherence=np.arctanh(coherence)\n",
    "                    aon_vHp_con.append(coherence)\n",
    "        \n",
    "        mean_con = np.mean(aon_vHp_con, axis=0)\n",
    "        return mean_con\n",
    "test_pli = epoch_coherogram(test_list[0]['mne_epoch_around_door'])\n",
    "plt.imshow(test_pli, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "mean_con_data['around_dig_mean_con'] = con_data_df_clean['mne_epoch_around_dig'].apply(epoch_coherogram)\n",
    "mean_con_data['around_door_mean_con'] = con_data_df_clean['mne_epoch_around_door'].apply(epoch_coherogram)\n",
    "\n",
    "mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "mean_con_data['task'] = con_data_df_clean['task']\n",
    "mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "mean_con_data['date'] = con_data_df_clean['date']\n",
    "\n",
    "mean_con_data.dropna(inplace=True)\n",
    "mean_con_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = mean_con_data['around_dig_mean_con'].apply(np.min).min()\n",
    "vmax = mean_con_data['around_dig_mean_con'].apply(np.max).max()\n",
    "\n",
    "BWcontext_data=mean_con_data[(mean_con_data['task']=='BWcontext')]\n",
    "BWnocontext_data=mean_con_data[(mean_con_data['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for group_name, group_df in task_data_dict.items():\n",
    "    \n",
    "    rat_ids, rat_nums = np.unique(group_df['rat_id'], return_counts=True)\n",
    "    rat_nums_max = rat_nums.max()\n",
    "\n",
    "    num_of_rows = 4 # Each row should be a rats\n",
    "    num_of_cols = rat_nums_max # Each column should be the max number of experiments for a rat\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_cols, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    dk1_count = 0\n",
    "    dk3_count = 0\n",
    "    dk5_count = 0\n",
    "    dk6_count = 0\n",
    "    for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "        rat_id = row['rat_id']\n",
    "        data = np.array(row['around_dig_mean_con'])\n",
    "        if rat_id == 'dk1':\n",
    "            ax=axs[0, dk1_count]\n",
    "            dk1_count += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax=axs[1, dk3_count]\n",
    "            dk3_count += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax=axs[2, dk5_count]\n",
    "            dk5_count += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax=axs[3, dk6_count]\n",
    "            dk6_count += 1\n",
    "        im = ax.imshow(data, extent=[-1*time_window, time_window, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{row['rat_id']} {row['date']}\")\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    \n",
    "    \n",
    "    # fig, axs = plt.subplots(group_df.shape[0] // 5 + int(group_df.shape[0] % 5 != 0), 5, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    # axs = axs.flatten()\n",
    "    # for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "    #     data = np.array(row['around_dig_mean_con'])\n",
    "    #     ax = axs[i]\n",
    "    #     im = ax.imshow(data, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    #     ax.set_title(f\"{row['rat_id']} {row['experiment']}\")\n",
    "    #     ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "    #     ax.axhline(12, color='green', linestyle='--')\n",
    "    #     ax.axhline(30, color='green', linestyle='--')\n",
    "    # for j in range(i + 1, len(axs)):\n",
    "    #     fig.delaxes(axs[j])\n",
    "    fig.suptitle(f\"{group_name} AON-vHp PLV Around Dig\", fontsize=16)\n",
    "    fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    fig.savefig(savepath + f'plv_around_dig_{group_name}.png', dpi=300, bbox_inches='tight')\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average PLI around door and dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df_truncated_1400.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "\n",
    "all_con_data=[]\n",
    "all_con_data_mean=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "        row=[task_name]\n",
    "         #print(row)\n",
    "        row_2=[task_name]\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            aon_vHp_con=[]\n",
    "            for event_epoch in event_epoch_list:\n",
    "                    #print(row,event, event_epoch) \n",
    "                    if event_epoch.events.shape[0] <5:\n",
    "                        print(f\"Skipping {event} for {task_name} due to insufficient events\")\n",
    "                        continue\n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    fs=2000\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/3\n",
    "                    # con= mne_connectivity.spectral_connectivity_time(event_epoch, method='coh', sfreq=int(fs), average=False,\n",
    "                    #                                      mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                    #                                      n_cycles=n_cycles, verbose=False, fmin=1, fmax=100, faverage=False)\n",
    "                    # coh = con.get_data(output='dense')\n",
    "                    # indices = con.names\n",
    "                    # print(coh.shape, indices)a\n",
    "                    # for i in range(coh.shape[0]):\n",
    "                    #     for j in range(coh.shape[1]):\n",
    "                    #         if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                    #             coherence= coh[i,j,:]\n",
    "                    #             coherence=np.arctanh(coherence)\n",
    "                    #             aon_vHp_con.append(coherence)\n",
    "\n",
    "                    con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='pli', sfreq=int(fs),\n",
    "                                                         mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                         cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax, faverage=False)\n",
    "                    coh = con.get_data(output='dense')\n",
    "                    indices = con.names\n",
    "                    \n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                coherence= coh[i,j,:,:]\n",
    "                                #coherence=np.arctanh(coherence)\n",
    "                                aon_vHp_con.append(coherence)\n",
    "            row.append(np.mean(aon_vHp_con, axis=0))\n",
    "            row_2.append(np.mean(aon_vHp_con))\n",
    "        all_con_data.append(row)                    \n",
    "        all_con_data_mean.append(row_2)\n",
    "# Convert all_con_data to a DataFrame for easier manipulation\n",
    "all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "all_con_data_df.to_pickle(savepath+'pli_coherogram_around_door_dig_truncated.pkl')\n",
    "fs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_con_data_df=pd.read_pickle(savepath+'pli_coherogram_around_door_dig_truncated.pkl')\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "fig.suptitle('AON-vHp Phase Lag Index Around Door and Dig', fontsize=20)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=0, vmax=1)\n",
    "    axs[0,i].set_xlabel('')\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].hlines(12, times[0], times[-1], color='green', linestyle='--')\n",
    "    axs[0,i].hlines(30, times[0], times[-1], color='green', linestyle='--')\n",
    "    \n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=0, vmax=1)\n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[1,i].hlines(12, times[0], times[-1], color='green', linestyle='--')\n",
    "    axs[1,i].hlines(30, times[0], times[-1], color='green', linestyle='--')\n",
    "    \n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    # axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('PLI', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_pli_coherogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Slope Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "#epoch_psi(epoch, fmin=1, fmax=100, fs=2000):\n",
    "def epoch_psi(epoch, fmin, fmax, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    aon_indices = [i for i, ch in enumerate(epoch.ch_names) if 'AON' in ch]\n",
    "    vHp_indices = [i for i, ch in enumerate(epoch.ch_names) if 'vHp' in ch]\n",
    "    indices = mne_connectivity.seed_target_indices(aon_indices, vHp_indices)\n",
    "\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        # Return empty arrays or np.nan to avoid TypeError\n",
    "        return [], []\n",
    "    else:\n",
    "        freqs = np.arange(fmin, fmax)\n",
    "        n_cycles = freqs / 3\n",
    "        con = mne_connectivity.phase_slope_index(\n",
    "            epoch, indices=indices, sfreq=int(fs),\n",
    "            mode='cwt_morlet', cwt_freqs=freqs,\n",
    "            cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax\n",
    "        )\n",
    "        coh = con.get_data()\n",
    "        print(coh.shape)\n",
    "        indices = con.names\n",
    "\n",
    "        mean_con = np.mean(coh, axis=0)\n",
    "        mean_con = list(mean_con[0, :])\n",
    "        all_cons = np.array([coh[i, 0, :] for i in range(coh.shape[0])])\n",
    "        return mean_con, all_cons\n",
    "\n",
    "epoch = test_list[0]['mne_epoch_around_door']\n",
    "mean_con, all_cons = epoch_psi(epoch, fmin=12, fmax=30, fs=2000)\n",
    "\n",
    "def generate_simulated_epoch(n_channels=4, n_times=2000, n_events=10, sfreq=2000):\n",
    "    ch_names = ['AON_1', 'AON_2', 'vHp_1', 'vHp_2']\n",
    "    ch_types = ['eeg'] * n_channels\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    data = np.random.randn(n_events, n_channels, n_times)  # Random data for simulation\n",
    "    events = np.array([[i, 0, 1] for i in range(n_events)])  # Dummy events\n",
    "    epoch = mne.EpochsArray(data, info, events)\n",
    "    return epoch\n",
    "\n",
    "simulated_epoch = generate_simulated_epoch()\n",
    "mean_con, all_cons = epoch_psi(simulated_epoch)\n",
    "plt.plot(mean_con)\n",
    "\n",
    "psi_data_df = pd.DataFrame()\n",
    "psi_data_df['around_dig_mean_con'], psi_data_df['around_dig_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_dig'].apply(epoch_psi))\n",
    "psi_data_df['around_door_mean_con'], psi_data_df['around_door_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_door'].apply(epoch_psi))\n",
    "psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "psi_data_df['task'] = con_data_df_clean['task']\n",
    "psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "psi_data_df.dropna(inplace=True)\n",
    "psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0) & psi_data_df['around_door_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "psi_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "BWcontext_data = psi_data_df[(psi_data_df['task'] == 'BWcontext')]\n",
    "BWnocontext_data = psi_data_df[(psi_data_df['task'] == 'BWnocontext')]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_mean_con'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_mean_con'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='orange', alpha=0.3)\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='blue', alpha=0.3)\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a cumulative figure with all bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "##############\n",
    "\n",
    "\n",
    "bands_list =[(4,8), (12,30), (30,80)]  # Theta, Beta, Gamma\n",
    "band_names = ['theta', 'beta', 'gamma']\n",
    "\n",
    "real_con_data = pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "shuffled_con_data = pd.read_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "def clean_and_merge_data(psi_data_df, con_data_df_clean):\n",
    "    psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "    psi_data_df['task'] = con_data_df_clean['task']\n",
    "    psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "    psi_data_df.dropna(inplace=True)\n",
    "    #psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "    psi_data_df.reset_index(drop=True, inplace=True)\n",
    "    return psi_data_df\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(60, 10), sharey='row', sharex=True)\n",
    "fig.suptitle('AON-vHp Phase Slope Index Around Dig', fontsize=24)\n",
    "for band_idx, (fmin, fmax) in enumerate(bands_list):\n",
    "    print(f\"Processing band: {band_names[band_idx]} ({fmin}-{fmax} Hz)\")\n",
    "    real_data_psi = pd.DataFrame()\n",
    "    real_data_psi['around_dig_mean_con'], real_data_psi['around_dig_all_cons'] = zip(*real_con_data['mne_epoch_around_dig'].apply(lambda x: epoch_psi(x, fmin=fmin, fmax=fmax)))\n",
    "\n",
    "    shuffled_data_psi = pd.DataFrame()\n",
    "    shuffled_data_psi['around_dig_mean_con'], shuffled_data_psi['around_dig_all_cons'] = zip(*shuffled_con_data['mne_epoch_around_dig'].apply(lambda x: epoch_psi(x, fmin=fmin, fmax=fmax)))\n",
    "\n",
    "    real_data_psi = clean_and_merge_data(real_data_psi, real_con_data)\n",
    "    shuffled_data_psi = clean_and_merge_data(shuffled_data_psi, shuffled_con_data)\n",
    "\n",
    "    for i, data in enumerate([real_data_psi, shuffled_data_psi]):\n",
    "        print(f\"Processing {'real' if i == 0 else 'shuffled'} data\")\n",
    "        BWcontext_data = data[(data['task'] == 'BWcontext')]\n",
    "        BWnocontext_data = data[(data['task'] == 'BWnocontext')]\n",
    "        \n",
    "        bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "        bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "        bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "        bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "        bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "        bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "        \n",
    "        ax = axs[band_idx, i]\n",
    "        ax.plot(times, bwnocontext_mean, label=' No Context', color='grey')\n",
    "        ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='grey', alpha=0.3)\n",
    "        ax.plot(times, bwcontext_mean, label='Context', color='black')\n",
    "        ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='black', alpha=0.3)\n",
    "        \n",
    "        ax.set_title(f'{band_names[band_idx].capitalize()} {\"Real\" if i == 0 else \"Shuffled\"}', fontsize=16)\n",
    "        ax.axhline(0, color='blue', linestyle='--')\n",
    "        ax.axvline(0, color='red', linestyle='-', linewidth=2)\n",
    "        if band_idx == 2:\n",
    "            ax.set_xlabel('Time (s)', fontsize=14)\n",
    "        else:\n",
    "            ax.set_xlabel('')\n",
    "        ax.set_ylabel('Phase Slope Index', fontsize=14)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, labels, loc='upper left', fontsize=12)\n",
    "        \n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig_bands_real_vs_shuffled.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSI for each frequency point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(type(low_fs), low_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "\n",
    "test_list = [con_data_df_clean.iloc[0]]\n",
    "mean_con_data=pd.DataFrame()\n",
    "#epoch_psi(epoch, fmin=1, fmax=100, fs=2000):\n",
    "def epoch_psi(epoch, fs=2000):\n",
    "    print(epoch.events.shape)\n",
    "    aon_indices = [i for i, ch in enumerate(epoch.ch_names) if 'AON' in ch]\n",
    "    vHp_indices = [i for i, ch in enumerate(epoch.ch_names) if 'vHp' in ch]\n",
    "    indices = mne_connectivity.seed_target_indices(aon_indices, vHp_indices)\n",
    "    print(indices)\n",
    "    if epoch.events.shape[0] < 5:\n",
    "        print(\"Not enough events in the epoch\")\n",
    "        # Return empty arrays or np.nan to avoid TypeError\n",
    "        return [], []\n",
    "    else:\n",
    "        low_fs = np.arange(1, 100,1)\n",
    "        high_fs = np.arange(2, 101,1)\n",
    "        \n",
    "        for bandi,(fmin, fmax) in enumerate(zip(low_fs, high_fs)):\n",
    "            \n",
    "            print(f\"{bandi}:Processing frequency band: {fmin}-{fmax} Hz\")\n",
    "            freqs = np.arange(fmin, fmax)\n",
    "            n_cycles = freqs / 3\n",
    "            con = mne_connectivity.phase_slope_index(\n",
    "                epoch, indices=indices, sfreq=int(fs),\n",
    "                mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                cwt_n_cycles=n_cycles, verbose=False, fmin=fmin, fmax=fmax\n",
    "            )\n",
    "            coh = con.get_data()\n",
    "            print(coh.shape)\n",
    "            indices = con.names\n",
    "\n",
    "            # mean_con = np.mean(coh, axis=0)\n",
    "            # mean_con = list(mean_con[0, :])\n",
    "            # all_cons = np.array([coh[i, 0, :] for i in range(coh.shape[0])])\n",
    "#    return mean_con, all_cons\n",
    "\n",
    "epoch = test_list[0]['mne_epoch_around_door']\n",
    "epoch_psi(epoch, fs=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_simulated_epoch(n_channels=4, n_times=2000, n_events=10, sfreq=2000):\n",
    "    ch_names = ['AON_1', 'AON_2', 'vHp_1', 'vHp_2']\n",
    "    ch_types = ['eeg'] * n_channels\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    data = np.random.randn(n_events, n_channels, n_times)  # Random data for simulation\n",
    "    events = np.array([[i, 0, 1] for i in range(n_events)])  # Dummy events\n",
    "    epoch = mne.EpochsArray(data, info, events)\n",
    "    return epoch\n",
    "\n",
    "simulated_epoch = generate_simulated_epoch()\n",
    "mean_con, all_cons = epoch_psi(simulated_epoch)\n",
    "plt.plot(mean_con)\n",
    "\n",
    "psi_data_df = pd.DataFrame()\n",
    "psi_data_df['around_dig_mean_con'], psi_data_df['around_dig_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_dig'].apply(epoch_psi))\n",
    "psi_data_df['around_door_mean_con'], psi_data_df['around_door_all_cons'] = zip(*con_data_df_clean['mne_epoch_around_door'].apply(epoch_psi))\n",
    "psi_data_df['experiment'] = con_data_df_clean['experiment']\n",
    "psi_data_df['task'] = con_data_df_clean['task']\n",
    "psi_data_df['rat_id'] = con_data_df_clean['rat_id']\n",
    "psi_data_df.dropna(inplace=True)\n",
    "psi_data_df = psi_data_df[psi_data_df['around_dig_mean_con'].apply(lambda x: len(x) > 0) & psi_data_df['around_door_mean_con'].apply(lambda x: len(x) > 0)]\n",
    "psi_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "BWcontext_data = psi_data_df[(psi_data_df['task'] == 'BWcontext')]\n",
    "BWnocontext_data = psi_data_df[(psi_data_df['task'] == 'BWnocontext')]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_mean_con'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_mean_con'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Stack the lists vertically and compute the mean across axis 0\n",
    "bwcontext_stacked = np.vstack(BWcontext_data['around_dig_all_cons'].values)\n",
    "bwcontext_mean = np.mean(bwcontext_stacked, axis=0)\n",
    "bw_context_sem = np.std(bwcontext_stacked, axis=0) / np.sqrt(bwcontext_stacked.shape[0])\n",
    "\n",
    "bwnocontext_stacked = np.vstack(BWnocontext_data['around_dig_all_cons'].values)\n",
    "bwnocontext_mean = np.mean(bwnocontext_stacked, axis=0)\n",
    "bwnocontext_sem = np.std(bwnocontext_stacked, axis=0) / np.sqrt(bwnocontext_stacked.shape[0])\n",
    "fig,ax=plt.subplots(figsize=(20, 10))\n",
    "ax.plot(times, bwnocontext_mean, label=' No Context', color='orange')\n",
    "ax.fill_between(times, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, color='orange', alpha=0.3)\n",
    "ax.plot(times, bwcontext_mean, label='Context', color='blue')\n",
    "ax.fill_between(times, bwcontext_mean - bw_context_sem, bwcontext_mean + bw_context_sem, color='blue', alpha=0.3)\n",
    "ax.set_title('AON-vHp PSI Beta Band Around Dig', fontsize=20)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=20)\n",
    "ax.set_ylabel('Phase Slope Index', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc='upper left', fontsize=15)\n",
    "fig.savefig(savepath + 'aon_vhp_psi_around_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=test_list[0]['mne_epoch_around_door']\n",
    "epoch.ch_names\n",
    "\n",
    "print(aon_indices, vHp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_con_data['around_dig_mean_con'] = con_data_df_clean['mne_epoch_around_dig'].apply(epoch_coherogram)\n",
    "mean_con_data['around_door_mean_con'] = con_data_df_clean['mne_epoch_around_door'].apply(epoch_coherogram)\n",
    "\n",
    "mean_con_data['experiment'] = con_data_df_clean['experiment']\n",
    "mean_con_data['task'] = con_data_df_clean['task']\n",
    "mean_con_data['rat_id'] = con_data_df_clean['rat_id']\n",
    "mean_con_data.dropna(inplace=True)\n",
    "mean_con_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference in coherence between BWContext and BWnOContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_con_data_df_net=all_con_data_df.__deepcopy__()\n",
    "all_con_data_df_net.set_index('task', inplace=True)\n",
    "all_con_data_df_net.loc['difference'] = all_con_data_df_net.loc['BWcontext'] - all_con_data_df_net.loc['BWnocontext']\n",
    "all_con_data_df_net.reset_index(inplace=True)\n",
    "\n",
    "fs=2000\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "times=np.arange(-2, 2, 1/fs)\n",
    "fig, axs=plt.subplots(1,2, figsize=(20,10), sharey=True)\n",
    "fig.suptitle('Difference in Coherence between BW Context and BW No Context')\n",
    "axs=axs.flatten()\n",
    "vmin = all_con_data_df_net[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df_net[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[i].imshow(all_con_data_df_net[event][2], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_xlabel('Time (s)')\n",
    "    axs[i].set_ylabel('Frequency (Hz)')\n",
    "    axs[i].set_title(event_names[i])\n",
    "    axs[i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "cbar = fig.colorbar(axs[0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_coherence_event_spectrogram.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Difference manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=2000\n",
    "time_window = 1\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "for row in con_data_df_clean.itertuples(index=False):\n",
    "    experiment = row.experiment\n",
    "    rat_id = row.rat_id\n",
    "    task = row.task\n",
    "    mne_epoch = row.mne_epoch_door_before\n",
    "    data_around_dig = row.mne_epoch_around_dig\n",
    "    data_before_dig = row.mne_epoch_dig_before\n",
    "    data_after_dig = row.mne_epoch_dig_after\n",
    "    data_before_door = row.mne_epoch_door_before\n",
    "    data_after_door = row.mne_epoch_door_after\n",
    "\n",
    "    event_of_interest = data_before_dig ### CHANGE THIS TO THE DESIRED EVENT\n",
    "\n",
    "    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "    print(event_of_interest.get_data().shape)  # Should be (n_epochs, n_channels,n_times)\n",
    "    single_data = event_of_interest.get_data()[0, 0, :]  # Get data for the first channel\n",
    "    print(single_data.shape)  # Should be (n_times,)\n",
    "    fs=2000\n",
    "    l_freq =12\n",
    "    h_freq = 30\n",
    "    iir_filter = mne.filter.create_filter(single_data, sfreq=fs,l_freq=l_freq, h_freq=h_freq, method='iir', verbose=False)\n",
    "    event_of_interest.filter(l_freq=l_freq, h_freq=h_freq, method='iir', iir_params=iir_filter, verbose=False)\n",
    "    event_of_interest.apply_hilbert(envelope=False, n_jobs=1, verbose=False)\n",
    "\n",
    "    aon_indices = [i for i, ch in enumerate(event_of_interest.ch_names) if 'AON' in ch]\n",
    "    vhp_indices = [i for i, ch in enumerate(event_of_interest.ch_names) if 'vHp' in ch]\n",
    "    aon_channels = [event_of_interest.ch_names[i] for i in aon_indices]\n",
    "    vhp_channels = [event_of_interest.ch_names[i] for i in vhp_indices]\n",
    "    print(aon_indices, vhp_indices, aon_channels, vhp_channels)\n",
    "    aon_vhp_pairs = [(aon_ch, vhp_ch) for aon_ch in aon_channels for vhp_ch in vhp_channels]\n",
    "    print(aon_vhp_pairs)\n",
    "    num_of_cols = event_of_interest.get_data().shape[0]\n",
    "    num_of_rows = len(aon_vhp_pairs)\n",
    "\n",
    "    fig, axs = plt.subplots(num_of_rows, num_of_cols, subplot_kw={'projection': 'polar'},figsize=(40, 10))\n",
    "    fig.suptitle(f'AON-vHp Phase Difference Around Dig for Rat: {rat_id}, Experiment: {experiment}, Task: {task}', fontsize=20)\n",
    "    for i, (aon_ch, vhp_ch) in enumerate(aon_vhp_pairs):\n",
    "        for j in range(num_of_cols):\n",
    "            ax = axs[i, j]\n",
    "            ax.set_xticklabels([])          # remove theta labels\n",
    "            ax.set_yticklabels([])          # remove radial labels\n",
    "            # or hide ticks entirely:\n",
    "            #ax.xaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticks([])\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'{aon_ch} - {vhp_ch}', fontsize=10)\n",
    "            aon_index = aon_indices[aon_channels.index(aon_ch)]\n",
    "            vhp_index = vhp_indices[vhp_channels.index(vhp_ch)]\n",
    "            aon_epoch_data = np.angle(event_of_interest.get_data()[j,aon_index, :])\n",
    "            vhp_epoch_data = np.angle(event_of_interest.get_data()[j,vhp_index, :])\n",
    "            #print(aon_index, vhp_index, aon_epoch_data.shape, vhp_epoch_data.shape)\n",
    "            phase_diff = aon_epoch_data - vhp_epoch_data\n",
    "            ispc = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "            pli = abs(np.mean(np.sign(np.imag(np.exp(1j * phase_diff)))))\n",
    "            phase_diff_wrapped = np.mod(phase_diff, 2 * np.pi)\n",
    "            ax.hist(phase_diff_wrapped, bins=50, color='red', alpha=0.7, density=True)\n",
    "            if i== 0:\n",
    "                ax.set_title(f'trial {j}\\nispc:{ispc:.2f} pli:{pli:.2f}', fontsize=10)\n",
    "            else:\n",
    "                ax.set_title(f'ispc:{ispc:.2f} pli:{pli:.2f}', fontsize=10)\n",
    "    fig.savefig(savepath + f'{task}_{rat_id}_{experiment}_phase_difference_aon_vhp_before_dig.png', dpi=100, bbox_inches='tight')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GC measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "##############\n",
    "\n",
    "\n",
    "\n",
    "con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_truncated_{int(time_window*fs)}.pkl')\n",
    "#con_data_df=pd.DataFrame(con_data_df, columns=['rat_id','task','mne_baseline','mne_epoch_door_before','mne_epoch_door_after',\n",
    "                                               #'mne_epoch_dig_before','mne_epoch_dig_after', 'mne_epoch_around_door', 'mne_epoch_around_dig'])\n",
    "\n",
    "def calculate_net_gc(mne_data):\n",
    "        \n",
    "        mne_data=mne_data.resample(500)\n",
    "        \n",
    "        aon_signals=[\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(aon_signals)\n",
    "        vhp_signals=[\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "            if \"vHp\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        print(vhp_signals)\n",
    "\n",
    "        indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "        indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "        print(\"indices_aon_vhp:\", indices_aon_vhp, \"indices_vhp_aon:\", indices_vhp_aon)\n",
    "        gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "        mne_data,\n",
    "        method=[\"gc\"],\n",
    "        indices=indices_aon_vhp,\n",
    "        fmin=2.5,\n",
    "        fmax=100,\n",
    "        rank=None,\n",
    "        gc_n_lags=50,\n",
    "        )\n",
    "        freqs = gc_ab.freqs\n",
    "\n",
    "        gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "            mne_data,\n",
    "            method=[\"gc\"],\n",
    "            indices=indices_vhp_aon,\n",
    "            fmin=2.5,\n",
    "            fmax=100,\n",
    "            rank=None,\n",
    "            gc_n_lags=50,\n",
    "        )\n",
    "        freqs = gc_ba.freqs\n",
    "\n",
    "        net_gc = gc_ab.get_data() - gc_ba.get_data()\n",
    "        return gc_ab.get_data()[0], gc_ba.get_data()[0],net_gc[0], freqs\n",
    "\n",
    "def calculate_gc_indch(mne_data):\n",
    "    mne_data = mne_data.resample(500)\n",
    "\n",
    "    aon_signals = [\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"AON\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "    vhp_signals = [\n",
    "        idx\n",
    "        for idx, ch_info in enumerate(mne_data.info[\"chs\"])\n",
    "        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for aon_idx in aon_signals:\n",
    "        for vhp_idx in vhp_signals:\n",
    "            indices_aon_vhp = (np.array([[aon_idx]]), np.array([[vhp_idx]]))\n",
    "            indices_vhp_aon = (np.array([[vhp_idx]]), np.array([[aon_idx]]))\n",
    "            print(\"indices_aon_vhp:\", indices_aon_vhp, \"indices_vhp_aon:\", indices_vhp_aon)\n",
    "            gc_ab = mne_connectivity.spectral_connectivity_epochs(\n",
    "                mne_data,\n",
    "                method=[\"gc\"],\n",
    "                indices=indices_aon_vhp,\n",
    "                fmin=2.5,\n",
    "                fmax=100,\n",
    "                rank=None,\n",
    "                gc_n_lags=50,\n",
    "            )\n",
    "            gc_ba = mne_connectivity.spectral_connectivity_epochs(\n",
    "                mne_data,\n",
    "                method=[\"gc\"],\n",
    "                indices=indices_vhp_aon,\n",
    "                fmin=2.5,\n",
    "                fmax=100,\n",
    "                rank=None,\n",
    "                gc_n_lags=50,\n",
    "            )\n",
    "            freqs = gc_ab.freqs\n",
    "            net_gc = gc_ab.get_data()[0] - gc_ba.get_data()[0]\n",
    "\n",
    "            aon_ch = mne_data.info[\"chs\"][aon_idx][\"ch_name\"]\n",
    "            vhp_ch = mne_data.info[\"chs\"][vhp_idx][\"ch_name\"]\n",
    "\n",
    "            results.append({\n",
    "                \"channelpair\": (aon_ch, vhp_ch),\n",
    "                \"gc_aon_vhp\": gc_ab.get_data()[0],\n",
    "                \"gc_vhp_aon\": gc_ba.get_data()[0],\n",
    "                \"net_gc\": net_gc,\n",
    "                \"freqs\": freqs\n",
    "            })\n",
    "    return results\n",
    "\n",
    "test_mne = con_data_df_clean.iloc[0]['mne_epoch_dig_after']\n",
    "test_netgc = calculate_net_gc(test_mne)\n",
    "test_indch = calculate_gc_indch(test_mne)\n",
    "print(test_indch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc_columns = ['mne_epoch_door_before', 'mne_epoch_door_after', 'mne_epoch_dig_before', 'mne_epoch_dig_after', 'mne_epoch_around_door', 'mne_epoch_around_dig']\n",
    "\n",
    "aon_vhp_gc_results = []\n",
    "vhp_aon_gc_results = []\n",
    "net_gc_results = []\n",
    "\n",
    "for idx, row in con_data_df_clean.iterrows():\n",
    "\n",
    "    for col in gc_columns:\n",
    "        gc_list = calculate_gc_indch(row[col])\n",
    "\n",
    "        for pair_idx, gc_dict in enumerate(gc_list):\n",
    "            aon_vhp_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['gc_aon_vhp'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "            vhp_aon_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['gc_vhp_aon'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "            net_gc_results.append({\n",
    "                'rat_id': row['rat_id'],\n",
    "                'task': row['task'],\n",
    "                'experiment': row['experiment'],\n",
    "                'date': row['date'],\n",
    "                'epoch_type': col,\n",
    "                'channelpair_idx': pair_idx,\n",
    "                'channelpair': gc_dict['channelpair'],\n",
    "                'gc_values': gc_dict['net_gc'],\n",
    "                'freqs': gc_dict['freqs']\n",
    "            })\n",
    "        # aon_vhp_gc_results.append(row_result_aon_vhp)\n",
    "        # vhp_aon_gc_results.append(row_result_vhp_aon)\n",
    "        # net_gc_results.append(row_result_net_gc)\n",
    "\n",
    "# Convert to DataFrames\n",
    "aon_vhp_gc_df = pd.DataFrame(aon_vhp_gc_results)\n",
    "vhp_aon_gc_df = pd.DataFrame(vhp_aon_gc_results)\n",
    "net_gc_df = pd.DataFrame(net_gc_results)\n",
    "\n",
    "# Expand the DataFrame so each AON-vHp channel pair has its own column for each epoch type\n",
    "\n",
    "# Example: save to disk\n",
    "aon_vhp_gc_df.to_pickle(savepath + f'vhp_aon_gc_shuffled.pkl')\n",
    "vhp_aon_gc_df.to_pickle(savepath + f'aon_vhp_gc_shuffled.pkl')\n",
    "net_gc_df.to_pickle(savepath + f'net_gc_shuffled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7\n",
    "fs=2000\n",
    "aon_vhp_gc_df=pd.read_pickle(savepath + f'aon_vhp_gc.pkl')\n",
    "vhp_aon_gc_df=pd.read_pickle(savepath + f'vhp_aon_gc.pkl')\n",
    "net_gc_df=pd.read_pickle(savepath + f'net_gc.pkl')\n",
    "\n",
    "def calculate_gc_per_band(gc_array,freqs_array, bands_dict):\n",
    "    freqs_array = np.array(freqs_array)  # Convert freqs_array to numpy array\n",
    "    print(len(gc_array))\n",
    "    gc_bands_dict={}\n",
    "    for band in bands_dict.keys():\n",
    "        band_indices=np.where((freqs_array>=bands_dict[band][0]) & (freqs_array<=bands_dict[band][1]))\n",
    "        gc_band=gc_array[band_indices]\n",
    "        gc_bands_dict[band]=np.sum(gc_band)*(freqs_array[1]-freqs_array[0])\n",
    "        #gc_bands_dict[band]=(np.sum(gc_band)*0.5)/len(gc_band)\n",
    "    return gc_bands_dict\n",
    "\n",
    "test_row = aon_vhp_gc_df.iloc[0]\n",
    "row_list= [test_row]\n",
    "bands_dict = {\n",
    "    'theta': (4, 8),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 100),\n",
    "    'theta+early_beta': (4, 20),\n",
    "    'total': (2.5, 100)\n",
    "}\n",
    "\n",
    "for row in row_list:\n",
    "    gc_values = row['gc_values']\n",
    "    freqs = row['freqs']\n",
    "    gc_bands = calculate_gc_per_band(gc_values, freqs, bands_dict)\n",
    "    print(row['channelpair'], row['epoch_type'], gc_bands)\n",
    "    for band in gc_bands.keys():\n",
    "        row[f'{band}'] = gc_bands[band]\n",
    "    print(row)\n",
    "events_dict = {\n",
    "    'mne_epoch_door_before': 'door_before',\n",
    "    'mne_epoch_door_after': 'door_after',\n",
    "    'mne_epoch_dig_before': 'dig_before',\n",
    "    'mne_epoch_dig_after': 'dig_after',\n",
    "    'mne_epoch_around_door': 'around_door',\n",
    "    'mne_epoch_around_dig': 'around_dig'\n",
    "}\n",
    "gc_df_dict = {'AON to vHp': aon_vhp_gc_df, 'vHp to AON': vhp_aon_gc_df, 'Net GC': net_gc_df}\n",
    "writer = pd.ExcelWriter(savepath + 'gc_band_results.xlsx')\n",
    "for i, gc_df in enumerate(gc_df_dict.values()):\n",
    "    band_results = []\n",
    "\n",
    "    for idx, row in gc_df.iterrows():\n",
    "        gc_values = row['gc_values']\n",
    "        freqs = row['freqs']\n",
    "        gc_bands = calculate_gc_per_band(gc_values, freqs, bands_dict)\n",
    "        for band in gc_bands.keys():\n",
    "            row[f'{band}'] = gc_bands[band]\n",
    "        row['event'] = events_dict[row['epoch_type']]\n",
    "        row.drop(['gc_values', 'freqs', 'epoch_type'], inplace=True)\n",
    "        band_results.append(row)\n",
    "    band_df = pd.DataFrame(band_results)\n",
    "    band_df_melted = band_df.melt(id_vars=['rat_id', 'task', 'experiment', 'date', 'event', 'channelpair'],\n",
    "                                  value_vars=list(bands_dict.keys()), var_name='band', value_name='gc_value')\n",
    "    band_df_melted.to_excel(writer, sheet_name=list(gc_df_dict.keys())[i], index=False)\n",
    "    \n",
    "    ########### Plotting ###########\n",
    "    \n",
    "\n",
    "    fig, axs=plt.subplots(3,2, sharex=False, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle(f'{list(gc_df_dict.keys())[i]} Granger causality per band')\n",
    "    for axi, event in enumerate(events_dict.values()):\n",
    "        print(axi, event)\n",
    "        ax=axs[axi]\n",
    "        ax.axhline(0, color='black', lw=1)\n",
    "        sns.barplot(x='band',y='gc_value',hue='task',hue_order=['BWcontext','BWnocontext'],data=band_df_melted[band_df_melted['event']==event], ax=ax)\n",
    "        #sns.stripplot(x='band',y='gc_value',hue='task',hue_order=['BWcontext','BWnocontext'],data=band_df_melted,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax)\n",
    "        ax.set_title(f\"{event}\", fontsize=10)\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'gc_events_perband_{list(gc_df_dict.keys())[i]}_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_gc_df=pd.DataFrame()\n",
    "aon_vhp_gc_df = pd.DataFrame()\n",
    "vhp_aon_gc_df = pd.DataFrame()\n",
    "\n",
    "for col in ['rat_id', 'task', 'experiment', 'date']:\n",
    "    net_gc_df[col] = con_data_df_clean[col]\n",
    "    aon_vhp_gc_df[col] = con_data_df_clean[col]\n",
    "    vhp_aon_gc_df[col] = con_data_df_clean[col]\n",
    "for event in ['door_before', 'door_after', 'dig_before', 'dig_after', 'around_door', 'around_dig']:\n",
    "    mne_col = f'mne_epoch_{event}' if event not in ['around_door', 'around_dig'] else f'mne_epoch_{event}'\n",
    "    aon_vhp_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[0])\n",
    "    vhp_aon_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[1])\n",
    "    net_gc_df[event] = con_data_df_clean[mne_col].apply(lambda x: calculate_gc_indch(x)[2])\n",
    "\n",
    "\n",
    "net_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "net_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "net_gc_df=pd.DataFrame(net_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door','around_dig', 'freqs', 'freqs_door'])\n",
    "\n",
    "aon_vhp_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "aon_vhp_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_gc_indch(x)[3])\n",
    "aon_vhp_gc_df=pd.DataFrame(aon_vhp_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door',\n",
    "                                                'around_dig', 'freqs', 'freqs_door'])\n",
    "\n",
    "vhp_aon_gc_df['freqs'] = con_data_df_clean['mne_epoch_dig_after'].apply(lambda x: calculate_net_gc(x)[3])\n",
    "vhp_aon_gc_df['freqs_door'] = con_data_df_clean['mne_epoch_door_after'].apply(lambda x: calculate_net_gc(x)[3])\n",
    "vhp_aon_gc_df=pd.DataFrame(vhp_aon_gc_df, columns=['rat_id','task','experiment','date','door_before','door_after','dig_before','dig_after','around_door',\n",
    "                                                    'around_dig', 'freqs', 'freqs_door']) \n",
    "\n",
    "\n",
    "net_gc_df.to_pickle(savepath+f'net_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "aon_vhp_gc_df.to_pickle(savepath+f'aon_vhp_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "vhp_aon_gc_df.to_pickle(savepath+f'vhp_aon_gc_events_density_{int(time_window*fs/2)}ms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "time_window = 0.7\n",
    "fs=2000\n",
    "##############\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "gc_dict = {'net': 'Net', 'aon_vhp': 'AON -> vHP', 'vhp_aon': 'vHP -> AON'}\n",
    "\n",
    "for gc_type in gc_dict.keys():\n",
    "    gc_data_df=pd.read_pickle(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "\n",
    "    gc_data_df_bwcontext=gc_data_df[gc_data_df['task']=='BWcontext']\n",
    "    gc_data_df_bwnocontext=gc_data_df[gc_data_df['task']=='BWnocontext']\n",
    "    writer=pd.ExcelWriter(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.xlsx')\n",
    "\n",
    "    fig,axs=plt.subplots(3,2, sharex=True, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle(f'Context vs No Context {gc_dict[gc_type]} Granger Causality')\n",
    "    events_dict={'door_before': 'Door Before','door_after': 'Door After','dig_before': 'Dig Before','dig_after': 'Dig After','around_door': 'Around Door','around_dig': 'Around Dig'}\n",
    "    for i,event in enumerate(events_dict.keys()):\n",
    "        ax=axs[i]\n",
    "        bwcontext_mean=np.mean(gc_data_df_bwcontext[event], axis=0)\n",
    "        bwnocontext_mean=np.mean(gc_data_df_bwnocontext[event], axis=0)\n",
    "        bwcontext_sem=scipy.stats.sem(gc_data_df_bwcontext[event], axis=0)\n",
    "        bwnocontext_sem=scipy.stats.sem(gc_data_df_bwnocontext[event], axis=0)\n",
    "        \n",
    "        freqs=np.linspace(2.5,100,len(bwcontext_mean))\n",
    "        \n",
    "        mean_dict={'frequency':freqs,'bwcontext':bwcontext_mean,'bwnocontext':bwnocontext_mean,'bwcontext_sem':bwcontext_sem,'bwnocontext_sem':bwnocontext_sem}\n",
    "        mean_df=pd.DataFrame(mean_dict)\n",
    "        mean_df.to_excel(writer, sheet_name=event)\n",
    "\n",
    "\n",
    "        ax.plot(freqs, bwcontext_mean, linewidth=2, label='Context')\n",
    "        ax.fill_between(freqs, bwcontext_mean - bwcontext_sem, bwcontext_mean + bwcontext_sem, alpha=0.2)\n",
    "        ax.plot(freqs, gc_data_df_bwnocontext[event].mean(), linewidth=2, label='No Context')\n",
    "        ax.fill_between(freqs, bwnocontext_mean - bwnocontext_sem, bwnocontext_mean + bwnocontext_sem, alpha=0.2)    \n",
    "        ax.plot((freqs[0], freqs[-1]), (0, 0), linewidth=2, linestyle=\"--\", color=\"k\")\n",
    "        ax.axvspan(4,12, alpha=0.2, color='red', label='Theta Range')\n",
    "        ax.axvspan(12,30, alpha=0.2, color='green', label='Beta Range')\n",
    "        ax.axvspan(30,80, alpha=0.2, color='grey', label='Gamma Range')\n",
    "        ax.set_title(f\"{events_dict[event]}\", fontsize=8)\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "    writer.close()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#%matplotlib qt\n",
    "bands_dict={'total':[2.5,100],'theta': [4,12],'beta':[12,30],'gamma':[30,80], 'beta+theta':[4,30], 'early_beta':[12,20], 'late_beta':[20,30]}\n",
    "\n",
    "gc_dict = {'net': 'Net', 'aon_vhp': 'AON -> vHP', 'vhp_aon': 'vHP -> AON'}\n",
    "\n",
    "for gc_type in gc_dict.keys():\n",
    "    gc_data_df=pd.read_pickle(savepath+f'{gc_type}_gc_events_density_{int(time_window*fs/2)}ms.pkl')\n",
    "    gc_data_df_bwcontext=gc_data_df[gc_data_df['task']=='BWcontext']\n",
    "    gc_data_df_bwnocontext=gc_data_df[gc_data_df['task']=='BWnocontext']\n",
    "    def calculate_gc_per_band(gc_array,freqs_array, bands_dict):\n",
    "        freqs_array = np.array(freqs_array)  # Convert freqs_array to numpy array\n",
    "        print(len(gc_array))\n",
    "        gc_bands_dict={}\n",
    "        for band in bands_dict.keys():\n",
    "            band_indices=np.where((freqs_array>=bands_dict[band][0]) & (freqs_array<=bands_dict[band][1]))\n",
    "            gc_band=gc_array[band_indices]\n",
    "            gc_bands_dict[band]=np.sum(gc_band)*(freqs_array[1]-freqs_array[0])\n",
    "            #gc_bands_dict[band]=(np.sum(gc_band)*0.5)/len(gc_band)\n",
    "        return gc_bands_dict\n",
    "\n",
    "    test_gc=gc_data_df_bwcontext['door_before'].iloc[0]\n",
    "    test_freqs=gc_data_df_bwcontext['freqs'].iloc[0]\n",
    "    test_gc_band=calculate_gc_per_band(test_gc,test_freqs, bands_dict)\n",
    "    print(test_gc_band)\n",
    "\n",
    "    gc_cols = ['door_before', 'door_after', 'dig_before', 'dig_after','around_door','around_dig']\n",
    "    gc_data_df_bands = []\n",
    "\n",
    "    for index, row in gc_data_df.iterrows():\n",
    "        rat_id = row['rat_id']\n",
    "        task = row['task']\n",
    "        for gc_col in gc_cols:\n",
    "            if gc_col=='around_door_truncated' or gc_col=='around_dig_truncated':\n",
    "                freqs = row['freqs_trunc']\n",
    "            elif gc_col=='around_door' or gc_col=='around_dig':\n",
    "                freqs = row['freqs_door']\n",
    "            else:\n",
    "                freqs = row['freqs']\n",
    "            gc_values = calculate_gc_per_band(row[gc_col], freqs, bands_dict)\n",
    "            for band, gc_value in gc_values.items():\n",
    "                gc_data_df_bands.append({\n",
    "                    'rat_id': rat_id,\n",
    "                    'task': task,\n",
    "                    'event': gc_col,\n",
    "                    'band': band,\n",
    "                    'gcvalue': gc_value\n",
    "                })\n",
    "\n",
    "    gc_data_df_bands = pd.DataFrame(gc_data_df_bands)\n",
    "    gc_data_df_bands=gc_data_df_bands[gc_data_df_bands['task']!='nocontext']\n",
    "    print(gc_data_df_bands)\n",
    "    writer=pd.ExcelWriter(savepath+f'gc_events_perband_{int(time_window*fs/2)}ms.xlsx')\n",
    "    fig, axs=plt.subplots(3,2, sharex=False, sharey=True, figsize=(15,10))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle('Average Net AON -> vHp granger causality per band')\n",
    "    for i, event in enumerate(gc_cols):\n",
    "        print(i, event)\n",
    "        ax=axs[i]\n",
    "        gc_event=gc_data_df_bands[gc_data_df_bands['event']==event]\n",
    "        gc_event.to_excel(writer, sheet_name=event)\n",
    "        ax.axhline(0, color='black', lw=1)\n",
    "        sns.boxplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,showfliers=False, ax=ax)\n",
    "        sns.stripplot(x='band',y='gcvalue',hue='task',hue_order=['BWcontext','BWnocontext'],data=gc_event,dodge=True,edgecolor='black',linewidth=1,jitter=True, legend=False, ax=ax)\n",
    "        ax.set_title(f\"{event}\", fontsize=10)\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(savepath+f'gc_events_perband_{int(time_window*fs/2)}ms.png')\n",
    "    plt.show()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making GC Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=2000\n",
    "time_window=1\n",
    "\n",
    "\n",
    "### Test Case\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "test_epoch = con_data_df_clean['mne_epoch_dig_before'].iloc[0]\n",
    "test_epoch = test_epoch.resample(500)\n",
    "fmin=2.5\n",
    "fmax=100\n",
    "freqs = np.arange(fmin,fmax)\n",
    "n_cycles = freqs/3\n",
    "\n",
    "###Specifying the Indices for AON and vHp channels\n",
    "aon_signals=[\n",
    "idx\n",
    "for idx, ch_info in enumerate(test_epoch.info[\"chs\"])\n",
    "if \"AON\" in ch_info[\"ch_name\"]\n",
    "]\n",
    "print(aon_signals)\n",
    "vhp_signals=[\n",
    "    idx\n",
    "    for idx, ch_info in enumerate(test_epoch.info[\"chs\"])\n",
    "    if \"vHp\" in ch_info[\"ch_name\"]\n",
    "]\n",
    "print(vhp_signals)\n",
    "\n",
    "indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "print(indices_aon_vhp)\n",
    "import itertools\n",
    "\n",
    "indices_pairs = list(itertools.product(aon_signals, vhp_signals))\n",
    "indices = (\n",
    "    np.array([pair[0] for pair in indices_pairs]),\n",
    "    np.array([pair[1] for pair in indices_pairs])\n",
    ")\n",
    "print(indices)\n",
    "# indices = [([aon], [vhp]) for aon in aon_signals for vhp in vhp_signals]\n",
    "# print(indices)\n",
    "\n",
    "\n",
    "con = mne_connectivity.spectral_connectivity_epochs(test_epoch, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "                                        mode='multitaper', mt_bandwidth=2.8,\n",
    "                                        verbose=True, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5)\n",
    "coh = con.get_data()\n",
    "print(coh.shape)\n",
    "# indices = con.names\n",
    "# aon_vHp_con = []\n",
    "# print(coh.shape, indices)\n",
    "\n",
    "# plt.imshow(coh[0, :, :], extent=[0, 1, 1, 100], aspect='auto', origin='lower', cmap='jet')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "# Extract all columns at once using vectorized operations\n",
    "experiments = con_data_df_clean['experiment'].values\n",
    "rat_ids = con_data_df_clean['rat_id'].values\n",
    "tasks = con_data_df_clean['task'].values\n",
    "events_dict = {'mne_epoch_door_before':'gc_door_before','mne_epoch_dig_before':'gc_dig_before','mne_epoch_dig_after':'gc_dig_after'}\n",
    "    \n",
    "for event in events_dict.keys():\n",
    "\n",
    "    events_of_interest = con_data_df_clean[event].values  ### CHANGE THIS TO THE DESIRED EVENT\n",
    "\n",
    "    all_gc_data = []\n",
    "\n",
    "    # Iterate only through the length, using vectorized column access\n",
    "    for i in range(len(con_data_df_clean)):\n",
    "        experiment = experiments[i]\n",
    "        rat_id = rat_ids[i]\n",
    "        task = tasks[i]\n",
    "        event_of_interest = events_of_interest[i]\n",
    "        \n",
    "        print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "        \n",
    "        aon_signals = [\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "            if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        \n",
    "        vhp_signals = [\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "            if \"vHp\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        \n",
    "        indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "        print(indices_aon_vhp)\n",
    "        indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "        \n",
    "        event_of_interest = event_of_interest.resample(500)\n",
    "        \n",
    "        fmin=2.5\n",
    "        fmax=100\n",
    "        freqs = np.arange(fmin,fmax)\n",
    "        n_cycles = freqs/3\n",
    "\n",
    "        con_aon_vhp = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "            mode='cwt_morlet', cwt_freqs=freqs, cwt_n_cycles=n_cycles, \n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        con_vhp_aon = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest, method='gc', sfreq=int(fs), indices=indices_vhp_aon,\n",
    "            mode='cwt_morlet', cwt_freqs=freqs, cwt_n_cycles=n_cycles,\n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        coh_aon_vhp = con_aon_vhp.get_data()[0, :, :]\n",
    "        coh_vhp_aon = con_vhp_aon.get_data()[0, :, :]\n",
    "        \n",
    "        all_gc_data.append([experiment, rat_id, task, coh_aon_vhp, coh_vhp_aon])\n",
    "\n",
    "    all_gc_data_df = pd.DataFrame(all_gc_data, columns=['experiment', 'rat_id', 'task', 'gc_aon_vhp', 'gc_vhp_aon'])\n",
    "    all_gc_data_df.to_pickle(savepath+f'{events_dict[event]}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indvidual expt Net GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gc_data_df=pd.read_pickle(savepath+'gc_dig_after.pkl')\n",
    "\n",
    "all_gc_data_df['net_gc'] = all_gc_data_df['gc_aon_vhp'] - all_gc_data_df['gc_vhp_aon']\n",
    "\n",
    "vmin = all_gc_data_df['net_gc'].apply(np.min).min()\n",
    "vmax = all_gc_data_df['net_gc'].apply(np.max).max()\n",
    "\n",
    "BWcontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWcontext')]\n",
    "BWnocontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "for group_name, group_df in task_data_dict.items():\n",
    "    fig, axs = plt.subplots(group_df.shape[0] // 5 + int(group_df.shape[0] % 5 != 0), 5, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    axs = axs.flatten()\n",
    "    for i, (idx, row) in enumerate(group_df.iterrows()):\n",
    "        data = np.array(row['net_gc'])\n",
    "        ax = axs[i]\n",
    "        im = ax.imshow(data, extent=[0,1, 1, 100], aspect='auto', cmap='jet', origin='lower', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{row['rat_id']} {row['experiment']}\")\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        fig.delaxes(axs[j])\n",
    "    fig.suptitle(f\"{group_name} AON -> vHp net GC\", fontsize=16)\n",
    "    fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    #fig.savefig(savepath + f'coherence_around_dig_{group_name}.png', dpi=300, bbox_inches='tight')\n",
    "    #plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc_list = ['gc_aon_vhp', 'gc_vhp_aon']#, 'net_gc']\n",
    "events_dict = {'gc_door_before':'Door Before', 'gc_dig_before': 'Dig Before', 'gc_dig_after' :'Dig After'}\n",
    "\n",
    "for gc in gc_list:\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    fig.suptitle(f'Average {gc}')\n",
    "    for coli, event in enumerate(events_dict.keys()):\n",
    "        all_gc_data_df=pd.read_pickle(savepath+f'{event}.pkl')\n",
    "        \n",
    "        BWcontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWcontext')]\n",
    "        BWnocontext_data=all_gc_data_df[(all_gc_data_df['task']=='BWnocontext')]\n",
    "        \n",
    "        bw_context_mean=BWcontext_data[gc].mean()\n",
    "        bw_nocontext_mean=BWnocontext_data[gc].mean()\n",
    "        #print(bw_context_mean.shape, bw_nocontext_mean.shape)\n",
    "        vmin = min(bw_context_mean.min(), bw_nocontext_mean.min())\n",
    "        vmax = max(bw_context_mean.max(), bw_nocontext_mean.max())\n",
    "        axs[0, coli].imshow(bw_context_mean, extent=[0, 1, 1, 100], aspect='auto', cmap='jet',origin='lower')#, vmin=vmin, vmax=vmax)\n",
    "        axs[0, coli].set_title(f'{events_dict[event]}')\n",
    "        axs[1, coli].imshow(bw_nocontext_mean, extent=[0, 1, 1, 100], aspect='auto', cmap='jet',origin='lower')#, vmin=vmin, vmax=vmax)\n",
    "        axs[1, coli].set_title(f'{events_dict[event]}')\n",
    "        axs.legend()\n",
    "        # for ax in axs:\n",
    "        #     ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        #     ax.axhline(12, color='green', linestyle='--')\n",
    "        #     ax.axhline(30, color='green', linestyle='--')\n",
    "    #fig.colorbar(axs[0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GC Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "\n",
    "# Extract all columns at once using vectorized operations\n",
    "experiments = con_data_df_clean['experiment'].values\n",
    "rat_ids = con_data_df_clean['rat_id'].values\n",
    "tasks = con_data_df_clean['task'].values\n",
    "events_dict = {'mne_epoch_door_before':'gc_door_before','mne_epoch_dig_before':'gc_dig_before','mne_epoch_dig_after':'gc_dig_after'}\n",
    "\n",
    "\n",
    "for event in events_dict.keys():\n",
    "\n",
    "    events_of_interest = con_data_df_clean[event].values  ### CHANGE THIS TO THE DESIRED EVENT\n",
    "\n",
    "    all_gc_data_real = []\n",
    "    all_gc_data_shuffled = []\n",
    "    \n",
    "\n",
    "    # Iterate only through the length, using vectorized column access\n",
    "    for i in range(len(con_data_df_clean)):\n",
    "        experiment = experiments[i]\n",
    "        rat_id = rat_ids[i]\n",
    "        task = tasks[i]\n",
    "        event_of_interest = events_of_interest[i]\n",
    "        \n",
    "        print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "        \n",
    "        aon_signals = [\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "            if \"AON\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        \n",
    "        vhp_signals = [\n",
    "            idx\n",
    "            for idx, ch_info in enumerate(event_of_interest.info[\"chs\"])\n",
    "            if \"vHp\" in ch_info[\"ch_name\"]\n",
    "        ]\n",
    "        \n",
    "        indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "        print(indices_aon_vhp)\n",
    "        indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))\n",
    "        \n",
    "        event_of_interest = event_of_interest.resample(500)\n",
    "        event_of_interest_shuffled = event_of_interest.copy()\n",
    "        event_of_interest_shuffled = coherence_functions.randomize_timepoints(event_of_interest_shuffled)\n",
    "        \n",
    "        \n",
    "        fmin=2.5\n",
    "        fmax=100\n",
    "        freqs = np.arange(fmin,fmax)\n",
    "        n_cycles = freqs/3\n",
    "\n",
    "        ##### Calculating and appending Real GC\n",
    "\n",
    "\n",
    "        con_aon_vhp_real = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "            mode='multitaper', mt_bandwidth=2.8, \n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        con_vhp_aon_real = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest, method='gc', sfreq=int(fs), indices=indices_vhp_aon,\n",
    "           mode='multitaper', mt_bandwidth=2.8,\n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        coh_aon_vhp_real = con_aon_vhp_real.get_data()[0, :]\n",
    "        coh_vhp_aon_real = con_vhp_aon_real.get_data()[0, :]\n",
    "        \n",
    "        all_gc_data_real.append([experiment, rat_id, task, coh_aon_vhp_real, coh_vhp_aon_real])\n",
    "        \n",
    "        ##### Calculating and appending Shuffled GC\n",
    "        \n",
    "        con_aon_vhp_shuffled = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest_shuffled, method='gc', sfreq=int(fs), indices=indices_aon_vhp,\n",
    "            mode='multitaper', mt_bandwidth=2.8, \n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        con_vhp_aon_shuffled = mne_connectivity.spectral_connectivity_epochs(\n",
    "            event_of_interest_shuffled, method='gc', sfreq=int(fs), indices=indices_vhp_aon,\n",
    "           mode='multitaper', mt_bandwidth=2.8,\n",
    "            verbose=False, fmin=fmin, fmax=fmax, faverage=False, gc_n_lags=5, rank=None\n",
    "        )\n",
    "        \n",
    "        coh_aon_vhp_shuffled = con_aon_vhp_shuffled.get_data()[0, :]\n",
    "        coh_vhp_aon_shuffled = con_vhp_aon_shuffled.get_data()[0, :]\n",
    "        \n",
    "        all_gc_data_shuffled.append([experiment, rat_id, task, coh_aon_vhp_shuffled, coh_vhp_aon_shuffled])\n",
    "\n",
    "\n",
    "    all_gc_data_df = pd.DataFrame(all_gc_data_real, columns=['experiment', 'rat_id', 'task', 'gc_aon_vhp', 'gc_vhp_aon'])\n",
    "    all_gc_data_df.to_pickle(savepath+f'{events_dict[event]}_density.pkl')\n",
    "\n",
    "    all_gc_data_df_shuffled = pd.DataFrame(all_gc_data_shuffled, columns=['experiment', 'rat_id', 'task', 'gc_aon_vhp', 'gc_vhp_aon'])\n",
    "    all_gc_data_df_shuffled.to_pickle(savepath+f'{events_dict[event]}_density_shuffled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Avg GC density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "gc_list = {'gc_aon_vhp':'red', 'gc_vhp_aon':'blue'}#, 'net_gc']\n",
    "events_dict = {'gc_door_before_density':'Door Before', 'gc_dig_before_density': 'Dig Before', 'gc_dig_after_density' :'Dig After'}\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6), sharey=True)\n",
    "fig.suptitle(f'GC Density')\n",
    "\n",
    "writer=pd.ExcelWriter(savepath+'events_granger_causality_density.xlsx')\n",
    "\n",
    "for coli, event in enumerate(events_dict.keys()):\n",
    "    all_gc_data_df=pd.read_pickle(savepath+f'{event}.pkl')\n",
    "    all_gc_data_df_shuffled=pd.read_pickle(savepath+f'{event}_shuffled.pkl')\n",
    "    \n",
    "    gc_density_dict={}\n",
    "        \n",
    "    BWcontext_data_real_df=all_gc_data_df[(all_gc_data_df['task']=='BWcontext')]\n",
    "    BWnocontext_data_real_df=all_gc_data_df[(all_gc_data_df['task']=='BWnocontext')]\n",
    "    BWcontext_data_shuffled_df=all_gc_data_df_shuffled[(all_gc_data_df_shuffled['task']=='BWcontext')]\n",
    "    BWnocontext_data_shuffled_df=all_gc_data_df_shuffled[(all_gc_data_df_shuffled['task']=='BWnocontext')]\n",
    "    \n",
    "    for gc in gc_list.keys():\n",
    "        \n",
    "        BWcontext_data_real=np.vstack(BWcontext_data_real_df[gc].to_numpy())\n",
    "        BWnocontext_data_real=np.vstack(BWnocontext_data_real_df[gc].to_numpy())\n",
    "        BWcontext_data_shuffled=np.vstack(BWcontext_data_shuffled_df[gc].to_numpy())\n",
    "        BWnocontext_data_shuffled=np.vstack(BWnocontext_data_shuffled_df[gc].to_numpy())\n",
    "        \n",
    "        bw_context_mean_real=np.mean(BWcontext_data_real, axis=0)\n",
    "        bw_nocontext_mean_real=np.mean(BWnocontext_data_real, axis=0)\n",
    "        bw_context_mean_shuffled=np.mean(BWcontext_data_shuffled, axis=0)\n",
    "        bw_nocontext_mean_shuffled=np.mean(BWnocontext_data_shuffled, axis=0)\n",
    "\n",
    "        bw_context_std_real=np.std(BWcontext_data_real, axis=0)\n",
    "        bw_nocontext_std_real=np.std(BWnocontext_data_real, axis=0)\n",
    "        bw_context_std_shuffled=np.std(BWcontext_data_shuffled, axis=0)\n",
    "        bw_nocontext_std_shuffled=np.std(BWnocontext_data_shuffled, axis=0)\n",
    "\n",
    "        freqs = np.linspace(2.5,100,len(bw_context_mean_real))\n",
    "        axs[0, coli].plot(freqs, bw_context_mean_real, label=f'{gc}', color = gc_list[gc]) #, vmin=vmin, vmax=vmax)\n",
    "        axs[0, coli].set_title(f'Context {events_dict[event]}')\n",
    "        axs[0, coli].plot(freqs, bw_context_mean_shuffled, label=f'{gc}', color = gc_list[gc], linestyle='dashed') #, vmin=vmin, vmax=vmax)\n",
    "        axs[0, coli].set_title(f'Context {events_dict[event]}')\n",
    "\n",
    "        axs[1, coli].plot(freqs, bw_nocontext_mean_real, label=f'{gc}', color = gc_list[gc])#, vmin=vmin, vmax=vmax)\n",
    "        axs[1, coli].set_title(f'No Context {events_dict[event]}')\n",
    "        axs[1, coli].plot(freqs, bw_nocontext_mean_shuffled, label=f'{gc}', color = gc_list[gc], linestyle='dashed')#, vmin=vmin, vmax=vmax)\n",
    "        axs[1, coli].set_title(f'No Context {events_dict[event]}')\n",
    "        \n",
    "        gc_density_dict.update({\n",
    "            f'real_{gc}_bwcontext_mean': bw_context_mean_real,\n",
    "            f'real_{gc}_bwcontext_sem': bw_context_std_real,\n",
    "            f'real_{gc}_bwnocontext_mean': bw_nocontext_mean_real,\n",
    "            f'real_{gc}_bwnocontext_sem': bw_nocontext_std_real,\n",
    "            f'shuffled_{gc}_bwcontext_mean': bw_context_mean_shuffled,\n",
    "            f'shuffled_{gc}_bwcontext_sem': bw_context_std_shuffled,\n",
    "            f'shuffled_{gc}_bwnocontext_mean': bw_nocontext_mean_shuffled,\n",
    "            f'shuffled_{gc}_bwnocontext_sem': bw_nocontext_std_shuffled,\n",
    "        })\n",
    "    gc_density_dict['freqs'] = freqs\n",
    "    gc_density_df = pd.DataFrame(gc_density_dict)\n",
    "    gc_density_df.to_excel(writer, sheet_name=events_dict[event])\n",
    "\n",
    "writer.close()\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "handles = [Line2D([0], [0], color = 'red', lw=2),\n",
    "           Line2D([0], [0], color = 'red',linestyle='dashed', lw=2),\n",
    "            Line2D([0], [0], color = 'blue', lw=2),\n",
    "            Line2D([0], [0], color = 'blue', linestyle='dashed',lw=2)]\n",
    "labels = ['AON -> vHP (Real)','AON -> vHP (Shuffled)', 'vHP -> AON (Real)','vHP -> AON (Shuffled)']\n",
    "fig.legend(handles, labels, loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GC Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.556151404609524\n"
     ]
    }
   ],
   "source": [
    "all_gc_data_df=pd.read_pickle(savepath+f'gc_door_before_density.pkl')\n",
    "\n",
    "def get_band_gc(data_array, band_start, band_end):\n",
    "    freq_axs = np.linspace(2.5, 100, len(data_array))\n",
    "    band_data = data[(freq_axs >= band_start) & (freq_axs <= band_end)]\n",
    "    power_sum = np.sum(band_data)\n",
    "    freq_diff = freq_axs[1] - freq_axs[0]\n",
    "    return power_sum * freq_diff\n",
    "\n",
    "test_data = all_gc_data_df['gc_aon_vhp'].iloc[0]\n",
    "\n",
    "beta_gc = get_band_gc(test_data, 12, 30)\n",
    "print(beta_gc)\n",
    "\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "for band, (band_start, band_end) in bands_dict.items():\n",
    "    all_gc_data_df[f'{band}_aon_to_vhp'] = all_gc_data_df['gc_aon_vhp'].apply(lambda x: get_band_gc(x, band_start, band_end))\n",
    "    all_gc_data_df[f'{band}_vhp_to_aon'] = all_gc_data_df['gc_vhp_aon'].apply(lambda x: get_band_gc(x, band_start, band_end))\n",
    "\n",
    "all_gc_data_df=all_gc_data_df.drop(columns=['gc_aon_vhp', 'gc_vhp_aon'])\n",
    "\n",
    "event_df_melted = pd.melt(all_gc_data_df, id_vars=['experiment', 'rat_id', 'task'], var_name='band', value_name='gc')\n",
    "split_cols = event_df_melted['band'].str.split('_', n=1, expand=True)\n",
    "event_df_melted['band'] = split_cols[0]\n",
    "event_df_melted['direction'] = split_cols[1]\n",
    "event_df_melted['data_type'] = 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc_door_before_density Door Before\n",
      "gc_dig_before_density Dig Before\n",
      "gc_dig_after_density Dig After\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc_list = {'gc_aon_vhp':'red', 'gc_vhp_aon':'blue'}#, 'net_gc']\n",
    "events_dict = {'gc_door_before_density':'Door Before', 'gc_dig_before_density': 'Dig Before', 'gc_dig_after_density' :'Dig After'}\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [2.5, 100]}\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 6), sharey=True)\n",
    "fig.suptitle(f'GC Per Band')\n",
    "data_type_suffix_dict ={'real':'','shuffled':'_shuffled'}\n",
    "\n",
    "writer=pd.ExcelWriter(savepath+'events_granger_causality_perband.xlsx')\n",
    "\n",
    "for coli, (file_name, event_name) in enumerate(events_dict.items()):\n",
    "    print(file_name, event_name)\n",
    "    event_df = []\n",
    "    for (data_type, suffix) in data_type_suffix_dict.items():\n",
    "        all_gc_data_df=pd.read_pickle(savepath+f'{file_name}{suffix}.pkl')\n",
    "        for band, (band_start, band_end) in bands_dict.items():\n",
    "            \n",
    "            all_gc_data_df[f'{band}_aon_to_vhp'] = all_gc_data_df['gc_aon_vhp'].apply(lambda x: get_band_gc(x, band_start, band_end))\n",
    "            all_gc_data_df[f'{band}_vhp_to_aon'] = all_gc_data_df['gc_vhp_aon'].apply(lambda x: get_band_gc(x, band_start, band_end))\n",
    "            \n",
    "        all_gc_data_df=all_gc_data_df.drop(columns=['gc_aon_vhp', 'gc_vhp_aon'])\n",
    "        event_df_melted = pd.melt(all_gc_data_df, id_vars=['experiment', 'rat_id', 'task'], var_name='band', value_name='gc')\n",
    "        split_cols = event_df_melted['band'].str.split('_', n=1, expand=True)\n",
    "        event_df_melted['band'] = split_cols[0]\n",
    "        event_df_melted['direction'] = split_cols[1]\n",
    "        event_df_melted['data_type'] = data_type\n",
    "        col_data = event_df_melted.pop('gc')\n",
    "        event_df_melted['gc'] = col_data        \n",
    "        event_df.append(event_df_melted)\n",
    "        \n",
    "    combined_df = pd.concat(event_df)\n",
    "    combined_df.to_excel(writer, sheet_name = event_name)\n",
    "    combined_df['group'] = combined_df['task'] + '_' + combined_df['data_type']\n",
    "    sns.barplot(\n",
    "    x='band', \n",
    "    y='gc', \n",
    "    hue='group', \n",
    "    data=combined_df, ax=axs[coli])\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NOT USED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gc_data_df = pd.read_pickle(savepath+'gc_around_dig.pkl')\n",
    "\n",
    "for row in all_gc_data_df.itertuples(index=False):\n",
    "    experiment = row.experiment\n",
    "    rat_id = row.rat_id\n",
    "    task = row.task\n",
    "    gc_aon_vhp = row.gc_aon_vhp\n",
    "    gc_vhp_aon = row.gc_vhp_aon\n",
    "    net_gc = gc_aon_vhp - gc_vhp_aon\n",
    "    vmin = min(gc_aon_vhp.min(), gc_vhp_aon.min(), net_gc.min())\n",
    "    vmax = max(gc_aon_vhp.max(), gc_vhp_aon.max(), net_gc.max())\n",
    "    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task}')\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "    fig.suptitle(f'Granger Causality Rat: {rat_id}, Experiment: {experiment}, Task: {task}', fontsize=20)\n",
    "\n",
    "    im = axs[0].imshow(gc_aon_vhp, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title('AON -> vHp')\n",
    "    axs[0].set_xlabel('Time (s)')\n",
    "    axs[0].set_ylabel('Frequency (Hz)')\n",
    "    \n",
    "    axs[1].imshow(gc_vhp_aon, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title('vHp -> AON')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "\n",
    "    axs[2].imshow(net_gc, extent=[-0.7, 0.7, 1, 100], aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[2].set_title('Difference (AON -> vHp) - (vHp -> AON)')\n",
    "    axs[2].set_xlabel('Time (s)')\n",
    "    axs[2].set_ylabel('Frequency (Hz)')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axvline(0, color='k', linestyle='--', linewidth=2)\n",
    "        ax.axhline(12, color='green', linestyle='--')\n",
    "        ax.axhline(30, color='green', linestyle='--')\n",
    "    # Create a common colorbar for all three subplots\n",
    "    # Remove the previous imshow call for axs[2] above, use this one for colorbar\n",
    "    cbar = fig.colorbar(im, ax=axs, orientation='vertical', fraction=0.02)\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(savepath + f'{task}_{rat_id}_{experiment}_gc_around_dig.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_data_df_clean=pd.read_pickle(savepath+'mne_epochs_array_df.pkl')\n",
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "rat_list=np.unique(con_data_df_clean['rat_id'])\n",
    "print(rat_list)\n",
    "all_con_data=[]\n",
    "all_con_data_mean=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "    #print(task_name)\n",
    "    # for rat_num, rat_name in enumerate(rat_list):\n",
    "    #     rat_task_data=task_data[task_data['rat_id']==rat_name]\n",
    "        row=[task_name]\n",
    "    #     #print(row)\n",
    "        row_2=[task_name]\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            aon_vHp_con=[]\n",
    "            for event_epoch in event_epoch_list:\n",
    "                    #print(row,event, event_epoch) \n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/2\n",
    "                    \n",
    "                    ###Specifying the Indices for AON and vHp channels\n",
    "                    aon_signals=[\n",
    "                    idx\n",
    "                    for idx, ch_info in enumerate(event_epoch.info[\"chs\"])\n",
    "                    if \"AON\" in ch_info[\"ch_name\"]\n",
    "                    ]\n",
    "                    print(aon_signals)\n",
    "                    vhp_signals=[\n",
    "                        idx\n",
    "                        for idx, ch_info in enumerate(event_epoch.info[\"chs\"])\n",
    "                        if \"vHp\" in ch_info[\"ch_name\"]\n",
    "                    ]\n",
    "                    print(vhp_signals)\n",
    "\n",
    "                    indices_aon_vhp = (np.array([aon_signals]), np.array([vhp_signals]))\n",
    "                    indices_vhp_aon = (np.array([vhp_signals]), np.array([aon_signals]))      \n",
    "                    gc_ab = mne_connectivity.spectral_connectivity_epochs(event_epoch, method=[\"gc\"], indices=indices_aon_vhp, fmin=2.5, fmax=100, rank=None,gc_n_lags=20)\n",
    "                    gc_ba= mne_connectivity.spectral_connectivity_epochs(event_epoch, method=[\"gc\"], indices=indices_vhp_aon, fmin=2.5, fmax=100, rank=None,gc_n_lags=20)\n",
    "                    net_gc= gc_ab.get_data() - gc_ba.get_data()\n",
    "                    print(net_gc.shape)\n",
    "\n",
    "                    coh = net_gc[0]\n",
    "                    #coh=np.abs(coh)\n",
    "                    print(coh.shape)\n",
    "                    indices = coh.names\n",
    "                    print(indices)\n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                aon_vHp_con.append(coh[i,j,:,:])\n",
    "            row.append(np.mean(aon_vHp_con, axis=0))\n",
    "            row_2.append(np.mean(aon_vHp_con))\n",
    "        all_con_data.append(row)                    \n",
    "        all_con_data_mean.append(row_2)\n",
    "# Convert all_con_data to a DataFrame for easier manipulation\n",
    "all_con_data_df = pd.DataFrame(all_con_data, columns=['task'] + event_list)\n",
    "#all_con_data_df.to_pickle(savepath+'coherence_spectrogram_around_door_dig.pkl')\n",
    "fs=2000\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-2, 2, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[0,i].set_xlabel('')\n",
    "\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\aon_vhp_coherence_event_spectrogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating complex coherence values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Coherence with Quiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "time_window = 1\n",
    "fs=2000\n",
    "#################\n",
    "con_data_df_clean = pd.read_pickle(savepath + f'marked_mne_epochs_array_{int(time_window*fs)}.pkl')\n",
    "#con_data_df_clean=pd.read_pickle(savepath+f'mne_epochs_array_df_shuffled_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_list=['mne_epoch_door_before', 'mne_epoch_dig_before','mne_epoch_dig_after','mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "\n",
    "shuffled = True\n",
    "\n",
    "\n",
    "importlib.reload(lfp_pre_processing_functions)\n",
    "print(event_list)\n",
    "BWcontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWcontext')]\n",
    "BWnocontext_data=con_data_df_clean[(con_data_df_clean['task']=='BWnocontext')]\n",
    "task_data_dict={'BWcontext':BWcontext_data,'BWnocontext':BWnocontext_data}\n",
    "\n",
    "rat_list=np.unique(con_data_df_clean['rat_id'])\n",
    "print(rat_list)\n",
    "all_coh_abs_data=[]\n",
    "all_coh_abs_data_mean=[]\n",
    "all_coh_phase_data=[]\n",
    "all_coh_phase_data_mean=[]\n",
    "ind_rows_df=[]\n",
    "for task_num,task_name in enumerate(task_data_dict.keys()):\n",
    "        task_data=task_data_dict[task_name]\n",
    "    #print(task_name)\n",
    "    # for rat_num, rat_name in enumerate(rat_list):\n",
    "    #     rat_task_data=task_data[task_data['rat_id']==rat_name]\n",
    "        row_coh_abs=[task_name]\n",
    "        row_coh_abs_mean=[task_name]\n",
    "        row_coh_phase=[task_name]\n",
    "        row_coh_phase_mean=[task_name]\n",
    "\n",
    "        for event in event_list:\n",
    "            #print(event)\n",
    "            event_epoch_list=task_data[event]\n",
    "            rat_id_list=task_data['rat_id']\n",
    "            exp_list=task_data['experiment']\n",
    "            \n",
    "            aon_vhp_coh_abs=[]\n",
    "            aon_vhp_coh_phase=[]\n",
    "            for rowi,event_epoch in enumerate(event_epoch_list):\n",
    "                    #print(row,event, event_epoch) \n",
    "                    rat_id=rat_id_list.iloc[rowi]\n",
    "                    experiment=exp_list.iloc[rowi]\n",
    "                    print(f'Processing Rat: {rat_id}, Experiment: {experiment}, Task: {task_name}, Event: {event}')\n",
    "                    fmin=1\n",
    "                    fmax=100\n",
    "                    freqs = np.arange(fmin,fmax)\n",
    "                    n_cycles = freqs/3\n",
    "\n",
    "                    if shuffled:\n",
    "                        event_epoch = lfp_pre_processing_functions.randomize_timepoints(event_epoch)\n",
    "                        suffix = \"_shuffled\"\n",
    "                    else:\n",
    "                        event_epoch=event_epoch\n",
    "                        suffix = \"\"\n",
    "                    con = mne_connectivity.spectral_connectivity_epochs(event_epoch, method='cohy', sfreq=int(fs),\n",
    "                                                         mode='cwt_morlet', cwt_freqs=freqs,\n",
    "                                                         cwt_n_cycles=n_cycles, verbose=False, fmin=1, fmax=100, faverage=False)\n",
    "                    coh = con.get_data(output='dense')\n",
    "                    coh_abs = np.abs(coh)\n",
    "                    coh_phase = np.angle(coh)\n",
    "\n",
    "                    indices = con.names\n",
    "                    print(indices)\n",
    "                    print(coh.shape)\n",
    "                    print(coh_abs.shape)\n",
    "                    print(coh_phase.shape)\n",
    "\n",
    "                    for i in range(coh.shape[0]):\n",
    "                        for j in range(coh.shape[1]):\n",
    "                            if 'AON' in indices[j] and 'vHp' in indices[i]:\n",
    "                                coherence_abs=coh_abs[i,j,:,:]\n",
    "                                coherence_abs=np.arctanh(coherence_abs)  # Apply Fisher transformation\n",
    "                                aon_vhp_coh_abs.append(coherence_abs)\n",
    "                                aon_vhp_coh_phase.append(coh_phase[i,j,:,:])\n",
    "                                ind_row =[rat_id, experiment, task_name, event, f'{indices[j]}-{indices[i]}', coh_phase[i,j,:,:]]\n",
    "\n",
    "                                ind_rows_df.append(ind_row)\n",
    "\n",
    "            row_coh_abs.append(np.mean(aon_vhp_coh_abs, axis=0))\n",
    "            row_coh_abs_mean.append(np.mean(aon_vhp_coh_abs))\n",
    "            row_coh_phase.append(np.mean(aon_vhp_coh_phase, axis=0))\n",
    "            row_coh_phase_mean.append(np.mean(aon_vhp_coh_phase))\n",
    "        all_coh_abs_data.append(row_coh_abs)\n",
    "        all_coh_abs_data_mean.append(row_coh_abs_mean)\n",
    "        all_coh_phase_data.append(row_coh_phase)\n",
    "        all_coh_phase_data_mean.append(row_coh_phase_mean)\n",
    "        \n",
    "ind_rows_df = pd.DataFrame(ind_rows_df, columns=['rat_id', 'experiment', 'task', 'event', 'channel_pair', 'coherence_phase'])\n",
    "\n",
    "\n",
    "ind_rows_df.to_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig{suffix}_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_abs_data_df = pd.DataFrame(all_coh_abs_data, columns=['task'] + event_list)\n",
    "all_coh_abs_data_df.to_pickle(savepath+f'coherence_abs_spectrogram_around_door_dig{suffix}_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df = pd.DataFrame(all_coh_phase_data, columns=['task'] + event_list)\n",
    "all_coh_phase_data_df.to_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig{suffix}_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "fs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = aon_vhp_coh_phase[0]\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 1\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 12\n",
    "fmax = 30\n",
    "tmin = 0.5\n",
    "tmax = 0.9\n",
    "\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "\n",
    "truncated_phase_data_real = all_coh_phase_data_df_real['mne_epoch_around_dig'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "# phase_context = np.array(all_coh_phase_data_df.loc[all_coh_phase_data_df['task'] == 'BWcontext', 'mne_epoch_around_dig'].iloc[0]).flatten()\n",
    "# phase_nocontext = np.array(all_coh_phase_data_df.loc[all_coh_phase_data_df['task'] == 'BWnocontext', 'mne_epoch_around_dig'].iloc[0]).flatten()\n",
    "phase_context = np.array(truncated_phase_data_real[all_coh_phase_data_df_real['task'] == 'BWcontext'].iloc[0]).flatten()\n",
    "phase_nocontext = np.array(truncated_phase_data_real[all_coh_phase_data_df_real['task'] == 'BWnocontext'].iloc[0]).flatten()\n",
    "\n",
    "truncated_phase_data_shuffled = all_coh_phase_data_df_shuffled['mne_epoch_around_dig'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "phase_context_shuffled = np.array(truncated_phase_data_shuffled[all_coh_phase_data_df_shuffled['task'] == 'BWcontext'].iloc[0]).flatten()\n",
    "phase_nocontext_shuffled = np.array(truncated_phase_data_shuffled[all_coh_phase_data_df_shuffled['task'] == 'BWnocontext'].iloc[0]).flatten()\n",
    "\n",
    "# Convert phase to [0, 2pi]\n",
    "phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "phase_context_shuffled = np.mod(phase_context_shuffled, 2 * np.pi)\n",
    "phase_nocontext_shuffled = np.mod(phase_nocontext_shuffled, 2 * np.pi)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, subplot_kw={'projection': 'polar'}, figsize=(12, 6))\n",
    "axs=axs.flatten()\n",
    "colors = {'BWcontext': 'blue', 'BWnocontext': 'orange'}\n",
    "\n",
    "# Plot BW Context\n",
    "axs[0].hist(phase_context, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "axs[0].set_title('Phase Difference Histogram\\nBW Context', fontsize=16)\n",
    "axs[0].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[0].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "# Plot BW No Context\n",
    "axs[1].hist(phase_nocontext, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "axs[1].set_title('Phase Difference Histogram\\nBW No Context', fontsize=16)\n",
    "axs[1].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[1].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "axs[2].hist(phase_context_shuffled, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "axs[2].set_title('Phase Difference Histogram (Shuffled)\\nBW Context', fontsize=16)\n",
    "axs[2].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[2].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "axs[3].hist(phase_nocontext_shuffled, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "axs[3].set_title('Phase Difference Histogram (Shuffled)\\nBW No Context', fontsize=16)\n",
    "axs[3].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "axs[3].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(savepath+f'coherence_phase_histogram_around_dig_truncated_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "# Use the Kolmogorov-Smirnov test to compare the two phase distributions\n",
    "ks_stat, p_value = ks_2samp(phase_context, phase_nocontext)\n",
    "print(f\"KS statistic: {ks_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the phase distributions of the two tasks.\")\n",
    "else:\n",
    "    print(\"No significant difference between the phase distributions of the two tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the polar plot but without averaging across experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 1\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 30 \n",
    "fmax = 80\n",
    "tmin = 0.4\n",
    "tmax = 0.7\n",
    "\n",
    "\n",
    "# all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "# all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "writer = pd.ExcelWriter(savepath+f'coherence_phase_analysis_around_door_dig_truncated_{int(time_window*fs)}.xlsx')\n",
    "bands_dict = {\n",
    "    'Theta': (4, 8),\n",
    "    'Beta': (12, 30),\n",
    "    'Gamma': (30, 80)\n",
    "}\n",
    "\n",
    "for band_name, (fmin, fmax) in bands_dict.items():\n",
    "    all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "    all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "    all_coh_phase_data_df_real['coherence_phase'] = all_coh_phase_data_df_real['coherence_phase'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "    all_coh_phase_data_df_real['coherence_phase'] = all_coh_phase_data_df_real['coherence_phase'].apply(lambda x: x.flatten())  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "\n",
    "    bw_context_data = all_coh_phase_data_df_real[(all_coh_phase_data_df_real['task'] == 'BWcontext') & (all_coh_phase_data_df_real['event']=='mne_epoch_around_dig')]\n",
    "    phase_context = np.array([value for lst in bw_context_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "    bw_nocontext_data = all_coh_phase_data_df_real[(all_coh_phase_data_df_real['task'] == 'BWnocontext') & (all_coh_phase_data_df_real['event']=='mne_epoch_around_dig')]\n",
    "    phase_nocontext = np.array([value for lst in bw_nocontext_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    all_coh_phase_data_df_shuffled['coherence_phase'] = all_coh_phase_data_df_shuffled['coherence_phase'].apply(lambda x: x[fmin:fmax, int(tmin*fs):int(tmax*fs)])  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "    all_coh_phase_data_df_shuffled['coherence_phase'] = all_coh_phase_data_df_shuffled['coherence_phase'].apply(lambda x: x.flatten())  # Theta band (8-12 Hz) and time window (0 to 0.4s)\n",
    "    bw_context_data_shuffled = all_coh_phase_data_df_shuffled[(all_coh_phase_data_df_shuffled['task'] == 'BWcontext') & (all_coh_phase_data_df_shuffled['event']=='mne_epoch_around_dig')]\n",
    "    phase_context_shuffled = np.array([value for lst in bw_context_data_shuffled['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    bw_nocontext_data_shuffled = all_coh_phase_data_df_shuffled[(all_coh_phase_data_df_shuffled['task'] == 'BWnocontext') & (all_coh_phase_data_df_shuffled['event']=='mne_epoch_around_dig')]\n",
    "    phase_nocontext_shuffled = np.array([value for lst in bw_nocontext_data_shuffled['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "\n",
    "    # Convert phase to [0, 2pi]\n",
    "    phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "    phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "    phase_context_shuffled = np.mod(phase_context_shuffled, 2 * np.pi)\n",
    "    phase_nocontext_shuffled = np.mod(phase_nocontext_shuffled, 2 * np.pi)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, subplot_kw={'projection': 'polar'}, figsize=(12, 6))\n",
    "    fig.suptitle('Coherence Phase Freq - {}-{} Hz, Time - {}-{} s'.format(fmin, fmax, tmin, tmax), fontsize=16)\n",
    "    axs=axs.flatten()\n",
    "    colors = {'BWcontext': 'black', 'BWnocontext': 'grey'}\n",
    "\n",
    "    # Plot BW Context\n",
    "    axs[0].hist(phase_context, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[0].set_title('Context', fontsize=16)\n",
    "    axs[0].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[0].set_xlim(0, 2 * np.pi)\n",
    "    counts, edges = np.histogram(phase_context, bins=100, range=(0, 2*np.pi))\n",
    "\n",
    "    # 5. Get bin centers\n",
    "    # This is the Python/NumPy way to find the midpoint of each bin\n",
    "    locs = (edges[:-1] + edges[1:]) / 2\n",
    "    closed_locs = np.append(locs, locs[0])\n",
    "    closed_counts = np.append(counts, counts[0])\n",
    "    # 6. Plot the line (MATLAB: plot(locs, counts, 'LineWidth', 3);)\n",
    "    axs[0].plot(closed_locs, closed_counts, 'black', linewidth=1, label='Bin Centers Line') # 'r-' adds color\n",
    "\n",
    "    # Plot BW No Context\n",
    "    axs[1].hist(phase_nocontext, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[1].set_title('No Context', fontsize=16)\n",
    "    axs[1].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[1].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "    axs[2].hist(phase_context_shuffled, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[2].set_title('Context(Shuffled)', fontsize=16)\n",
    "    axs[2].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[2].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "    axs[3].hist(phase_nocontext_shuffled, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[3].set_title('No Context(Shuffled)', fontsize=16)\n",
    "    axs[3].set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "    axs[3].set_xlim(0, 2 * np.pi)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'coherence_phase_polarhist_around_dig_{fmin}_{fmax}_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "\n",
    "    #########Plotting in a simple histogram##########\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    axs=axs.flatten()\n",
    "    fig.suptitle('Coherence Phase Freq - {}-{} Hz, Time - {}-{} s'.format(fmin, fmax, tmin, tmax), fontsize=16)\n",
    "    colors = {'BWcontext': 'black', 'BWnocontext': 'grey'}\n",
    "\n",
    "    # Convert phase values from [0, 2π] to [-π, π]\n",
    "    phase_context_centered = np.where(phase_context > np.pi, phase_context - 2*np.pi, phase_context)\n",
    "    phase_nocontext_centered = np.where(phase_nocontext > np.pi, phase_nocontext - 2*np.pi, phase_nocontext)\n",
    "    phase_context_shuffled_centered = np.where(phase_context_shuffled > np.pi, phase_context_shuffled - 2*np.pi, phase_context_shuffled)\n",
    "    phase_nocontext_shuffled_centered = np.where(phase_nocontext_shuffled > np.pi, phase_nocontext_shuffled - 2*np.pi, phase_nocontext_shuffled)\n",
    "\n",
    "    # Plotting the histograms with centered x-axis\n",
    "    axs[0].hist(phase_context_centered, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[0].set_title('Context', fontsize=16)\n",
    "    axs[0].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[0].set_xticklabels(['-π', '-2π/3', '-π/3', '0', 'π/3', '2π/3', 'π'])\n",
    "    axs[0].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[1].hist(phase_nocontext_centered, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[1].set_title('No Context', fontsize=16)\n",
    "    axs[1].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[1].set_xticklabels(['-π', '-2π/3', '-π/3', '0', 'π/3', '2π/3', 'π'])\n",
    "    axs[1].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[2].hist(phase_context_shuffled_centered, bins=100, density=True, color=colors['BWcontext'], alpha=0.7)\n",
    "    axs[2].set_title('Context(Shuffled)', fontsize=16)\n",
    "    axs[2].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[2].set_xticklabels(['-π', '-2π/3', '-π/3', '0', 'π/3', '2π/3', 'π'])\n",
    "    axs[2].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    axs[3].hist(phase_nocontext_shuffled_centered, bins=100, density=True, color=colors['BWnocontext'], alpha=0.7)\n",
    "    axs[3].set_title('No Context(Shuffled)', fontsize=16)\n",
    "    axs[3].set_xticks(np.linspace(-np.pi, np.pi, 7))\n",
    "    axs[3].set_xticklabels(['-π', '-2π/3', '-π/3', '0', 'π/3', '2π/3', 'π'])\n",
    "    axs[3].set_xlim(-np.pi, np.pi)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savepath+f'coherence_phase_histogram_around_dig_{fmin}_{fmax}_{int(time_window*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Statistical test for difference in phase distributions between tasks\n",
    "\n",
    "    data_dict = {'context_real': phase_context,\n",
    "                 'nocontext_real': phase_nocontext,\n",
    "                 'context_shuffled': phase_context_shuffled,\n",
    "                 'nocontext_shuffled': phase_nocontext_shuffled}\n",
    "    df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data_dict.items()]))\n",
    "    df.to_excel(writer, sheet_name=f'{band_name}_phase_data', index=False)\n",
    "writer.close()\n",
    "\n",
    "ks_stat, p_value = ks_2samp(phase_context, phase_nocontext)\n",
    "print(f\"KS statistic: {ks_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the phase distributions of the two tasks.\")\n",
    "else:\n",
    "    print(\"No significant difference between the phase distributions of the two tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making polar plots with Context and No Context in single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 1\n",
    "fs=2000\n",
    "\n",
    "\n",
    "fmin = 30 \n",
    "fmax = 80\n",
    "tmin = 0.4\n",
    "tmax = 0.7\n",
    "\n",
    "\n",
    "# all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "# all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_spectrogram_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "all_coh_phase_data_df_shuffled=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "all_coh_phase_data_df_real=pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract phase data for each condition\n",
    "writer = pd.ExcelWriter(savepath+f'coherence_phase_analysis_around_door_dig_truncated_{int(time_window*fs)}.xlsx')\n",
    "bands_dict = {\n",
    "    'Theta': (4, 8),\n",
    "    'Beta': (12, 30),\n",
    "    'Gamma': (30, 80)\n",
    "}\n",
    "\n",
    "tmin = 0\n",
    "tmax = 1\n",
    "\n",
    "tmin_idx = int(tmin * fs)\n",
    "tmax_idx = int(tmax * fs)\n",
    "\n",
    "events_dict = {\n",
    "'mne_epoch_door_before': 'Door Before',\n",
    "'mne_epoch_dig_before': 'Dig Before',\n",
    "'mne_epoch_dig_after': 'Dig After',\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(3,3, subplot_kw={'projection': 'polar'}, figsize=(18, 12))\n",
    "\n",
    "for axi_row,(band_name, (fmin, fmax)) in enumerate(bands_dict.items()):\n",
    "\n",
    "    for axi_col,(event_key, event_name) in enumerate(events_dict.items()):\n",
    "\n",
    "        for data_type in ['real', 'shuffled']:\n",
    "            if data_type == 'real':\n",
    "                all_coh_phase_data_df = pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_truncated_{int(time_window*fs)}.pkl')\n",
    "                linestyle = 'solid'  \n",
    "            else:\n",
    "                all_coh_phase_data_df = pd.read_pickle(savepath+f'coherence_phase_individual_epochs_around_door_dig_shuffled_truncated_{int(time_window*fs)}.pkl')\n",
    "                linestyle = 'dashed'\n",
    "            print(f'{axi_row} {axi_col} Processing Band: {band_name}, Event: {event_name}, Data Type: {data_type}')\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            all_coh_phase_data_df['coherence_phase'] = all_coh_phase_data_df['coherence_phase'].apply(lambda x: x[fmin:fmax, tmin_idx:tmax_idx])\n",
    "            all_coh_phase_data_df['coherence_phase'] = all_coh_phase_data_df['coherence_phase'].apply(lambda x: x.flatten())  \n",
    "\n",
    "            bw_context_data = all_coh_phase_data_df[(all_coh_phase_data_df['task'] == 'BWcontext') & (all_coh_phase_data_df['event']==event_key)]\n",
    "            phase_context = np.array([value for lst in bw_context_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "            bw_nocontext_data = all_coh_phase_data_df[(all_coh_phase_data_df['task'] == 'BWnocontext') & (all_coh_phase_data_df['event']==event_key)]\n",
    "            phase_nocontext = np.array([value for lst in bw_nocontext_data['coherence_phase'] for value in lst]).flatten()\n",
    "\n",
    "            # Convert phase to [0, 2pi]\n",
    "            phase_context = np.mod(phase_context, 2 * np.pi)\n",
    "            phase_nocontext = np.mod(phase_nocontext, 2 * np.pi)\n",
    "\n",
    "            ax = axs[axi_row, axi_col]    \n",
    "            \n",
    "            counts, edges = np.histogram(phase_context, bins=100, range=(0, 2*np.pi), density=True)\n",
    "            locs = (edges[:-1] + edges[1:]) / 2\n",
    "            closed_locs = np.append(locs, locs[0])\n",
    "            closed_counts = np.append(counts, counts[0])\n",
    "            ax.fill(closed_locs, closed_counts, color='blue', alpha=0.3)  # Fill the area with black color\n",
    "            ax.plot(closed_locs, closed_counts, 'blue', linewidth=1, label=f'Context ({data_type})', linestyle=linestyle) # 'r-' adds color\n",
    "\n",
    "            counts, edges = np.histogram(phase_nocontext, bins=100, range=(0, 2*np.pi), density=True)\n",
    "            locs = (edges[:-1] + edges[1:]) / 2\n",
    "            closed_locs = np.append(locs, locs[0])\n",
    "            closed_counts = np.append(counts, counts[0])\n",
    "            ax.fill(closed_locs, closed_counts, color='orange', alpha=0.3)  # Fill the area with grey color\n",
    "            ax.plot(closed_locs, closed_counts, 'orange', linewidth=1, label=f'No Context ({data_type})', linestyle=linestyle)  #ax.set_xticks(np.linspace(0, 2 * np.pi, 8, endpoint=False))\n",
    "            ax.set_xlim(0, 2 * np.pi)\n",
    "            ax.set_rticks([])  # Remove radial ticks for clarity\n",
    "            # if axi_row == 0 and axi_col == 0:\n",
    "            #     ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "            ax.set_title(f'{band_name} Band - {event_name}', fontsize=12)\n",
    "            #ax.set_rmax(0.5)  # Set maximum radius for better visualization\n",
    "# Create custom labels that combine color, style and condition\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color='blue', linestyle='solid', label='Context (real)'),\n",
    "    plt.Line2D([0], [0], color='blue', linestyle='dashed', label='Context (shuffled)'),\n",
    "    plt.Line2D([0], [0], color='orange', linestyle='solid', label='No Context (real)'),\n",
    "    plt.Line2D([0], [0], color='orange', linestyle='dashed', label='No Context (shuffled)')\n",
    "]\n",
    "\n",
    "# Add legend at the bottom\n",
    "fig.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, 0), \n",
    "          ncol=4, fontsize=12)\n",
    "\n",
    "# Adjust subplot spacing to make room for legend\n",
    "plt.subplots_adjust(bottom=0.12)\n",
    "fig.suptitle(f'Coherence Phase Analysis {tmin}s-{tmax}s', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(savepath+f'coherence_phase_polarhist_all_events_{int(tmin*fs)}-{int(tmax*fs)}.png', dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_list=['mne_epoch_around_door','mne_epoch_around_dig']\n",
    "fs=2000\n",
    "times=np.arange(-0.7, 0.7, 1/fs)\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10), sharey=True)\n",
    "all_con_data_df=all_coh_abs_data_df\n",
    "aon_vhp_phase=all_coh_phase_data_df\n",
    "vmin = all_con_data_df[event_list].applymap(np.min).min().min()\n",
    "vmax = all_con_data_df[event_list].applymap(np.max).max().max()\n",
    "event_names=['Around Door','Around Dig']\n",
    "freqs=np.arange(2.5, 100, 0.5)\n",
    "for i, event in enumerate(event_list):\n",
    "    axs[0,i].imshow(all_con_data_df[event][0], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    coh_phase = aon_vhp_phase[event][0]\n",
    "    X, Y = np.meshgrid(np.linspace(times[0], times[-1], coh_phase.shape[1]), np.linspace(freqs[0], freqs[-1], coh_phase.shape[0]))\n",
    "\n",
    "    U = np.cos(coh_phase)\n",
    "    V = np.sin(coh_phase)\n",
    "    f_x = 100\n",
    "    f_y = 5\n",
    "    axs[0, i].quiver(X[2::f_y, ::f_x], Y[2::f_y, ::f_x], U[2::f_y, ::f_x], V[2::f_y, ::f_x], angles='uv', scale=40, alpha=0.7)\n",
    "\n",
    "    axs[0,i].set_xlabel('')\n",
    "\n",
    "    axs[0,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[0,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[0,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    \n",
    "    axs[1,i].imshow(all_con_data_df[event][1], extent=[times[0], times[-1], 1, 100],\n",
    "                   aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    coh_phase = aon_vhp_phase[event][1]\n",
    "    X, Y = np.meshgrid(np.linspace(times[0], times[-1], coh_phase.shape[1]), np.linspace(freqs[0], freqs[-1], coh_phase.shape[0]))\n",
    "\n",
    "    U = np.cos(coh_phase)\n",
    "    V = np.sin(coh_phase)\n",
    "    f_x = 100\n",
    "    f_y = 5\n",
    "    axs[1, i].quiver(X[2::f_y, ::f_x], Y[2::f_y, ::f_x], U[2::f_y, ::f_x], V[2::f_y, ::f_x], angles='uv', scale=40, alpha=0.7)\n",
    "\n",
    "    \n",
    "    axs[1,i].set_xlabel('Time (s)', fontsize=20)\n",
    "    axs[1,i].set_ylabel('Frequency (Hz)', fontsize=20)\n",
    "    axs[1,i].set_title(event_names[i], fontsize=20)\n",
    "    axs[1,i].vlines(0, 0, 100, color='k', linestyle='--')\n",
    "\n",
    "    axs[0,0].text(-0.2, 0.5, 'Context', transform=axs[0,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[1,0].text(-0.2, 0.5, 'No Context', transform=axs[1,0].transAxes, fontsize=18, verticalalignment='center', rotation=90)\n",
    "    axs[0,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axs[1,i].tick_params(axis='both', which='major', labelsize=20)\n",
    "    # axs[0,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[0,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticks(np.arange(-2, 3, 1))  # Set x-ticks from -2 to 2 seconds\n",
    "    # axs[1,i].set_xticklabels(np.arange(-2, 3, 1))  # Set x-tick labels from -2 to 2 seconds\n",
    "\n",
    "    # Add a colorbar\n",
    "cbar = fig.colorbar(axs[0,0].images[0], ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Coherence (Z-transformed)', loc='center', fontsize=20, labelpad=10)\n",
    "cbar.ax.tick_params(labelsize=20)  # Set colorbar tick label size\n",
    "\n",
    "fig.savefig(savepath+'aon_vhp_coherogram.png',format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Behavior Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Behavior Correlation with Power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_df=pd.read_pickle(savepath+'compiled_data_all_epochs.pkl')\n",
    "behavior_df.iloc[:,-5:]=behavior_df.iloc[:,-5:].applymap(lambda x: scipy.signal.welch(x, fs=2000, nperseg=2000)[1])\n",
    "\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80], 'theta': [4, 12], 'total': [1, 100]}\n",
    "for col in behavior_df.columns[-7:]:\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        behavior_df[band + '_' + col] = behavior_df[col].apply(lambda x: functions.get_band_power(x, band_start, band_end))\n",
    "\n",
    "behavior_df['channel'] = behavior_df['channel'].apply(lambda x: 'AON' if 'AON' in x else 'vHp')\n",
    "\n",
    "behavior_df_grouped=behavior_df.groupby(['task', 'channel'])\n",
    "writer=pd.ExcelWriter(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_power_correlation.xlsx')\n",
    "for (task, channel), group in behavior_df_grouped:\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "    axs = axs.flatten()\n",
    "    group=behavior_df[(behavior_df['channel']==channel) & (behavior_df['task']==task)]\n",
    "\n",
    "    power_columns=group.columns[17:]\n",
    "    print(power_columns)\n",
    "    group_melted=pd.melt(group, id_vars=['rat', 'task', 'channel', 'correct?'], value_vars=power_columns, var_name='band_event', value_name='power')\n",
    "    group_melted['band']=group_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "    group_melted['event']=group_melted['band_event'].apply(lambda x: x.split('_')[1:])\n",
    "    group_melted['event']=group_melted['event'].apply(lambda x: x[0]+'_'+x[1])\n",
    "    group_melted['correct?']=group_melted['correct?'].apply(lambda x: 'Incorrect' if x=='0' else 'Correct')\n",
    "    \n",
    "    group_melted.to_excel(writer, sheet_name=f'{channel}_{task}')\n",
    "\n",
    "\n",
    "    correct_counts = group_melted[group_melted['correct?'] == 'Correct'].shape[0]\n",
    "    incorrect_counts = group_melted[group_melted['correct?'] == 'Incorrect'].shape[0]\n",
    "    print(f\"Number of Corrects: {correct_counts}\")\n",
    "    print(f\"Number of Incorrects: {incorrect_counts}\")\n",
    "    events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "    for i, event in enumerate(events_list):\n",
    "        ax=axs[i]\n",
    "        sns.boxplot(x='band', y='power', hue='correct?', data=group_melted[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "        #sns.stripplot(x='band', y='power', hue='correct?', data=aon_behavior_df_melted[aon_behavior_df_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax)\n",
    "        ax.set_title(event)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Power')\n",
    "        ax.legend(title='Correct?')\n",
    "    fig.suptitle(f'{channel} {task}')\n",
    "    fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_power_{channel}_{task}.png')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Behavior Correlation with Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "time_window=  1\n",
    "fs=2000\n",
    "behavior_coherence_df=pd.read_pickle(savepath+f'compiled_data_all_epochs_truncated_{int(time_window*fs)}.pkl')\n",
    "behavior_coherence_df_marked=pd.read_pickle(savepath+f'marked_mne_epochs_array_df_truncated_2000_251125.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "behavior_coherence_df['unique_id']=behavior_coherence_df['rat']+'_'+behavior_coherence_df['task']+behavior_coherence_df['date']\n",
    "behavior_coherence_df_grouped=behavior_coherence_df.groupby(['unique_id', 'trial'])\n",
    "behavior_coherence_compiled_data_df=[]\n",
    "\n",
    "for (unique_id, trial), group in behavior_coherence_df_grouped:\n",
    "    print(unique_id, trial)\n",
    "    channels_list=list(group['channel'].unique())\n",
    "    print(channels_list)\n",
    "    info=mne.create_info(ch_names=channels_list, sfreq=fs, ch_types='eeg')\n",
    "\n",
    "    mne_epoch_door_before=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_door_after=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_dig_before=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_dig_after=np.zeros((1,len(channels_list),int(time_window*fs)))\n",
    "    mne_epoch_around_door=np.zeros((1,len(channels_list),int(time_window*fs)*2))\n",
    "    mne_epoch_around_dig=np.zeros((1,len(channels_list),int(time_window*fs)*2))\n",
    "\n",
    "    for channel_num, channel_id in enumerate(channels_list):\n",
    "        data=group[group['channel']==channel_id]\n",
    "        mne_epoch_door_before[0,channel_num,:]=data['pre_door'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_door_after[0,channel_num,:]=data['post_door'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_dig_before[0,channel_num,:]=data['pre_dig'].values[0][:int(time_window*fs)]\n",
    "        mne_epoch_dig_after[0,channel_num,:]=data['post_dig'].values[0][:int(time_window*fs)]\n",
    "        mid_point = int(len(data['around_door'].values[0])/2)\n",
    "        mne_epoch_around_door[0,channel_num,:]=data['around_door'].values[0][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]\n",
    "        mne_epoch_around_dig[0,channel_num,:]=data['around_dig'].values[0][mid_point-int(time_window*fs):mid_point+int(time_window*fs)]\n",
    "\n",
    "    # mne_epoch_around_door_truncated = mne_epoch_around_door[:, :, 3000:5000]\n",
    "    # mne_epoch_around_dig_truncated = mne_epoch_around_dig[:, :, 3000:5000]\n",
    "    mne_epoch_door_before = mne.EpochsArray(mne_epoch_door_before, info)\n",
    "    mne_epoch_door_after= mne.EpochsArray(mne_epoch_door_after, info)\n",
    "    mne_epoch_dig_before = mne.EpochsArray(mne_epoch_dig_before, info)\n",
    "    mne_epoch_dig_after = mne.EpochsArray(mne_epoch_dig_after, info)\n",
    "    mne_epoch_around_door = mne.EpochsArray(mne_epoch_around_door, info)\n",
    "    mne_epoch_around_dig = mne.EpochsArray(mne_epoch_around_dig, info)\n",
    "    \n",
    "    behavior_coherence_compiled_data={\n",
    "        'rat': group['rat'].values[0],\n",
    "        'task': group['task'].values[0],\n",
    "        'date': group['date'].values[0],\n",
    "        'unique_id': unique_id,\n",
    "        'trial': trial,\n",
    "        'side': group['side'].values[0],\n",
    "        'correct?': group['correct'].values[0],\n",
    "        'time_to_dig': group['timestamps'].iloc[0][1] - group['timestamps'].iloc[0][0],\n",
    "        'pre_door': mne_epoch_door_before,\n",
    "        'post_door': mne_epoch_door_after,\n",
    "        'pre_dig': mne_epoch_dig_before,\n",
    "        'post_dig': mne_epoch_dig_after,\n",
    "        'around_door': mne_epoch_around_door,\n",
    "        'around_dig': mne_epoch_around_dig\n",
    "        ,'around_door_truncated': mne_epoch_around_door,\n",
    "        'around_dig_truncated': mne_epoch_around_dig}\n",
    "    \n",
    "    behavior_coherence_compiled_data_df.append(behavior_coherence_compiled_data)\n",
    "behavior_coherence_compiled_data_df=pd.DataFrame(behavior_coherence_compiled_data_df)\n",
    "behavior_coherence_compiled_data_df.to_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "# def lfp_to_mne_epoch(lfp_data):\n",
    "#     fs=2000\n",
    "#     freqs = np.arange(1,100)\n",
    "#     n_cycles = freqs/2\n",
    "#     empty_array=np.zeros((1,1,len(lfp_data)))\n",
    "#     empty_array[0,0,:]=lfp_data\n",
    "#     info = mne.create_info(ch_names=['1'], sfreq=fs, ch_types='eeg')\n",
    "#     mne_epoch = mne.EpochsArray(empty_array, info)\n",
    "#     return mne_epoch\n",
    "\n",
    "# behavior_coherence_df[['pre_door','post_door', 'pre_dig', 'post_dig']]=behavior_coherence_df[['pre_door','post_door', 'pre_dig', 'post_dig']].applymap(lambda x: lfp_to_mne_epoch(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "time_window=  1\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "print(behavior_coherence_compiled_data_df_truncated.columns)\n",
    "common_cols = ['rat', 'task', 'date', 'unique_id', 'trial', 'side', 'correct?','time_to_dig']\n",
    "\n",
    "pre_door_df = behavior_coherence_compiled_data_df_truncated[common_cols+['pre_door']]\n",
    "pre_dig_df = behavior_coherence_compiled_data_df_truncated[common_cols+['pre_dig']]\n",
    "post_dig_df = behavior_coherence_compiled_data_df_truncated[common_cols+['post_dig']]\n",
    "\n",
    "annotated_file = pd.read_csv(savepath+'con_data_df_annotation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of bad epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bad_pre_door =0\n",
    "total_bad_pre_dig =0\n",
    "total_bad_post_dig =0\n",
    "\n",
    "for index, row in annotated_file.iterrows():\n",
    "    door_before_bad_epochs = len(json.loads(row['annotation_door_before']))\n",
    "    dig_before_bad_epochs = len(json.loads(row['annotation_dig_before']))\n",
    "    dig_after_bad_epochs = len(json.loads(row['annotation_dig_after']))\n",
    "    \n",
    "    total_bad_pre_door = total_bad_pre_door + door_before_bad_epochs \n",
    "    total_bad_pre_dig = total_bad_pre_dig + dig_before_bad_epochs\n",
    "    total_bad_post_dig  =   total_bad_post_dig + dig_after_bad_epochs\n",
    "\n",
    "print(total_bad_pre_door)\n",
    "print(total_bad_pre_dig)\n",
    "print(total_bad_post_dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_door_df_filtered = []\n",
    "pre_dig_df_filtered = []\n",
    "post_dig_df_filtered = []\n",
    "# Iterate over rows using iterrows()\n",
    "\n",
    "\n",
    "\n",
    "for index, row in annotated_file.iterrows():\n",
    "    print(index)\n",
    "    unique_id = f\"{row['rat_id']}_{row['task']}{row['date']}\"\n",
    "    print(unique_id)\n",
    "    pre_door_exp_df = pre_door_df[pre_door_df['unique_id']==unique_id]\n",
    "    pre_dig_exp_df = pre_dig_df[pre_dig_df['unique_id']==unique_id]\n",
    "    post_dig_exp_df = post_dig_df[post_dig_df['unique_id']==unique_id]\n",
    "    \n",
    "    door_before_bad_epochs = json.loads(row['annotation_door_before'])\n",
    "    dig_before_bad_epochs = json.loads(row['annotation_dig_before'])\n",
    "    dig_after_bad_epochs = json.loads(row['annotation_dig_after'])\n",
    "    \n",
    "    pre_door_exp_df_filtered = pre_door_exp_df[~pre_door_exp_df['trial'].isin(door_before_bad_epochs)]\n",
    "    pre_dig_exp_df_filtered = pre_dig_exp_df[~pre_dig_exp_df['trial'].isin(dig_before_bad_epochs)]\n",
    "    post_dig_exp_df_filtered = post_dig_exp_df[~post_dig_exp_df['trial'].isin(dig_after_bad_epochs)]\n",
    "    \n",
    "    pre_door_df_filtered.append(pre_door_exp_df_filtered)\n",
    "    pre_dig_df_filtered.append(pre_dig_exp_df_filtered)\n",
    "    post_dig_df_filtered.append(post_dig_exp_df_filtered)\n",
    "\n",
    "    \n",
    "pre_door_df_filtered=pd.concat(pre_door_df_filtered).reset_index(drop=True)\n",
    "pre_dig_df_filtered=pd.concat(pre_dig_df_filtered).reset_index(drop=True)\n",
    "post_dig_df_filtered=pd.concat(post_dig_df_filtered).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "importlib.reload(power_functions)\n",
    "bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12],'theta+beta':[4,30] ,'total': [1, 100]}\n",
    "for band, (band_start, band_end) in bands_dict.items():\n",
    "    pre_door_df_filtered[band + '_' + 'pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    pre_dig_df_filtered[band + '_' + 'pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    post_dig_df_filtered[band + '_' + 'post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "\n",
    "    pre_door_df_filtered[band + '_' + 'pli_pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: coherence_functions.convert_epoch_to_pli_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    pre_dig_df_filtered[band + '_' + 'pli_pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: coherence_functions.convert_epoch_to_pli_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    post_dig_df_filtered[band + '_' + 'pli_post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: coherence_functions.convert_epoch_to_pli_behavior(x, band_start=band_start, band_end=band_end))\n",
    "\n",
    "    pre_door_df_filtered[band + '_' + 'plv_pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: coherence_functions.convert_epoch_to_plv_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    pre_dig_df_filtered[band + '_' + 'plv_pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: coherence_functions.convert_epoch_to_plv_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    post_dig_df_filtered[band + '_' + 'plv_post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: coherence_functions.convert_epoch_to_plv_behavior(x, band_start=band_start, band_end=band_end))\n",
    "\n",
    "    pre_door_df_filtered[band + '_' + 'aon_power_pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"AON\"))\n",
    "    pre_dig_df_filtered[band + '_' + 'aon_power_pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"AON\"))\n",
    "    post_dig_df_filtered[band + '_' + 'aon_power_post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"AON\"))\n",
    "\n",
    "    pre_door_df_filtered[band + '_' + 'vhp_power_pre_door'] = pre_door_df_filtered['pre_door'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"vHp\"))\n",
    "    pre_dig_df_filtered[band + '_' + 'vhp_power_pre_dig'] = pre_dig_df_filtered['pre_dig'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"vHp\"))\n",
    "    post_dig_df_filtered[band + '_' + 'vhp_power_post_dig'] = post_dig_df_filtered['post_dig'].apply(lambda x: power_functions.convert_epoch_to_power(x, band_start=band_start, band_end=band_end, brain_area=\"vHp\"))\n",
    "\n",
    "pre_door_df_filtered.to_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered.to_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered.to_pickle(savepath + 'coh_beh_post_dig_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_door_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_post_dig_df.pkl')\n",
    "\n",
    "pre_door_df_filtered=pre_door_df_filtered.drop('pre_door', axis=1)\n",
    "pre_dig_df_filtered=pre_dig_df_filtered.drop('pre_dig', axis=1)\n",
    "post_dig_df_filtered=post_dig_df_filtered.drop('post_dig', axis=1)\n",
    "\n",
    "pre_door_df_filtered.to_csv(savepath + 'coh_beh_pre_door_1000ms.csv')\n",
    "pre_dig_df_filtered.to_csv(savepath + 'coh_beh_pre_dig_1000ms.csv')\n",
    "post_dig_df_filtered.to_csv(savepath + 'coh_beh_post_dig_1000ms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "pre_door_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_door_df.pkl')\n",
    "pre_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_pre_dig_df.pkl')\n",
    "post_dig_df_filtered=pd.read_pickle(savepath + 'coh_beh_post_dig_df.pkl')\n",
    "\n",
    "band = 'beta'\n",
    "event_of_interest = 'pre_dig'\n",
    "\n",
    "event_band = f'{band}_{event_of_interest}'\n",
    "\n",
    "\n",
    "task_experiments = pre_dig_df_filtered.groupby(['task','unique_id'])\n",
    "task_list= pre_dig_df_filtered['task'].unique()\n",
    "print(task_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for task in task_list:\n",
    "    task_data  = pre_dig_df_filtered[pre_dig_df_filtered['task']==task]\n",
    "    ax.scatter(task_data['time_to_dig'], task_data[event_band], label = task)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for task in task_list:\n",
    "    task_data = pre_dig_df_filtered[pre_dig_df_filtered['task'] == task]\n",
    "    unique_experiments = task_data['unique_id'].unique()\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(20, 20))\n",
    "    fig.suptitle(f'{task} - Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "    dk1_i=0\n",
    "    dk3_i=0\n",
    "    dk5_i=0\n",
    "    dk6_i=0\n",
    "    for experiment in unique_experiments:\n",
    "        print(task, experiment)    \n",
    "        task_exp_data =  task_data[task_data['unique_id'] == experiment]\n",
    "        time_to_dig = task_exp_data['time_to_dig']\n",
    "        coherence_value = task_exp_data[event_band]\n",
    "        \n",
    "        rat_id = task_exp_data['rat'].values[0]\n",
    "        if rat_id == 'dk1':\n",
    "            ax = axs[0, dk1_i]\n",
    "            dk1_i += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax = axs[1, dk3_i]\n",
    "            dk3_i += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax = axs[2, dk5_i]\n",
    "            dk5_i += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax = axs[3, dk6_i]\n",
    "            dk6_i += 1\n",
    "        else:\n",
    "            continue  # Skip if rat_id is not one of the specified rats\n",
    "        ax.scatter(time_to_dig, coherence_value, label=experiment)\n",
    "        \n",
    "        ## Plotting Regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(time_to_dig, coherence_value)\n",
    "        ax.plot(time_to_dig, intercept + slope * time_to_dig, color='red', label=f'Fit: y={slope:.2f}x+{intercept:.2f}\\nR²={r_value**2:.2f}, p={p_value:.4f}')\n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "                \n",
    "        \n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing multivariate regression with mixed effects model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pre_dig_df_filtered\n",
    "\n",
    "context_data = data[data['task']=='BWcontext']\n",
    "nocontext_data = data[data['task']=='BWnocontext']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import sys\n",
    "!c:\\Users\\sinha\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "context_data_clean = context_data.copy()\n",
    "\n",
    "# Log transform the outcome\n",
    "context_data_clean['log_time_to_dig'] = np.log(context_data_clean['time_to_dig'])\n",
    "\n",
    "# Rename problematic column names for theta+beta band\n",
    "context_data_clean = context_data_clean.rename(columns={\n",
    "    'theta+beta_pre_dig': 'theta_plus_beta_pre_dig',\n",
    "    'theta+beta_plv_pre_dig': 'theta_plus_beta_plv_pre_dig',\n",
    "    'theta+beta_pli_pre_dig': 'theta_plus_beta_pli_pre_dig',\n",
    "    'theta+beta_aon_power_pre_dig': 'theta_plus_beta_aon_power_pre_dig',\n",
    "    'theta+beta_vhp_power_pre_dig': 'theta_plus_beta_vhp_power_pre_dig'\n",
    "})\n",
    "\n",
    "# Dictionary to store results\n",
    "all_results = {}\n",
    "\n",
    "# Define bands with their proper names for column access\n",
    "bands_analysis = {\n",
    "    'beta': 'beta',\n",
    "    'gamma': 'gamma',\n",
    "    'theta': 'theta',\n",
    "    'theta+beta': 'theta_plus_beta',\n",
    "    'total': 'total'\n",
    "}\n",
    "\n",
    "# Run analysis for each band\n",
    "for band_name, band_prefix in bands_analysis.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANALYZING {band_name.upper()} BAND - LOG TRANSFORMED\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Build formula\n",
    "    formula = f\"\"\"log_time_to_dig ~ trial + {band_prefix}_pre_dig + {band_prefix}_plv_pre_dig + \n",
    "                  {band_prefix}_pli_pre_dig + {band_prefix}_aon_power_pre_dig + \n",
    "                  {band_prefix}_vhp_power_pre_dig\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Fit model with clustered standard errors\n",
    "        model = smf.ols(formula, data=context_data_clean)\n",
    "        result = model.fit(cov_type='cluster', \n",
    "                          cov_kwds={'groups': context_data_clean['rat']})\n",
    "        \n",
    "        # Store result\n",
    "        all_results[band_name] = result\n",
    "        \n",
    "        # Print summary\n",
    "        print(result.summary())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {band_name} band: {e}\")\n",
    "        all_results[band_name] = None\n",
    "\n",
    "# Create comprehensive summary table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPREHENSIVE SUMMARY: ALL FREQUENCY BANDS (LOG TRANSFORMED)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for band_name, result in all_results.items():\n",
    "    if result is not None:\n",
    "        # Get the column prefix\n",
    "        band_prefix = bands_analysis[band_name]\n",
    "        vhp_var = f'{band_prefix}_vhp_power_pre_dig'\n",
    "        \n",
    "        # Extract key statistics\n",
    "        summary_data.append({\n",
    "            'Band': band_name,\n",
    "            'Trial_Beta': result.params['trial'],\n",
    "            'Trial_P': result.pvalues['trial'],\n",
    "            'VHP_Beta': result.params[vhp_var],\n",
    "            'VHP_SE': result.bse[vhp_var],\n",
    "            'VHP_P': result.pvalues[vhp_var],\n",
    "            'VHP_CI_Lower': result.conf_int().loc[vhp_var, 0],\n",
    "            'VHP_CI_Upper': result.conf_int().loc[vhp_var, 1],\n",
    "            'R_squared': result.rsquared,\n",
    "            'Adj_R_squared': result.rsquared_adj,\n",
    "            'AIC': result.aic,\n",
    "            'BIC': result.bic\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Add significance flags and effect interpretation\n",
    "summary_df['VHP_Sig'] = summary_df['VHP_P'].apply(\n",
    "    lambda x: '***' if x < 0.001 else '**' if x < 0.01 else '*' if x < 0.05 else 'ns'\n",
    ")\n",
    "summary_df['Trial_Sig'] = summary_df['Trial_P'].apply(\n",
    "    lambda x: '***' if x < 0.001 else '**' if x < 0.01 else '*' if x < 0.05 else 'ns'\n",
    ")\n",
    "\n",
    "# Calculate percent change in original scale (multiplicative effect)\n",
    "summary_df['VHP_Percent_Change'] = (np.exp(summary_df['VHP_Beta']) - 1) * 100\n",
    "\n",
    "# Display summary\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Print significant findings\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SIGNIFICANT VHP POWER EFFECTS (p < 0.05):\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "sig_findings = summary_df[summary_df['VHP_P'] < 0.05].sort_values('VHP_P')\n",
    "if len(sig_findings) > 0:\n",
    "    for _, row in sig_findings.iterrows():\n",
    "        print(f\"{row['Band'].upper()} Band:\")\n",
    "        print(f\"  Beta coefficient: {row['VHP_Beta']:.4f} {row['VHP_Sig']}\")\n",
    "        print(f\"  Standard error: {row['VHP_SE']:.4f}\")\n",
    "        print(f\"  P-value: {row['VHP_P']:.6f}\")\n",
    "        print(f\"  95% CI: [{row['VHP_CI_Lower']:.4f}, {row['VHP_CI_Upper']:.4f}]\")\n",
    "        print(f\"  Effect: {row['VHP_Percent_Change']:.1f}% change in digging time\")\n",
    "        print(f\"  (Positive = slower, Negative = faster)\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No significant VHP power effects found.\")\n",
    "\n",
    "# Print trial effects\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRIAL EFFECTS (Learning):\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    sig_marker = row['Trial_Sig']\n",
    "    if sig_marker != 'ns':\n",
    "        print(f\"{row['Band'].upper()}: β = {row['Trial_Beta']:.4f} {sig_marker}, p = {row['Trial_P']:.4f}\")\n",
    "\n",
    "# Model comparison\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL FIT COMPARISON:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "best_model = summary_df.loc[summary_df['Adj_R_squared'].idxmax()]\n",
    "print(f\"Best fitting model: {best_model['Band'].upper()} band\")\n",
    "print(f\"Adjusted R²: {best_model['Adj_R_squared']:.4f}\")\n",
    "print(f\"AIC: {best_model['AIC']:.2f}\")\n",
    "\n",
    "print(\"\\nAll models ranked by Adjusted R²:\")\n",
    "print(summary_df[['Band', 'Adj_R_squared', 'AIC']].sort_values('Adj_R_squared', ascending=False).to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv('frequency_band_analysis_results.csv', index=False)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Results saved to 'frequency_band_analysis_results.csv'\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the short MNE Epochs to coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 0.7  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "for time_window in [0.7]:\n",
    "    behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "    print(behavior_coherence_compiled_data_df_truncated.head())\n",
    "    importlib.reload(coherence_functions)\n",
    "    bands_dict = {'beta': [12, 30], 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "    for col in ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig']:\n",
    "        print(col)\n",
    "        for band, (band_start, band_end) in bands_dict.items():\n",
    "            behavior_coherence_compiled_data_df_truncated[band + '_' + col] = behavior_coherence_compiled_data_df_truncated[col].apply(lambda x: coherence_functions.convert_epoch_to_coherence_behavior(x, band_start=band_start, band_end=band_end))\n",
    "    behavior_coherence_compiled_data_df_truncated.drop(columns=['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig'], inplace=True)\n",
    "    behavior_coherence_compiled_data_df_truncated.to_pickle(savepath+f'\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Coherence vs Time to Dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.7\n",
    "fs=2000\n",
    "from scipy.stats import linregress\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "#behavior_coherence_compiled_data_df_truncated['beta_pre_dig'] = behavior_coherence_compiled_data_df_truncated['beta_pre_dig'] - behavior_coherence_compiled_data_df_truncated['beta_pre_door']\n",
    "#behavior_coherence_compiled_data_df_truncated['theta_pre_dig'] = behavior_coherence_compiled_data_df_truncated['theta_pre_dig'] - behavior_coherence_compiled_data_df_truncated['theta_pre_door']\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3,2,figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig_hist, axs_hist = plt.subplots(3, 2, figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs_hist = axs_hist.flatten()\n",
    "\n",
    "grouped_df=behavior_coherence_compiled_data_df_truncated.groupby(['task'])\n",
    "band='theta'\n",
    "event='around_dig'\n",
    "task_dict = {'BWcontext': 'Context', 'BWnocontext': 'No Context'}\n",
    "\n",
    "events_dict ={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig', 'around_door':'Around Door', 'around_dig':'Around Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    ax = axs[i]\n",
    "    ax_hist = axs_hist[i]\n",
    "    print(np.where(behavior_coherence_compiled_data_df_truncated['{}_{}'.format(band,event)]==0))\n",
    "    for task, group in grouped_df:\n",
    "        print(task)\n",
    "        print('{}_{}'.format(band,event))\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)]))>0]\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group = group[(np.abs(group['time_to_dig'] - group['time_to_dig'].mean()) <= (3 * group['time_to_dig'].std()))] # Removing Outliers from Time\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)] - group['{}_{}'.format(band,event)].mean()) <= (3 * group['{}_{}'.format(band,event)].std()))]  #Removing Outliers from Coherence\n",
    "        \n",
    "        #Plotting Regression\n",
    "        sns.regplot(y='time_to_dig', x='{}_{}'.format(band,event), data=group, ax=ax, label=task[0])\n",
    "        y= group['time_to_dig'].values\n",
    "        x= group['{}_{}'.format(band,event)].values\n",
    "        slope, intercept, r, p, se = linregress(x, y)\n",
    "        print(f'{task[0]}: Slope: {slope}, Intercept: {intercept}, R-squared: {r**2}, P-value: {p}')\n",
    "        \n",
    "        ## Plotting Histogram\n",
    "        sns.histplot(group['{}_{}'.format(band,event)], bins=30, kde=True, ax=ax_hist, label=task[0], color=colors[task[0]], stat='density', alpha=0.5)\n",
    "        ax_hist.axvline(group['{}_{}'.format(band,event)].mean(), color=colors[task[0]], linestyle='--', label=f'{task[0]} Mean')\n",
    "        ax_hist.axvline(group['{}_{}'.format(band,event)].median(), color=colors[task[0]], linestyle=':', label=f'{task[0]} Median')\n",
    "    \n",
    "    #Setting Histogram axis labels and title and legend\n",
    "    ax_hist.set_title(f'{events_dict[event]} - {band} Coherence Histogram', fontsize=16)\n",
    "    ax_hist.set_xlabel('Beta Coherence (Z-transformed)', fontsize=14)            \n",
    "    handles, labels = ax_hist.get_legend_handles_labels()\n",
    "    ax_hist.legend()\n",
    "    #ax_hist.legend(handles, [task_dict[l] for l in labels], title='Task', loc='upper right', fontsize=12)    \n",
    "    \n",
    "    \n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    ax.set_xlabel('Beta Coherence (Z-transformed)', fontsize=14)\n",
    "    ax.set_ylabel('Time to Dig (s)', fontsize=14)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, [task_dict[l] for l in labels], title='Task', loc='upper right', fontsize=12)\n",
    "    #ax.legend(title='Task')\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle(f'{band} Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "#fig.savefig(savepath+f'{band}_coherence_vs_time_to_dig_{int(time_window*fs)}.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence vs Time to Dig per rat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.4\n",
    "fs=2000\n",
    "event_of_interest = 'post_dig'\n",
    "band_of_interest = 'gamma'\n",
    "\n",
    "event_band = f'{band_of_interest}_{event_of_interest}'\n",
    "\n",
    "from scipy.stats import linregress\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "task_experiments = behavior_coherence_compiled_data_df_truncated.groupby(['task','unique_id'])\n",
    "task_list= behavior_coherence_compiled_data_df_truncated['task'].unique()\n",
    "print(task_list)\n",
    "for task in task_list:\n",
    "    task_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == task]\n",
    "    unique_experiments = task_data['unique_id'].unique()\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(20, 20))\n",
    "    fig.suptitle(f'{task} - Coherence vs Time to Dig', fontsize=20, y=1.02)\n",
    "    dk1_i=0\n",
    "    dk3_i=0\n",
    "    dk5_i=0\n",
    "    dk6_i=0\n",
    "    for experiment in unique_experiments:\n",
    "        print(task, experiment)    \n",
    "        task_exp_data =  task_data[task_data['unique_id'] == experiment]\n",
    "        time_to_dig = task_exp_data['time_to_dig']\n",
    "        coherence_value = task_exp_data[event_band]\n",
    "        \n",
    "        rat_id = task_exp_data['rat'].values[0]\n",
    "        if rat_id == 'dk1':\n",
    "            ax = axs[0, dk1_i]\n",
    "            dk1_i += 1\n",
    "        elif rat_id == 'dk3':\n",
    "            ax = axs[1, dk3_i]\n",
    "            dk3_i += 1\n",
    "        elif rat_id == 'dk5':\n",
    "            ax = axs[2, dk5_i]\n",
    "            dk5_i += 1\n",
    "        elif rat_id == 'dk6':\n",
    "            ax = axs[3, dk6_i]\n",
    "            dk6_i += 1\n",
    "        else:\n",
    "            continue  # Skip if rat_id is not one of the specified rats\n",
    "        ax.scatter(time_to_dig, coherence_value, label=experiment)\n",
    "        \n",
    "        ## Plotting Regression\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(time_to_dig, coherence_value)\n",
    "        ax.plot(time_to_dig, intercept + slope * time_to_dig, color='red', label=f'Fit: y={slope:.2f}x+{intercept:.2f}\\nR²={r_value**2:.2f}, p={p_value:.4f}')\n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "                \n",
    "        \n",
    "        ax.set_title(f'Rat: {rat_id}', fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Coherence through trials as experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_of_interest = 'pre_dig' \n",
    "band_of_interest = 'beta'\n",
    "time_window = 0.4  # seconds\n",
    "fs = 2000  # Sampling frequency\n",
    "\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "power_per_trial_df = pd.read_excel(savepath+'power_per_trial_mt.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "band_event = band_of_interest+'_'+event_of_interest\n",
    "\n",
    "vmin = behavior_coherence_compiled_data_df_truncated[band_event].min()\n",
    "vmax = behavior_coherence_compiled_data_df_truncated[band_event].max()\n",
    "\n",
    "coherence_bwcontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWcontext']\n",
    "coherence_bwnocontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWnocontext']\n",
    "\n",
    "power_bwcontext_data = power_per_trial_df[power_per_trial_df['task'] == 'BWcontext']\n",
    "power_bwnocontext_data = power_per_trial_df[power_per_trial_df['task'] == 'BWnocontext']\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs = axs.flatten()\n",
    "#task_data_dict = {'BWcontext': coherence_bwcontext_data, 'BWnocontext': coherence_bwnocontext_data}\n",
    "# task_list =[ 'BWcontext', 'BWnocontext']\n",
    "# for axi,(task_name, task_data) in enumerate(task_data_dict.items()):\n",
    "#     print(f\"Task: {task_name}\")\n",
    "#     experiment_ids = task_data['unique_id'].unique()\n",
    "#     print(f\"Number of unique IDs for {task_name}: {len(experiment_ids)}\")\n",
    "#     task_data_dict = {}\n",
    "#     for experiment_idi in experiment_ids:\n",
    "#         experiment_data=task_data[task_data['unique_id'] == experiment_idi]\n",
    "#         rat_date = experiment_idi.split('_')[0] +'_'+experiment_idi.split('_')[1][-8:]\n",
    "#         task_data_dict[rat_date] = experiment_data[band_event].values\n",
    "#     task_data_dict['trials'] = np.arange(start=1,stop=21,step=1, dtype=int)  # Assuming 20 trials per unique ID\n",
    "#     task_data_df = pd.DataFrame.from_dict(task_data_dict, orient='index').T\n",
    "#     task_data_df = task_data_df.fillna(0)  # Fill NaN values with 0\n",
    "#     task_data_df = task_data_df.loc[:, (task_data_df != 0).any(axis=0)]\n",
    "#     ax = axs[axi]\n",
    "#     ax.set_title(f'{task_name} - {band_of_interest} {event_of_interest}', fontsize=16)\n",
    "#     ax.set_xlabel('Trials', fontsize=14)\n",
    "#     ax.set_ylabel(f'{band_of_interest} Coherence (Z-transformed)', fontsize=14)\n",
    "#     sns.heatmap(task_data_df.set_index('trials').T, cmap='Purples', ax=ax, cbar_kws={'label': f'{band_of_interest} Coherence (Z-transformed)'}, vmin=vmin, vmax=vmax)\n",
    "    # If you want to see the unique IDs themselves, uncomment the next line\n",
    "    # print(f\"Unique IDs: {unique_ids}\")\n",
    "aon_power_per_trial_df = power_per_trial_df[power_per_trial_df['channel'] == 'AON']\n",
    "vHp_power_per_trial_df = power_per_trial_df[power_per_trial_df['channel'] == 'vHp']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 10), sharex=True, constrained_layout=True)    \n",
    "task_list = ['BWcontext', 'BWnocontext']\n",
    "for axi, task_name in enumerate(task_list):\n",
    "    print(f\"Task: {task_name}\")\n",
    "    coherence_task_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == task_name]\n",
    "    aon_power_task_data = aon_power_per_trial_df[aon_power_per_trial_df['task'] == task_name]\n",
    "    vhp_power_task_data = vHp_power_per_trial_df[vHp_power_per_trial_df['task'] == task_name]    \n",
    "    coherence_task_dict = {}\n",
    "    aon_power_task_dict = {}\n",
    "    vhp_power_task_dict = {}\n",
    "    experiment_ids = coherence_task_data['unique_id'].unique()\n",
    "    for experiment_idi in experiment_ids:\n",
    "        \n",
    "        rat_idi = experiment_idi.split('_')[0]\n",
    "        date_idi = experiment_idi.split('_')[1][-8:]\n",
    "        rat_date = rat_idi + '_' + date_idi\n",
    "\n",
    "        coherence_experiment_data=coherence_task_data[coherence_task_data['unique_id'] == experiment_idi]\n",
    "        \n",
    "        ## Power Data\n",
    "        aon_power_experiment_data = aon_power_task_data[aon_power_task_data['unique_id'] == rat_idi+\"_\"+task_name+'_'+date_idi]\n",
    "        vhp_power_experiment_data = vhp_power_task_data[vhp_power_task_data['unique_id'] == rat_idi+\"_\"+task_name+'_'+date_idi]\n",
    "        \n",
    "        aon_power_per_trial_list=[]\n",
    "        vhp_power_per_trial_list=[]\n",
    "        for triali in range(0, 20):\n",
    "            if triali not in aon_power_experiment_data['trial'].values:\n",
    "                print(f\"Trial {triali} not found in AON power data for {experiment_idi}. Skipping...\")\n",
    "                aon_power_per_trial_list.append(0)\n",
    "            else:\n",
    "                aon_power_trial = aon_power_experiment_data[aon_power_experiment_data['trial'] == triali][f'{band_event}_mt'].values\n",
    "                aon_power_per_trial_list.append(aon_power_trial.mean())\n",
    "            \n",
    "            if triali not in vhp_power_experiment_data['trial'].values:\n",
    "                print(f\"Trial {triali} not found in vHp power data for {experiment_idi}. Skipping...\")\n",
    "                vhp_power_per_trial_list.append(0)\n",
    "            else:\n",
    "                vhp_power_trial = vhp_power_experiment_data[vhp_power_experiment_data['trial'] == triali][f'{band_event}_mt'].values\n",
    "                vhp_power_per_trial_list.append(vhp_power_trial.mean())\n",
    "        aon_power_per_trial_list = np.array(aon_power_per_trial_list)\n",
    "        vhp_power_per_trial_list = np.array(vhp_power_per_trial_list)\n",
    "        \n",
    "        coherence_task_dict[rat_date] = coherence_experiment_data[band_event].values\n",
    "        aon_power_task_dict[rat_date] = aon_power_per_trial_list\n",
    "        vhp_power_task_dict[rat_date] = vhp_power_per_trial_list\n",
    "        \n",
    "    def dict_to_df(task_data_dict):\n",
    "        # Exclude 'trials' key from min/max calculation\n",
    "        arrays = [v for k, v in task_data_dict.items() if k != 'trials']\n",
    "        vmin = np.min(np.concatenate(arrays))\n",
    "        vmax = np.max(np.concatenate(arrays))\n",
    "        task_data_dict['trials'] = np.arange(start=1,stop=21,step=1, dtype=int)\n",
    "        task_data_df = pd.DataFrame.from_dict(task_data_dict, orient='index').T\n",
    "        task_data_df = task_data_df.fillna(0)  # Fill NaN values with 0\n",
    "        #task_data_df = task_data_df.loc[:, (task_data_df != 0).any(axis=0)]\n",
    "        return task_data_df, vmin, vmax\n",
    "    task_data_dicts ={ 'Coherence' : coherence_task_dict,\n",
    "                        'AON Power': aon_power_task_dict,\n",
    "                        'vHp Power': vhp_power_task_dict}\n",
    "    for j, (task_data_name, task_data_dict) in enumerate(task_data_dicts.items()):\n",
    "        task_data_df,vmin,vmax = dict_to_df(task_data_dict)\n",
    "        print(f\"Task Data for {task_data_name}:\", vmin, vmax)\n",
    "        ax = axs[j, axi]\n",
    "        ax.set_title(f'{task_name} - {band_of_interest} {event_of_interest} - {task_data_name}', fontsize=16)\n",
    "        ax.set_xlabel('Trials', fontsize=14)\n",
    "        ax.set_ylabel(f'{task_data_name} (Z-transformed)', fontsize=14)\n",
    "        sns.heatmap(task_data_df.set_index('trials').T, cmap='Purples', ax=ax, cbar_kws={'label': f'{task_data_name} (Z-transformed)'}, vmin=vmin, vmax=vmax)\n",
    "        ax.set_xticklabels(task_data_df['trials'], rotation=45)\n",
    "fig.savefig(savepath+f'{band_of_interest}_coherence_power_vs_trials_{event_of_interest}.png', format='png', dpi=600, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Mann Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.4\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "\n",
    "event_of_interest = 'around_dig' \n",
    "band_of_interest = 'beta'\n",
    "\n",
    "band_event = band_of_interest+'_'+event_of_interest\n",
    "\n",
    "vmin = behavior_coherence_compiled_data_df_truncated[band_event].min()\n",
    "vmax = behavior_coherence_compiled_data_df_truncated[band_event].max()\n",
    "\n",
    "bwcontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWcontext']\n",
    "bwnocontext_data = behavior_coherence_compiled_data_df_truncated[behavior_coherence_compiled_data_df_truncated['task'] == 'BWnocontext']\n",
    "\n",
    "t,p = scipy.stats.mannwhitneyu(bwcontext_data[band_event], bwnocontext_data[band_event])\n",
    "print(f\"Mann - Whitney U test between BWcontext and BWNocontext for {band_event}: t={t}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Phase Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the short MNE Epochs to Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=0.7\n",
    "fs=2000\n",
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_coherence_single_epochs_mne_truncated_{int(time_window*fs)}.pkl')\n",
    "print(behavior_coherence_compiled_data_df_truncated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(coherence_functions)\n",
    "bands_dict = {'beta': [12, 30]}#, 'gamma': [30, 80],'theta':[4,12], 'total': [1, 100]}\n",
    "for col in ['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig']:\n",
    "    print(col)\n",
    "    for band, (band_start, band_end) in bands_dict.items():\n",
    "        behavior_coherence_compiled_data_df_truncated[band + '_' + col] = behavior_coherence_compiled_data_df_truncated[col].apply(lambda x: coherence_functions.convert_epoch_to_phase_behavior(x, band_start=band_start, band_end=band_end))\n",
    "behavior_coherence_compiled_data_df_truncated.drop(columns=['pre_door', 'post_door', 'pre_dig', 'post_dig', 'around_door','around_dig'], inplace=True)\n",
    "behavior_coherence_compiled_data_df_truncated.to_pickle(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_phase_compiled_data_df_truncated_{int(time_window*fs)}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_coherence_compiled_data_df_truncated=pd.read_pickle(savepath+f'behavior_phase_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3,2,figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "grouped_df=behavior_coherence_compiled_data_df_truncated.groupby(['task'])\n",
    "band='beta'\n",
    "event='around_dig'\n",
    "events_dict ={'pre_door':'Pre Door', 'post_door':'Post Door', 'pre_dig':'Pre Dig', 'post_dig':'Post Dig', 'around_door':'Around Door', 'around_dig':'Around Dig'}\n",
    "for i, event in enumerate(events_dict.keys()):\n",
    "    ax = axs[i]\n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    print(np.where(behavior_coherence_compiled_data_df_truncated['{}_{}'.format(band,event)]==0))\n",
    "    for task, group in grouped_df:\n",
    "        print(task)\n",
    "        print('{}_{}'.format(band,event))\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)]))>0]\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group['{}_{}'.format(band,event)] = group['{}_{}'.format(band,event)].apply(lambda x: np.arctanh(x))\n",
    "        print(group['{}_{}'.format(band,event)].mean())\n",
    "        group = group[(np.abs(group['time_to_dig'] - group['time_to_dig'].mean()) <= (3 * group['time_to_dig'].std()))]\n",
    "        group = group[(np.abs(group['{}_{}'.format(band,event)] - group['{}_{}'.format(band,event)].mean()) <= (3 * group['{}_{}'.format(band,event)].std()))]\n",
    "        sns.regplot(x='time_to_dig', y='{}_{}'.format(band,event), data=group, ax=ax, label=task)\n",
    "    ax.set_ylabel('Beta PLI', fontsize=14)\n",
    "    ax.set_xlabel('Time to Dig (s)', fontsize=14)\n",
    "    ax.legend(title='Task')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle(f'Beta pli vs Time to Dig', fontsize=20, y=1.02)\n",
    "#fig.savefig(savepath+'beta_coherence_vs_time_to_dig.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of beta values for each event, comparing BW Context and BW No Context\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 20), sharey=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "events = list(events_dict.keys())\n",
    "for i, event in enumerate(events):\n",
    "    ax = axs[i]\n",
    "    for task in ['BWcontext', 'BWnocontext']:\n",
    "        data = behavior_coherence_compiled_data_df_truncated[\n",
    "            behavior_coherence_compiled_data_df_truncated['task'] == task\n",
    "        ]['{}_{}'.format(band, event)].dropna()\n",
    "        ax.hist(data, bins=30, alpha=0.6, label=task, density=True)\n",
    "    ax.set_title(f'{events_dict[event]}', fontsize=16)\n",
    "    ax.set_xlabel('Beta Value', fontsize=14)\n",
    "    ax.set_ylabel('Density', fontsize=14)\n",
    "    ax.legend(title='Task')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "fig.suptitle('Histogram of Beta Values per Event', fontsize=20, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Behavior Coherence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=  0.4\n",
    "fs=2000\n",
    "\n",
    "loaded_df=pd.read_pickle(savepath+f'\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "print(loaded_df.head())\n",
    "coherence_band_event_df=loaded_df.loc[:,'beta_pre_door':]\n",
    "print(coherence_band_event_df.columns)\n",
    "group_melted=pd.melt(loaded_df, id_vars=['rat', 'task', 'date', 'trial','correct?', 'time_to_dig'], value_vars=coherence_band_event_df.columns, var_name='band_event', value_name='coherence')\n",
    "group_melted['band']=group_melted['band_event'].apply(lambda x: x.split('_')[0])\n",
    "group_melted['event']=group_melted['band_event'].apply(lambda x: x.split('_')[1:])\n",
    "group_melted['event']=group_melted['event'].apply(lambda x: x[0]+'_'+x[1])\n",
    "group_melted.drop(columns=['band_event'], inplace=True)\n",
    "group_melted['correct?']=group_melted['correct?'].apply(lambda x: 'Incorrect' if x=='0' else 'Correct')\n",
    "events_list=['pre_door','post_door','pre_dig','post_dig', 'around_door', 'around_dig']\n",
    "writer=pd.ExcelWriter(savepath+f'behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.xlsx')\n",
    "for event in events_list:\n",
    "    event_df=group_melted[group_melted['event']==event]\n",
    "    event_df.to_excel(writer, sheet_name=event)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "loaded_df=loaded_df.drop(columns=['around_door_truncated','around_dig_truncated'])\n",
    "writer=pd.ExcelWriter(savepath+f'beh_dig_coh_compiled_{int(time_window*fs/2)}ms.xlsx')\n",
    "loaded_df.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This plots the number of correct vs incorrect trials and the coherence. The idea is to check if the correct trials in general had a higher coherence than incorrect trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bwcontext_df=group_melted[group_melted['task']=='BWcontext']\n",
    "correct_counts = bwcontext_df[bwcontext_df['correct?'] == 'Correct'].shape[0]\n",
    "incorrect_counts = bwcontext_df[bwcontext_df['correct?'] == 'Incorrect'].shape[0]\n",
    "print(f\"Number of Corrects: {correct_counts}\", f\"Number of Incorrects: {incorrect_counts}\", 'bwcontext')\n",
    "bwnocontext_df=group_melted[group_melted['task']=='BWnocontext']\n",
    "correct_counts = bwnocontext_df[bwnocontext_df['correct?'] == 'Correct'].shape[0]\n",
    "incorrect_counts = bwnocontext_df[bwnocontext_df['correct?'] == 'Incorrect'].shape[0]\n",
    "print(f\"Number of Corrects: {correct_counts}\", f\"Number of Incorrects: {incorrect_counts}\", 'bwnocontext')\n",
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, event in enumerate(events_list):\n",
    "    ax=axs[i]\n",
    "    sns.boxplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwcontext_df[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "    sns.stripplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwcontext_df[group_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax, size=1, legend=False)\n",
    "    ax.set_title(event)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.legend(title='Correct?')\n",
    "fig.suptitle(f'BW Context Coherence and Correctness')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_BWcontext.png')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 10), sharex=True, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "for i, event in enumerate(events_list):\n",
    "    ax=axs[i]\n",
    "    sns.boxplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwnocontext_df[group_melted['event']==event], showfliers=False, ax=ax)\n",
    "    sns.stripplot(x='band', y='coherence', hue='correct?',hue_order=['Correct', 'Incorrect'], data=bwnocontext_df[group_melted['event']==event], dodge=True, edgecolor='black', linewidth=1, jitter=True, ax=ax, size=1, legend=False)\n",
    "    ax.set_title(event)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Coherence')\n",
    "    ax.legend(title='Correct?')\n",
    "fig.suptitle(f'BW No Context Coherence and Correctness')\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_BWnocontext.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=['BWcontext','BWnocontext']\n",
    "loaded_df['correct?']=loaded_df['correct?'].apply(lambda x: 'Correct' if x=='1' else 'Incorrect')\n",
    "correctness=['Correct','Incorrect']\n",
    "fig, axs=plt.subplots(2,2, figsize=(20,10))\n",
    "axs=axs.flatten()\n",
    "axi=0\n",
    "for task in tasks:\n",
    "    for dig_type in correctness:\n",
    "\n",
    "        ax=axs[axi]\n",
    "        task_df=loaded_df[(loaded_df['task']==task) & (loaded_df['correct?']==dig_type)]\n",
    "        events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "        bands=['total','beta','theta','gamma']\n",
    "        \n",
    "        correlation_matrix = np.zeros((len(events_list), len(bands)))\n",
    "\n",
    "        for i, event in enumerate(events_list):\n",
    "            for j, band in enumerate(bands):\n",
    "                column_name = f'{band}_{event}'\n",
    "                correlation_matrix[i, j] = task_df['time_to_dig'].corr(task_df[column_name])\n",
    "        \n",
    "        cax = ax.matshow(correlation_matrix, cmap='coolwarm')\n",
    "        fig.colorbar(cax, ax=ax)\n",
    "\n",
    "        ax.set_xticks(np.arange(len(bands)))\n",
    "        ax.set_yticks(np.arange(len(events_list)))\n",
    "        ax.set_xticklabels(bands)\n",
    "        ax.set_yticklabels(events_list)\n",
    "        ax.set_title(f'{task} {dig_type}')\n",
    "        axi=axi+1\n",
    "fig.tight_layout()\n",
    "# plt.show()\n",
    "# plt.xlabel('Bands')\n",
    "# plt.ylabel('Events')\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()        \n",
    "# bwcontext_df=loaded_df[(loaded_df['task']=='BWcontext') & (loaded_df['correct?']=='0')]\n",
    "# events_list=['pre_door','post_door','pre_dig','post_dig']\n",
    "# bands=['total','beta','theta','gamma']\n",
    "\n",
    "# correlation_matrix = np.zeros((len(events_list), len(bands)))\n",
    "\n",
    "# for i, event in enumerate(events_list):\n",
    "#     for j, band in enumerate(bands):\n",
    "#         column_name = f'{band}_{event}'\n",
    "#         correlation_matrix[i, j] = bwcontext_df['time_to_dig'].corr(bwcontext_df[column_name])\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# cax = ax.matshow(correlation_matrix, cmap='coolwarm')\n",
    "# fig.colorbar(cax)\n",
    "\n",
    "# ax.set_xticks(np.arange(len(bands)))\n",
    "# ax.set_yticks(np.arange(len(events_list)))\n",
    "# ax.set_xticklabels(bands)\n",
    "# ax.set_yticklabels(events_list)\n",
    "\n",
    "# plt.xlabel('Bands')\n",
    "# plt.ylabel('Events')\n",
    "# plt.title('Correlation Matrix Heatmap')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "loaded_df=pd.read_pickle(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\behavior_coherence_compiled_data_df_truncated_{int(time_window*fs)}.pkl')\n",
    "print(loaded_df.head())\n",
    "loaded_df=loaded_df[loaded_df['rat']!='dk3']\n",
    "print(loaded_df.head())\n",
    "\n",
    "fig, ax=plt.subplots(1,1, figsize=(10,10))\n",
    "tasks=['BWcontext','BWnocontext']\n",
    "loaded_df['correct?']=loaded_df['correct?'].apply(lambda x: 'Correct' if x=='1' else 'Incorrect')\n",
    "correctness=['Correct','Incorrect']\n",
    "bwcontext_incorrect_df=loaded_df[(loaded_df['task']=='BWcontext')]\n",
    "bwnocontext_incorrect_df=loaded_df[(loaded_df['task']=='BWnocontext')]\n",
    "x=bwcontext_incorrect_df['time_to_dig']\n",
    "y=bwcontext_incorrect_df['beta_pre_dig']\n",
    "df = pd.DataFrame({'coherence': y, 'time': x})\n",
    "df.drop(df[df['coherence'] == 0].index, inplace=True)  # Remove rows with coherence = 0\n",
    "\n",
    "try:\n",
    "    correlation_coefficient, p_value = pearsonr(df['coherence'], df['time'])\n",
    "\n",
    "    print(f\"Pearson Correlation Coefficient (r): {correlation_coefficient:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    correlation_coefficient_s, p_value_s = spearmanr(df['coherence'], df['time'])\n",
    "\n",
    "    print(f\"\\nSpearman Rank Correlation Coefficient (rs): {correlation_coefficient_s:.4f}\")\n",
    "    print(f\"P-value: {p_value_s:.4f}\")\n",
    "\n",
    "    # --- Interpretation ---\n",
    "    alpha = 0.05 # Set your significance level\n",
    "    print(f\"\\nSignificance Level (alpha): {alpha}\")\n",
    "\n",
    "    if p_value <= alpha:\n",
    "        print(\"Result: Reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is a statistically significant linear relationship between the variables.\")\n",
    "    else:\n",
    "        print(\"Result: Fail to reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is NOT enough evidence for a statistically significant linear relationship.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure 'coherence_data' and 'time_data' are populated correctly with numerical lists or arrays of the same length.\")\n",
    "# --- Create a Pandas DataFrame ---\n",
    "\n",
    "print(f\"Original number of data points: {len(df)}\")\n",
    "\n",
    "# --- Calculate IQR Fences for BOTH variables ---\n",
    "Q1_coherence = df['coherence'].quantile(0.25)\n",
    "Q3_coherence = df['coherence'].quantile(0.75)\n",
    "IQR_coherence = Q3_coherence - Q1_coherence\n",
    "lower_fence_coherence = Q1_coherence - 1.5 * IQR_coherence\n",
    "upper_fence_coherence = Q3_coherence + 1.5 * IQR_coherence\n",
    "\n",
    "Q1_time = df['time'].quantile(0.25)\n",
    "Q3_time = df['time'].quantile(0.75)\n",
    "IQR_time = Q3_time - Q1_time\n",
    "lower_fence_time = Q1_time - 1.5 * IQR_time\n",
    "upper_fence_time = Q3_time + 1.5 * IQR_time\n",
    "\n",
    "\n",
    "print(\"\\n--- Outlier Fences ---\")\n",
    "print(f\"Coherence: Lower={lower_fence_coherence:.2f}, Upper={upper_fence_coherence:.2f}\")\n",
    "print(f\"Time:      Lower={lower_fence_time:.2f}, Upper={upper_fence_time:.2f}\")\n",
    "\n",
    "# --- Identify outliers (points outside fences for EITHER variable) ---\n",
    "outlier_condition = (\n",
    "    (df['coherence'] < lower_fence_coherence) | (df['coherence'] > upper_fence_coherence) |\n",
    "    (df['time'] < lower_fence_time) | (df['time'] > upper_fence_time)\n",
    ")\n",
    "\n",
    "outliers = df[outlier_condition]\n",
    "print(f\"\\nIdentified {len(outliers)} potential outliers:\")\n",
    "print(outliers)\n",
    "# --- Filter out the outliers ---\n",
    "df_filtered = df[~outlier_condition] # Use ~ to negate the condition, keeping non-outliers\n",
    "print(f\"\\nNumber of data points after removing outliers: {len(df_filtered)}\")\n",
    "\n",
    "\n",
    "# --- Recalculate Correlation on Filtered Data ---\n",
    "if len(df_filtered) > 1: # Need at least 2 points to calculate correlation\n",
    "    # Extract the filtered data columns\n",
    "    coherence_filtered = df_filtered['coherence']\n",
    "    time_filtered = df_filtered['time']\n",
    "\n",
    "    # Calculate original correlation (optional comparison)\n",
    "    try:\n",
    "      original_r, original_p = pearsonr(df['coherence'], df['time'])\n",
    "      print(f\"\\nOriginal Correlation (r): {original_r:.4f}, p-value: {original_p:.4f}\")\n",
    "    except Exception as e:\n",
    "      print(f\"\\nCould not calculate original correlation: {e}\")\n",
    "\n",
    "\n",
    "    # Calculate filtered correlation\n",
    "    try:\n",
    "      filtered_r, filtered_p = pearsonr(coherence_filtered, time_filtered)\n",
    "      print(f\"Filtered Correlation (r): {filtered_r:.4f}, p-value: {filtered_p:.4f}\")\n",
    "\n",
    "      # Interpretation (using alpha = 0.05)\n",
    "      alpha = 0.05\n",
    "      if filtered_p <= alpha:\n",
    "          print(\"Result (Filtered): Reject H0. Statistically significant linear relationship found.\")\n",
    "      else:\n",
    "          print(\"Result (Filtered): Fail to reject H0. No statistically significant linear relationship found.\")\n",
    "    except Exception as e:\n",
    "      print(f\"Could not calculate filtered correlation: {e}\")\n",
    "\n",
    "sns.regplot(y=df['coherence'], x=df['time'], label='Context', ax=ax)\n",
    "sns.regplot(x=bwnocontext_incorrect_df['time_to_dig'], y=bwnocontext_incorrect_df['beta_pre_dig'], label='No context', ax=ax)\n",
    "plt.xlabel('Time to Dig (s)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Coherence', fontsize=20)\n",
    "plt.title('AON-VHP Beta Pre Dig Coherence vs Time to Dig', fontsize=20)\n",
    "plt.legend(fontsize=20) \n",
    "plt.tight_layout()\n",
    "#fig.savefig(f'C:\\\\Users\\\\{user}\\\\Dropbox\\\\CPLab\\\\results\\\\beta_pre_dig_vs_time_to_dig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# bwcontext_correct_df=loaded_df[(loaded_df['task']=='BWcontext') & (loaded_df['correct?']=='Correct')]\n",
    "# bwnocontext_correct_df=loaded_df[(loaded_df['task']=='BWnocontext') & (loaded_df['correct?']=='Correct')]\n",
    "# sns.regplot(x=bwcontext_correct_df['time_to_dig'], y=bwcontext_correct_df['gamma_pre_dig'], label='BWcontext',robust=True, order=2)\n",
    "# sns.regplot(x=bwnocontext_correct_df['time_to_dig'], y=bwnocontext_correct_df['gamma_pre_dig'], label='BWnocontext',robust=True, order=2)\n",
    "# plt.xlabel('Time to Dig')\n",
    "# plt.ylabel('Beta Pre Dig')\n",
    "# plt.title('Beta Pre Dig vs Time to Dig for Correct Trials')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# --- Plot SVM regression for BWcontext and BWnocontext separately ---\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Prepare data for each task\n",
    "for task_name, color in colors.items():\n",
    "  task_df = loaded_df[(loaded_df['task'] == task_name) & (~outlier_condition)]\n",
    "  if task_df.empty:\n",
    "    print(f\"Skipping {task_name}: no data after outlier removal.\")\n",
    "    continue\n",
    "  X_task = task_df['time_to_dig'].values.reshape(-1, 1)\n",
    "  y_task = task_df['beta_pre_dig'].values\n",
    "\n",
    "  # Fit SVM regression\n",
    "  svm_poly_task = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "  )\n",
    "  svm_poly_task.fit(X_task, y_task)\n",
    "  x_range_task = np.linspace(X_task.min(), X_task.max(), 200).reshape(-1, 1)\n",
    "  y_pred_task = svm_poly_task.predict(x_range_task)\n",
    "\n",
    "  # Scatter and SVM fit\n",
    "  ax2.scatter(X_task, y_task, color=color, alpha=0.5, label=f'{task_name} data')\n",
    "  ax2.plot(x_range_task, y_pred_task, color=color, linestyle='-', linewidth=2, label=f'{task_name} SVM fit')\n",
    "\n",
    "ax2.set_xlabel('Time to Dig (s)', fontsize=20)\n",
    "ax2.set_ylabel('Coherence', fontsize=20)\n",
    "ax2.set_title('SVM Poly Fit: BWcontext vs BWnocontext', fontsize=20)\n",
    "ax2.legend(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Get residuals for each group\n",
    "residuals = {}\n",
    "for task_name in colors.keys():\n",
    "  task_df = loaded_df[(loaded_df['task'] == task_name) & (~outlier_condition)]\n",
    "  if task_df.empty:\n",
    "    print(f\"Skipping {task_name} residuals: no data after outlier removal.\")\n",
    "    continue\n",
    "  X_task = task_df['time_to_dig'].values.reshape(-1, 1)\n",
    "  y_task = task_df['beta_pre_dig'].values\n",
    "  svm_poly_task = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "  )\n",
    "  svm_poly_task.fit(X_task, y_task)\n",
    "  y_pred_task = svm_poly_task.predict(X_task)\n",
    "  residuals[task_name] = y_task - y_pred_task\n",
    "\n",
    "# t-test on residuals (only if both groups have data)\n",
    "if all(k in residuals and len(residuals[k]) > 0 for k in ['BWcontext', 'BWnocontext']):\n",
    "  t_stat, p_val = ttest_ind(residuals['BWcontext'], residuals['BWnocontext'], equal_var=False)\n",
    "  print(f\"Residuals t-test: t={t_stat:.4f}, p={p_val:.4g}\")\n",
    "  if p_val < 0.05:\n",
    "    print(\"Statistically significant difference in SVM fit residuals between BWcontext and BWnocontext.\")\n",
    "  else:\n",
    "    print(\"No statistically significant difference in SVM fit residuals between BWcontext and BWnocontext.\")\n",
    "else:\n",
    "  print(\"Not enough data for both groups to perform residuals t-test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print(f\"Number of data points: {len(df)}\")\n",
    "coherence_data = df['coherence']\n",
    "time_data = df['time']\n",
    "# --- Perform the Spearman Rank Correlation Test ---\n",
    "try:\n",
    "    correlation_coefficient_s, p_value_s = spearmanr(coherence_data, time_data)\n",
    "\n",
    "    print(f\"\\nSpearman Rank Correlation Coefficient (rs): {correlation_coefficient_s:.4f}\")\n",
    "    print(f\"P-value: {p_value_s:.4f}\")\n",
    "\n",
    "    # --- Interpretation ---\n",
    "    alpha = 0.05 # Set your significance level\n",
    "    print(f\"\\nSignificance Level (alpha): {alpha}\")\n",
    "\n",
    "    if p_value_s <= alpha:\n",
    "        print(\"Result: Reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is a statistically significant monotonic relationship between the variables.\")\n",
    "    else:\n",
    "        print(\"Result: Fail to reject the null hypothesis (H0).\")\n",
    "        print(\"Conclusion: There is NOT enough evidence for a statistically significant monotonic relationship.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure 'coherence_data' and 'time_data' are populated correctly with numerical lists or arrays of the same length.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
